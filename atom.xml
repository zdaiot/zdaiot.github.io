<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zdaiot</title>
  
  <subtitle>404NotFound</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.zdaiot.com/"/>
  <updated>2023-03-28T09:52:27.000Z</updated>
  <id>https://www.zdaiot.com/</id>
  
  <author>
    <name>zdaiot</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>git原理简介</title>
    <link href="https://www.zdaiot.com/Tools/Git/git%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/"/>
    <id>https://www.zdaiot.com/Tools/Git/git原理简介/</id>
    <published>2023-03-28T09:52:27.000Z</published>
    <updated>2023-03-28T09:52:27.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="与-的区别"><a href="#与-的区别" class="headerlink" title="~与^的区别"></a>~与^的区别</h2><p>波浪号<code>~</code>，英文名叫 <strong>tilde</strong>。脱字符<code>^</code>，英文名叫<strong>caret</strong>。那么关于这两个该怎么区分呢？</p><p>在<a href="https://stackoverflow.com/a/12527561/15304315" target="_blank" rel="noopener">What’s the difference between HEAD^ and HEAD~ in Git?</a>中介绍如下：</p><p><strong>Rules of thumb</strong></p><ul><li>Use <code>~</code> most of the time — to go back a number of generations, usually what you want</li><li>Use <code>^</code> on merge commits — because they have two or more (immediate) parents</li></ul><p><strong>Mnemonics:</strong></p><ul><li>Tilde <code>~</code> is almost linear in appearance and wants to go backward in a straight line</li><li>Caret <code>^</code> suggests an interesting segment of a tree or a fork in the road</li></ul><p>该如何理解呢？看如下例子。在该例子中，A、B、D、G位于同一个branch，D由G与H merge合并而来，所以<code>G=D^1</code>，G是D第一个parent；<code>H=D^2</code>，H是D的第二个parent。</p><p>B是A的当前分支所在时间线中的父节点，所以<code>B=A~1</code>；D是A在当前分支所在时间线中的父节点的父节点，所以<code>D=A~2</code>。</p><p><img src="/Tools/Git/git原理简介/pDAzG.png" alt="enter image description here" style="zoom:67%;"></p><p>关于更详细的例子可以参考<a href="https://git-scm.com/docs/git-rev-parse#Documentation/git-rev-parse.txt-emltrevgtltngtemegemHEADv1510em：" target="_blank" rel="noopener">https://git-scm.com/docs/git-rev-parse#Documentation/git-rev-parse.txt-emltrevgtltngtemegemHEADv1510em：</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">G   H   I   J</span><br><span class="line"> \ /     \ /</span><br><span class="line">  D   E   F</span><br><span class="line">   \  |  / \</span><br><span class="line">    \ | /   |</span><br><span class="line">     \|/    |</span><br><span class="line">      B     C</span><br><span class="line">       \   /</span><br><span class="line">        \ /</span><br><span class="line">         A</span><br><span class="line"></span><br><span class="line">A =      = A^0</span><br><span class="line">B = A^   = A^1     = A~1</span><br><span class="line">C =      = A^2</span><br><span class="line">D = A^^  = A^1^1   = A~2</span><br><span class="line">E = B^2  = A^^2</span><br><span class="line">F = B^3  = A^^3</span><br><span class="line">G = A^^^ = A^1^1^1 = A~3</span><br><span class="line">H = D^2  = B^^2    = A^^^2  = A~2^2</span><br><span class="line">I = F^   = B^3^    = A^^3^</span><br><span class="line">J = F^2  = B^3^2   = A^^3^2</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://stackoverflow.com/a/12527561/15304315" target="_blank" rel="noopener">What’s the difference between HEAD^ and HEAD~ in Git?</a><br><a href="https://stackoverflow.com/a/29120883/15304315" target="_blank" rel="noopener">What’s the difference between HEAD^ and HEAD~ in Git?</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;与-的区别&quot;&gt;&lt;a href=&quot;#与-的区别&quot; class=&quot;headerlink&quot; title=&quot;~与^的区别&quot;&gt;&lt;/a&gt;~与^的区别&lt;/h2&gt;&lt;p&gt;波浪号&lt;code&gt;~&lt;/code&gt;，英文名叫 &lt;strong&gt;tilde&lt;/strong&gt;。脱字符&lt;code&gt;^&lt;/code&gt;，英文名叫&lt;strong&gt;caret&lt;/strong&gt;。那么关于这两个该怎么区分呢？&lt;/p&gt;
&lt;p&gt;在&lt;a href=&quot;https://stackoverflow.com/a/12527561/15304315&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;What’s the difference between HEAD^ and HEAD~ in Git?&lt;/a&gt;中介绍如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rules of thumb&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use &lt;code&gt;~&lt;/code&gt; most of the time — to go back a number of generations, usually what you want&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;^&lt;/code&gt; on merge commits — because they have two or more (immediate) parents&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Tools" scheme="https://www.zdaiot.com/categories/Tools/"/>
    
      <category term="Git" scheme="https://www.zdaiot.com/categories/Tools/Git/"/>
    
    
      <category term="github" scheme="https://www.zdaiot.com/tags/github/"/>
    
      <category term="git" scheme="https://www.zdaiot.com/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>bash属性、startup文件与history</title>
    <link href="https://www.zdaiot.com/Linux/%E7%BB%B4%E6%8A%A4/bash%E5%B1%9E%E6%80%A7%E3%80%81startup%E6%96%87%E4%BB%B6%E4%B8%8Ehistory/"/>
    <id>https://www.zdaiot.com/Linux/维护/bash属性、startup文件与history/</id>
    <published>2023-03-14T07:14:18.000Z</published>
    <updated>2023-03-14T07:14:18.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="bash与shell区别"><a href="#bash与shell区别" class="headerlink" title="bash与shell区别"></a>bash与shell区别</h2><p>shell有多个含义：</p><ul><li>Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。</li><li>Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。</li></ul><p>bash（GNU Bourne-Again Shell）是最常用的一种shell，是当前大多数Linux发行版的默认Shell。除了bash外，其它的shell还有zsh、sh等。</p><blockquote><p>sh的全名是Bourne Shell。名字中的玻恩就是这个Shell的作者。而bash的全名是Bourne Again Shell。最开始在Unix系统中流行的是sh，而bash作为sh的改进版本，提供了更加丰富的功能。一般来说，都推荐使用bash作为默认的Shell。</p></blockquote><p><strong>如何查看当前系统中默认shell？</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="variable">$SHELL</span></span><br></pre></td></tr></table></figure><p>当前正在使用的 Shell 不一定是默认 Shell，一般来说，<code>ps</code>命令结果的倒数第二行是当前 Shell。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ps</span><br><span class="line">  PID TTY          TIME CMD</span><br><span class="line"> 4467 pts/0    00:00:00 bash</span><br><span class="line"> 5379 pts/0    00:00:00 ps</span><br></pre></td></tr></table></figure><p>Shell相当于是一个翻译，把我们在计算机上的操作或我们的命令，翻译为计算机可识别的二进制命令，传递给内核，以便调用计算机硬件执行相关的操作；同时，计算机执行完命令后，再通过Shell翻译成自然语言，呈现在我们面前。</p><p><img src="/Linux/维护/bash属性、startup文件与history/v2-6af56fdefc44ea333fa6f1409b4a72dc_b.jpg" alt="img" style="zoom:50%;"></p><h2 id="bash运行方式"><a href="#bash运行方式" class="headerlink" title="bash运行方式"></a>bash运行方式</h2><h3 id="含义"><a href="#含义" class="headerlink" title="含义"></a>含义</h3><p>Linux shell是用户与Linux系统进行交互的媒介，而bash作为目前Linux系统中最常用的shell，它在运行时具有两种属性，即“<strong>交互</strong>”与“<strong>登陆</strong>”。</p><ul><li>交互式，是shell的一种运行模式，交互式shell等待你输入命令，并且立即执行，然后将结果反馈给你。这是每个CLI用户都非常熟悉的流程：登录、执行一些命令、登出。当你登出后，这个shell就终止了。</li><li>而非交互式，是shell的另一种运行模式，它专门被用来执行预先设定的命令。在这种模式下，shell不与用户进行交互，而是读取存放在脚本文件中的命令并执行它们。当它读到文件的结尾，这个shell就终止了。</li></ul><p>那么我们启动的时候，如何才能进行进行交互或登陆呢？</p><p>根据bash手册上的描述：</p><blockquote><p>An interactive shell is one started without non-option arguments and without the -c option whose standard input and error are both connected to terminals (as determined by isatty(3)), or one started with the -i option.</p></blockquote><p>从上面的描述看，只要执行bash命令的时候，不带有“选项以外的参数”或者-c选项，就会启动一个交互式shell。</p><ul><li>“选项以外的参数”指的就是shell的脚本文件；</li><li>-c选项将指定字符串作为命令读入bash，也就相当于执行指定的命令，它和前者有些类似，只是不从脚本文件中读取罢了。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[chen@localhost Temp]$ <span class="built_in">echo</span> <span class="string">"uname -r; date"</span> &gt; script.sh</span><br><span class="line">[chen@localhost Temp]$ bash ./script.sh <span class="comment"># 非交互式</span></span><br><span class="line">3.10.0-514.el7.x86_64</span><br><span class="line">Tue Apr 18 14:43:50 CST 2017</span><br><span class="line">[chen@localhost Temp]$ </span><br><span class="line">[chen@localhost Temp]$ bash -c <span class="string">"uname -r; date"</span>  <span class="comment"># 非交互式</span></span><br><span class="line">3.10.0-514.el7.x86_64</span><br><span class="line">Tue Apr 18 14:44:49 CST 2017</span><br><span class="line">[chen@localhost Temp]$</span><br></pre></td></tr></table></figure><p>另外，从上面描述来看，通常来说，用于执行脚本的shell都是“非交互式”的，但我们也有办法把它启动为“交互式”shell，方法就是在执行bash命令时，添加<code>-i</code>选项：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[chen@localhost Temp]$ bash -c <span class="string">"echo \$-"</span></span><br><span class="line">hBc</span><br><span class="line"><span class="comment"># 我们看到，添加了-i选项的bash -c命令为我们启动了一个“交互式”shell。</span></span><br><span class="line">[chen@localhost Temp]$ bash -i -c <span class="string">"echo \$-"</span>  <span class="comment"># 交互式</span></span><br><span class="line">himBHc</span><br></pre></td></tr></table></figure><blockquote><p>这里解释一下<code>echo \$-</code>：It shows your Builtin Set Flags. <code>man bash</code> then look for SHELL BUILTIN COMMANDS and then look for the <code>set subsection</code>. You will find the meanings of all those flags:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; h: Remember the location of commands as they are looked up for execution.  This is enabled by default.</span><br><span class="line">&gt; i: interactive</span><br><span class="line">&gt; m: Monitor mode.  Job control is enabled</span><br><span class="line">&gt; B: The shell performs brace expansion (see Brace Expansion above).  This is on by default</span><br><span class="line">&gt; H: Enable !  style history substitution.  This option is on by default when the shell is interactive.</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><h3 id="判断"><a href="#判断" class="headerlink" title="判断"></a>判断</h3><p>那么我们如何在shell脚本或者startup文件中判断当前shell的运行方式呢？</p><p>我们首先来看，bash手册的描述：</p><blockquote><p><code>PS1</code> is set and <code>$-</code> includes <code>i</code> if bash is interactive, allowing a shell script or a startup file to test this state.</p></blockquote><p>也就是说，可以判断变量<code>PS1</code>是否有值，或者判断变量<code>$-</code>是否包含<code>i</code>，实现在shell脚本或者startup文件中判断当前shell的运行方式。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在shell脚本中写入如下语句，通过输出判断当前shell运行方式</span></span><br><span class="line">[chen@localhost Temp]$ cat ./test1.sh </span><br><span class="line"><span class="built_in">echo</span> <span class="string">"\$0   : <span class="variable">$0</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"\$-   : $-"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"\$PS1 : <span class="variable">$PS1</span>"</span></span><br><span class="line">[chen@localhost Temp]$ bash ./test1.sh     <span class="comment"># 非交互式shell</span></span><br><span class="line"><span class="variable">$0</span>   : ./test1.sh</span><br><span class="line">$-   : hB</span><br><span class="line"><span class="variable">$PS1</span> : </span><br><span class="line">[chen@localhost Temp]$ bash -i ./test1.sh  <span class="comment"># 交互式shell</span></span><br><span class="line"><span class="variable">$0</span>   : ./test1.sh</span><br><span class="line">$-   : himB</span><br><span class="line"><span class="variable">$PS1</span> : [\u@\h \W]\$</span><br></pre></td></tr></table></figure><h2 id="登陆shell与非登陆shell"><a href="#登陆shell与非登陆shell" class="headerlink" title="登陆shell与非登陆shell"></a>登陆shell与非登陆shell</h2><h3 id="含义-1"><a href="#含义-1" class="headerlink" title="含义"></a>含义</h3><p>“登陆shell”通常指的是：</p><ol><li>用户通过输入用户名/密码（或证书认证）后启动的shell；</li><li>通过带有<code>-l|--login</code>参数的<code>bash</code>命令启动的shell。例如，系统启动、远程登录、使用<code>su -</code>切换用户、通过<code>bash --login</code>命令启动bash等。</li></ol><p>而其他情况启动的shell基本上就都是“非登陆shell”了。例如，从图形界面启动终端、使用<code>su</code>切换用户、通过<code>bash</code>命令启动bash等。</p><h3 id="判断-1"><a href="#判断-1" class="headerlink" title="判断"></a>判断</h3><p>根据bash手册上的描述：</p><blockquote><p>A login shell is one whose first character of argument zero is a <code>-</code>, or one started with the <code>--login</code> option.</p></blockquote><p>我们可以通过在shell中<code>echo $0</code>查看，显示<code>-bash</code>的一定是“登陆shell”，反之显示<code>bash</code>的则不好说。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[chen@localhost ~]$ bash --login</span><br><span class="line">[chen@localhost ~]$ <span class="built_in">echo</span> <span class="variable">$0</span></span><br><span class="line">bash</span><br></pre></td></tr></table></figure><p>可以看出，使用<code>bash --login</code>启动的“登陆shell”，其<code>$0</code>也并非以<code>-</code>开头，这也就是为什么手册上的描述里使用“or”的原因。</p><p>另外，当我们执行<code>exit</code>命令退出shell时，也可以观察到它们的不同之处：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[chen@localhost ~]$ bash --login</span><br><span class="line">[chen@localhost ~]$ <span class="built_in">exit</span>   <span class="comment"># 退出登陆shell</span></span><br><span class="line"><span class="built_in">logout</span></span><br><span class="line">[chen@localhost ~]$ bash</span><br><span class="line">[chen@localhost ~]$ <span class="built_in">exit</span>   <span class="comment"># 退出非登陆shell</span></span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure><p>原则上讲，我们使用<code>logout</code>退出“登陆shell”，使用<code>exit</code>退出“非登录shell”。但其实<code>exit</code>命令会判断当前shell的“登陆”属性，并分别调用<code>logout</code>或<code>exit</code>指令，因此使用起来相对方便。</p><h3 id="主要区别"><a href="#主要区别" class="headerlink" title="主要区别"></a>主要区别</h3><p>对于用户而言，“登录shell”和“非登陆shell”的主要区别在于<strong>启动shell时所执行的startup文件不同</strong>。</p><p>简单来说，“登录shell”执行的startup文件为<code>~/.bash_profile</code>，而“非登陆shell”执行的startup文件为<code>~/.bashrc</code>。</p><p>下面我们进行详细说明。</p><h2 id="bash的startup文件"><a href="#bash的startup文件" class="headerlink" title="bash的startup文件"></a>bash的startup文件</h2><p>它支持的startup文件也并不单一，甚至容易让人感到费解。接下来以<strong>CentOS7</strong>系统为例，对bash的startup文件进行一些必要的梳理和总结。</p><p>根据bash手册的描述：</p><blockquote><ul><li><p>/etc/profile<br>The systemwide initialization file, executed for login shells</p></li><li><p>/etc/bash.bash_logout<br>The systemwide login shell cleanup file, executed when a login shell exits</p></li><li><p>~/.bash_profile<br>The personal initialization file, executed for login shells</p></li><li><p>~/.bashrc<br>The individual per-interactive-shell startup file</p></li><li><p>~/.bash_logout<br>The individual login shell cleanup file, executed when a login shell exits</p></li></ul></blockquote><p>此外，bash还支持<code>~/.bash_login</code>和<code>~/.profile</code>文件，作为对其他shell的兼容，它们与<code>~/.bash_profile</code>文件的作用是相同的。</p><p>备注：Debian系统会使用<code>~/.profile</code>文件取代<code>~/.bash_profile</code>文件，因此在相关细节上，会与CentOS略有不同。</p><h3 id="profile与rc系列"><a href="#profile与rc系列" class="headerlink" title="profile与rc系列"></a>profile与rc系列</h3><p>通过名字的不同，我们可以直观地将startup文件分为“profile”与“rc”两个系列，其实他们的功能都很类似，但是使用的场景不同，这也是大家最容易忽略的地方。</p><p>所谓的不同场景，其实就是shell的运行模式。我们知道运行中的bash有“交互”和“登陆”两种属性，而执行“profile”系列还是“rc”系列，就与shell的这两个属性有关。</p><p><strong>原理上讲，“登陆shell”启动时会加载“profile”系列的startup文件，而“交互式非登陆shell”启动时会加载“rc”系列的startup文件。</strong></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>对于“登录shell”而言，“交互式”执行“登陆”和“登出”相关的“profile”系列startup文件，“非交互式”只执行“登陆”相关的“profile”系列startup文件；对于“非登陆shell”而言，“交互式”执行“rc”系列的startup文件，而“非交互式”执行的配置文件由环境变量<code>BASH_ENV</code>指定。</p><p>Linux中startup文件区分全局和个人：全局startup文件放在<code>/etc</code>目录下，用于设置所有用户共同的配置，除非你清楚地知道你在做的事情，否则不要轻易改动它们；个人startup文件放在<code>~</code>目录下，用于设置某个用户的个性化配置。</p><p><code>~/.bash_profile</code>会显式调用<code>~/.bashrc</code>文件，而<code>~/.bashrc</code>又会显式调用<code>/etc/bashrc</code>文件，这是为了让所有交互式界面看起来一样。无论你是从远程登录（登陆shell），还是从图形界面打开终端（非登陆shell），你都拥有相同的提示符，因为环境变量<code>PS1</code>在<code>/etc/bashrc</code>文件中被统一设置过。</p><p>下面我来对startup文件进行一个完整的总结：</p><div class="table-container"><table><thead><tr><th>startup文件</th><th>交互登陆</th><th>非交互登陆</th><th>交互非登陆</th><th>非交互非登陆</th></tr></thead><tbody><tr><td>/etc/profile</td><td>直接执行1</td><td>直接执行1</td><td>-</td><td>-</td></tr><tr><td>~/.bash_profile</td><td>直接执行2</td><td>直接执行2</td><td>-</td><td>-</td></tr><tr><td>~/.bash_login</td><td>条件执行2</td><td>条件执行2</td><td>-</td><td>-</td></tr><tr><td>~/.profile</td><td>条件执行2</td><td>条件执行2</td><td>-</td><td>-</td></tr><tr><td>~/.bash_logout</td><td>直接执行3</td><td>不执行</td><td>-</td><td>-</td></tr><tr><td>/etc/bash.bash_logout</td><td>直接执行4</td><td>不执行</td><td>-</td><td>-</td></tr><tr><td>~/.bashrc</td><td>引用执行2.1</td><td>引用执行2.1</td><td>直接执行1</td><td>-</td></tr><tr><td>/etc/bashrc</td><td>引用执行2.2</td><td>引用执行2.2</td><td>引用执行1.1</td><td>-</td></tr></tbody></table></div><p>备注：</p><ol><li>“直接执行”表示此文件被系统直接调用，它的执行是无条件的；</li><li>“条件执行”表示此文件被系统调用是有先决条件的（没有优先级更高的文件可用）；</li><li>“引用执行”表示此文件不是被系统直接调用的，而是被其他文件显式调用的；</li><li>后面的数字表示文件被调用的顺序，数字越大调用越靠后；</li><li>“非交互非登陆”shell的配置文件可以由<code>BASH_ENV</code>环境变量指定；</li></ol><p>如果你想对bash的功能进行设置或者是定义一些别名，推荐你修改<code>~/.bashrc</code>文件，这样无论你以何种方式打开shell，你的配置都会生效。而如果你要更改一些环境变量，推荐你修改<code>~/.bash_profile</code>文件，因为考虑到shell的继承特性，这些更改确实只应该被执行一次（而不是多次）。针对所有用户进行全局设置，推荐你在<code>/etc/profile.d</code>目录下添加以<code>.sh</code>结尾的文件，而不是去修改全局startup文件。</p><blockquote><p>具体更加详细的解释可以参考文章<a href="https://blog.csdn.net/sch0120/article/details/70256318" target="_blank" rel="noopener">关于“.bash_profile”和“.bashrc”区别的总结</a>。</p></blockquote><h2 id="bash-history"><a href="#bash-history" class="headerlink" title="bash history"></a>bash history</h2><p>默认情况下, bash 只在退出的时候更新命令历史, 而且这个”更新”是用新版直接覆盖旧版。这会使你无法保持一份完整的命令历史记录, 原因有两个：</p><ul><li>如果一个用户登录多次，这种覆盖的机制会使得只有最后一个退出的 bash 能保存它的历史记录。(一个登录的用户打开多个终端模拟器, 或者使用 screen/tmux 等工具启动多个 bash 等也在此列 )</li><li>如果你的 bash 异常退出了 – 比如网络故障，防火墙更改，或者它的进程被杀掉了 – 会话中所有的历史记录都会丢失。</li></ul><p>你设置在 .bashrc 文件中添加下面这句就够了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">shopt</span> -s histappend</span><br></pre></td></tr></table></figure><p>它让 shell 退出时是添加新记录，而不是覆盖原来的文件。这样你关闭多个终端时就不会挨个覆盖了。</p><p>顺便，你也许想把历史记录保存条数设置大一点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置历史记录条数</span></span><br><span class="line"><span class="built_in">export</span> HISTFILESIZE=100000</span><br><span class="line"><span class="comment"># 设置显示历史记录条数</span></span><br><span class="line"><span class="built_in">export</span> HISTSIZE=10000</span><br></pre></td></tr></table></figure><p>另外下面非常推荐设置，可以让你能够用方向键翻阅历史</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">bind</span> <span class="string">'"\e[A": history-search-backward'</span></span><br><span class="line"><span class="built_in">bind</span> <span class="string">'"\e[B": history-search-forward'</span></span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.runoob.com/linux/linux-shell.html" target="_blank" rel="noopener">Shell 教程</a><br><a href="https://wangdoc.com/bash/intro" target="_blank" rel="noopener">Bash 简介</a><br><a href="https://zhuanlan.zhihu.com/p/56532223" target="_blank" rel="noopener">Bash编程入门-1：Shell与Bash</a><br><a href="https://blog.csdn.net/sch0120/article/details/70226903" target="_blank" rel="noopener">关于“交互式-非交互式”与“登录-非登陆”shell的总结</a><br><a href="https://stackoverflow.com/questions/35432562/why-does-running-echo-output-himbh-on-the-bash-shell" target="_blank" rel="noopener">Why does running “echo $-“ output “himBH” on the bash shell?</a><br><a href="https://blog.csdn.net/sch0120/article/details/70256318" target="_blank" rel="noopener">关于“.bash_profile”和“.bashrc”区别的总结</a><br><a href="https://www.zhihu.com/question/19863362/answer/37672858" target="_blank" rel="noopener">bash 下 history 会因多个终端而覆盖丢失，有好的解决方案吗？ - Zhou Zhao的回答 - 知乎</a><br><a href="https://felixc.at/2013/09/how-to-avoid-losing-any-history-lines/" target="_blank" rel="noopener">[译] 如何防止丢失任何 bash 历史命令?</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;bash与shell区别&quot;&gt;&lt;a href=&quot;#bash与shell区别&quot; class=&quot;headerlink&quot; title=&quot;bash与shell区别&quot;&gt;&lt;/a&gt;bash与shell区别&lt;/h2&gt;&lt;p&gt;shell有多个含义：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。&lt;/li&gt;
&lt;li&gt;Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;bash（GNU Bourne-Again Shell）是最常用的一种shell，是当前大多数Linux发行版的默认Shell。除了bash外，其它的shell还有zsh、sh等。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;sh的全名是Bourne Shell。名字中的玻恩就是这个Shell的作者。而bash的全名是Bourne Again Shell。最开始在Unix系统中流行的是sh，而bash作为sh的改进版本，提供了更加丰富的功能。一般来说，都推荐使用bash作为默认的Shell。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.zdaiot.com/categories/Linux/"/>
    
      <category term="维护" scheme="https://www.zdaiot.com/categories/Linux/%E7%BB%B4%E6%8A%A4/"/>
    
    
      <category term="Linux" scheme="https://www.zdaiot.com/tags/Linux/"/>
    
      <category term="bashrc" scheme="https://www.zdaiot.com/tags/bashrc/"/>
    
      <category term="bash_profile" scheme="https://www.zdaiot.com/tags/bash-profile/"/>
    
  </entry>
  
  <entry>
    <title>决策树（下）—— XGBoost、LightGBM</title>
    <link href="https://www.zdaiot.com/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%88%E4%B8%8B%EF%BC%89%E2%80%94%E2%80%94%20XGBoost%E3%80%81LightGBM/"/>
    <id>https://www.zdaiot.com/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/</id>
    <published>2022-10-31T15:48:11.000Z</published>
    <updated>2022-10-31T15:48:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要参考了<a href="https://www.zhihu.com/people/is-aze" target="_blank" rel="noopener">阿泽</a>作者的笔记，对于不理解的地方，我会添加个人注释。</p><h2 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h2><p>XGBoost 是大规模并行 boosting tree 的工具，它是目前最快最好的开源 boosting tree 工具包，比常见的工具包快 10 倍以上。Xgboost 和 GBDT 两者都是 boosting 方法，除了工程实现、解决问题上的一些差异外，最大的不同就是目标函数的定义。故本文将从数学原理和工程实现上进行介绍，并在最后介绍下 Xgboost 的优点。</p><h3 id="数学原理"><a href="#数学原理" class="headerlink" title="数学原理"></a>数学原理</h3><h4 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h4><p>我们知道 XGBoost 是由 k 个基模型组成的一个加法运算式：</p><script type="math/tex; mode=display">\hat{y}_i=\sum_{t=1}^{k}\ f_t(x_i) \\</script><p>其中 $f_k$ 为第 $k$ 个基模型， $\hat{y}_i$ 为第 $i$ 个样本的预测值。</p><p>损失函数可由预测值 $\hat{y}_i$ 与真实值 $y_i$ 进行表示：</p><script type="math/tex; mode=display">L=\sum_{i=1}^n l( y_i, \hat{y}_i) \\</script><p>其中 $n$ 为样本数量。</p><p>我们知道模型的预测精度由模型的偏差和方差共同决定，<strong>损失函数代表了模型的偏差，想要方差小则需要简单的模型，所以目标函数由模型的损失函数 $L$ 与抑制模型复杂度的正则项 $\Omega$ 组成</strong>，所以我们有：</p><script type="math/tex; mode=display">Obj =\sum_{i=1}^n l(\hat{y}_i, y_i) + \sum_{t=1}^k \Omega(f_t) \\</script><p>$\Omega$ 为模型的正则项，由于 XGBoost 支持决策树也支持线性模型，所以这里再不展开描述。</p><p>我们知道 boosting 模型是前向加法，以第 $t$ 步的模型为例，模型对第 $i$ 个样本 $x_{i}$ 的预测为：</p><script type="math/tex; mode=display">\hat{y}_i^t= \hat{y}_i^{t-1} + f_t(x_i) \\</script><p>其中 $\hat{y}_i^{t-1}$ 由第 $t-1$ 步的模型给出的预测值，是已知常数，$f_t(x_i)$ 是我们这次需要加入的新模型的预测值，此时，目标函数就可以写成：</p><script type="math/tex; mode=display">\begin{align} Obj^{(t)} &= \sum_{i=1}^nl(y_i, \hat{y}_i^t) + \sum_{i=1}^t\Omega(f_i) \\ &= \sum_{i=1}^n l\left(y_i, \hat{y}_i^{t-1} + f_t(x_i) \right) + \sum_{i=1}^t \Omega(f_i) \end{align} \\</script><p>求此时最优化目标函数，就相当于求解 $f_t(x_i)$ 。</p><blockquote><p>泰勒公式是将一个在 $x=x_0$ 处具有 $n$ 阶导数的函数 $f(x)$ 利用关于 $x-x_0$ 的 $n$ 次多项式来逼近函数的方法，若函数 $f(x)$ 在包含 $x_0$ 的某个闭区间 [a,b] 上具有 $n$ 阶导数，且在开区间 (a,b) 上具有 $n+1$ 阶导数，则对闭区间 [a,b] 上任意一点 $x$ 有 $\displaystyle f(x)=\sum_{i=0}^{n}\frac{f^{(i)}(x_0)}{i!}(x-x_0)^ i+R_n(x)$ ，其中的多项式称为函数在 $x_0$ 处的泰勒展开式， $R_n(x)$ 是泰勒公式的余项且是 $(x−x_0)^n$ 的高阶无穷小。</p></blockquote><p>根据泰勒公式我们把函数 $f(x+\Delta x)$ 在点 $x$ 处进行泰勒的二阶展开，可得到如下等式：</p><script type="math/tex; mode=display">f(x+\Delta x) \approx f(x) + f'(x)\Delta x + \frac12 f''(x)\Delta x^2 \\</script><p>我们把 $\hat{y}_i^{t-1}$ 视为 $x$ ， $f_t(x_i)$ 视为 $\Delta x$ ，故可以将目标函数写为：</p><script type="math/tex; mode=display">Obj^{(t)} = \sum_{i=1}^n \left[ l(y_i, \hat{y}_i^{t-1}) + g_if_t(x_i) + \frac12h_if_t^2(x_i) \right] + \sum_{i=1}^t \Omega(f_i) \\</script><p>其中 $g_{i}$ 为损失函数的一阶导， $h_{i}$ 为损失函数的二阶导，<strong>注意这里的导是对 $\hat{y}_i^{t-1}$ 求导</strong>。</p><p>我们以平方损失函数为例：</p><script type="math/tex; mode=display">\sum_{i=1}^n \left(y_i - (\hat{y}_i^{t-1} + f_t(x_i)) \right)^2 \\</script><p>则：</p><script type="math/tex; mode=display">\begin{align} g_i &= \frac{\partial (\hat{y}^{t-1} - y_i)^2}{\partial {\hat{y}^{t-1} } } = 2(\hat{y}^{t-1} - y_i) \\ h_i &=\frac{\partial^2(\hat{y}^{t-1} - y_i)^2}{ {\hat{y}^{t-1} } } = 2 \end{align} \\</script><p>由于在第 $t$ 步时 $\hat{y}_i^{t-1}$ 其实是一个已知的值，所以 $l(y_i, \hat{y}_i^{t-1})$ 是一个常数，其对函数的优化不会产生影响，因此目标函数可以写成：</p><script type="math/tex; mode=display">Obj^{(t)} \approx \sum_{i=1}^n \left[ g_if_t(x_i) + \frac12h_if_t^2(x_i) \right] + \sum_{i=1}^t \Omega(f_i) \\</script><p>所以我们只需要求出每一步损失函数的一阶导和二阶导的值（由于前一步的 $\hat{y}^{t-1}$ 是已知的，所以这两个值就是常数），然后最优化目标函数，就可以得到每一步的 $f(x)$ ，最后根据加法模型得到一个整体模型。</p><h4 id="基于决策树的目标函数"><a href="#基于决策树的目标函数" class="headerlink" title="基于决策树的目标函数"></a>基于决策树的目标函数</h4><p>我们知道 Xgboost 的基模型<strong>不仅支持决策树，还支持线性模型</strong>，这里我们主要介绍基于决策树的目标函数。</p><p>我们可以将决策树定义为 $f_t(x)=w_{q(x)}$ ，其中$w \in \mathbf{R}^{T}, q: \mathbf{R}^{d} \rightarrow\{1,2, \cdots, T\}$，$t$表示boosting在进行前向加法时的第$t$个模型。 $x$ 为某一样本，这里的 $q(x)$ 代表了该样本在哪个叶子结点上，而 $w_q$ 则代表了叶子结点取值 $w$ ，所以 $w_{q(x)}$ 就代表了每个样本的取值 $w$ （即预测值）。如下图所示：</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/image-20221101221923407.png" alt="image-20221101221923407" style="zoom: 33%;"></p><p>决策树的复杂度可由叶子数 $T$ 组成，叶子节点越少模型越简单，此外叶子节点也不应该含有过高的权重 $w$ （类比 LR 的每个变量的权重），所以目标函数的正则项可以定义为：</p><script type="math/tex; mode=display">\Omega(f_t)=\gamma T + \frac12 \lambda \sum_{j=1}^T w_j^2 \\</script><p>即决策树模型的复杂度由生成的所有决策树的叶子节点数量，和所有节点权重所组成的向量的 $L_2$ 范式共同决定。下图给出了基于决策树的 XGBoost 的正则项的求解方式。</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/image-20221101222030743.png" alt="image-20221101222030743" style="zoom:40%;"></p><p>我们设 $I_j= \{ i \vert q(x_i)=j \}$ 为第 $j$ 个叶子节点的样本集合，故我们的目标函数可以写成：</p><script type="math/tex; mode=display">\begin{align} Obj^{(t)} &\approx \sum_{i=1}^n \left[ g_if_t(x_i) + \frac12h_if_t^2(x_i) \right] + \Omega(f_t) \\ &= \sum_{i=1}^n \left[ g_iw_{q(x_i)} + \frac12h_iw_{q(x_i)}^2 \right] + \gamma T + \frac12 \lambda \sum_{j=1}^Tw_j^2 \\ &= \sum_{j=1}^T \left[(\sum_{i \in I_j}g_i)w_j + \frac12(\sum_{i \in I_j}h_i + \lambda)w_j^2 \right] + \gamma T \end{align} \\</script><p>第二步到第三步可能看的不是特别明白，这边做些解释：第二步是遍历所有的样本后求每个样本的损失函数，但样本最终会落在叶子节点上，所以我们也可以遍历叶子节点，然后获取叶子节点上的样本集合，最后在求损失函数。即我们之前样本的集合，现在都改写成叶子结点的集合，由于一个叶子结点有多个样本存在，因此才有了 $\sum_{i \in I_j}g_i$ 和 $\sum_{i \in I_j}h_i$ 这两项， $w_j$ 为第 $j$ 个叶子节点取值。</p><p>为简化表达式，我们定义 $G_j=\sum_{i \in I_j}g_i ， H_j=\sum_{i \in I_j}h_i$ ，则目标函数为：</p><script type="math/tex; mode=display">Obj^{(t)} = \sum_{j=1}^T \left[G_jw_j + \frac12(H_j + \lambda)w_j^2 \right] + \gamma T \\</script><p>这里我们要注意 $G_j $和 $H_j$ 是前 t-1 步得到的结果，其值已知可视为常数，只有最后一棵树的叶子节点 $w_j$ 不确定，那么将目标函数对 $w_j$ 求一阶导，并令其等于 0 ，则可以求得叶子结点 $j$ 对应的权值：</p><script type="math/tex; mode=display">w_j^*=-\frac{G_j}{H_j+\lambda} \\</script><p>所以目标函数可以化简为：</p><script type="math/tex; mode=display">Obj = -\frac12 \sum_{j=1}^T \frac{G_j^2}{H_j+\lambda} + \gamma T \\</script><p>下图给出目标函数计算的例子，求每个节点每个样本的一阶导数 $g_i$ 和二阶导数 $h_i$ ，然后针对每个节点对所含样本求和得到的 $G_j$ 和 $H_j$ ，最后遍历决策树的节点即可得到目标函数。</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/image-20221101222937890.png" alt="image-20221101222937890" style="zoom:50%;"></p><h4 id="最优切分点划分算法"><a href="#最优切分点划分算法" class="headerlink" title="最优切分点划分算法"></a>最优切分点划分算法</h4><p>在决策树的生长过程中，一个非常关键的问题是如何找到叶子的节点的最优切分点，Xgboost 支持两种分裂节点的方法——贪心算法和近似算法。</p><p><strong>1）贪心算法</strong></p><ol><li>从深度为 0 的树开始，对每个叶节点枚举所有的可用特征；</li><li>针对每个特征，把属于该节点的训练样本根据该特征值进行升序排列，通过线性扫描的方式来决定该特征的最佳分裂点，并记录该特征的分裂收益；</li><li>选择收益最大的特征作为分裂特征，用该特征的最佳分裂点作为分裂位置，在该节点上分裂出左右两个新的叶节点，并为每个新节点关联对应的样本集</li><li>回到第 1 步，递归执行到满足特定条件为止</li></ol><p>那么如何计算每个特征的分裂收益呢？</p><p>假设我们在某一节点完成特征分裂，则分裂前的目标函数可以写为：</p><script type="math/tex; mode=display">Obj_{1} =-\frac12 [\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}] + \gamma \\</script><p>分裂后的目标函数为：</p><script type="math/tex; mode=display">Obj_2 = -\frac12 [ \frac{G_L^2}{H_L+\lambda} + \frac{G_R^2}{H_R+\lambda}] +2\gamma \\</script><p>则对于目标函数来说，分裂后的收益为：</p><script type="math/tex; mode=display">Gain=\frac12 \left[ \frac{G_L^2}{H_L+\lambda} + \frac{G_R^2}{H_R+\lambda} - \frac{(G_L+G_R)^2}{H_L+H_R+\lambda}\right] - \gamma \\</script><p>注意该特征收益也可作为特征重要性输出的重要依据。</p><p>对于每次分裂，我们都需要枚举所有特征可能的分割方案，如何高效地枚举所有的分割呢？</p><p>我假设我们要枚举所有 $x &lt; a$ 这样的条件，对于某个特定的分割点 $a$ 我们要计算 $a$ 左边和右边的导数和。</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/image-20221101224051238.png" alt="image-20221101224051238" style="zoom:50%;"></p><p>我们可以发现对于所有的分裂点 $a$ ，我们只要做一遍从左到右的扫描就可以枚举出所有分割的梯度和 $G_L$ 和 $G_R$ 。然后用上面的公式计算每个分割方案的分数就可以了。</p><p>观察分裂后的收益，我们会发现节点划分不一定会使得结果变好，因为我们有一个引入新叶子的惩罚项，也就是说引入的分割带来的增益如果小于一个阀值的时候，我们可以剪掉这个分割。</p><p><strong>2）近似算法</strong></p><p>贪婪算法可以得到最优解，但当数据量太大时则无法读入内存进行计算，近似算法主要针对贪婪算法这一缺点给出了近似最优解。</p><p>对于每个特征，只考察分位点可以减少计算复杂度。</p><p>该算法会首先根据特征分布的分位数提出候选划分点，然后将连续型特征映射到由这些候选点划分的桶中，然后聚合统计信息找到所有区间的最佳分裂点。</p><p>在提出候选切分点时有两种策略：</p><ul><li>Global：学习每棵树前就提出候选切分点，并在每次分裂时都采用这种分割；</li><li>Local：每次分裂前将重新提出候选切分点。</li></ul><p>直观上来看，Local 策略需要更多的计算步骤，而 Global 策略因为节点没有划分所以需要更多的候选点。</p><p>下图给出不同种分裂策略的 AUC 变换曲线，横坐标为迭代次数，纵坐标为测试集 AUC，eps 为近似算法的精度，其倒数为桶的数量。</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/v2-1da040923ad9beaf222a2dd60a8f3752_b.jpg" alt="img" style="zoom: 50%;"></p><p>我们可以看到 Global 策略在候选点数多时（eps 小）可以和 Local 策略在候选点少时（eps 大）具有相似的精度。此外我们还发现，在 eps 取值合理的情况下，分位数策略可以获得与贪婪算法相同的精度。</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/v2-161382c979557b8bae1563a459cd1ed4_b.jpg" alt="img" style="zoom:67%;"></p><ul><li><strong>第一个 for 循环：</strong>对特征 $k$ 根据该特征分布的分位数找到切割点的候选集合 $S_k=\{s_{k1},s_{k2},…,s_{kl} \}$ 。XGBoost 支持 Global 策略和 Local 策略。</li><li><strong>第二个 for 循环：</strong>针对每个特征的候选集合，将样本映射到由该特征对应的候选点集构成的分桶区间中，即 ${s_{k,v}≥x_{jk}&gt;s_{k,v−1} }$ ，对每个桶统计 $G,H$ 值，最后在这些统计量上寻找最佳分裂点。</li></ul><p>下图给出近似算法的具体例子，以三分位为例：</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/v2-5d1dd1673419599094bf44dd4b533ba9_b.jpg" alt="img" style="zoom:67%;"></p><p>根据样本特征进行排序，然后基于分位数进行划分，并统计三个桶内的 $G,H$ 值，最终求解节点划分的增益。</p><h4 id="加权分位数缩略图"><a href="#加权分位数缩略图" class="headerlink" title="加权分位数缩略图"></a>加权分位数缩略图</h4><p>事实上， XGBoost 不是简单地按照样本个数进行分位，而是以二阶导数值 $h_i$ 作为样本的权重进行划分，如下：</p><p>那么问题来了：为什么要用 $h_i$ 进行样本加权？</p><p>我们知道模型的目标函数为：</p><script type="math/tex; mode=display">Obj^{(t)} \approx \sum_{i=1}^n \left[ g_if_t(x_i) + \frac12h_if_t^2(x_i) \right] + \sum_{i=1}^t \Omega(f_i) \\</script><p>我们稍作整理，便可以看出 $h_i$ 有对 loss 加权的作用。</p><script type="math/tex; mode=display">\begin{align} Obj^{(t)} & \approx \sum_{i=1}^n \left[ g_if_t(x_i) + \frac12h_if_t^2(x_i) \right] + \sum_{i=1}^t \Omega(f_i) \\ \\ &= \sum_{i=1}^{n} [ g_i f_t(x_i) + \frac{1}{2}h_i f_t^2(x_i) \color{red}{+ \frac{1}{2}\frac{g_i^2}{h_i} }]+\Omega(f_t) \color{red}{+ C} \\ &= \sum_{i=1}^{n} \color{red}{\frac{1}{2}h_i} \left[ f_t(x_i) - \left( -\frac{g_i}{h_i} \right) \right]^2 + \Omega(f_t) + C \end{align} \\</script><p>其中 $\frac{1}{2}\frac{g_i^2}{h_i}$ 与 $C$ 皆为常数。我们可以看到 $h_i$ 就是平方损失函数中样本的权重。</p><p>对于样本权值相同的数据集来说，找到候选分位点已经有了解决方案（GK 算法），但是当样本权值不一样时，该如何找到候选分位点呢？（作者给出了一个 Weighted Quantile Sketch 算法，这里将不做介绍。）</p><h4 id="稀疏感知算法"><a href="#稀疏感知算法" class="headerlink" title="稀疏感知算法"></a>稀疏感知算法</h4><p>在决策树的第一篇文章中我们介绍 CART 树在应对数据缺失时的分裂策略，XGBoost 也给出了其解决方案。</p><p>XGBoost 在构建树的节点过程中只考虑非缺失值的数据遍历，而为每个节点增加了一个缺省方向，当样本相应的特征值缺失时，可以被归类到缺省方向上，最优的缺省方向可以从数据中学到。至于如何学到缺省值的分支，其实很简单，分别枚举特征缺省的样本归为左右分支后的增益，选择增益最大的枚举项即为最优缺省方向。</p><p>在构建树的过程中需要枚举特征缺失的样本，乍一看该算法的计算量增加了一倍，但其实该算法在构建树的过程中只考虑了特征未缺失的样本遍历，而特征值缺失的样本无需遍历只需直接分配到左右节点，故算法所需遍历的样本量减少，下图可以看到稀疏感知算法比 basic 算法速度块了超过 50 倍。</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/v2-e065bea4b424ea2d13b25ed2e7004aa8_b.jpg" alt="img" style="zoom:50%;"></p><h3 id="工程实现"><a href="#工程实现" class="headerlink" title="工程实现"></a>工程实现</h3><h4 id="块结构设计"><a href="#块结构设计" class="headerlink" title="块结构设计"></a>块结构设计</h4><p>我们知道，决策树的学习最耗时的一个步骤就是在每次寻找最佳分裂点是都需要对特征的值进行排序。而 XGBoost 在训练之前对根据特征对数据进行了排序，然后保存到块结构中，并在每个块结构中都采用了稀疏矩阵存储格式（Compressed Sparse Columns Format，CSC）进行存储，后面的训练过程中会重复地使用块结构，可以大大减小计算量。</p><ul><li>每一个块结构包括一个或多个已经排序好的特征；</li><li>缺失特征值将不进行排序；</li><li>每个特征会存储指向样本梯度统计值的索引，方便计算一阶导和二阶导数值；</li></ul><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/image-20221101230024796.png" alt="image-20221101230024796" style="zoom:50%;"></p><p><strong>这种块结构存储的特征之间相互独立，方便计算机进行并行计算</strong>。在对节点进行分裂时需要选择增益最大的特征作为分裂，这时各个特征的增益计算可以同时进行，这也是 Xgboost 能够实现分布式或者多线程计算的原因。</p><h4 id="缓存访问优化算法"><a href="#缓存访问优化算法" class="headerlink" title="缓存访问优化算法"></a>缓存访问优化算法</h4><p>块结构的设计可以减少节点分裂时的计算量，但特征值通过索引访问样本梯度统计值的设计会导致访问操作的内存空间不连续，这样会造成缓存命中率低，从而影响到算法的效率。</p><p>为了解决缓存命中率低的问题，XGBoost 提出了缓存访问优化算法：为每个线程分配一个连续的缓存区，将需要的梯度信息存放在缓冲区中，这样就是实现了非连续空间到连续空间的转换，提高了算法效率。</p><p>此外适当调整块大小，也可以有助于缓存优化。</p><h4 id="“核外”块计算"><a href="#“核外”块计算" class="headerlink" title="“核外”块计算"></a>“核外”块计算</h4><p>当数据量过大时无法将数据全部加载到内存中，只能先将无法加载到内存中的数据暂存到硬盘中，直到需要时再进行加载计算，而这种操作必然涉及到因内存与硬盘速度不同而造成的资源浪费和性能瓶颈。为了解决这个问题，XGBoost 独立一个线程专门用于从硬盘读入数据，以实现处理数据和读入数据同时进行。</p><p>此外，XGBoost 还用了两种方法来降低硬盘读写的开销：</p><ul><li><strong>块压缩：</strong>对 Block 进行按列压缩，并在读取时进行解压；</li><li><strong>块拆分：</strong>将每个块存储到不同的磁盘中，从多个磁盘读取可以增加吞吐量。</li></ul><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ol><li><strong>精度更高：</strong>GBDT 只用到一阶泰勒展开，而 XGBoost 对损失函数进行了二阶泰勒展开。XGBoost 引入二阶导一方面是为了增加精度，另一方面也是为了能够自定义损失函数，二阶泰勒展开可以近似大量损失函数；</li><li><strong>灵活性更强：</strong>GBDT 以 CART 作为基分类器，XGBoost 不仅支持 CART 还支持线性分类器，（使用线性分类器的 XGBoost 相当于带 L1 和 L2 正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题））。此外，XGBoost 工具支持自定义损失函数，只需函数支持一阶和二阶求导；</li><li><strong>正则化：</strong>XGBoost 在目标函数中加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、叶子节点权重的 L2 范式。正则项降低了模型的方差，使学习出来的模型更加简单，有助于防止过拟合；</li><li><strong>Shrinkage（缩减）：</strong>相当于学习速率。XGBoost 在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间；</li><li><strong>列抽样：</strong>XGBoost 借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算；</li><li><strong>缺失值处理：</strong>XGBoost 采用的稀疏感知算法极大的加快了节点分裂的速度；</li><li><strong>可以并行化操作：</strong>块结构可以很好的支持并行计算。</li></ol><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ol><li>虽然利用预排序和近似算法可以降低寻找最佳分裂点的计算量，但在节点分裂过程中仍需要遍历数据集；</li><li>预排序过程的空间复杂度过高，不仅需要存储特征值，还需要存储特征对应样本的梯度统计值的索引，相当于消耗了两倍的内存。</li></ol><h2 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h2><p>LightGBM 由微软提出，主要用于解决 GDBT 在海量数据中遇到的问题，以便其可以更好更快地用于工业实践中。</p><p>从 LightGBM 名字我们可以看出其是轻量级（Light）的梯度提升机（GBM），其相对 XGBoost 具有训练速度快、内存占用低的特点。下图分别显示了 XGBoost、XGBoost_hist（利用梯度直方图的 XGBoost） 和 LightGBM 三者之间针对不同数据集情况下的内存和训练时间的对比：</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/v2-e015e3c4018f44787d74a47c9e0cd040_b.jpg" alt="img"></p><p>那么 LightGBM 到底如何做到更快的训练速度和更低的内存使用的呢？</p><p>我们刚刚分析了 XGBoost 的缺点，LightGBM 为了解决这些问题提出了以下几点解决方案：</p><ol><li>单边梯度抽样算法；</li><li>直方图算法；</li><li>互斥特征捆绑算法；</li><li>基于最大深度的 Leaf-wise 的垂直生长算法；</li><li>类别特征最优分割；</li><li>特征并行和数据并行；</li><li>缓存优化。</li></ol><p>本节将继续从数学原理和工程实现两个角度介绍 LightGBM。</p><h3 id="数学原理-1"><a href="#数学原理-1" class="headerlink" title="数学原理"></a>数学原理</h3><h4 id="单边梯度抽样算法"><a href="#单边梯度抽样算法" class="headerlink" title="单边梯度抽样算法"></a>单边梯度抽样算法</h4><p>GBDT 算法的梯度大小可以反映样本的权重，梯度越小说明模型拟合的越好，单边梯度抽样算法（Gradient-based One-Side Sampling, GOSS）利用这一信息对样本进行抽样，减少了大量梯度小的样本，在接下来的计算过程中只需关注梯度高的样本，极大的减少了计算量。</p><p>GOSS 算法保留了梯度大的样本，并对梯度小的样本进行随机抽样，为了不改变样本的数据分布，在计算增益时为梯度小的样本引入一个常数进行平衡。具体算法如下所示：</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/v2-31e5d8d2d0862eda0c40303b3cba6089_b.jpg" alt="img" style="zoom:50%;"></p><p>我们可以看到 GOSS 事先基于梯度的绝对值对样本进行排序（<strong>无需保存排序后结果</strong>），然后拿到前 a% 的梯度大的样本，和总体样本的 b%，在计算增益时，通过乘上 $\frac{1-a}{b}$ 来放大梯度小的样本的权重。<strong>一方面算法将更多的注意力放在训练不足的样本上，另一方面通过乘上权重来防止采样对原始数据分布造成太大的影响。</strong></p><blockquote><p> 采样之前梯度小的样本数量是$整体数量<em>1-a$，采样之后变为了$整体</em>b$，会影响数据分布，乘以这个系数之后，数量就回到了$1-a$的量级。</p></blockquote><h4 id="直方图算法"><a href="#直方图算法" class="headerlink" title="直方图算法"></a>直方图算法</h4><p><strong>1) 直方图算法</strong></p><p>直方图算法的基本思想是将连续的特征离散化为 k 个离散特征，同时构造一个宽度为 k 的直方图用于统计信息（含有 k 个 bin）。利用直方图算法我们无需遍历数据，只需要遍历 k 个 bin 即可找到最佳分裂点。</p><p>我们知道特征离散化的具有很多优点，如存储方便、运算更快、鲁棒性强、模型更加稳定等等。对于直方图算法来说最直接的有以下两个优点（以 k=256 为例）：</p><ul><li><strong>内存占用更小：</strong>XGBoost 需要用 32 位的浮点数去存储特征值，并用 32 位的整形去存储索引，而 LightGBM 只需要用 8 位去存储直方图，相当于减少了 1/8；</li><li><strong>计算代价更小：</strong>计算特征分裂增益时，XGBoost 需要遍历一次数据找到最佳分裂点，而 LightGBM 只需要遍历一次 k 次，直接将时间复杂度从 $O(#data <em> #feature)$ 降低到 $O(k </em> #feature)$ ，而我们知道 $#data &gt;&gt; k$ 。</li></ul><p>虽然将特征离散化后无法找到精确的分割点，可能会对模型的精度产生一定的影响，但较粗的分割也起到了正则化的效果，一定程度上降低了模型的方差。</p><p><strong>2) 直方图加速</strong></p><p>在构建叶节点的直方图时，我们还可以通过父节点的直方图与相邻叶节点的直方图相减的方式构建，从而减少了一半的计算量。在实际操作过程中，我们还可以先计算直方图小的叶子节点，然后利用直方图作差来获得直方图大的叶子节点。</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/v2-66982f5386b2e9be3e50a651e01b9c21_b.jpg" alt="img"></p><p><strong>3) 稀疏特征优化</strong></p><p>XGBoost 在进行预排序时只考虑非零值进行加速，而 LightGBM 也采用类似策略：只用非零特征构建直方图。</p><h4 id="互斥特征捆绑算法"><a href="#互斥特征捆绑算法" class="headerlink" title="互斥特征捆绑算法"></a>互斥特征捆绑算法</h4><p>高维特征往往是稀疏的，而且特征间可能是相互排斥的（如两个特征不同时取非零值），如果两个特征并不完全互斥（如只有一部分情况下是不同时取非零值），可以用互斥率表示互斥程度。互斥特征捆绑算法（Exclusive Feature Bundling, EFB）指出如果将一些特征进行融合绑定，则可以降低特征数量。</p><p>针对这种想法，我们会遇到两个问题：</p><ol><li>哪些特征可以一起绑定？</li><li>特征绑定后，特征值如何确定？</li></ol><p><strong>对于问题一：</strong>EFB 算法利用特征和特征间的关系构造一个加权无向图，并将其转换为图着色算法。我们知道图着色是个 NP-Hard 问题，故采用贪婪算法得到近似解，具体步骤如下：</p><ol><li>构造一个加权无向图，顶点是特征，边是两个特征间互斥程度；</li><li>根据节点的度进行降序排序，度越大，与其他特征的冲突越大；</li><li>遍历每个特征，将它分配给现有特征包，或者新建一个特征包，是的总体冲突最小。</li></ol><p>算法允许两两特征并不完全互斥来增加特征捆绑的数量，通过设置最大互斥率 $\gamma$ 来平衡算法的精度和效率。EFB 算法的伪代码如下所示：</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/v2-3eb0ef1f565e344013e8f700fba617da_b.jpg" alt="img" style="zoom:50%;"></p><p>我们看到时间复杂度为 $O(#feature^2)$ ，在特征不多的情况下可以应付，但如果特征维度达到百万级别，计算量则会非常大，为了改善效率，我们提出了一个更快的解决方案：将 EFB 算法中通过构建图，根据节点度来排序的策略改成了根据非零值的技术排序，因为非零值越多，互斥的概率会越大。</p><p><strong>对于问题二：</strong>论文给出特征合并算法，其关键在于原始特征能从合并的特征中分离出来。假设 Bundle 中有两个特征值，A 取值为 [0, 10]、B 取值为 [0, 20]，为了保证特征 A、B 的互斥性，我们可以给特征 B 添加一个偏移量转换为 [10, 30]，Bundle 后的特征其取值为 [0, 30]，这样便实现了特征合并。具体算法如下所示：</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/v2-ea09eac195f8187917685b8139dc45cf_b.jpg" alt="img" style="zoom:50%;"></p><h4 id="带深度限制的-Leaf-wise-算法"><a href="#带深度限制的-Leaf-wise-算法" class="headerlink" title="带深度限制的 Leaf-wise 算法"></a>带深度限制的 Leaf-wise 算法</h4><p>在建树的过程中有两种策略：</p><ul><li>Level-wise：基于层进行生长，直到达到停止条件；</li><li>Leaf-wise：每次分裂增益最大的叶子节点，直到达到停止条件。</li></ul><p>XGBoost 采用 Level-wise 的增长策略，方便并行计算每一层的分裂节点，提高了训练速度，但同时也因为节点增益过小增加了很多不必要的分裂，降低了计算量；LightGBM 采用 Leaf-wise 的增长策略减少了计算量，配合最大深度的限制防止过拟合，由于每次都需要计算增益最大的节点，所以无法并行分裂。</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/v2-76f2f27dd24fc452a9a65003e5cdd305_r.jpg" alt="img" style="zoom:80%;"></p><h4 id="类别特征最优分割"><a href="#类别特征最优分割" class="headerlink" title="类别特征最优分割"></a>类别特征最优分割</h4><p>大部分的机器学习算法都不能直接支持类别特征，一般都会对类别特征进行编码，然后再输入到模型中。常见的处理类别特征的方法为 one-hot 编码，但我们知道<strong>对于决策树来说并不推荐使用 one-hot 编码：</strong></p><ol><li>会产生样本切分不平衡问题，切分增益会非常小。使用one-hot编码的话，意味着在每一个决策节点上只能使用one vs rest（例如是不是狗，是不是猫等）的切分方式。当类别值很多时，每个类别上的数据可能会比较少，这时候切分会产生不平衡，这意味着切分增益也会很小（比较直观的理解是，不平衡的切分和不切分没有区别）。如，国籍切分后，会产生是否中国，是否美国等一系列特征，这一系列特征上只有少量样本为 1，大量样本为 0。这种划分的增益非常小：较小的那个拆分样本集，它占总样本的比例太小。无论增益多大，乘以该比例之后几乎可以忽略；较大的那个拆分样本集，它几乎就是原始的样本集，增益几乎为零；</li><li>影响决策树学习：决策树依赖的是数据的统计信息，而就算one-hot编码可以在这个类别特征进行切分，也会把数据切分到零散的小空间上。在这些零散的小空间上统计信息不准确的，学习效果变差。本质是因为one-hot码编码之后的特征的表达能力较差的，特征的预测能力被人为的拆分成多份，每一份与其他特征竞争最优划分点都失败，最终该特征得到的重要性会比实际值低。</li></ol><p><strong>LightGBM 原生支持类别特征</strong>，采用 many-vs-many 的切分方式将类别特征分为两个子集，实现类别特征的最优切分。假设有某维特征有 $k$ 个类别，则有 $2^{(k-1)} - 1$ 种可能，时间复杂度为 $O(2^k)$ ，LightGBM 基于 Fisher 大佬的 《<a href="https://link.zhihu.com/?target=http%3A//www.csiss.org/SPACE/workshops/2004/SAC/files/fisher.pdf" target="_blank" rel="noopener">On Grouping For Maximum Homogeneity</a>》实现了 $O(klogk)$ 的时间复杂度。</p><p>下图为左边为基于 one-hot 编码进行分裂，右边为 LightGBM 基于 many-vs-many 进行分裂（叶子节点的含义是X=A或者X=C放到左孩子，其余放到右孩子），在给定深度情况下，后者能学出更好的模型。</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/v2-34558cd9eab486eed731ba7aadca5992_b.jpg" alt="img" style="zoom:50%;"></p><p>其基本思想在于每次分组时都会<strong>根据训练目标</strong>对类别特征进行分类，根据其累积值 $\frac{\sum gradient }{\sum hessian}$ 对直方图进行排序，然后在排序的直方图上找到最佳分割。此外，LightGBM 还加了约束条件正则化，防止过拟合。</p><blockquote><p>下图是根据类标sum(y)/count(y)进行排序并划分的示意图。</p></blockquote><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/v2-9c70d63970befd6cdac3b0e530b93559_720w.jpg" alt="img" style="zoom: 40%;"></p><p>我们可以看到这种处理类别特征的方式使得 AUC 提高了 1.5 个点，且时间仅仅多了 20%。</p><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/v2-ea588783be9403a0f7115c408389031d_b.jpg" alt="img" style="zoom: 67%;"></p><blockquote><p>对于类别特征，补充另外的处理方式。</p><ol><li><p>转成数值特征。在使用 sklearn 或 XGBoost 等不支持类别特征的最优切分工具时，可以用这个方法。常见的转换方法有: a) 把类别特征转成one-hot coding扔到NN里训练个embedding；b) 类似于CTR特征，统计每个类别对应的label(训练目标)的均值。统计的时候有一些小技巧，比如不把自身的label算进去(leave-me-out, leave-one-out)统计， 防止信息泄露。</p><p>关于”leave-me-out”的统计方法。一个简单的例子，比如样本1，3，5属于同个类别（在类别特征上的属性一样），对于样本1，可以用3和5的label均值，样本3用1和5的均值……这样可以防止每一个样本直接把自身的label信息放到特征里面，减少统计特征的信息泄露，防止过拟合。</p></li><li><p>其他的编码方法，比如binary coding等等，同样可以用于不支持类别特征的算法。这里有一个比较好的开源项目，封装了常见的各种编码方法: <a href="https://github.com/scikit-learn-contrib/categorical-encoding" target="_blank" rel="noopener">https://github.com/scikit-learn</a></p></li></ol></blockquote><h3 id="工程实现-1"><a href="#工程实现-1" class="headerlink" title="工程实现"></a>工程实现</h3><h4 id="特征并行"><a href="#特征并行" class="headerlink" title="特征并行"></a>特征并行</h4><p>传统的特征并行算法在于对数据进行垂直划分，然后使用不同机器找到不同特征的最优分裂点，基于通信整合得到最佳划分点，然后基于通信告知其他机器划分结果。</p><p>传统的特征并行方法有个很大的缺点：需要告知每台机器最终划分结果，增加了额外的复杂度（因为对数据进行垂直划分，每台机器所含数据不同，划分结果需要通过通信告知）。</p><p>LightGBM 则不进行数据垂直划分，每台机器都有训练集完整数据，在得到最佳划分方案后可在本地执行划分而减少了不必要的通信。</p><h4 id="数据并行"><a href="#数据并行" class="headerlink" title="数据并行"></a>数据并行</h4><p>传统的数据并行策略主要为水平划分数据，然后本地构建直方图并整合成全局直方图，最后在全局直方图中找出最佳划分点。</p><p>这种数据划分有一个很大的缺点：通讯开销过大。如果使用点对点通信，一台机器的通讯开销大约为 $O(#machine <em> #feature </em>#bin )$ ；如果使用集成的通信，则通讯开销为 $O(2 <em> #feature </em>#bin )$ 。</p><p>LightGBM 采用分散规约（Reduce scatter）的方式将直方图整合的任务分摊到不同机器上，从而降低通信代价，并通过直方图做差进一步降低不同机器间的通信。</p><h4 id="投票并行"><a href="#投票并行" class="headerlink" title="投票并行"></a>投票并行</h4><p>针对数据量特别大特征也特别多的情况下，可以采用投票并行。投票并行主要针对数据并行时数据合并的通信代价比较大的瓶颈进行优化，其通过投票的方式只合并部分特征的直方图从而达到降低通信量的目的。</p><p>大致步骤为两步：</p><ol><li>本地找出 Top K 特征，并基于投票筛选出可能是最优分割点的特征；</li><li>合并时只合并每个机器选出来的特征。</li></ol><h4 id="缓存优化"><a href="#缓存优化" class="headerlink" title="缓存优化"></a>缓存优化</h4><p>上边说到 XGBoost 的预排序后的特征是通过索引给出的样本梯度的统计值，因其索引访问的结果并不连续，XGBoost 提出缓存访问优化算法进行改进。</p><p>而 LightGBM 所使用直方图算法对 Cache 天生友好：</p><ol><li>首先，所有的特征都采用相同的方法获得梯度（区别于不同特征通过不同的索引获得梯度），只需要对梯度进行排序并可实现连续访问，大大提高了缓存命中；</li><li>其次，因为不需要存储特征到样本的索引，降低了存储消耗，而且也不存在 Cache Miss的问题。</li></ol><p><img src="/MachineLearning/机器学习/决策树（下）—— XGBoost、LightGBM/v2-19436e5546c47fed4a85000b1fff9abb_b.jpg" alt="img"></p><h3 id="与-XGBoost-的对比"><a href="#与-XGBoost-的对比" class="headerlink" title="与 XGBoost 的对比"></a>与 XGBoost 的对比</h3><p>本节主要总结下 LightGBM 相对于 XGBoost 的优点，从内存和速度两方面进行介绍。</p><h4 id="内存更小"><a href="#内存更小" class="headerlink" title="内存更小"></a>内存更小</h4><ol><li>XGBoost 使用预排序后需要记录特征值及其对应样本的统计值的索引，而 LightGBM 使用了直方图算法将特征值转变为 bin 值，且不需要记录特征到样本的索引，将空间复杂度从 O(2∗#data) 降低为 O(#bin) ，极大的减少了内存消耗；</li><li>LightGBM 采用了直方图算法将存储特征值转变为存储 bin 值，降低了内存消耗；</li><li>LightGBM 在训练过程中采用互斥特征捆绑算法减少了特征数量，降低了内存消耗。</li></ol><h4 id="速度更快"><a href="#速度更快" class="headerlink" title="速度更快"></a>速度更快</h4><ol><li>LightGBM 采用了直方图算法将遍历样本转变为遍历直方图，极大的降低了时间复杂度；</li><li>LightGBM 在训练过程中采用单边梯度算法过滤掉梯度小的样本，减少了大量的计算；</li><li>LightGBM 采用了基于 Leaf-wise 算法的增长策略构建树，减少了很多不必要的计算量；</li><li>LightGBM 采用优化后的特征并行、数据并行方法加速计算，当数据量非常大的时候还可以采用投票并行的策略；</li><li>LightGBM 对缓存也进行了优化，增加了 Cache hit 的命中率。</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/87885678" target="_blank" rel="noopener">【机器学习】决策树（下）——XGBoost、LightGBM（非常详细）</a><br><a href="https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf" target="_blank" rel="noopener">陈天奇论文演讲 PPT</a><br><a href="https://www.zhihu.com/question/266195966/answer/306104444" target="_blank" rel="noopener">关于sklearn中的决策树是否应该用one-hot编码？ - 柯国霖的回答 - 知乎</a><br><a href="https://blog.csdn.net/anshuai_aw1/article/details/83275299" target="_blank" rel="noopener">Lightgbm如何处理类别特征？</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要参考了&lt;a href=&quot;https://www.zhihu.com/people/is-aze&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;阿泽&lt;/a&gt;作者的笔记，对于不理解的地方，我会添加个人注释。&lt;/p&gt;
&lt;h2 id=&quot;XGBoost&quot;&gt;&lt;a href=&quot;#XGBoost&quot; class=&quot;headerlink&quot; title=&quot;XGBoost&quot;&gt;&lt;/a&gt;XGBoost&lt;/h2&gt;&lt;p&gt;XGBoost 是大规模并行 boosting tree 的工具，它是目前最快最好的开源 boosting tree 工具包，比常见的工具包快 10 倍以上。Xgboost 和 GBDT 两者都是 boosting 方法，除了工程实现、解决问题上的一些差异外，最大的不同就是目标函数的定义。故本文将从数学原理和工程实现上进行介绍，并在最后介绍下 Xgboost 的优点。&lt;/p&gt;
&lt;h3 id=&quot;数学原理&quot;&gt;&lt;a href=&quot;#数学原理&quot; class=&quot;headerlink&quot; title=&quot;数学原理&quot;&gt;&lt;/a&gt;数学原理&lt;/h3&gt;&lt;h4 id=&quot;目标函数&quot;&gt;&lt;a href=&quot;#目标函数&quot; class=&quot;headerlink&quot; title=&quot;目标函数&quot;&gt;&lt;/a&gt;目标函数&lt;/h4&gt;
    
    </summary>
    
    
      <category term="MachineLearning" scheme="https://www.zdaiot.com/categories/MachineLearning/"/>
    
      <category term="机器学习" scheme="https://www.zdaiot.com/categories/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="决策树" scheme="https://www.zdaiot.com/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>决策树（中）—— Random Forest、Adaboost、GBDT</title>
    <link href="https://www.zdaiot.com/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%88%E4%B8%AD%EF%BC%89%E2%80%94%E2%80%94%20Random%20Forest%E3%80%81Adaboost%E3%80%81GBDT/"/>
    <id>https://www.zdaiot.com/MachineLearning/机器学习/决策树（中）—— Random Forest、Adaboost、GBDT/</id>
    <published>2022-10-31T14:14:11.000Z</published>
    <updated>2022-10-31T14:14:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要参考了<a href="https://www.zhihu.com/people/is-aze" target="_blank" rel="noopener">阿泽</a>作者的笔记，对于不理解的地方，我会添加个人注释。</p><h2 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h2><p>常见的集成学习框架有三种：Bagging，Boosting 和 Stacking。三种集成学习框架在基学习器的产生和综合结果的方式上会有些区别，我们先做些简单的介绍。</p><h3 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h3><p>Bagging 全称叫 <strong>B</strong>ootstrap <strong>agg</strong>regating（ Bootstrap 抽样方法） ，每个基学习器都会对训练集进行有放回抽样得到子训练集，比较著名的采样法为 0.632 自助法。每个基学习器基于不同子训练集进行训练，并综合所有基学习器的预测值得到最终的预测结果。Bagging 常用的综合方法是投票法，票数最多的类别为预测类别。</p><p><img src="/MachineLearning/机器学习/决策树（中）—— Random Forest、Adaboost、GBDT/v2-a0a3cb02f629f3db360fc68b4c2153c0_b.jpg" alt="img" style="zoom:80%;"></p><h3 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h3><p>Boosting 训练过程为阶梯状，基模型的训练是有顺序的，每个基模型都会在前一个基模型学习的基础上进行学习，最终综合所有基模型的预测值产生最终的预测结果，用的比较多的综合方式为加权法。</p><p><img src="/MachineLearning/机器学习/决策树（中）—— Random Forest、Adaboost、GBDT/v2-3aab53d50ab65e11ad3c9e3decf895c2_b.jpg" alt="img" style="zoom:80%;"></p><h3 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h3><p>Stacking 是先用全部数据训练好基模型，然后每个基模型都对每个训练样本进行的预测，其预测值将作为训练样本的特征值，最终会得到新的训练样本，然后基于新的训练样本进行训练得到模型。对测试集也做相同的操作，得到最终预测结果。</p><p><img src="/MachineLearning/机器学习/决策树（中）—— Random Forest、Adaboost、GBDT/v2-f6787a16c23950d129a7927269d5352a_b.jpg" alt="img" style="zoom:80%;"></p><blockquote><p>上图绿色是训练过程，红色是预测过程。</p></blockquote><p>那么，为什么集成学习会好于单个学习器呢？原因可能有三：</p><ol><li>训练样本可能无法选择出最好的单个学习器，由于没法选择出最好的学习器，所以干脆结合起来一起用；</li><li>假设能找到最好的学习器，但由于算法运算的限制无法找到最优解，只能找到次优解，采用集成学习可以弥补算法的不足；</li><li>可能算法无法得到最优解，而集成学习能够得到近似解。比如说最优解是一条对角线，而单个决策树得到的结果只能是平行于坐标轴的，但是集成学习可以去拟合这条对角线。</li></ol><h2 id="偏差与方差"><a href="#偏差与方差" class="headerlink" title="偏差与方差"></a>偏差与方差</h2><p>我们从偏差和方差的角度来理解集成学习。</p><h3 id="集成学习的偏差与方差"><a href="#集成学习的偏差与方差" class="headerlink" title="集成学习的偏差与方差"></a>集成学习的偏差与方差</h3><p>偏差（Bias）描述的是预测值和真实值之差；方差（Variance）描述的是预测值作为随机变量的离散程度。放一张很经典的图：</p><p><img src="/MachineLearning/机器学习/决策树（中）—— Random Forest、Adaboost、GBDT/v2-60c942f91d33d9dedf9dd2c7d482af5d_b.jpg" alt="img" style="zoom:67%;"></p><ul><li><strong>偏差：</strong>描述样本拟合出的模型的预测结果的期望与样本真实结果的差距，要想偏差表现的好，就需要复杂化模型，增加模型的参数，但这样容易过拟合，过拟合对应上图的 High Variance，点会很分散。低偏差对应的点都打在靶心附近，所以喵的很准，但不一定很稳；</li><li><strong>方差：</strong>描述样本上训练出来的模型在测试集上的表现，要想方差表现的好，需要简化模型，减少模型的复杂度，但这样容易欠拟合，欠拟合对应上图 High Bias，点偏离中心。低方差对应就是点都打的很集中，但不一定是靶心附近，手很稳，但不一定瞄的准。</li></ul><p>我们常说集成学习中的基模型是弱模型，通常来说弱模型是偏差高（在训练集上准确度低）方差小（防止过拟合能力强）的模型，<strong>但并不是所有集成学习框架中的基模型都是弱模型</strong>。<strong>Bagging 和 Stacking 中的基模型为强模型（偏差低，方差高），而Boosting 中的基模型为弱模型（偏差高，方差低）</strong>。</p><blockquote><p>弱模型，模型简单，偏差高，方差小，防止过拟合能力强；</p><p>强模型，模型复杂，偏差小，方差大，容易过拟合。</p></blockquote><p>在 Bagging 和 Boosting 框架中，通过计算基模型的期望和方差我们可以得到模型整体的期望和方差。为了简化模型，我们假设基模型的期望为 $\mu$ ，方差 $\sigma ^ 2$ ，模型的权重为 $r$ ，两两模型间的相关系数 $\rho$ 相等。由于 Bagging 和 Boosting 的基模型都是线性组成的，那么有：</p><p>模型总体期望：</p><script type="math/tex; mode=display">\begin{align} E(F) &= E(\sum_{i}^{m}{r_i f_i}) \\ &= \sum_{i}^{m}r_i E(f_i) \end{align} \\</script><p>模型总体方差（公式推导参考协方差的性质，协方差与方差的关系）：</p><script type="math/tex; mode=display">\begin{align} Var(F) &= Var(\sum_{i}^{m}{r_i f_i}) \\ &= \sum_{i}^{m}Var(r_if_i) + \sum_{i \neq j}^{m}Cov(r_i f_i , r_j f_j) \\ &= \sum_{i}^{m} {r_i}^2 Var(f_i) + \sum_{i \neq j}^{m}\rho r_i r_j \sqrt{Var(f_i)} \sqrt{Var(f_j)} \\ &= mr^2\sigma^2 + m(m-1)\rho r^2 \sigma^2\\ &= m r^2 \sigma^2 (1-\rho) + m^2 r^2 \sigma^2 \rho \end{align} \\</script><p>模型的准确度可由偏差和方差共同决定：</p><script type="math/tex; mode=display">Error = bias^2 + var + \xi \\</script><h3 id="Bagging-的偏差与方差"><a href="#Bagging-的偏差与方差" class="headerlink" title="Bagging 的偏差与方差"></a>Bagging 的偏差与方差</h3><p>对于 Bagging 来说，每个基模型的权重等于 1/m 且期望近似相等，故我们可以得到：</p><script type="math/tex; mode=display">\begin{align} E(F) & = \sum_{i}^{m}r_i E(f_i) \\ &= m \frac{1}{m} \mu \\ &= \mu \\ Var(F) &= m r^2 \sigma^2 (1-\rho) + m^2 r^2 \sigma^2 \rho \\ &= m \frac{1}{m^2} \sigma^2 (1-\rho) + m^2 \frac{1}{m^2} \sigma^2 \rho \\ &= \frac{\sigma^2(1 - \rho)}{m} + \sigma^2 \rho \end{align} \\</script><p>通过上式我们可以看到：</p><ul><li><strong>整体模型的期望等于基模型的期望，这也就意味着整体模型的偏差和基模型的偏差近似。</strong></li><li><strong>整体模型的方差小于等于基模型的方差，当且仅当相关性为 1 时取等号，随着基模型数量增多，整体模型的方差减少，从而防止过拟合的能力增强，模型的准确度得到提高。</strong>但是，模型的准确度一定会无限逼近于 1 吗？并不一定，当基模型数增加到一定程度时，方差公式第一项的改变对整体方差的作用很小，防止过拟合的能力达到极限，这便是准确度的极限了。</li></ul><p>在此我们知道了为什么 Bagging 中的基模型一定要为强模型，如果 Bagging 使用弱模型则会导致整体模型的偏差提高，而准确度降低。</p><p>Random Forest 是经典的基于 Bagging 框架的模型，并在此基础上通过引入特征采样和样本采样来降低基模型间的相关性，在公式中显著降低方差公式中的第二项，略微升高第一项，从而使得整体降低模型整体方差。</p><h3 id="Boosting-的偏差与方差"><a href="#Boosting-的偏差与方差" class="headerlink" title="Boosting 的偏差与方差"></a>Boosting 的偏差与方差</h3><p>对于 Boosting 来说，由于基模型共用同一套训练集，所以基模型间具有强相关性，故模型间的相关系数近似等于 1，针对 Boosting 化简公式为：</p><script type="math/tex; mode=display">\begin{align} E(F) & = \sum_{i}^{m}r_i E(f_i) \\ Var(F) &= m r^2 \sigma^2 (1-\rho) + m^2 r^2 \sigma^2 \rho \\ &= m \frac{1}{m^2} \sigma^2 (1-1) + m^2 \frac{1}{m^2} \sigma^2 1 \\&= \sigma^2 \end{align} \\</script><p>通过观察整体方差的表达式我们容易发现：</p><ul><li>整体模型的方差等于基模型的方差，如果基模型不是弱模型，其方差相对较大，这将导致整体模型的方差很大，即无法达到防止过拟合的效果。因此，Boosting 框架中的基模型必须为弱模型。</li><li>此外 Boosting 框架中采用基于贪心策略的前向加法，整体模型的期望由基模型的期望累加而成，所以随着基模型数的增多，整体模型的期望值增加，整体模型的准确度提高。</li></ul><p>基于 Boosting 框架的 Gradient Boosting Decision Tree 模型中基模型也为树模型，同 Random Forrest，我们也可以对特征进行随机抽样来使基模型间的相关性降低，从而达到减少方差的效果。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>我们可以使用模型的偏差和方差来近似描述模型的准确度；</li><li>对于 Bagging 来说，整体模型的偏差与基模型近似，而随着模型的增加可以降低整体模型的方差，故其基模型需要为强模型；</li><li>对于 Boosting 来说，整体模型的方差近似等于基模型的方差，而整体模型的偏差由基模型累加而成，故基模型需要为弱模型。</li></ul><h2 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h2><p>Random Forest（随机森林），用随机的方式建立一个森林。RF 算法由很多决策树组成，每一棵决策树之间没有关联。建立完森林后，当有新样本进入时，每棵决策树都会分别进行判断，然后基于投票法给出分类结果。</p><h3 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h3><p>Random Forest（随机森林）是 Bagging 的扩展变体，它在以决策树为基学习器构建 Bagging 集成的基础上，进一步在决策树的训练过程中引入了随机特征选择，因此可以概括 RF 包括四个部分：</p><ol><li>随机选择样本（放回抽样）；</li><li>随机选择特征；</li><li>构建决策树；</li><li>随机森林投票（平均）。</li></ol><p>随机选择样本和 Bagging 相同，采用的是 Bootstrap 自助采样法；随机选择特征具体来说，传统决策树在选择划分属性时是在当前节点的属性集合（假定有$d$个属性）中选择一个最优属性；而在RF中，对基决策树的每个节点，先<strong>从该节点的属性集合</strong>中随机选择一个包含$k$个属性的子集，然后再从这个子集中选择一个最优属性用于划分。这里的参数$k$控制了随机性的引入程度：若$k=d$，则基决策树的构建与传统决策树相同；若令$k=1$，则是随机选择一个属性用于划分；一般情况下，推荐值$k=log_2 d$。</p><p>这种随机性导致随机森林的偏差会有稍微的增加（相比于单棵不随机树），但是由于随机森林的“平均”特性，会使得它的方差减小，而且方差的减小补偿了偏差的增大，因此总体而言是更好的模型。</p><p>随机采样由于引入了两种采样方法保证了随机性，所以每棵树都是最大可能的进行生长就算不剪枝也不会出现过拟合。</p><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ol><li>在数据集上表现良好，相对于其他算法有较大的优势</li><li>易于并行化，在大数据集上有很大的优势；</li><li>能够处理高维度数据，不用做特征选择，不需要降维。</li><li>它可以判断特征的重要程度，可以判断出不同特征之间的相互影响</li><li>对于不平衡的数据集来说，它可以平衡误差</li><li>如果有很大一部分的特征遗失，仍可以维持准确度</li></ol><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ol><li>随机森林已经被证明在某些噪音较大的分类或回归问题上会过拟合。</li><li>对于有不同取值的属性的数据，取值划分较多的属性会对随机森林产生更大的影响，所以随机森林在这种数据上产出的属性权值是不可信的</li></ol><h2 id="Adaboost"><a href="#Adaboost" class="headerlink" title="Adaboost"></a>Adaboost</h2><p>AdaBoost（Adaptive Boosting，自适应增强），其自适应在于：<strong>前一个基本分类器分错的样本会得到加强，加权后的全体样本再次被用来训练下一个基本分类器。同时，在每一轮中加入一个新的弱分类器，直到达到某个预定的足够小的错误率或达到预先指定的最大迭代次数。</strong></p><h3 id="思想-1"><a href="#思想-1" class="headerlink" title="思想"></a>思想</h3><p>Adaboost 迭代算法有三步：</p><ol><li>初始化训练样本的权值分布，每个样本具有相同权重；</li><li>训练弱分类器，如果样本分类正确，则在构造下一个训练集中，它的权值就会被降低；反之提高。用更新过的样本集去训练下一个分类器；</li><li>将所有弱分类组合成强分类器，各个弱分类器的训练过程结束后，加大分类误差率小的弱分类器的权重，降低分类误差率大的弱分类器的权重。</li></ol><h3 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h3><p>Adaboost 模型是加法模型，学习算法为前向分步学习算法，损失函数为指数函数的分类问题。</p><p><strong>加法模型</strong>：最终的强分类器是由若干个弱分类器加权平均得到的。</p><script type="math/tex; mode=display">F_{k}(x)=\sum_{i=1}^{k}\alpha_i f_i(x)</script><p><strong>前向分布学习算法</strong>：算法是通过一轮轮的弱学习器学习，利用前一个弱学习器的结果来更新后一个弱学习器的训练集权重。第 k 轮的强学习器为：</p><script type="math/tex; mode=display">F_{k}(x)=\sum_{i=1}^{k}\alpha_i f_i(x)=F_{k-1}(x)+\alpha_{k}f_k(x) \\</script><p>定义损失函数为 n 个样本的指数损失函数，在分类正确的时候，指数部分为负数，单调递减；在分类错误的时候，指数部分为正数，单调递增，满足<strong>损失函数的定义</strong>：</p><script type="math/tex; mode=display">L(y,F) = \sum_\limits{i=1}^{n}exp(-y_iF_{k}(x_i)) \\</script><p>利用前向分布学习算法的关系可以得到：</p><script type="math/tex; mode=display">\begin{align} L(y, F) &= \sum_\limits{i=1}^{m}exp[(-y_i) (F_{k-1}(x_i) + \alpha_k f_k(x_i))] \\ &= \sum_\limits{i=1}^{m}exp[-y_i F_{k-1}(x_i) -y_i \alpha_k f_k(x_i)] \\ &= \sum_\limits{i=1}^{m}exp[-y_i F_{k-1}(x_i) ] exp[-y_i \alpha_k f_k(x_i)] \end{align} \\</script><p>因为 $F_{k-1}(x)$ 已知，所以令 $w_{k,i} = exp(-y_iF_{k-1}(x_i))$ ，随着每一轮迭代而将这个式子带入损失函数，损失函数转化为：</p><script type="math/tex; mode=display">L(y, F(x)) =\sum_\limits{i=1}^{m}w_{k,i}exp[-y_i\alpha_k f_k(x_i)] \\</script><p>于是分类器$f_k(x)$ 和这个分类器的权重$\alpha_k$可以表示成：</p><script type="math/tex; mode=display">\left(\alpha_{k}^{*}, f_{k}^{*}(x)\right)=\underbrace{\arg \min }_{\alpha, f} \sum_{i=1}^{N} {w}_{k i} \exp \left(-y_{i} \alpha_{k} f_{k}(x)\right)</script><p>我们<strong>先求</strong>$f_k(x)$ ，分类器的权重$\alpha_k$可以认为是一个确定的数，$f_k(x)$是使得分错的（带权重的）样本里损失函数最小的那个，可以得到：</p><script type="math/tex; mode=display">f_k(x) =\underbrace{\arg \min }_{f}\; \sum_\limits{i=1}^{m}w_{k,i}I(y_i \neq f_k(x_i)) \\</script><blockquote><p>注意：<strong>重点理解上面两个式子的等价性，这一步相当于针对不同权重的样本训练分类器</strong>。</p></blockquote><p>然后<strong>再求</strong>$\alpha_k$，将 $f_k(x)$ 带入损失函数，并对 $\alpha$ 求导，使其等于 0，则就得到了：</p><script type="math/tex; mode=display">\alpha_k = \frac{1}{2}log\frac{1-e_k}{e_k} \\</script><p>其中$e_k$ 即为我们前面的分类误差率。</p><script type="math/tex; mode=display">e_k = \frac{\sum\limits_{i=1}^{m}w_{ki}^{’}I(y_i \neq f_k(x_i))}{\sum\limits_{i=1}^{m}w_{ki}^{’}} = \sum\limits_{i=1}^{m}w_{ki}I(y_i \neq f_k(x_i)) \\</script><p><strong>最后</strong>看样本权重的更新。利用 $F_{k}(x) = F_{k-1}(x) + \alpha_kf_k(x)$ 和 $w_{k+1,i}=w_{k,i}exp[-y_i\alpha_kf_k(x,i)]$ ，即可得：</p><script type="math/tex; mode=display">w_{k+1,i} = w_{ki}exp[-y_i\alpha_kf_k(x_i)] \\</script><p>这样就得到了样本权重更新公式。</p><blockquote><p>$\alpha_k$的详细推导过程可以参考<a href="https://www.jianshu.com/p/0d850d85dcbd" target="_blank" rel="noopener">机器学习笔记：AdaBoost 公式推导</a>。</p></blockquote><p><strong>正则化</strong></p><p>为了防止 Adaboost 过拟合，我们通常也会加入正则化项，这个正则化项我们通常称为步长（learning rate）。对于前面的弱学习器的迭代</p><script type="math/tex; mode=display">F_{k}(x) = F_{k-1}(x) + \alpha_kf_k(x) \\</script><p>加上正则化项 $\mu$ 我们有：</p><script type="math/tex; mode=display">F_{k}(x) = F_{k-1}(x) + \mu\alpha_kf_k(x) \\</script><p>$\mu$ 的取值范围为 $0&lt;\mu\leq1$ 。对于同样的训练集学习效果，较小的 $\mu$ 意味着我们需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。</p><h3 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h3><h4 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h4><ol><li>分类精度高；</li><li>可以用各种回归分类模型来构建弱学习器，非常灵活；</li><li>不容易发生过拟合。</li></ol><h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><ol><li>对异常点敏感，异常点会获得较高权重。</li></ol><h2 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h2><p>GBDT（Gradient Boosting Decision Tree）是一种迭代的决策树算法，该算法由多棵决策树组成，从名字中我们可以看出来它是属于 Boosting 策略。GBDT 是被公认的泛化能力较强的算法。</p><p>Gradient Boosting 和其它 Boosting 算法一样，通过将表现一般的数个模型（通常是深度固定的决策树）组合在一起来集成一个表现较好的模型。抽象地说，模型的训练过程是对一任意可导目标函数的优化过程。通过反复地选择一个指向负梯度方向的函数，该算法可被看做在函数空间里对目标函数进行优化。因此可以说 Gradient Boosting = Gradient Descent + Boosting。</p><p>和 AdaBoost 一样，Gradient Boosting 也是重复选择一个表现一般的模型并且每次基于先前模型的表现进行调整。不同的是，AdaBoost 是通过提升错分数据点的权重来定位模型的不足而 Gradient Boosting 是通过算梯度（gradient）来定位模型的不足。因此相比 AdaBoost, Gradient Boosting 可以使用更多种类的目标函数。</p><h3 id="思想-2"><a href="#思想-2" class="headerlink" title="思想"></a>思想</h3><p>GBDT 由三个概念组成：Regression Decision Tree（即 DT）、Gradient Boosting（即 GB），和 Shrinkage（一个重要演变）</p><h4 id="回归树（Regression-Decision-Tree）"><a href="#回归树（Regression-Decision-Tree）" class="headerlink" title="回归树（Regression Decision Tree）"></a>回归树（Regression Decision Tree）</h4><p>如果认为 GBDT 由很多分类树那就大错特错了（虽然调整后也可以分类）。对于分类树而言，其值加减无意义（如性别），而对于回归树而言，其值加减才是有意义的（如说年龄）。GBDT 的核心在于累加所有树的结果作为最终结果，所以 GBDT 中的树都是回归树，不是分类树，这一点相当重要。</p><p>回归树在分枝时会穷举每一个特征的每个阈值以找到最好的分割点，衡量标准是最小化均方误差。</p><h4 id="梯度迭代（Gradient-Boosting）"><a href="#梯度迭代（Gradient-Boosting）" class="headerlink" title="梯度迭代（Gradient Boosting）"></a>梯度迭代（Gradient Boosting）</h4><p>上面说到 GBDT 的核心在于累加所有树的结果作为最终结果，GBDT 的每一棵树都是以之前树得到的残差来更新目标值，这样每一棵树的值加起来即为 GBDT 的预测值。</p><p>模型的预测值可以表示为：</p><script type="math/tex; mode=display">F_k(x) = \sum_{i=1}^{k}f_{i}(x) \\</script><p>$f_{i}(x)$ 为基模型与其权重的乘积，模型的训练目标是使预测值 $F_k(x)$ 逼近真实值 $y$，也就是说要让每个基模型的预测值逼近各自要预测的部分真实值。由于要同时考虑所有基模型，导致了整体模型的训练变成了一个非常复杂的问题。所以研究者们想到了一个贪心的解决手段：每次只训练一个基模型。那么，现在改写整体模型为迭代式：</p><script type="math/tex; mode=display">F_k(x) = F_{k-1}(x)+f_{k}(x)\\</script><p>这样一来，每一轮迭代中，只要集中解决一个基模型的训练问题：使 $F_k(x)$ 逼近真实值 $y$ 。</p><p>举个例子：比如说 A 用户年龄 20 岁，第一棵树预测 12 岁，那么残差就是 8，第二棵树用 8 来学习，假设其预测为 5，那么其残差即为 3，如此继续学习即可。</p><p>那么 Gradient 从何体现？其实很简单，其<strong>残差其实是最小均方损失函数关于预测值的反向梯度(划重点)</strong>：</p><script type="math/tex; mode=display">-\frac{\partial (\frac{1}{2}(y-F_{k}(x))^2)}{\partial F_k(x)} = y-F_{k}(x) \\</script><p>也就是说，<strong>预测值和实际值的残差与损失函数的负梯度相同</strong>。</p><p>但要注意，基于残差 GBDT 容易对异常值敏感，举例：</p><p><img src="/MachineLearning/机器学习/决策树（中）—— Random Forest、Adaboost、GBDT/v2-52f8fe9d1990c31335bf26c0c85d7ad5_b.jpg" alt="img" style="zoom:50%;"></p><p>很明显后续的模型会对第 4 个值关注过多，这不是一种好的现象，所以一般回归类的损失函数会用<strong>绝对损失或者 Huber 损失函数</strong>来代替平方损失函数。</p><p><img src="/MachineLearning/机器学习/决策树（中）—— Random Forest、Adaboost、GBDT/v2-c657e78a5a9e3646dc493a3f69556c8a_b.jpg" alt="img" style="zoom:50%;"></p><p>GBDT 的 Boosting 不同于 Adaboost 的 Boosting，<strong>GBDT 的每一步残差计算其实变相地增大了被分错样本的权重，而对与分对样本的权重趋于 0</strong>，这样后面的树就能专注于那些被分错的样本。</p><blockquote><p>可以理解：adaboost中是显示的设置了每个样本的权重，而gbdt则是由于错分样本导致残差变大，变相的加大了下一次基模型学习时样本的权重，所以两种方式不同，但有类似的效果。</p></blockquote><h4 id="缩减（Shrinkage）"><a href="#缩减（Shrinkage）" class="headerlink" title="缩减（Shrinkage）"></a>缩减（Shrinkage）</h4><p>Shrinkage 的思想认为，每走一小步逐渐逼近结果的效果要比每次迈一大步很快逼近结果的方式更容易避免过拟合。即它并不是完全信任每一棵残差树。</p><script type="math/tex; mode=display">F_i(x)=F_{i-1}(x)+\mu f_i(x) \quad (0<\mu \leq 1) \\</script><p>Shrinkage 不直接用残差修复误差，而是只修复一点点，把大步切成小步。本质上 Shrinkage 为每棵树设置了一个 weight，累加时要乘以这个 weight，当 weight 降低时，基模型数会配合增大。</p><h3 id="优缺点-2"><a href="#优缺点-2" class="headerlink" title="优缺点"></a>优缺点</h3><h4 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h4><ol><li>可以自动进行特征组合，拟合非线性数据；</li><li>可以灵活处理各种类型的数据。</li></ol><h4 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h4><ol><li>损失函数是MSE时，对异常点敏感。</li></ol><h3 id="与-Adaboost-的对比"><a href="#与-Adaboost-的对比" class="headerlink" title="与 Adaboost 的对比"></a>与 Adaboost 的对比</h3><h4 id="相同"><a href="#相同" class="headerlink" title="相同"></a>相同</h4><ol><li>都是 Boosting 家族成员，使用弱分类器；</li><li>都使用前向分布算法；</li></ol><h4 id="不同"><a href="#不同" class="headerlink" title="不同"></a>不同</h4><ol><li><strong>boosting策略不同</strong>：Adaboost强调Adaptive（自适应，每个新的模型都会基于前一个模型的表现结果进行调整），通过不断修改样本权重（增大分错样本权重，降低分对样本权重），不断加入弱分类器进行boosting；GBDT 则是在确定损失函数后，本轮 cart 树的拟合目标就是沿着损失函数相对于前一轮组合树模型的负梯度方向进行拟合，也就是希望最快速度地最小化预测值与真实值之间的差异；当损失函数选择为 square loss 时候，其沿着负梯度方向拟合表现为拟合残差（选择其他损失函数不一定表现出拟合残差的性质）。</li><li><strong>损失函数不同</strong>：AdaBoost 采用的是指数损失，GBDT 使用的是绝对损失或者 Huber 损失函数。</li></ol><h3 id="与LR-Linear-Regression-Logistic-Regression"><a href="#与LR-Linear-Regression-Logistic-Regression" class="headerlink" title="与LR(Linear Regression? Logistic Regression?)"></a>与LR(Linear Regression? Logistic Regression?)</h3><p>从决策边界来说，线性回归的决策边界是一条直线，逻辑回归的决策边界根据是否使用核函数可以是一条直线或者曲线（如下图所示），而GBDT的决策边界可能是很多条线。</p><p><img src="/MachineLearning/机器学习/决策树（中）—— Random Forest、Adaboost、GBDT/v2-044baf1462d172dc1abac7f953571138_b.jpg" alt="img" style="zoom:50%;"></p><p>GBDT并不一定总是好于线性回归或逻辑回归。根据没有免费的午餐原则，没有一个算法是在所有问题上都能好于另一个算法的。根据奥卡姆剃刀原则，如果GBDT和线性回归或逻辑回归在某个问题上表现接近，那么我们应该选择相对比较简单的线性回归或逻辑回归。具体选择哪一个算法还是要根据实际问题来决定。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://easyai.tech/ai-definition/random-forest/" target="_blank" rel="noopener">随机森林 – Random forest</a><br><a href="https://www.jianshu.com/p/0d850d85dcbd" target="_blank" rel="noopener">机器学习笔记：AdaBoost 公式推导</a><br><a href="https://zhuanlan.zhihu.com/p/86263786" target="_blank" rel="noopener">【机器学习】决策树（中）——Random Forest、Adaboost、GBDT （非常详细）</a><br><a href="https://zhuanlan.zhihu.com/p/42740654" target="_blank" rel="noopener">Adaboost, GBDT 与 XGBoost 的区别</a><br><a href="https://mp.weixin.qq.com/s/SRP1yTzqCJsniPfMpQHJ1w" target="_blank" rel="noopener">Boosting和AdaBoost的可视化的清晰的解释</a><br><a href="https://ixyzero.com/blog/archives/4242.html" target="_blank" rel="noopener">机器学习算法中GBDT与AdaBoost的区别与联系</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要参考了&lt;a href=&quot;https://www.zhihu.com/people/is-aze&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;阿泽&lt;/a&gt;作者的笔记，对于不理解的地方，我会添加个人注释。&lt;/p&gt;
&lt;h2 id=&quot;集成学习&quot;&gt;&lt;a href=&quot;#集成学习&quot; class=&quot;headerlink&quot; title=&quot;集成学习&quot;&gt;&lt;/a&gt;集成学习&lt;/h2&gt;&lt;p&gt;常见的集成学习框架有三种：Bagging，Boosting 和 Stacking。三种集成学习框架在基学习器的产生和综合结果的方式上会有些区别，我们先做些简单的介绍。&lt;/p&gt;
&lt;h3 id=&quot;Bagging&quot;&gt;&lt;a href=&quot;#Bagging&quot; class=&quot;headerlink&quot; title=&quot;Bagging&quot;&gt;&lt;/a&gt;Bagging&lt;/h3&gt;&lt;p&gt;Bagging 全称叫 &lt;strong&gt;B&lt;/strong&gt;ootstrap &lt;strong&gt;agg&lt;/strong&gt;regating（ Bootstrap 抽样方法） ，每个基学习器都会对训练集进行有放回抽样得到子训练集，比较著名的采样法为 0.632 自助法。每个基学习器基于不同子训练集进行训练，并综合所有基学习器的预测值得到最终的预测结果。Bagging 常用的综合方法是投票法，票数最多的类别为预测类别。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MachineLearning" scheme="https://www.zdaiot.com/categories/MachineLearning/"/>
    
      <category term="机器学习" scheme="https://www.zdaiot.com/categories/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="决策树" scheme="https://www.zdaiot.com/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>决策树（上）—— ID3、C4.5、CART</title>
    <link href="https://www.zdaiot.com/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%88%E4%B8%8A%EF%BC%89%E2%80%94%E2%80%94%20ID3%E3%80%81C4.5%E3%80%81CART/"/>
    <id>https://www.zdaiot.com/MachineLearning/机器学习/决策树（上）—— ID3、C4.5、CART/</id>
    <published>2022-10-26T13:25:11.000Z</published>
    <updated>2022-10-26T13:25:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近想学习一下LightGBM，一直对决策树不是很熟悉，所以学习一下~</p><p>本文主要参考了<a href="https://www.zhihu.com/people/is-aze" target="_blank" rel="noopener">阿泽</a>作者的笔记，对于不理解的地方，我会添加个人注释。</p><p>决策树是一个非常常见并且优秀的机器学习算法，它易于理解、可解释性强，其可作为分类算法，也可用于回归模型。</p><h2 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h2><p>这部分内容主要参考了<a href="https://www.cnblogs.com/codeshell/p/13948083.html" target="_blank" rel="noopener">决策树算法-理论篇-如何计算信息纯度 </a>。</p><h3 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h3><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p><strong>信息熵</strong>（一般用<strong>H</strong> 表示），度量信息熵的单位是<strong>比特</strong>。就是说，信息量的多少是可以量化的。一条信息量的多少与信息的不确定性有关，可以认为，信息量就等于不确定性的多少（信息的不确定度）。</p><p>设$X$是一个取有限个值的离散随机变量，其信息熵的计算公式如下：</p><script type="math/tex; mode=display">\mathrm{H}(\mathrm{X})=-\sum_{i=1}^{n} p\left(x_{i}\right) \log p\left(x_{i}\right)</script><p>其中，该公式的含义是：</p><ul><li>待分类的事物可以分在多个分类中，这里的$n$就是分类的数目</li><li>$H(X)$ 表示熵，数学含义是，所有类别包含的信息期望值</li><li>$\log p\left(x_{i}\right)$表示符号的信息值，$p\left(x_{i}\right) $是选择该类的概率，$p(x_i)=P(X=x_i), i=1,2,\dots, n$</li><li>公式中的$log$一般以2为底</li><li>由定义可知，熵只依赖于$X$的分布，而与$X$的取值无关，所以也可将$X$的熵记作$H(p)$。</li></ul><p>总之，就是要知道，信息量的多少是可以用数学公式计算出来的，用信息论中的专业术语就叫做信息熵。信息熵越大，信息量也就越大。</p><p>下面这张图片解释了信息熵的由来。</p><p><img src="/MachineLearning/机器学习/决策树（上）—— ID3、C4.5、CART/webp.webp" alt="img" style="zoom:80%;"></p><h4 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h4><p>假设我们有如下数据集：</p><div class="table-container"><table><thead><tr><th>序号</th><th>条件:天气晴朗?</th><th>条件:是否刮风?</th><th>结果:去踢球吗?</th></tr></thead><tbody><tr><td>1</td><td>是</td><td>否</td><td>去</td></tr><tr><td>2</td><td>是</td><td>是</td><td>不去</td></tr><tr><td>3</td><td>否</td><td>是</td><td>不去</td></tr><tr><td>4</td><td>否</td><td>否</td><td>不去</td></tr></tbody></table></div><p>可以看到这个表格中有4 行（第一行表头不算），4 列数据。一般在机器学习中，最后一列称为<strong>目标(target)</strong>，前边的列都称为<strong>特征(features)</strong>。</p><p>根据表格，我们可以知道，所有的分类共有2 种，也就是“去” 和“不去”，“去”出现了1 次，“不去”出现了3 次。</p><p>分别计算“去” 和“不去” 出现的概率：</p><ul><li><code>P(去) = 1 / 4 = 0.25</code></li><li><code>P(不去) = 3 / 4 = 0.75</code></li></ul><p>然后，根据熵的计算公式来计算“去”和“不去” 的信息熵，其中log 以2 为底：</p><ul><li><code>H(去) = 0.25 * log 0.25 = -0.5</code></li><li><code>H(不去) = 0.74 * log 0.75 = -0.31127812445913283</code></li></ul><p>所以，整个表格含有的信息量就是：</p><ul><li><code>H(表格) = -(H(去) + H(不去)) = 0.81127812445913283</code></li></ul><h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><p>将计算信息熵的过程用<code>Python</code> 代码实现，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="comment"># 本函数用于计算一组数据的信息熵</span></span><br><span class="line"><span class="comment"># data_set 是一个列表，代表一组数据</span></span><br><span class="line"><span class="comment"># data_set 的元素data 也是一个列表</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_ent</span><span class="params">(data_set)</span>:</span></span><br><span class="line">    labels = &#123;&#125; <span class="comment"># 用于统计每个label 的数量</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> data_set:</span><br><span class="line">        label = data[<span class="number">-1</span>]<span class="comment"># 只用最后一个元素做计算</span></span><br><span class="line">        <span class="keyword">if</span> label <span class="keyword">not</span> <span class="keyword">in</span> labels:</span><br><span class="line">            labels[label] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        labels[label] += <span class="number">1</span> </span><br><span class="line"></span><br><span class="line">    ent = <span class="number">0</span> <span class="comment"># 熵</span></span><br><span class="line">    n = len(data_set)   <span class="comment"># 数据条数</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算信息熵</span></span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> labels:</span><br><span class="line">        prob = float(labels[label]) / n <span class="comment"># label 的概率</span></span><br><span class="line">        ent -= prob * math.log(prob, <span class="number">2</span>) <span class="comment"># 根据信息熵公式计算</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ent</span><br></pre></td></tr></table></figure><p>下面用该函数来计算表格的信息熵：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将表格转化为 python 列表</span></span><br><span class="line"><span class="comment"># "yes" 表示"去"</span></span><br><span class="line"><span class="comment"># "no" 表示"不去"</span></span><br><span class="line">data_set = [[<span class="string">'yes'</span>], [<span class="string">'no'</span>], [<span class="string">'no'</span>], [<span class="string">'no'</span>]] </span><br><span class="line">ent = calc_ent(data_set)</span><br><span class="line">print(ent)<span class="comment"># 0.811278124459</span></span><br></pre></td></tr></table></figure><p>可见，用代码计算出来的结果是 <strong>0.811278124459</strong>，跟我们手算的结果 <strong>0.81127812445913283</strong> 是一样的（保留的小数位数不同）。</p><h3 id="信息纯度"><a href="#信息纯度" class="headerlink" title="信息纯度"></a>信息纯度</h3><p>信息的纯度与信息熵成反比，可以将信息熵理解为 <strong>“不纯度”</strong> 。</p><ul><li>信息熵越大，信息量越大，数据不确定性越高，信息越杂乱，纯度越低。意味着分类的各个类型占比近似很难区分</li><li>信息熵越小，信息量越小，数据不确定性越低，信息越规整，纯度越高。意味着在数据集里我们要分类的某一种类型占比很高</li></ul><p>举一个例子，比如我们想分类A和B，用公式量化来体现就是：</p><p>1）如果分类结果中A和B各占50%，那么意味着分类结果很失败，这无异于随机地乱猜，完全没起到分类效果，公式计算结果如下：</p><p><img src="/MachineLearning/机器学习/决策树（上）—— ID3、C4.5、CART/640-1666945135086-9.png" alt="图片" style="zoom: 80%;"></p><p>2）如果分类结果中A占比100%，B占比0%或者B占比100%，A占比0%时，那么意味着分类很成功，因为我们成功地区分了A和B，我们就说此时的纯度很高，公式计算结果如下：</p><p><img src="/MachineLearning/机器学习/决策树（上）—— ID3、C4.5、CART/640-1666945150778-12.png" alt="图片" style="zoom:80%;"></p><h3 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h3><p>条件熵$H(Y|X)$表示在已知随机变量$X$的条件下随机变量$Y$的不确定性。随机变量$X$给定的条件下随机变量$Y$的条件熵$H(Y|X)$，定义为$X$给定条件下$Y$的条件概率分布的熵对$X$的数学期望。</p><script type="math/tex; mode=display">H(Y \mid X)=\sum_{i=1}^{n} p(x_i) H\left(Y \mid X=x_{i}\right)</script><h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><h4 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h4><p><strong>信息增益就是，在根据某个属性划分数据集的前后，信息量发生的变化。</strong></p><blockquote><p>信息熵代表不纯度，只要将分类前后的不纯度相减，那就可以得到一种 <strong>“纯度提升值”</strong> 的指标，我们把它叫做 <strong>“信息增益”</strong>。</p></blockquote><p>特征$A$对训练数据集$D$的信息增益$Gain(D,A)$，定义为集合$D$的经验熵$H(D)$与特征$A$给定条件下$D$的条件熵$H(D|A)$之差。信息增益的计算公式如下：</p><script type="math/tex; mode=display">Gain(D,A)=H(D)-H(D|A)</script><p>所有子节点的信息熵会按照子节点在父节点中的出现的概率来计算，这叫做<strong>归一化信息熵</strong>。</p><p><strong>信息增益的目的在于，将数据集划分之后带来的纯度提升，也就是信息熵的下降</strong>。如果数据集在根据某个属性划分之后，能够获得最大的信息增益，那么这个属性就是最好的选择。</p><p>所以，我们想要找到根节点，就需要计算每个属性作为根节点时的信息增益，那么获得信息增益最大的那个属性，就是根节点。</p><h4 id="计算-1"><a href="#计算-1" class="headerlink" title="计算"></a>计算</h4><p><strong>信息增益等于按照某个属性划分前后的信息熵之差。</strong>它的计算方式简单来说，先基于特征A进行划分，再基于目标变量进行划分，这是一个嵌套的过程。</p><p>这个表格划分之前的信息熵我们已经知道了，就是我们在上面计算的结果：</p><ul><li><code>H(表格) = 0.81127812445913283</code>。</li></ul><p>接下来，我们计算按照“天气晴朗”划分的信息增益。按照“天气晴朗”划分后有两个表格。</p><p>表格1，“天气晴朗”的值为“是”：</p><div class="table-container"><table><thead><tr><th>序号</th><th>条件:天气晴朗?</th><th>条件:是否刮风?</th><th>结果:去踢球吗?</th></tr></thead><tbody><tr><td>1</td><td><strong>是</strong></td><td>否</td><td>去</td></tr><tr><td>2</td><td><strong>是</strong></td><td>是</td><td>不去</td></tr></tbody></table></div><p>分类共有2 种，也就是“去” 和“不去”，“去”出现了1 次，“不去”出现了1 次。</p><p>所以，“去” 和“不去” 出现的概率均为0.5：</p><ul><li><code>P(去) = P(不去) = 1 / 2 = 0.5</code></li></ul><p>然后，“去”和“不去” 的信息熵，其中log 以2 为底：</p><ul><li><code>H(去) = H(不去) = 0.5 * log 0.5 = -0.5</code></li></ul><p>所以，表格1 含有的信息量就是：</p><ul><li><code>H(表格1) = -(H(去) + H(不去)) = 1</code></li></ul><p>表格2，“天气晴朗”的值为“否”：</p><div class="table-container"><table><thead><tr><th>序号</th><th>条件:天气晴朗?</th><th>条件:是否刮风?</th><th>结果:去踢球吗?</th></tr></thead><tbody><tr><td>3</td><td><strong>否</strong></td><td>是</td><td>不去</td></tr><tr><td>4</td><td><strong>否</strong></td><td>否</td><td>不去</td></tr></tbody></table></div><p>所有的分类只有1 种，是“不去”。所以：</p><ul><li><code>P(不去) = 1</code></li></ul><p>然后，“不去” 的信息熵，其中log 以2 为底：</p><ul><li><code>H(不去) = 1 * log 1 = 0</code></li></ul><p>所以，表格2 含有的信息量就是：</p><ul><li><code>H(表格2) = 0</code></li></ul><p>总数据共有4 份：</p><ul><li>表格1 中有2 份，概率为 2/4 = 0.5</li><li>表格2 中有2 份，概率为 2/4 = 0.5</li></ul><p>所以，最终按照“天气晴朗”划分的信息增益为：</p><ul><li><code>G(天气晴朗) = H(表格) - (0.5*H(表格1) + 0.5*H(表格2)) = H(表格) - 0.5 = 0.31127812445913283。</code></li></ul><h2 id="决策树概述"><a href="#决策树概述" class="headerlink" title="决策树概述"></a>决策树概述</h2><p>不同于逻辑回归，决策树属于<strong>非线性模型</strong>，可以用于分类，也可用于回归。它是一种树形结构，可以认为是if-then规则的集合，是以实例为基础的归纳学习。基本思想是自顶向下，以信息增益（或信息增益比，基尼系数等）为度量构建一颗度量标准下降最快的树，每个内部节点代表一个属性的测试，直到叶子节点处只剩下同一类别的样本。它的决策流程如下所示：</p><p><img src="/MachineLearning/机器学习/决策树（上）—— ID3、C4.5、CART/640.png" alt="图片" style="zoom:80%;"></p><h2 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a>ID3</h2><p>ID3 算法是建立在奥卡姆剃刀（用较少的东西，同样可以做好事情）的基础上：越是小型的决策树越优于大的决策树。</p><blockquote><p>奥卡姆剃刀：“如无必要，勿增实体”，即“简单有效原理”。</p></blockquote><h3 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h3><p>从信息论的知识中我们知道：信息熵越大，从而样本纯度越低。ID3 算法的核心思想就是以信息增益来度量特征选择，选择信息增益最大的特征进行分裂。算法采用自顶向下的贪婪搜索遍历可能的决策树空间（C4.5 也是贪婪搜索）。 其大致步骤为：</p><ol><li>初始化特征集合和数据集合；</li><li>计算数据集合信息熵和所有特征的条件熵，选择信息增益最大的特征作为当前决策节点；</li><li>更新数据集合和特征集合（删除上一步使用的特征，并按照特征值来划分不同分支的数据集合）；</li><li>重复 2，3 两步，若子集值包含单一特征，则为分支叶子节点。</li></ol><blockquote><p>从这个过程，我们可以发现：最开始选择的特征肯定是提供信息量最大的，因为它是遍历所有特征后选择的结果。因此，<strong>按照决策过程中特征从上到下的顺序，我们也可以将特征的重要程度进行排序。</strong>这也就解释了为什么树模型有feature_importance这个参数了。</p></blockquote><h3 id="划分标准"><a href="#划分标准" class="headerlink" title="划分标准"></a>划分标准</h3><p>ID3 使用的分类标准是信息增益，它表示得知特征 A 的信息而使得样本集合不确定性减少的程度。</p><p>数据集的信息熵：</p><script type="math/tex; mode=display">H(D)=-\sum_{k=1}^{K} \frac{\left|C_{k}\right|}{|D|} \log _{2} \frac{\left|C_{k}\right|}{|D|}</script><p>其中$C_k$表示集合$D$中属于第$k$类样本的样本子集。</p><p>针对某个特征 $A$，对于数据集 $D$ 的条件熵 $H(D|A)$为：</p><script type="math/tex; mode=display">\begin{aligned} H(D \mid A) &=\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} H\left(D_{i}\right) \\ &=-\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|}\left(\sum_{k=1}^{K} \frac{\left|D_{i k}\right|}{\left|D_{i}\right|} \log _{2} \frac{\left|D_{i k}\right|}{\left|D_{i}\right|}\right) \end{aligned}</script><p>其中 $D_i$ 表示 $D$ 中特征 $A$ 取第$ i$ 个值的样本子集，$ D_{ik}$ 表示$ D_i $中属于第$ k $类的样本子集。</p><p>信息增益 = 信息熵 - 条件熵：</p><script type="math/tex; mode=display">Gain(D,A)=H(D)-H(D|A)</script><p>信息增益越大表示使用特征 A 来划分所获得的“纯度提升越大”。</p><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li>ID3 没有剪枝策略，容易过拟合；</li><li>信息增益准则对可取值数目较多的特征有所偏好，类似“编号”的特征其信息增益接近于 1。这是因为当特征的取值较多时，根据此特征划分更容易得到纯度更高的子集，条件熵越小，因此划分之后的熵更低，由于划分前的熵是一定的，因此信息增益更大，因此信息增益比较偏向取值较多的特征；</li><li>只能用于处理离散分布的特征；</li><li>没有考虑缺失值。</li></ul><h2 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h2><p>C4.5 算法最大的特点是克服了 ID3 对特征数目的偏重这一缺点，引入信息增益率来作为分类标准。</p><h3 id="思想-1"><a href="#思想-1" class="headerlink" title="思想"></a>思想</h3><p>C4.5 相对于 ID3 的缺点对应有以下改进方式：</p><ul><li>引入悲观剪枝策略进行后剪枝；</li><li>引入信息增益率作为划分标准；</li><li>将连续特征离散化，假设 n 个样本的连续特征 A 有 m 个取值，C4.5 将其排序并取相邻两样本值的平均数共 m-1 个划分点，分别计算以该划分点作为二元分类点时的信息增益，并选择信息增益最大的点作为该连续特征的二元离散分类点。</li></ul><p>对于缺失值的处理可以分为两个子问题：</p><ul><li><p>问题一：在特征值缺失的情况下进行划分特征的选择？（即如何计算特征的信息增益率）</p><p>C4.5 的做法是：对于具有缺失值特征，用没有缺失的样本子集所占比重来折算；</p></li><li><p>问题二：选定该划分特征，对于缺失该特征值的样本如何处理？（即到底把这个样本划分到哪个结点里）</p><p>C4.5 的做法是：将样本同时划分到所有子节点，不过要调整样本的权重值，其实也就是以不同概率划分到不同节点中。</p></li></ul><h3 id="划分标准-1"><a href="#划分标准-1" class="headerlink" title="划分标准"></a>划分标准</h3><p>利用信息增益率可以克服信息增益的缺点，其公式为</p><script type="math/tex; mode=display">\begin{aligned} Gain_{ratio}(D,A)&=\frac{Gain(D,A)}{H_A(D)} \\ H_A(D) &=-\sum_{i=1}^{n}\frac{|D_i|}{|D|}log_2\frac{|D_i|}{|D|} \end{aligned} \\</script><p>$H_A(D)$ 称为特征 $A$ 的固有值，$n$是特征$A$取值的个数。它的计算公式与熵类似，只不过数据集的熵是依据类别进行划分的，而这里是将特征A取值相同的样本划分到同一个子集中，来计算熵。</p><blockquote><p>信息增益比本质： 是在信息增益的基础之上乘上一个惩罚参数——分裂信息(Split information)。特征个数较多时，惩罚参数较小；特征个数较少时，惩罚参数较大。</p></blockquote><p>这里需要注意，信息增益率对可取值较少的特征有所偏好（分母越小，整体越大），因此 C4.5 并不是直接用增益率最大的特征进行划分，而是使用一个<strong>启发式方法</strong>：先从候选划分特征中找到信息增益高于平均值的特征，再从中选择增益率最高的。</p><h3 id="剪枝策略"><a href="#剪枝策略" class="headerlink" title="剪枝策略"></a>剪枝策略</h3><p>为什么要剪枝：过拟合的树在泛化能力的表现非常差。</p><h4 id="预剪枝"><a href="#预剪枝" class="headerlink" title="预剪枝"></a>预剪枝</h4><p>在节点划分前来确定是否继续增长，及早停止增长的主要方法有：</p><ul><li>节点内数据样本低于某一阈值；</li><li>所有节点特征都已分裂；</li><li>节点划分前准确率比划分后准确率高。</li></ul><p>预剪枝不仅可以降低过拟合的风险而且还可以减少训练时间，但另一方面它是基于“贪心”策略，会带来欠拟合风险。</p><h4 id="后剪枝"><a href="#后剪枝" class="headerlink" title="后剪枝"></a>后剪枝</h4><p>在已经生成的决策树上进行剪枝，从而得到简化版的剪枝决策树。</p><p>C4.5 采用的<strong>悲观剪枝方法</strong>，用递归的方式从低往上针对每一个非叶子节点，评估用一个最佳叶子节点去代替这课子树是否有益。如果剪枝后与剪枝前相比其错误率是保持或者下降，则这棵子树就可以被替换掉。C4.5 通过训练数据集上的错误分类数量来估算未知样本上的错误率。</p><p>后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但同时其训练时间会大的多。</p><h3 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h3><ul><li>剪枝策略可以再优化；</li><li>C4.5 用的是多叉树，用二叉树效率更高；</li><li>C4.5 只能用于分类；</li><li>C4.5 使用的熵模型拥有大量耗时的对数运算，连续值还有排序运算；</li><li>C4.5 在构造树的过程中，对数值属性值需要按照其大小进行排序，从中选择一个分割点，所以只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时，程序无法运行。</li></ul><h2 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h2><p>ID3 和 C4.5 虽然在对训练样本集的学习中可以尽可能多地挖掘信息，但是其生成的决策树分支、规模都比较大，CART 算法的二分法可以简化决策树的规模，提高生成决策树的效率。</p><h3 id="思想-2"><a href="#思想-2" class="headerlink" title="思想"></a>思想</h3><p>CART 包含的基本过程有分裂，剪枝和树选择。</p><ul><li><strong>分裂：</strong>分裂过程是一个二叉递归划分过程，其输入和预测特征既可以是连续型的也可以是离散型的，CART 没有停止准则，会一直生长下去；</li><li><strong>剪枝：</strong>采用<strong>代价复杂度剪枝</strong>，从最大树开始，每次选择训练数据熵对整体性能贡献最小的那个分裂节点作为下一个剪枝对象，直到只剩下根节点。CART 会产生一系列嵌套的剪枝树，需要从中选出一颗最优的决策树；</li><li><strong>树选择：</strong>用单独的测试集评估每棵剪枝树的预测性能（也可以用交叉验证）。</li></ul><p>CART 在 C4.5 的基础上进行了很多提升。</p><ul><li>C4.5 为多叉树，运算速度慢，CART 为二叉树，运算速度快；</li><li>C4.5 只能分类，CART 既可以分类也可以回归；</li><li>CART 使用 Gini 系数作为变量的不纯度量，减少了大量的对数运算；</li><li>CART 采用代理测试来估计缺失值，而 C4.5 以不同概率划分到不同节点中；</li><li>CART 采用“基于代价复杂度剪枝”方法进行剪枝，而 C4.5 采用悲观剪枝方法。</li></ul><h3 id="划分标准-2"><a href="#划分标准-2" class="headerlink" title="划分标准"></a>划分标准</h3><p>熵模型拥有大量耗时的对数运算，基尼指数在简化模型的同时还保留了熵模型的优点。基尼指数代表了模型的不纯度，基尼系数越小，不纯度越低，特征越好。所以决策树分裂选取Feature的时候，要选择使基尼指数最小的Feature，但注意信息增益（率）则是选择最大值，这个值的选取是相反的。</p><p>对于给定的样本集合$D$，其基尼指数定义为：</p><script type="math/tex; mode=display">\begin{aligned} Gini(D)&=\sum_{k=1}^{K}\frac{|C_k|}{|D|}(1-\frac{|C_k|}{|D|}) \\ &=1-\sum_{k=1}^{K}(\frac{|C_k|}{|D|})^2 \end{aligned} \\</script><p>在特征$A$的条件下，集合$D$的基尼指数定义为：</p><script type="math/tex; mode=display">\\ Gini(D|A) &= \sum_{i=1}^{n}\frac{|D_i|}{|D|}Gini(D_i)</script><p>其中 $k$ 代表类别。</p><p>基尼指数反映了从<strong>数据集中随机抽取两个样本，其类别标记不一致的概率</strong>。因此基尼指数越小，则数据集纯度越高。基尼指数偏向于特征值较多的特征，类似信息增益。基尼指数可以用来度量任何不均匀分布，是介于 0~1 之间的数，0 是完全相等，1 是完全不相等，</p><p>此外，当 CART 为二分类，其表达式为：</p><script type="math/tex; mode=display">Gini(D|A)=\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2) \\</script><p>我们可以看到在平方运算和二分类的情况下，其运算更加简单。当然其性能也与熵模型非常接近。</p><p>那么问题来了：基尼指数与熵模型性能接近，但到底与熵模型的差距有多大呢？</p><p>我们知道 $ln(x) = -1+x +o(x)$ ，所以</p><script type="math/tex; mode=display">\begin{aligned} H(X)&=-\sum_{k=1}^{K} p_{k} \ln p_{k}\\&\approx \sum_{k=1}^{K} p_{k}\left(1-p_{k}\right) \end{aligned} \\</script><p>我们可以看到，基尼指数可以理解为熵模型的一阶泰勒展开。这边在放上一张很经典的图：</p><p><img src="/MachineLearning/机器学习/决策树（上）—— ID3、C4.5、CART/640-1666947861684-15.jpeg" alt="图片" style="zoom:80%;"></p><h3 id="特征处理"><a href="#特征处理" class="headerlink" title="特征处理"></a>特征处理</h3><h4 id="连续特征"><a href="#连续特征" class="headerlink" title="连续特征"></a>连续特征</h4><p><strong>如果特征值是连续值：</strong>特征a有连续值m个，从小到大排列。m个数值就有m-1个切分点，分别使用每个切分点把连续数值离散划分成两类，将节点数据集按照划分点分为D1和D2子集，然后计算每个划分点下对应的基尼指数，对比所有信息增益比（CART基尼指数），选择值最小（最大）的一个作为最终的特征划分。</p><p><img src="/MachineLearning/机器学习/决策树（上）—— ID3、C4.5、CART/640-1667184073450-18.jpeg" alt="图片" style="zoom:67%;"></p><p>以上就实现了将连续特征值离散化，但是<strong>CART与ID3，C4.5处理离散属性不同的是：如果当前节点为连续属性，则该属性（剩余的属性值）后面还可以参与子节点的产生选择过程。</strong></p><h4 id="离散特征"><a href="#离散特征" class="headerlink" title="离散特征"></a>离散特征</h4><p><strong>如果特征值是离散值：</strong>CART的处理思想与C4.5稍微所有不同。如果离散特征值多于两个，那么C4.5会在节点上根据特征值划分出多叉树。但是CART则不同，无论离散特征值有几个，在节点上都划分成二叉树。CART树是如何进行分类的呢？</p><p>还是假设特征a有m个离散值。分类标准是：每一次将其中一个特征分为一类，其它非该特征分为另外一类。依照这个标准遍历所有的分类情况，计算每种分类下的基尼指数，最后选择值最小的一个作为最终的特征划分。</p><p><img src="/MachineLearning/机器学习/决策树（上）—— ID3、C4.5、CART/640-1667184294370-21.png" alt="图片" style="zoom:67%;"></p><p><strong>特征值连续和离散有各自的处理方法，不应该混淆使用。比如分类0,1,2只代表标签含义，如果进行加减的运算或者求平均则没有任何意义。因此，CART分类树会根据特征类型选择不同的划分方法，并且与C4.5不同是，它永远只有两个分支。</strong></p><p><img src="/MachineLearning/机器学习/决策树（上）—— ID3、C4.5、CART/640-1667184356009-24.jpeg" alt="图片" style="zoom:67%;"></p><h3 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h3><p>上文说到，模型对于缺失值的处理会分为两个子问题：</p><ol><li>如何在特征值缺失的情况下进行划分特征的选择？</li><li>选定该划分特征，模型对于缺失该特征值的样本该进行怎样处理？</li></ol><p>对于问题 1，CART 一开始严格要求分裂特征评估时只能使用在该特征上没有缺失值的那部分数据，在后续版本中，CART 算法使用了一种惩罚机制来抑制提升值，从而反映出缺失值的影响（例如，如果一个特征在节点的 20% 的记录是缺失的，那么这个特征就会减少 20% 或者其他数值）。</p><p>对于问题 2，CART 算法的机制是为树的每个节点都找到代理分裂器，无论在训练数据上得到的树是否有缺失值都会这样做。在代理分裂器中，特征的分值必须超过默认规则的性能才有资格作为代理（即代理就是代替缺失值特征作为划分特征的特征），当 CART 树中遇到缺失值时，这个实例划分到左边还是右边是决定于其排名最高的代理，如果这个代理的值也缺失了，那么就使用排名第二的代理，以此类推，如果所有代理值都缺失，那么默认规则就是把样本划分到较大的那个子节点。代理分裂器可以确保无缺失训练数据上得到的树可以用来处理包含确实值的新数据。</p><h3 id="剪枝策略-1"><a href="#剪枝策略-1" class="headerlink" title="剪枝策略"></a>剪枝策略</h3><p>采用一种“基于代价复杂度的剪枝”方法进行后剪枝，这种方法会生成一系列树，每个树都是通过将前面的树的某个或某些子树替换成一个叶节点而得到的，这一系列树中的最后一棵树仅含一个用来预测类别的叶节点。然后用一种成本复杂度的度量准则来判断哪棵子树应该被一个预测类别值的叶节点所代替。这种方法需要使用一个单独的测试数据集来评估所有的树，根据它们在测试数据集熵的分类性能选出最佳的树。</p><p>我们来看具体看一下代价复杂度剪枝算法：</p><p>首先我们将最大树称为 $T_0$，我们希望减少树的大小来防止过拟合，但又担心去掉节点后预测误差会增大，所以我们定义了一个损失函数来达到这两个变量之间的平衡。损失函数定义如下：</p><script type="math/tex; mode=display">C_\alpha(T)=C(T)+\alpha|T| \\</script><p>$T$ 为任意子树，$ C(T) $为预测误差， $|T|$ 为子树 $T$ 的叶子节点个数， $\alpha$ 是参数，$ C(T) $衡量训练数据的拟合程度， $|T| $衡量树的复杂度， $\alpha$ 权衡拟合程度与树的复杂度。</p><p>那么如何找到合适的 $\alpha$ 来使得复杂度和拟合度达到最好的平衡点呢，最好的办法就是令$ \alpha$ 从 0 取到正无穷，对于每一个固定的 $\alpha $，我们都可以找到使得 $C_\alpha(T) $最小的最优子树 $T(\alpha) $。当$ \alpha$ 很小的时候，$ T_0$ 是最优子树；当 $\alpha $最大时，单独的根节点是这样的最优子树。随着 $\alpha$ 增大，我们可以得到一个这样的子树序列：$ T_0, T_1, T_2, T_3, … ,T_n$ ，这里的子树$ T_{i+1} $生成是根据前一个子树 $T_i $剪掉某一个内部节点生成的。</p><p>Breiman 证明：将 $\alpha$ 从小增大， $0=\alpha_0&lt;\alpha_0&lt;…&lt;\alpha_n&lt;\infty$ ，在每个区间$ [\alpha_i,\alpha_{i+1}) $中，子树 $T_i $是这个区间里最优的。</p><p>这是代价复杂度剪枝的核心思想。</p><p>我们每次剪枝都是针对某个非叶节点，其他节点不变，所以我们只需要计算该节点剪枝前和剪枝后的损失函数即可。</p><p>对于任意内部节点 $t$，剪枝前的状态，有 $|T_t|$ 个叶子节点，预测误差是$ C(T_t) $；剪枝后的状态：只有本身一个叶子节点，预测误差是$ C(t) $。</p><p>因此剪枝前以 $t $节点为根节点的子树的损失函数是：</p><script type="math/tex; mode=display">C_\alpha(T)=C(T_t)+\alpha|T| \\</script><p>剪枝后的损失函数是</p><script type="math/tex; mode=display">C_\alpha(t) = C(t)+\alpha \\</script><p>通过 Breiman 证明我们知道一定存在一个 $\alpha $使得 $C_\alpha(T)=C_\alpha(t)$ ，使得这个值为：</p><script type="math/tex; mode=display">\alpha = \frac{C(t)-C(T_t)}{|T_t|-1} \\</script><p>$\alpha$ 的意义在于，$ [\alpha_i,\alpha_{i+1}) $中，子树 $T_i $是这个区间里最优的。当 $\alpha $大于这个值是，一定有 $C_\alpha(T)&gt;C_\alpha(t)$ ，也就是剪掉这个节点后都比不剪掉要更优。所以每个最优子树对应的是一个区间，在这个区间内都是最优的。</p><p>然后我们对 $T_i$ 中的每个内部节点$ t $都计算：</p><script type="math/tex; mode=display">g(t) = \frac{C(t)-C(T_t)}{|T_t|-1} \\</script><p>$g(t)$ 表示阈值，故我们每次都会减去最小的$ T_t $。</p><h3 id="类别不平衡"><a href="#类别不平衡" class="headerlink" title="类别不平衡"></a>类别不平衡</h3><p>CART 的一大优势在于：无论训练数据集有多失衡，它都可以将其子冻消除不需要建模人员采取其他操作。</p><p>CART 使用了一种先验机制，其作用相当于对类别进行加权。这种先验机制嵌入于 CART 算法判断分裂优劣的运算里，在 CART 默认的分类模式中，总是要计算每个节点关于根节点的类别频率的比值，这就相当于对数据自动重加权，对类别进行均衡。</p><p>对于一个二分类问题，节点 node 被分成类别 1 当且仅当：</p><script type="math/tex; mode=display">\frac{N_1(node)}{N_1(root)} > \frac{N_0(node)}{N_0(root)} \\</script><p>比如二分类，根节点属于 1 类和 0 类的分别有 20 和 80 个。在子节点上有 30 个样本，其中属于 1 类和 0 类的分别是 10 和 20 个。如果 10/20&gt;20/80，该节点就属于 1 类。</p><p>通过这种计算方式就无需管理数据真实的类别分布。假设有 $K $个目标类别，就可以确保根节点中每个类别的概率都是$ 1/K$。这种默认的模式被称为“先验相等”。</p><p>先验设置和加权不同之处在于先验不影响每个节点中的各类别样本的数量或者份额。先验影响的是每个节点的类别赋值和树生长过程中分裂的选择。</p><h3 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h3><p>CART（Classification and Regression Tree，分类回归树），从名字就可以看出其不仅可以用于分类，也可以应用于回归。与分类树不同，回归树的预测变量是连续值，比如预测一个人的年龄，又或者预测季度的销售额等等。另外，回归树在<strong>选择特征的度量标准</strong>和<strong>决策树建立后预测的方式</strong>上也存在不同。</p><h4 id="连续值处理"><a href="#连续值处理" class="headerlink" title="连续值处理"></a>连续值处理</h4><p>对于连续值，CART 分类树采用基尼系数的大小来度量特征的各个划分点。在回归模型中，我们使用常见的RSS<strong>残差平方和</strong>。线性回归的损失函数是以最小化离差平方和的形式给出的，回归树使用的度量标准也是一样的，通过最小化残差平方和作为判断标准，公式如下：</p><script type="math/tex; mode=display">\min _{j, s}\left[\min _{c_{1}} \sum_{x_{i} \in R_{1}(j, s)}\left(y_{i}-c_{1}\right)^{2}+\min _{c_{2}} \sum_{x_{2} \in R_{2}(j, s)}\left(y_{i}-c_{2}\right)^{2}\right]</script><p>其中，$R_1、R_2$是划分的两个子集，回归树是二叉树，固只有两个子集； $c_1、c_2$是$R_1、R_2$子集的样本均值，$y_i$是样本目标变量的真实值，$j$是当前的样本特征，$s$是划分点。</p><p>上面公式的含义是：计算所有的特征以及相应所有切分点下的残差平方和，找到一组(特征$j$，切分点$s$)，以满足：分别最小化左子树和右子树的残差平方和，并在此基础上再次最小化二者之和。</p><h4 id="预测方式"><a href="#预测方式" class="headerlink" title="预测方式"></a>预测方式</h4><p>对于决策树建立后做预测的方式，上面讲到了 CART 分类树采用叶子节点里概率最大的类别作为当前节点的预测类别。而回归树输出不是类别，它采用的是用最终叶子的均值或者中位数来预测输出结果。以均值为例，进行详细描述。</p><p>一个回归树对应着输入特征空间的一个划分，以及在划分单元上的输出值。先假设数据集已被划分，R1,R2,…,Rm共m的子集，回归树要求每个划分Rm中都对应一个固定的输出值$c_m$。这个$c_m$值其实就是每个子集中所有样本的目标变量$y$的平均值，并以此$c_m$作为该子集的预测值。</p><script type="math/tex; mode=display">f(x)=\sum_{m=1}^{M} c_{m} I\left(x \in R_{m}\right)</script><h4 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h4><ol><li>无论是ID3、C4.5还是CART，在做特征选择的时候都是选择最优的一个特征来做分类决策，但是大多数，分类决策不应该是由某一个特征决定的，而是应该由一组特征决定的。这样决策得到的决策树更加准确。这个决策树叫做多变量决策树(multi-variate decision tree)。在选择最优特征的时候，多变量决策树不是选择某一个最优特征，而是选择最优的一个特征线性组合来做决策。这个算法的代表是OC1，这里不多介绍。</li><li>如果样本发生一点点的改动，就会导致树结构的剧烈改变。这个可以通过集成学习里面的随机森林之类的方法解决。</li></ol><h2 id="ID3、C4-5-和-CART-总结"><a href="#ID3、C4-5-和-CART-总结" class="headerlink" title="ID3、C4.5 和 CART 总结"></a>ID3、C4.5 和 CART 总结</h2><p>最后通过总结的方式对比下 ID3、C4.5 和 CART 三者之间的差异。</p><p><img src="/MachineLearning/机器学习/决策树（上）—— ID3、C4.5、CART/640-1667185689025-27.png" alt="图片" style="zoom:67%;"></p><p>除了之前列出来的划分标准、剪枝策略、连续值确实值处理方式等之外，我再介绍一些其他差异：</p><ul><li><strong>划分标准的差异：</strong>ID3 使用信息增益偏向特征值多的特征，C4.5 使用信息增益率克服信息增益的缺点，偏向于特征值小的特征，CART 使用基尼指数克服 C4.5 需要求 log 的巨大计算量，偏向于特征值较多的特征。</li><li><strong>使用场景的差异：</strong>ID3 和 C4.5 都只能用于分类问题，CART 可以用于分类和回归问题；ID3 和 C4.5 是多叉树，速度较慢，CART 是二叉树，计算速度很快；</li><li><strong>样本数据的差异：</strong>ID3 只能处理离散数据且缺失值敏感，C4.5 和 CART 可以处理连续性数据且有多种方式处理缺失值；从样本量考虑的话，小样本建议 C4.5、大样本建议 CART。C4.5 处理过程中需对数据集进行多次扫描排序，处理成本耗时较高，而 CART 本身是一种大样本的统计方法，小样本处理下泛化误差较大 ；</li><li><strong>样本特征的差异：</strong>ID3 和 C4.5 层级之间只使用一次特征，CART 可多次重复使用特征；</li><li><strong>剪枝策略的差异：</strong>ID3 没有剪枝策略，C4.5 是通过悲观剪枝策略来修正树的准确性，而 CART 是通过代价复杂度剪枝。</li></ul><h2 id="决策树算法优缺点总结"><a href="#决策树算法优缺点总结" class="headerlink" title="决策树算法优缺点总结"></a>决策树算法优缺点总结</h2><p>我们前面介绍了决策树的特征选择，生成，和剪枝，然后对ID3, C4.5和CART算法也分别进行了详细的分析。下面我们来看看决策树算法作为一个大类别的分类回归算法的优缺点。</p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol><li>简单直观，生成的决策树很直观。</li><li>基本不需要预处理，不需要提前归一化，处理缺失值。</li><li>使用决策树预测的代价是O(log2m)， m为样本数。</li><li>既可以处理离散值也可以处理连续值。很多算法只是专注于离散值或者连续值。</li><li>可以处理多维度输出的分类问题。</li><li>相比于神经网络之类的黑盒分类模型，决策树在逻辑上可以得到很好的解释</li><li>可以交叉验证的剪枝来选择模型，从而提高泛化能力。</li><li>对于异常点的容错能力好，健壮性高。</li></ol><p><strong>决策树算法的缺点</strong></p><ol><li>决策树算法非常容易过拟合，导致泛化能力不强。可以通过设置节点最少样本数量和限制决策树深度来改进。</li><li>决策树会因为样本发生一点点的改动，就会导致树结构的剧烈改变。这个可以通过集成学习之类的方法解决。</li><li>寻找最优的决策树是一个NP难的问题，我们一般是通过启发式方法，容易陷入局部最优。可以通过集成学习之类的方法来改善。</li><li>有些比较复杂的关系，决策树很难学习，比如异或。这个就没有办法了，一般这种关系可以换神经网络分类方法来解决。</li><li>如果某些特征的样本比例过大，生成决策树容易偏向于这些特征。这个可以通过调节样本权重来改善。</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cnblogs.com/codeshell/p/13948083.html" target="_blank" rel="noopener">决策树算法-理论篇-如何计算信息纯度</a><br><a href="https://zhuanlan.zhihu.com/p/85731206" target="_blank" rel="noopener">【机器学习】决策树（上）——ID3、C4.5、CART（非常详细）</a><br><a href="https://www.cnblogs.com/muzixi/p/6566803.html" target="_blank" rel="noopener">决策树—信息增益，信息增益比，Geni指数的理解</a><br><a href="http://mp.weixin.qq.com/s?__biz=MzUzODYwMDAzNA==&amp;mid=2247485668&amp;idx=1&amp;sn=b7cbd37c7ed9a81ab756048942436ecb&amp;chksm=fad47fe9cda3f6ffd45001aae7889d2d565d9fc15f0c99a6db3bfcd7602fa586879e3b91d537&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">决策树学习笔记（一）：特征选择</a><br><a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1666946224&amp;ver=4131&amp;signature=QE9hbabvljJmSPd4Kj1nLFCW1eURBR6N2t8CaNpGQsTdOrkwOwjroPX8eKF3GFLaQneyZrvZF5zt2aE7cQcHfwypGXurIhU2FVfZYWx2gebOiJiLPKmrCwID9UlLQU1h&amp;new=1" target="_blank" rel="noopener">决策树学习笔记（三）：CART算法，决策树总结</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近想学习一下LightGBM，一直对决策树不是很熟悉，所以学习一下~&lt;/p&gt;
&lt;p&gt;本文主要参考了&lt;a href=&quot;https://www.zhihu.com/people/is-aze&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;阿泽&lt;/a&gt;作者的笔记，对于不理解的地方，我会添加个人注释。&lt;/p&gt;
&lt;p&gt;决策树是一个非常常见并且优秀的机器学习算法，它易于理解、可解释性强，其可作为分类算法，也可用于回归模型。&lt;/p&gt;
&lt;h2 id=&quot;预备知识&quot;&gt;&lt;a href=&quot;#预备知识&quot; class=&quot;headerlink&quot; title=&quot;预备知识&quot;&gt;&lt;/a&gt;预备知识&lt;/h2&gt;&lt;p&gt;这部分内容主要参考了&lt;a href=&quot;https://www.cnblogs.com/codeshell/p/13948083.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;决策树算法-理论篇-如何计算信息纯度 &lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MachineLearning" scheme="https://www.zdaiot.com/categories/MachineLearning/"/>
    
      <category term="机器学习" scheme="https://www.zdaiot.com/categories/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="决策树" scheme="https://www.zdaiot.com/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>正则表达式</title>
    <link href="https://www.zdaiot.com/Python/%E5%B8%B8%E7%94%A8%E7%AC%AC%E4%B8%89%E6%96%B9%E5%8C%85/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    <id>https://www.zdaiot.com/Python/常用第三方包/正则表达式/</id>
    <published>2022-09-20T06:54:33.000Z</published>
    <updated>2022-09-20T06:54:33.000Z</updated>
    
    <content type="html"><![CDATA[<p>正则表达式很常用，但是规则也很复杂，每次用的时候查资料即可。我这里只是总结一下常用的正则表达式。</p><h2 id="字符串过滤"><a href="#字符串过滤" class="headerlink" title="字符串过滤"></a>字符串过滤</h2><p>我们常常需要根据正则表达式，来对字符串进行过滤。例如仅保留汉字、数字、字母等。用法如下例所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding = utf-8</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">num = <span class="string">'a￥1aB23Cqqq$我.04'</span></span><br><span class="line">print(<span class="string">"原字符串： "</span>, num)</span><br><span class="line"><span class="comment"># 字符串只保留中文</span></span><br><span class="line">num1 = re.sub(<span class="string">u"([^\u4e00-\u9fa5])"</span>, <span class="string">""</span>, num)</span><br><span class="line">print(<span class="string">"字符串只保留中文： "</span>, num1)</span><br><span class="line"><span class="comment"># 字符串只保留英文</span></span><br><span class="line">num2 = re.sub(<span class="string">u"([^\u0041-\u005a\u0061-\u007a])"</span>, <span class="string">""</span>, num)</span><br><span class="line">print(<span class="string">"字符串只保留英文： "</span>, num2)</span><br><span class="line"><span class="comment"># 字符串只保留数字</span></span><br><span class="line">num3 = re.sub(<span class="string">u"([^\u0030-\u0039])"</span>, <span class="string">""</span>, num)</span><br><span class="line">print(<span class="string">"字符串只保留数字： "</span>, num3)</span><br><span class="line">num4 = re.sub(<span class="string">"\D"</span>, <span class="string">""</span>, num)</span><br><span class="line">print(<span class="string">"字符串只保留数字： "</span>, num4)</span><br><span class="line"><span class="comment"># 字符串保留数字.和￥</span></span><br><span class="line">num5 = re.sub(<span class="string">u"([^\u0030-\u0039\u002e\uffe5])"</span>, <span class="string">""</span>, num)</span><br><span class="line">print(<span class="string">"字符串保留数字.和￥： "</span>, num5)</span><br><span class="line"><span class="comment"># 字符串只保留英文和数字</span></span><br><span class="line">num6 = re.sub(<span class="string">u"([^\u0041-\u005a\u0061-\u007a\u0030-\u0039])"</span>, <span class="string">""</span>, num)</span><br><span class="line">print(<span class="string">"字符串只保留英文和数字： "</span>, num6)</span><br><span class="line"></span><br><span class="line">s = <span class="string">"ABC今天下雨了，abs不开心123！。?？"</span></span><br><span class="line"><span class="comment"># 字符串只保留中文、字母、数字。</span></span><br><span class="line">num7 = re.sub(<span class="string">u"([^\u4e00-\u9fa5\u0041-\u005a\u0061-\u007a\u0030-\u0039])"</span>, <span class="string">""</span>, s)</span><br><span class="line">print(<span class="string">'字符串只保留汉字、英文和数字： '</span>, num7)</span><br></pre></td></tr></table></figure><p>输出结果如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">原字符串：  a￥1aB23Cqqq$我.04</span><br><span class="line">字符串只保留中文：  我</span><br><span class="line">字符串只保留英文：  aaBCqqq</span><br><span class="line">字符串只保留数字：  12304</span><br><span class="line">字符串只保留数字：  12304</span><br><span class="line">字符串保留数字.和￥：  ￥123.04</span><br><span class="line">字符串只保留英文和数字：  a1aB23Cqqq04</span><br><span class="line">字符串只保留汉字、英文和数字：  ABC今天下雨了abs不开心123</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/BurningSilence/article/details/118488543" target="_blank" rel="noopener">python正则过滤字符串，只保留数字、字母等</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;正则表达式很常用，但是规则也很复杂，每次用的时候查资料即可。我这里只是总结一下常用的正则表达式。&lt;/p&gt;
&lt;h2 id=&quot;字符串过滤&quot;&gt;&lt;a href=&quot;#字符串过滤&quot; class=&quot;headerlink&quot; title=&quot;字符串过滤&quot;&gt;&lt;/a&gt;字符串过滤&lt;/h2&gt;&lt;p&gt;我们常常需要根据正则表达式，来对字符串进行过滤。例如仅保留汉字、数字、字母等。用法如下例所示：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# coding = utf-8&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; re&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;num = &lt;span class=&quot;string&quot;&gt;&#39;a￥1aB23Cqqq$我.04&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;print(&lt;span class=&quot;string&quot;&gt;&quot;原字符串： &quot;&lt;/span&gt;, num)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 字符串只保留中文&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;num1 = re.sub(&lt;span class=&quot;string&quot;&gt;u&quot;([^\u4e00-\u9fa5])&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;&quot;&lt;/span&gt;, num)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;print(&lt;span class=&quot;string&quot;&gt;&quot;字符串只保留中文： &quot;&lt;/span&gt;, num1)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 字符串只保留英文&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;num2 = re.sub(&lt;span class=&quot;string&quot;&gt;u&quot;([^\u0041-\u005a\u0061-\u007a])&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;&quot;&lt;/span&gt;, num)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;print(&lt;span class=&quot;string&quot;&gt;&quot;字符串只保留英文： &quot;&lt;/span&gt;, num2)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 字符串只保留数字&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;num3 = re.sub(&lt;span class=&quot;string&quot;&gt;u&quot;([^\u0030-\u0039])&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;&quot;&lt;/span&gt;, num)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;print(&lt;span class=&quot;string&quot;&gt;&quot;字符串只保留数字： &quot;&lt;/span&gt;, num3)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;num4 = re.sub(&lt;span class=&quot;string&quot;&gt;&quot;\D&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;&quot;&lt;/span&gt;, num)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;print(&lt;span class=&quot;string&quot;&gt;&quot;字符串只保留数字： &quot;&lt;/span&gt;, num4)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 字符串保留数字.和￥&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;num5 = re.sub(&lt;span class=&quot;string&quot;&gt;u&quot;([^\u0030-\u0039\u002e\uffe5])&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;&quot;&lt;/span&gt;, num)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;print(&lt;span class=&quot;string&quot;&gt;&quot;字符串保留数字.和￥： &quot;&lt;/span&gt;, num5)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 字符串只保留英文和数字&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;num6 = re.sub(&lt;span class=&quot;string&quot;&gt;u&quot;([^\u0041-\u005a\u0061-\u007a\u0030-\u0039])&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;&quot;&lt;/span&gt;, num)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;print(&lt;span class=&quot;string&quot;&gt;&quot;字符串只保留英文和数字： &quot;&lt;/span&gt;, num6)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;s = &lt;span class=&quot;string&quot;&gt;&quot;ABC今天下雨了，abs不开心123！。?？&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 字符串只保留中文、字母、数字。&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;num7 = re.sub(&lt;span class=&quot;string&quot;&gt;u&quot;([^\u4e00-\u9fa5\u0041-\u005a\u0061-\u007a\u0030-\u0039])&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;&quot;&lt;/span&gt;, s)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;print(&lt;span class=&quot;string&quot;&gt;&#39;字符串只保留汉字、英文和数字： &#39;&lt;/span&gt;, num7)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;输出结果如下所示：&lt;/p&gt;
    
    </summary>
    
    
      <category term="Python" scheme="https://www.zdaiot.com/categories/Python/"/>
    
      <category term="常用第三方包" scheme="https://www.zdaiot.com/categories/Python/%E5%B8%B8%E7%94%A8%E7%AC%AC%E4%B8%89%E6%96%B9%E5%8C%85/"/>
    
    
      <category term="Python" scheme="https://www.zdaiot.com/tags/Python/"/>
    
      <category term="re" scheme="https://www.zdaiot.com/tags/re/"/>
    
  </entry>
  
  <entry>
    <title>nohup、&amp;、重定向使用</title>
    <link href="https://www.zdaiot.com/Linux/%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/nohup%E3%80%81&amp;%E3%80%81%E9%87%8D%E5%AE%9A%E5%90%91%E4%BD%BF%E7%94%A8/"/>
    <id>https://www.zdaiot.com/Linux/常用指令/nohup、&amp;、重定向使用/</id>
    <published>2022-08-26T07:08:00.000Z</published>
    <updated>2022-08-26T07:08:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>事先声明，此文章大部分内容来源于<a href="https://blog.csdn.net/xiaojin21cen/article/details/88991768" target="_blank" rel="noopener">Linux shell 命令中nohup 、&amp;、重定向的使用</a>。不理解的地方我会添加个人见解。</p><h2 id="nohup-和-amp-使用方法"><a href="#nohup-和-amp-使用方法" class="headerlink" title="nohup 和 &amp; 使用方法"></a>nohup 和 &amp; 使用方法</h2><h3 id="nohup-（不挂断）"><a href="#nohup-（不挂断）" class="headerlink" title="nohup （不挂断）"></a>nohup （不挂断）</h3><blockquote><p><code>nohup</code> 是 no hung up 的缩写，意思是不挂断 。</p><p>使用 Xshell 等 Linux 客户端工具，远程执行 Linux 脚本时，有时候会由于网络问题，导致客户端失去连接，终端断开，脚本运行一半就意外结束了。这种时候，就可以用<code>nohup</code> 指令来运行指令，即使客户端与服务端断开，服务端的脚本仍可继续运行。</p></blockquote><p><code>nohup</code> 语法格式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup  <span class="built_in">command</span>  [arg...]</span><br></pre></td></tr></table></figure><p><strong>说明：</strong></p><ul><li>除了无法进行输入操作（比如输入命令、换行、打空格等） 外 ，</li><li>标准输出保存到 <code>nohup.out</code>文件中。</li><li>关闭客户端后，命令仍然会运行，<strong>不会挂断</strong>。</li></ul><p><strong>例如：</strong></p><p>执行 <code>nohup sh test.sh</code> 脚本命令后，终端不能接收任何输入，标准输出 会输出到当前目录的<code>nohup.out</code> 文件。即使关闭 xshell 退出后，当前 session 依然继续运行。</p><h3 id="amp-（可交互）"><a href="#amp-（可交互）" class="headerlink" title="&amp; （可交互）"></a>&amp; （可交互）</h3><p><code>&amp;</code> 语法格式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">command</span>   [arg...]   &amp;</span><br></pre></td></tr></table></figure><p><strong>说明：</strong></p><ul><li>能进行输入操作（比如输入命令、换行、打空格等），即 <strong>可进行交互</strong> 输入和输出的操作。</li><li>标准输出 保存到 <code>nohup.out</code>文件中。</li><li>但是 关闭客户端后，<strong>程序会就马上停止</strong>。</li></ul><p><strong>例如：</strong></p><p>执行 <code>sh test.sh &amp;</code> 脚本命令后 ，关闭 xshell，脚本程序也立刻停止。</p><h3 id="nohup-和-amp-一块使用（不挂断，可交互）"><a href="#nohup-和-amp-一块使用（不挂断，可交互）" class="headerlink" title="nohup 和 &amp; 一块使用（不挂断，可交互）"></a>nohup 和 &amp; 一块使用（不挂断，可交互）</h3><p>语法格式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup   <span class="built_in">command</span>  [arg...]  &amp;</span><br></pre></td></tr></table></figure><p>说明：</p><ul><li>能进行输入操作（比如输入命令、换行、打空格等），即 <strong>可进行交互</strong> 输入和输出的操作，</li><li>标准输出 保存到 <code>nohup.out</code> 中，</li><li>关闭客户端后命令仍然会运行。</li></ul><p><strong>例子：</strong>  </p><p>执行 <code>nohup sh test.sh &amp;</code> 命令后，能进行输入操作，标准输出 的日志写入到 <code>nohup.out</code> 文件，即使关闭 xshell，退出当前 session 后，脚本命令依然继续运行。</p><blockquote><p>输入输出问题已经解决了， 是不是就完美了？ 其实还有一个问题没有解决， 请往下看！</p></blockquote><h2 id="日志的重定向-gt"><a href="#日志的重定向-gt" class="headerlink" title="日志的重定向 &gt;"></a>日志的重定向 &gt;</h2><p>上面提到的日志文件默认名称是 <code>nohup.out</code> ，如果修改日志文件的名称，则用到 <strong><code>重定向</code></strong> ，符号是 <strong><code>&gt;</code></strong> ，语法格式是</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; logFile </span><br><span class="line">&gt;&gt; logFile  # 以追加的方式</span><br></pre></td></tr></table></figure><p>说明：</p><ul><li><code>&gt;</code> 是重定向的符号。<code>&gt;&gt;</code>表示输出以追加的方式重定向。</li><li>logFile 是日志文件名称，最好是英文、数字。</li></ul><p>此时， <code>nohup</code>、 <code>&amp;</code> 、 <code>&gt;</code> 三者一块使用的 <strong>语法格式</strong> ：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup  <span class="built_in">command</span> &gt;logFile  &amp;</span><br></pre></td></tr></table></figure><p>示例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup  start.sh &gt;aa.log  &amp;</span><br></pre></td></tr></table></figure><p>说明：执行上面的命令后，可以进行输入，也能在后台运行，运行的日志输出到 <code>aa.log</code> 日志中。</p><h2 id="错误信息的处理"><a href="#错误信息的处理" class="headerlink" title="错误信息的处理"></a>错误信息的处理</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup  <span class="built_in">command</span> &gt;logFile  &amp;</span><br></pre></td></tr></table></figure><p>虽然解决输入输出，后台也能运行问题，但是还有一项是 <strong>错误信息</strong> 无法输出到 日志文件中，要解决这个问题，需要增加命令 <code>2 &gt; file</code> 。</p><p>标准输出 和 错误信息 同时使用，语法格式如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;logFile1   2 &gt;logFile2</span><br></pre></td></tr></table></figure><p>有人会疑问，<code>2</code> 是什么意思？ 请往下看。</p><h3 id="Linux-标准输入、输出、错误信息的符号"><a href="#Linux-标准输入、输出、错误信息的符号" class="headerlink" title="Linux 标准输入、输出、错误信息的符号"></a>Linux 标准输入、输出、错误信息的符号</h3><p>Linux 标准输入、输出、错误信息的符号：</p><ul><li><code>0</code> 表示 stdin (standard input) <code>标准信息输入</code> ；</li><li><code>1</code> 表示 stdout (standard output) <code>标准信息输出</code> ；</li><li><code>2</code> 表示 stderr (standard error) <code>错误信息</code> ；</li><li><code>/dev/null</code> 表示空设备文件。 如果不想输出任何的日志时，使用此参数 。</li></ul><p>再来回顾上面的示例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;logFile1   2 &gt;logFile2</span><br></pre></td></tr></table></figure><ul><li><p><code>&gt; logFile1</code> ：即 <code>1 &gt;logFile1</code>，1 是<code>标准信息输出</code>，是默认的，可以省略，logFile1 是 日志文件名字。</p></li><li><p><code>2 &gt;logFile2</code> ：2 是<code>错误信息</code>，即将 <code>错误信息</code> 输出 到 logFile2 文件中 。</p></li></ul><p>到这时，明白 <code>2</code> 含义了吧！</p><h3 id="3-2、错误信息-和-标准输出-输出在同一个文件中"><a href="#3-2、错误信息-和-标准输出-输出在同一个文件中" class="headerlink" title="3.2、错误信息 和 标准输出 输出在同一个文件中"></a>3.2、错误信息 和 标准输出 输出在同一个文件中</h3><p>如果想把 错误信息 和 标准输出 在同一个文件中 ，使用 <code>2&gt;&amp;1</code> 。 语法如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;logFile   2&gt;&amp;1</span><br></pre></td></tr></table></figure><p>说明：</p><ul><li><code>&gt;logFile</code> 表示 标准信息 输出到 logFile 文件中；</li><li><code>2&gt;&amp;1</code> 表示 把 2（错误信息） 重定向， 输出到 1（标准输出） 中 。</li></ul><p>两者的共同使用，表示 把 2（错误信息） 、1（标准输出） 都输出到同一个文件（logFile）中。</p><h3 id="思考：不想输出日志信息怎么办-？"><a href="#思考：不想输出日志信息怎么办-？" class="headerlink" title="思考：不想输出日志信息怎么办 ？"></a>思考：不想输出日志信息怎么办 ？</h3><p>提示：<code>/dev/null</code> 表示空设备文件。 如果不想输出任何的日志时，使用此参数 。</p><h2 id="综合使用（推荐）"><a href="#综合使用（推荐）" class="headerlink" title="综合使用（推荐）"></a>综合使用（推荐）</h2><p>综上所述， 功能最全、推荐语法如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup  <span class="built_in">command</span>  &gt;logFile   2&gt;&amp;1  &amp;</span><br></pre></td></tr></table></figure><p>示例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup  start.sh &gt; mySysLog.log  2&gt;&amp;1   &amp;</span><br></pre></td></tr></table></figure><p>说明： 执行命令后，并且将 <code>标准输出(1)</code>、<code>错误信息(2)</code> 写入到 mySysLog.log 文件中。</p><h2 id="知识扩展"><a href="#知识扩展" class="headerlink" title="知识扩展"></a>知识扩展</h2><h3 id="不停止服务，直接清空-nohup-out"><a href="#不停止服务，直接清空-nohup-out" class="headerlink" title="不停止服务，直接清空 nohup.out"></a>不停止服务，直接清空 nohup.out</h3><p>如果脚本一直运行下去，nohup.out 日志会一直增长，日志但是硬盘容量有限，怎么把日志文件的大小减少 ？  </p><p>注意，千万别直接删除日志文件，会造成服务无法输出日志，服务异常直接停止运行，这是最严重生产事故。</p><p>不停止服务，直接清空 nohup.out 文件有两种方法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第1种：</span></span><br><span class="line">cat /dev/null &gt; nohup.out</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第2种：</span></span><br><span class="line">cp /dev/null nohup.out</span><br></pre></td></tr></table></figure><h3 id="只记录警告级别比较高的日志"><a href="#只记录警告级别比较高的日志" class="headerlink" title="只记录警告级别比较高的日志"></a>只记录警告级别比较高的日志</h3><p>输出的日志太多，nohup.out 增长特别快，对于不重要的日记，可以不记录，选择只记录警告级别比较高的日志。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 只输出错误信息到日志文件，其它日志不输出</span></span><br><span class="line">nohup ./program &gt; /dev/null   2&gt;error.log  &amp;</span><br></pre></td></tr></table></figure><h3 id="不想输出日志"><a href="#不想输出日志" class="headerlink" title="不想输出日志"></a>不想输出日志</h3><p>不想输出日志，什么日志都不要，只要服务能正常运行就行了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 什么日志也不输出</span></span><br><span class="line">nohup ./program &gt; /dev/null   2&gt;&amp;1   &amp;</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/xiaojin21cen/article/details/88991768" target="_blank" rel="noopener">Linux shell 命令中nohup 、&amp;、重定向的使用</a><br><a href="https://www.runoob.com/linux/linux-shell-io-redirections.html" target="_blank" rel="noopener">Shell 输入/输出重定向</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;事先声明，此文章大部分内容来源于&lt;a href=&quot;https://blog.csdn.net/xiaojin21cen/article/details/88991768&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Linux shell 命令中nohup 、&amp;amp;、重定向的使用&lt;/a&gt;。不理解的地方我会添加个人见解。&lt;/p&gt;
&lt;h2 id=&quot;nohup-和-amp-使用方法&quot;&gt;&lt;a href=&quot;#nohup-和-amp-使用方法&quot; class=&quot;headerlink&quot; title=&quot;nohup 和 &amp;amp; 使用方法&quot;&gt;&lt;/a&gt;nohup 和 &amp;amp; 使用方法&lt;/h2&gt;&lt;h3 id=&quot;nohup-（不挂断）&quot;&gt;&lt;a href=&quot;#nohup-（不挂断）&quot; class=&quot;headerlink&quot; title=&quot;nohup （不挂断）&quot;&gt;&lt;/a&gt;nohup （不挂断）&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;nohup&lt;/code&gt; 是 no hung up 的缩写，意思是不挂断 。&lt;/p&gt;
&lt;p&gt;使用 Xshell 等 Linux 客户端工具，远程执行 Linux 脚本时，有时候会由于网络问题，导致客户端失去连接，终端断开，脚本运行一半就意外结束了。这种时候，就可以用&lt;code&gt;nohup&lt;/code&gt; 指令来运行指令，即使客户端与服务端断开，服务端的脚本仍可继续运行。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;nohup&lt;/code&gt; 语法格式：&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.zdaiot.com/categories/Linux/"/>
    
      <category term="常用指令" scheme="https://www.zdaiot.com/categories/Linux/%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/"/>
    
    
      <category term="Linux" scheme="https://www.zdaiot.com/tags/Linux/"/>
    
      <category term="nohup" scheme="https://www.zdaiot.com/tags/nohup/"/>
    
  </entry>
  
  <entry>
    <title>top指令详解</title>
    <link href="https://www.zdaiot.com/Linux/%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/top%E6%8C%87%E4%BB%A4%E8%AF%A6%E8%A7%A3/"/>
    <id>https://www.zdaiot.com/Linux/常用指令/top指令详解/</id>
    <published>2022-07-20T02:51:29.000Z</published>
    <updated>2022-07-20T02:51:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>注意以下内容，主要参考了<a href="https://www.cnblogs.com/ggjucheng/archive/2012/01/08/2316399.html" target="_blank" rel="noopener">linux的top命令参数详解</a>。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。</p><p>top显示系统当前的进程和其他状况，是一个动态显示过程，即可以通过用户按键来不断刷新当前状态。如果在前台执行该命令，它将独占前台，直到用户终止该程序为止。 比较准确的说，top命令提供了实时的对系统处理器的状态监视。它将显示系统中CPU最“敏感”的任务列表。该命令可以按CPU使用。内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定。 </p><h2 id="参数含义"><a href="#参数含义" class="headerlink" title="参数含义"></a>参数含义</h2><p>下面详细介绍它的使用方法。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">top - 01:06:48 up  1:22,  1 user,  load average: 0.06, 0.60, 0.48</span><br><span class="line">Tasks:  29 total,   1 running,  28 sleeping,   0 stopped,   0 zombie</span><br><span class="line">Cpu(s):  0.3% us,  1.0% sy,  0.0% ni, 98.7% id,  0.0% wa,  0.0% hi,  0.0% si</span><br><span class="line">Mem:    191272k total,   173656k used,    17616k free,    22052k buffers</span><br><span class="line">Swap:   192772k total,        0k used,   192772k free,   123988k cached</span><br><span class="line"></span><br><span class="line">PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND</span><br><span class="line">1379 root      16   0  7976 2456 1980 S  0.7  1.3   0:11.03 sshd</span><br><span class="line">14704 root      16   0  2128  980  796 R  0.7  0.5   0:02.72 top</span><br><span class="line">1 root      16   0  1992  632  544 S  0.0  0.3   0:00.90 init</span><br><span class="line">2 root      34  19     0    0    0 S  0.0  0.0   0:00.00 ksoftirqd/0</span><br><span class="line">3 root      RT   0     0    0    0 S  0.0  0.0   0:00.00 watchdog/0</span><br></pre></td></tr></table></figure><p>统计信息区前五行是系统整体的统计信息。第一行是任务队列信息，同 uptime 命令的执行结果。其内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">01:06:48    当前时间</span><br><span class="line">up 1:22    系统运行时间，格式为时:分</span><br><span class="line">1 user    当前登录用户数</span><br><span class="line">load average: 0.06, 0.60, 0.48    系统负载，即任务队列的平均长度。三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。</span><br></pre></td></tr></table></figure><p>第二、三行为进程和CPU的信息。当有多个CPU时，这些内容可能会超过两行。内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">total 进程总数</span><br><span class="line">running 正在运行的进程数</span><br><span class="line">sleeping 睡眠的进程数</span><br><span class="line">stopped 停止的进程数</span><br><span class="line">zombie 僵尸进程数</span><br><span class="line">Cpu(s): </span><br><span class="line">0.3% us 用户空间占用CPU百分比</span><br><span class="line">1.0% sy 内核空间占用CPU百分比</span><br><span class="line">0.0% ni 用户进程空间内改变过优先级的进程占用CPU百分比</span><br><span class="line">98.7% id 空闲CPU百分比</span><br><span class="line">0.0% wa 等待输入输出的CPU时间百分比</span><br><span class="line">0.0%hi：硬件CPU中断占用百分比</span><br><span class="line">0.0%si：软中断占用百分比</span><br><span class="line">0.0%st：虚拟机占用百分比</span><br></pre></td></tr></table></figure><p>最后两行为内存信息。内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Mem:</span><br><span class="line">191272k total    物理内存总量</span><br><span class="line">173656k used    使用的物理内存总量</span><br><span class="line">17616k free    空闲内存总量</span><br><span class="line">22052k buffers    用作内核缓存的内存量</span><br><span class="line">Swap: </span><br><span class="line">192772k total    交换区总量</span><br><span class="line">0k used    使用的交换区总量</span><br><span class="line">192772k free    空闲交换区总量</span><br><span class="line">123988k cached    缓冲的交换区总量，内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖，该数值即为这些内容已存在于内存中的交换区的大小，相应的内存再次被换出时可不必再对交换区写入。</span><br></pre></td></tr></table></figure><p>进程信息区统计信息区域的下方显示了各个进程的详细信息。首先来认识一下各列的含义。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">序号  列名    含义</span><br><span class="line">a    PID     进程id</span><br><span class="line">b    PPID    父进程id</span><br><span class="line">c    RUSER   Real user name</span><br><span class="line">d    UID     进程所有者的用户id</span><br><span class="line">e    USER    进程所有者的用户名</span><br><span class="line">f    GROUP   进程所有者的组名</span><br><span class="line">g    TTY     启动进程的终端名。不是从终端启动的进程则显示为 ?</span><br><span class="line">h    PR      优先级</span><br><span class="line">i    NI      nice值。负值表示高优先级，正值表示低优先级</span><br><span class="line">j    P       最后使用的CPU，仅在多CPU环境下有意义</span><br><span class="line">k    %CPU    上次更新到现在的CPU时间占用百分比</span><br><span class="line">l    TIME    进程使用的CPU时间总计，单位秒</span><br><span class="line">m    TIME+   进程使用的CPU时间总计，单位1/100秒</span><br><span class="line">n    %MEM    进程使用的物理内存百分比</span><br><span class="line">o    VIRT    进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES</span><br><span class="line">p    SWAP    进程使用的虚拟内存中，被换出的大小，单位kb。</span><br><span class="line">q    RES     进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA</span><br><span class="line">r    CODE    可执行代码占用的物理内存大小，单位kb</span><br><span class="line">s    DATA    可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb</span><br><span class="line">t    SHR     共享内存大小，单位kb</span><br><span class="line">u    nFLT    页面错误次数</span><br><span class="line">v    nDRT    最后一次写入到现在，被修改过的页面数。</span><br><span class="line">w    S       进程状态(D=不可中断的睡眠状态,R=运行,S=睡眠,T=跟踪/停止,Z=僵尸进程)</span><br><span class="line">x    COMMAND 命令名/命令行</span><br><span class="line">y    WCHAN   若该进程在睡眠，则显示睡眠中的系统函数名</span><br><span class="line">z    Flags   任务标志，参考 sched.h</span><br></pre></td></tr></table></figure><p>默认情况下仅显示比较重要的 PID、USER、PR、NI、VIRT、RES、SHR、S、%CPU、%MEM、TIME+、COMMAND 列。可以通过下面的快捷键来更改显示内容。 </p><ul><li>更改显示内容通过 <strong>f</strong> 键可以选择显示的内容。按 f 键之后会显示列的列表，按 a-z 即可显示或隐藏对应的列，最后按回车键确定。</li><li>按 <strong>o</strong> 键可以改变列的显示顺序。按小写的 a-z 可以将相应的列向右移动，而大写的 A-Z 可以将相应的列向左移动。最后按回车键确定。</li><li>按大写的 <strong>F</strong> 或 <strong>O</strong> 键，然后按 a-z 可以将进程按照相应的列进行排序。而大写的 <strong>R</strong> 键可以将当前的排序倒转。</li></ul><h2 id="命令使用"><a href="#命令使用" class="headerlink" title="命令使用"></a>命令使用</h2><p>top使用格式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top [-] [d] [p] [q] [c] [C] [S] [s] [n]</span><br></pre></td></tr></table></figure><p>参数说明：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">d 指定每两次屏幕信息刷新之间的时间间隔。当然用户可以使用s交互命令来改变之。 </span><br><span class="line">p 通过指定监控进程ID来仅仅监控某个进程的状态。 </span><br><span class="line">q 该选项将使top没有任何延迟的进行刷新。如果调用程序有超级用户权限，那么top将以尽可能高的优先级运行。 </span><br><span class="line">S 指定累计模式 </span><br><span class="line">s 使top命令在安全模式中运行。这将去除交互命令所带来的潜在危险。 </span><br><span class="line">i 使top不显示任何闲置或者僵死进程。 </span><br><span class="line">c 显示整个命令行而不只是显示命令名</span><br></pre></td></tr></table></figure><p>附常用操作:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">top   //每隔5秒显式所有进程的资源占用情况</span><br><span class="line">top -d 2  //每隔2秒显式所有进程的资源占用情况</span><br><span class="line">top -c  //每隔5秒显式进程的资源占用情况，并显示进程的命令行参数(默认只有进程名)</span><br><span class="line">top -p 12345 -p 6789//每隔5秒显示pid是12345和pid是6789的两个进程的资源占用情况</span><br><span class="line">top -d 2 -c -p 123456 //每隔2秒显示pid是12345的进程的资源使用情况，并显式该进程启动的命令行参数</span><br></pre></td></tr></table></figure><h2 id="交互命令"><a href="#交互命令" class="headerlink" title="交互命令"></a>交互命令</h2><p>在top命令执行过程中可以使用的一些交互命令。这些命令都是单字母的，如果在命令行中使用了-s选项， 其中一些命令可能会被屏蔽。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">h：显示帮助画面，给出一些简短的命令总结说明；</span><br><span class="line">k：终止一个进程；</span><br><span class="line">i：忽略闲置和僵死进程，这是一个开关式命令；</span><br><span class="line">q：退出程序；</span><br><span class="line">r：重新安排一个进程的优先级别；</span><br><span class="line">S：切换到累计模式；</span><br><span class="line">s：改变两次刷新之间的延迟时间（单位为s），如果有小数，就换算成ms。</span><br><span class="line">输入0值则系统将不断刷新，默认值是5s；</span><br><span class="line"></span><br><span class="line">f或者F：从当前显示中添加或者删除项目；</span><br><span class="line">o或者O：改变显示项目的顺序；</span><br><span class="line">l：切换显示平均负载和启动时间信息；</span><br><span class="line">m：切换显示内存信息；</span><br><span class="line">t：切换显示进程和CPU状态信息；</span><br><span class="line">c：切换显示命令名称和完整命令行；</span><br><span class="line">M：根据驻留内存大小进行排序；</span><br><span class="line">P：根据CPU使用百分比大小进行排序；</span><br><span class="line">T：根据时间/累计时间进行排序；</span><br><span class="line">w：将当前设置写入~/.toprc文件中。</span><br></pre></td></tr></table></figure><h2 id="单位切换"><a href="#单位切换" class="headerlink" title="单位切换"></a>单位切换</h2><p>顶部的内存信息可以在top运行时按E切换，每次切换转换率为1000，只是没有单位，切换的单位为 k,m,g,t,p。</p><p>例如：</p><p><img src="/Linux/常用指令/top指令详解/top1-165828697137611.jpg" alt="top1"></p><p><img src="/Linux/常用指令/top指令详解/top2-165828701166415.jpg" alt="top2"></p><p>底下的进程信息按e切换，每次切换转换率为1000，切换的单位也是 k,m,g,t,p。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cnblogs.com/ggjucheng/archive/2012/01/08/2316399.html" target="_blank" rel="noopener">linux的top命令参数详解</a><br><a href="https://blog.kelu.org/tech/2017/10/07/linux-top-switch-ram.html" target="_blank" rel="noopener">Linux 在 TOP 命令中切换内存的显示单位</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;注意以下内容，主要参考了&lt;a href=&quot;https://www.cnblogs.com/ggjucheng/archive/2012/01/08/2316399.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;linux的top命令参数详解&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。&lt;/p&gt;
&lt;p&gt;top显示系统当前的进程和其他状况，是一个动态显示过程，即可以通过用户按键来不断刷新当前状态。如果在前台执行该命令，它将独占前台，直到用户终止该程序为止。 比较准确的说，top命令提供了实时的对系统处理器的状态监视。它将显示系统中CPU最“敏感”的任务列表。该命令可以按CPU使用。内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定。 &lt;/p&gt;
&lt;h2 id=&quot;参数含义&quot;&gt;&lt;a href=&quot;#参数含义&quot; class=&quot;headerlink&quot; title=&quot;参数含义&quot;&gt;&lt;/a&gt;参数含义&lt;/h2&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://www.zdaiot.com/categories/Linux/"/>
    
      <category term="常用指令" scheme="https://www.zdaiot.com/categories/Linux/%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/"/>
    
    
      <category term="top" scheme="https://www.zdaiot.com/tags/top/"/>
    
  </entry>
  
  <entry>
    <title>Expressive TTS</title>
    <link href="https://www.zdaiot.com/DeepLearningApplications/%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90/Expressive%20TTS/"/>
    <id>https://www.zdaiot.com/DeepLearningApplications/语音合成/Expressive TTS/</id>
    <published>2022-06-04T17:24:03.000Z</published>
    <updated>2022-06-04T17:24:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要来源于<a href="https://zhuanlan.zhihu.com/p/507708489" target="_blank" rel="noopener">Expressive TTS（01）</a>。</p><p>Expressive TTS是目前语音合成领域中比较活跃的方向，它和单纯TTS的区别是，它更关注合成声音的风格（例如新闻播报，讲故事，解说）、情感（例如生气，兴奋，悲伤）、韵律（例如重读，强调、语调）等等。自从深度学习技术大放异彩后，语音合成模型在合成声音的自然度方面有了极大的提高（例如Tacotron，Tacotron2，WaveNet），跳词复读的问题也在最近得到了解决（例如DurIAN，FastSpeech），而深度学习不仅可以让语音的自然度得到大幅度的提升，对一些难以显式建模的特征上也有很强大的学习能力，因此，让语音合成能更加具有expressive成为了一个研究热点。</p><h2 id="第一篇：Uncovering-Latent-Style-Factors-for-Expressive-Speech-Synthesis（2017）"><a href="#第一篇：Uncovering-Latent-Style-Factors-for-Expressive-Speech-Synthesis（2017）" class="headerlink" title="第一篇：Uncovering Latent Style Factors for Expressive Speech Synthesis（2017）"></a>第一篇：Uncovering Latent Style Factors for Expressive Speech Synthesis（2017）</h2><p><a href="https://arxiv.org/abs/1711.00520" target="_blank" rel="noopener">https://arxiv.org/abs/1711.00520</a></p><p>这一篇是 google 的王宇轩大佬早在 2017 年上传到 arxiv 上的一篇文章，也是表现力语音合成领域可追溯到的比较早的一篇文章。</p><h3 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h3><p>理想情况下，生成的语音应该<strong>传达正确的信息（可理解性 intelligibility）</strong>，同时<strong>听起来像人类的语言（自然性 naturalness）</strong>，具有<strong>正确的语调（表现力 expressiveness）</strong>。 然而，大多数现有的合成模型如 Tacotron 仅关注前两个问题，并没有明确地对语调进行建模。尽管有重要的应用，如对话助手和长篇阅读，但富有表现力的 TTS 仍然被认为是一个重要的开放问题。</p><blockquote><p>韵律变化本质上是多尺度的。音调和说话持续时间的局部变化可以传达语义，而整体音调轨迹等全局属性可以传达情绪和情感。</p></blockquote><p>在这项工作中，作者引入了 “风格标记（style tokens）” 的概念，它可以被视为捕捉韵律变化的潜在变量，而单靠文本输入是无法捕捉的。</p><h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="/DeepLearningApplications/语音合成/Expressive TTS/v2-4e78816e425a73de0cc8d4d757b0e83c_r.jpg" alt></p><p>理想情况下，一个富有表现力的 TTS 模型应该允许在合成过程中明确地控制对韵律（prosody）的选择。由于 Tacotron 只将文本作为输入，为了准确地重建训练信号，它必须学会将任何韵律信息隐式地储存在它的权重中，而我们并不能明确地控制它。为了允许显式的对韵律进行控制，作者在 Tacotron 中引入了一个专门的网络组件，用一个新的风格注意力模块（style attention）来增强现有的文本编码器的注意力模块（text attention）。新的注意力模块关注一个风格编码器（style encoder），它将 K 个 “风格标记” 作为输入，并输出它们的嵌入向量来作为风格注意力模块的输入（可以简单的理解为 K 个风格标记就是 1 到 K 的数字，然后经过一个 embedding，得到 K 个一维的 embedding vector 作为 style attention 的输入）。在解码器中，通过一种加权求和的操作将来自文本注意力和风格注意力的两个上下文向量结合起来。计算 weighted 的操作作者称为一个 controller layer（在图中并未明显体现，文章提到 The weights are predicted by a single layer MLP with sigmoid outputs）。Tacotron 模型的其余部分保持不变。  </p><p>作者提到 style tokens 的嵌入值是随机初始化的，并通过反向传播自动学习，它们的学习仅由解码器的重建损失指导。因此，风格标记本身的学习是完全无监督的。</p><p>为什么使用基于注意力的风格标记呢？</p><blockquote><p>首先，注意力有助于学习整体韵律风格的解耦（decomposition），鼓励产生具有独立韵律风格的可解释 tokens。这类似于学习一个风格原子的字典，可以结合起来重现整体风格（举个例子：每个原子都有自己的一个风格如 A 原子语速快、B 原子音调高，将 AB 原子组合起来可能能够产生一种听起来生气的情绪（即合成的语音语速又快音调又高））。<br>此外，注意力机制在解码器的时间分辨率上学习风格标记的组合，这使得时间变化的韵律操作成为可能。（简单的理解为就是比如说在生成一句长时间语音的时候，某个时刻可能音调高，某个时刻可能语速快些，从而生成的这一段语音在时间维度上可以组合不同的风格标记）。</p></blockquote><p>为什么这种方式能够在合成语音的时候实现可控性（controllability）呢？</p><blockquote><p>源自于风格编码器和文本编码器之间的一个重要区别。文本编码器是以输入的文本序列为条件的，而风格编码器则不需要输入，所有的训练序列都共享 tokens。换句话说，风格编码器计算的是训练集的先验 prior，而文本编码器计算的是后验 posteriors（以单个输入序列为条件）。这种设计允许风格标记捕捉与文本无关的韵律变化，这使得推理中的可控性得以实现。</p></blockquote><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p><a href="https://link.zhihu.com/?target=https%3A//google.github.io/tacotron/publications/uncovering_latent_style_factors_for_expressive_speech_synthesis/" target="_blank" rel="noopener">Sound demos</a></p><p>为了合成特定风格的语音，作者将所选风格标记的嵌入向量广播式地添加到完整的风格嵌入矩阵 style embedding matrix 中，从而使合成的语音偏向于指定风格。同样，可以通过连续广播添加或线性内插风格嵌入向量来混合不同的风格。</p><p><img src="/DeepLearningApplications/语音合成/Expressive TTS/v2-36c6d4fdad3edd49131f72fcef87534d_r.jpg" alt></p><p>从图 2 中可以看出，”token 1” 大致对应于具有正常音高范围的马虎、草率（sloppy）风格，”token 8” 大致对应于机器人声音的风格，而 “token 9” 大致对应于高音调声音。这些风格在一定程度上反映在平滑的 F0 轨迹上。例如，”token 9” 倾向于比其他两个有更高的音调，而 “token 8” 的音调轨迹则保持平缓和低沉。同样的趋势可以从图 2(b) 中看出，该图是由不同的语句产生的，表明风格标记的运作独立于文本输入。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>本文提出的风格标记（style tokens）可以在无监督的情况下学习，不需要注释的标签。在 Tacotron 模型中实现了风格标记，并证明它们确实对应于不同的声音风格因素，通过在推理中指定所需的风格来实现某种程度的声音控制。</p><h2 id="第二篇：-Style-Tokens-Unsupervised-Style-Modeling-Control-and-Transfer-in-End-to-End-Speech-Synthesis（2018）"><a href="#第二篇：-Style-Tokens-Unsupervised-Style-Modeling-Control-and-Transfer-in-End-to-End-Speech-Synthesis（2018）" class="headerlink" title="第二篇： Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis（2018）"></a>第二篇： Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis（2018）</h2><p><a href="https://arxiv.org/abs/1803.09017" target="_blank" rel="noopener">https://arxiv.org/abs/1803.09017</a></p><p>这一篇是王大佬接第一篇的续作，在这一篇文章中王大佬正式提出了 GSTs（global style tokens）的概念。</p><h3 id="动机-1"><a href="#动机-1" class="headerlink" title="动机"></a>动机</h3><p>韵律 prosody 是语音中一些现象的汇合，如副语言信息、语调 intonation、重音 stress 和风格 style。这篇文章主要关注 style modeling，它的目标是为模型提供一种能力，这种能力能够为给定内容选择一种说话风格。风格包含丰富的信息，如意图和情感，并影响说话人对语调和语速的选择。适当的风格呈现会影响整体感知。</p><p>风格建模 style modeling 有如下几个挑战：</p><ol><li>对 “正确的” 声音风格没有客观的衡量标准，这使得建模和评估都很困难。获取大型数据集的注释可能成本很高，而且同样存在问题，因为人类评分者经常会有分歧。</li><li>富有表现力的声音的高动态范围（如音调的高低起伏大）很难建模。许多 TTS 模型，包括最近的端到端系统，只在其输入数据上学习平均的声调分布（因为输入只有文本信息，不包含声学信息），产生的语音尤其是长句子的表现力较差。并且，它们往往缺乏控制语音合成的表达方式的能力。</li></ol><h3 id="模型结构-1"><a href="#模型结构-1" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="/DeepLearningApplications/语音合成/Expressive TTS/v2-56b8b6297cc6b6ef0a4cb38b727ef602_r.jpg" alt></p><ul><li><strong>训练期间：</strong></li></ul><p>1）参考编码器 reference encoder，将可变长度的音频序列的 prosody 压缩成一个固定长度的向量，称之为 reference embedding。在训练期间，参考音频是真实音频。</p><blockquote><p>reference encoder 架构的细节：输入 log-mel spectrogram ——&gt; 6*(2DConv+Batch Norm+ReLU) ——&gt;reshape 3 dimensions (保留时间维度，将 channel 和 freq reshape 成一维，即 [batch_size, channel, freq, time]——&gt;[batch_size, channel*freq, time]) ——&gt;single layer unidirectional GRU (128 unit) ——&gt; 输出：reference embedding (the last GRU state)。</p></blockquote><p>2）reference embedding 被传递到一个风格标记层 style token layer，在那里它被用作注意力模块的查询向量。注意，这里的注意力不是用来学习对齐的。相反，它学习 referensce embedding 和随机初始化的嵌入库中 (a bank of randomly initialized embeddings) 的每个 token 之间的相似性测量。这组嵌入被称之为全局风格标记 global style tokens (GSTs) 或标记嵌入 token embeddings，在所有训练序列中共享。</p><p>3) 注意力模块输出一组组合权重，代表每个 style token 对 referensce embedding 的贡献。GSTs 的加权总和被称之为风格嵌入 style embedding，在每个时间段被传递给文本编码器进行调节。</p><blockquote><p>style token layer 由 10 (实验发现 10 个足以代表训练数据中小而丰富的韵律维度) 个 style token embeddings (为了和 text encoder 匹配，所以维度是 256D) 和一个 multi-head attention 组成。输入 reference embedding(128D) 和 style token embeddings(256D) ——&gt; multi-head attention ——&gt; 输出 style embedding (256D)。最后将 style embedding 加到对应的 text encoder states 上。</p></blockquote><p>4）style token layer 与模型的其他部分共同训练，只由 Tacotron 解码器的重建损失驱动。因此，GSTs 不需要任何明确的风格或韵律标签。</p><ul><li><strong>推理期间：</strong></li></ul><p>1）可以直接将文本编码器限定在某些标记上，如图 3 推理模式图的右侧所描述的（”以 tokenB 为条件”）。这允许在没有参考音频的情况下进行风格控制和操作。</p><p>2）可以输入一个不同的音频（其对应的文本内容不需要与要合成的文本相同）来实现风格转移。这在图 3 的推理模式图的左侧被描绘出来（”以音频为条件”）。</p><p>总的来说，GSTs 模型可以被认为是一种将 reference embedding 分解为一组基础向量或 style token embedding 的端到端方法。GSTs 层在概念上与 VQ-VAE 编码器有些类似，因为它学习了其输入的量化表示。感觉用 VQ-VAE 来做 reference embedding 的解耦也可以，但是作者说实验效果很差。</p><p><strong>GSTs embeddings 也可以被看作是一个外部存储器，存储从训练数据中提取的风格信息。参考信号在训练时指导记忆的写入，在推理时指导记忆的读取。</strong></p><h3 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h3><p><a href="https://link.zhihu.com/?target=https%3A//google.github.io/tacotron/publications/global_style_tokens/" target="_blank" rel="noopener">Sound demos</a></p><p>感兴趣的可以点击上边这个链接听一下文章提供的 Audio samples。</p><h3 id="结论-1"><a href="#结论-1" class="headerlink" title="结论"></a>结论</h3><p>这项工作介绍了 GSTs。GSTs 是直观的，不需要明确的标签就能学习。当对富有表现力的语音数据进行训练时，GSTs 模型会产生可解释的嵌入 embeddings，可用于控制 control 和转移风格 transfer style。</p><p>然而，在实验中也发现了一些问题，比如并非所有的 single-token 都能捕捉到单一的属性：虽然一个 token 可能学会了代表说话速度，但其他 tokens 可能学会了反映训练数据中风格共现的混合属性（例如，一个低音调的 token 也能编码较慢的说话速度）。探索更多独立的风格属性学习（可以理解为解耦的更彻底）仍是目前工作的一个重点。</p><h2 id="第三篇：-Learning-latent-representations-for-style-control-and-transfer-in-end-to-end-speech-synthesis（2019）"><a href="#第三篇：-Learning-latent-representations-for-style-control-and-transfer-in-end-to-end-speech-synthesis（2019）" class="headerlink" title="第三篇： Learning latent representations for style control and transfer in end-to-end speech synthesis（2019）"></a>第三篇： Learning latent representations for style control and transfer in end-to-end speech synthesis（2019）</h2><p>Learning latent representations for style control and transfer in end-to-end speech synthesis</p><h3 id="动机-2"><a href="#动机-2" class="headerlink" title="动机"></a>动机</h3><p>VAE 有很多优点，如学习分解因素、平滑插值或在潜在表征 latent representation 之间连续取样，可以获得可解释的同（重）构体。</p><blockquote><p>最主要的就是，VAE 可以很容易地得到解耦 disentangle 之后的 latent code，每个 latent code 的维度都可以代表一个特定的概念，通过调整某个概念的值，我们就能控制特定的概念。比如在 image synthesis 中，调整特定维度的 latent code 就可以控制合成出来的物体的角度、大小等特定概念。</p></blockquote><p>直观地说，在语音合成中，说话人的潜在状态 latent state，如 affect 和意图 intent，有助于形成韵律 prosody、情感 emotion 或说话风格 speaker style。latent state 所起的作用与 VAE 中的潜在表征 latent representation 相当相似。因此，本文将 VAE 引入 Tacotron2，以学习说话人状态在连续空间中的潜态表示，并进一步控制语音合成中的说话风格。</p><h3 id="模型结构-2"><a href="#模型结构-2" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="/DeepLearningApplications/语音合成/Expressive TTS/v2-6b6d453d2502259d73e6c47cfcb0bec3_r.jpg" alt></p><p>如图 4 所示，整个网络结构由两部分组成，(1) 识别模型或推理网络，它将参考音频编码为固定长度的潜在表示（潜在表征 z 代表风格表示）；（2）一个基于 Tacotron2 的端到端 TTS 模型，它将综合的编码器状态（包括潜在表征和文本编码器状态）转换为具有特定风格的目标句。</p><blockquote><p>识别模型架构的细节（其中 reference encoder 和第二篇一致）：输入 mel spectrogram ——&gt; 6*(2DConv+Batch Norm+ReLU) ——&gt;reshape 3 dimensions (保留时间维度，将 channel 和 freq reshape 成一维，即 [batch_size, channel, freq, time]——&gt;[batch_size, channel*freq, time]) ——&gt;a GRU ——&gt; 输出：reference embedding (the last GRU state) ——&gt; 两个单独的全连接层 + linear activation function——&gt; 输出：均值和方差 ——&gt; 重采样 reparameterization ——&gt;输出：z。  </p><p>输出的 text encoder state 加上 z（先经过一个 linear layer 调整一下维度）被送到 Tacotron2 的 decoder 中。</p></blockquote><p><img src="/DeepLearningApplications/语音合成/Expressive TTS/v2-28890d23b720e5209f78594f7596061f_r.jpg" alt></p><p>损失函数 loss 为 VAE 的损失 (其中重构损失选择 L2-loss)+ $l_{stop}$ (stop token loss)。</p><h3 id="KL-collapse-problem"><a href="#KL-collapse-problem" class="headerlink" title="KL collapse problem"></a>KL collapse problem</h3><p>所谓 KL collapse problem 是指在训练过程中 KL loss 下降得比其它 loss 都快从而造成 KL loss 很快收敛到 0 并不再上升，这会造成 encoder 无法继续训练。因此作者使用了 KL annealing 来解决这个问题，具体来说，首先用一个动态调整的 weight 来控制 KL loss 的训练强度，其次是减少 KL loss 的训练次数，即每隔 K 个 step 才训练一次 KL loss。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kl_anneal_function</span><span class="params">(self, anneal_function, lag, step, k, x0, upper)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> anneal_function == <span class="string">'logistic'</span>:</span><br><span class="line">            <span class="keyword">return</span> float(upper/(upper+np.exp(-k*(step-x0))))</span><br><span class="line">        <span class="keyword">elif</span> anneal_function == <span class="string">'linear'</span>:</span><br><span class="line">            <span class="keyword">if</span> step &gt; lag:</span><br><span class="line">                <span class="keyword">return</span> min(upper, step/x0)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> anneal_function == <span class="string">'constant'</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># KL Divergence Loss</span></span><br><span class="line">kl_loss = <span class="number">-0.5</span> * torch.sum(<span class="number">1</span> + logvar - mu.pow(<span class="number">2</span>) - logvar.exp())</span><br><span class="line">kl_weight = self.kl_anneal_function(self.anneal_function, self.lag, step, self.k, self.x0, self.upper)</span><br><span class="line"></span><br><span class="line">total_loss = (mel_loss + gate_loss + kl_weight * kl_loss)</span><br></pre></td></tr></table></figure><h3 id="实验-2"><a href="#实验-2" class="headerlink" title="实验"></a>实验</h3><p>在推理阶段，在 style control 评估中，直接操作 z，不需要经过整个识别模型。在 style transfer 的评估中，需要把音频片段作为参考，并通过识别模型。 Parallel transfer 意味着目标文本信息与参考音频的相同，反之 non-parallel style transfer 意味着目标文本信息与参考音频的不同。</p><p><a href="http://home.ustc.edu.cn/~zyj008/ICASSP2019/" target="_blank" rel="noopener">Speech Demo</a></p><p><img src="/DeepLearningApplications/语音合成/Expressive TTS/v2-fe5c19623b709f8167cfea4775591632_r.jpg" alt></p><p>如图 5 所示，这两个 z 是通过向识别模型提供两个参考音频而得到的， $z_a$表示说话语速快和高音调， $z_d$表示说话语速慢和低音调。通过对这两个 z 的插值 interpolation 操作，可以看到生成的语音的音高和语速都在逐渐下降。这一结果表明，学习到的潜在空间在控制声谱图的趋势方面是连续的，这将进一步反映在风格的变化上。</p><p><img src="/DeepLearningApplications/语音合成/Expressive TTS/v2-9c2ad5e41f8b669875d4da61f50830eb_r.jpg" alt></p><p>一个解耦过的表征（也就是 z）意味着一个潜在变量（也就是其中的一个维度或者值）能够完全单独控制一个概念，并且对其他因素的变化没有影响。从图 6 可以看出，通过操纵单一维度而固定其他维度对声谱图的改变，调整其中一个维度，生成的语音只有一个属性发生变化，如 z 的几个维度可以分别控制着合成语音的音高、局部音调的变化、语速等风格属性。这表明，在这个模型中，VAE 具有学习解耦 latent state 的能力。</p><p><img src="/DeepLearningApplications/语音合成/Expressive TTS/v2-8b91f7edc330186214b7d222c01b4e73_r.jpg" alt></p><p>从图 7 可以看出，生成的声谱图和参考的声谱图具有相似的属性。</p><h3 id="结论-2"><a href="#结论-2" class="headerlink" title="结论"></a>结论</h3><p>本文提出了 VAE+Tacotron2 来对生成的语音进行控制，最终得到了与 GSTs 模型相似的效果。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/507708489" target="_blank" rel="noopener">Expressive TTS（01）</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要来源于&lt;a href=&quot;https://zhuanlan.zhihu.com/p/507708489&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Expressive TTS（01）&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Expressive TTS是目前语音合成领域中比较活跃的方向，它和单纯TTS的区别是，它更关注合成声音的风格（例如新闻播报，讲故事，解说）、情感（例如生气，兴奋，悲伤）、韵律（例如重读，强调、语调）等等。自从深度学习技术大放异彩后，语音合成模型在合成声音的自然度方面有了极大的提高（例如Tacotron，Tacotron2，WaveNet），跳词复读的问题也在最近得到了解决（例如DurIAN，FastSpeech），而深度学习不仅可以让语音的自然度得到大幅度的提升，对一些难以显式建模的特征上也有很强大的学习能力，因此，让语音合成能更加具有expressive成为了一个研究热点。&lt;/p&gt;
&lt;h2 id=&quot;第一篇：Uncovering-Latent-Style-Factors-for-Expressive-Speech-Synthesis（2017）&quot;&gt;&lt;a href=&quot;#第一篇：Uncovering-Latent-Style-Factors-for-Expressive-Speech-Synthesis（2017）&quot; class=&quot;headerlink&quot; title=&quot;第一篇：Uncovering Latent Style Factors for Expressive Speech Synthesis（2017）&quot;&gt;&lt;/a&gt;第一篇：Uncovering Latent Style Factors for Expressive Speech Synthesis（2017）&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.00520&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://arxiv.org/abs/1711.00520&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这一篇是 google 的王宇轩大佬早在 2017 年上传到 arxiv 上的一篇文章，也是表现力语音合成领域可追溯到的比较早的一篇文章。&lt;/p&gt;
    
    </summary>
    
    
      <category term="DeepLearningApplications" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/"/>
    
      <category term="语音合成" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90/"/>
    
    
      <category term="语音合成" scheme="https://www.zdaiot.com/tags/%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90/"/>
    
      <category term="Expressive TTS" scheme="https://www.zdaiot.com/tags/Expressive-TTS/"/>
    
  </entry>
  
  <entry>
    <title>语音合成模型</title>
    <link href="https://www.zdaiot.com/DeepLearningApplications/%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90/%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    <id>https://www.zdaiot.com/DeepLearningApplications/语音合成/语音合成模型/</id>
    <published>2022-06-04T12:28:03.000Z</published>
    <updated>2022-06-04T12:28:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>本篇介绍几个经典的语音合成模型。</p><h2 id="什么是语音合成"><a href="#什么是语音合成" class="headerlink" title="什么是语音合成"></a>什么是语音合成</h2><p>语音合成是通过文字人工生成人类声音， 也可以说语音生成是给定一段文字去生成对应的人类读音。 这里声音是一个连续的模拟的信号。而合成过程是通过计算机， 数字信号去模拟。 这里就需要数字信号处理模拟信号信息，详细内容可参考 [1]。</p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/webp" alt="img"></p><p>Fig. 1 an example of voice signal. </p><p>图片1， 就是一个例子用来表示人类声音的信号图。 这里横轴是时间， 纵轴是声音幅度大小。声音有三个重要的指标，<strong>振幅（amplitude）</strong>, <strong>周期（period）</strong>和<strong>频率（frequency）</strong>。 振幅指的是波的高低幅度，表示声音的强弱，周期和频率互为倒数的关系， 用来表示两个波之间的时间长度，或者每秒震动的次数。 而声音合成是根据声波的特点， 用数字的方式去生成类似人声的频率和振幅， 即音频的数字化。了解了音频的数字化，也就知道了我们要生成的目标函数。</p><p>音频的数字化主要有三个步骤。</p><p><strong>取样（sampling）</strong>：在音频数字化的过程，采样是指一个固定的频率对音频信号进行采样， 采样的频率越高， 对应的音频数据的保真度就越好。 当然， 数据量越大，需要的内存也就越大。 如果想完全无损采样， 需要使用Nyquist sampling frequency， 就是原音频的频率2倍。</p><p><strong>量化 （quantization）</strong>： 采样的信号都要进行量化， 把信号的幅度变成有限的离散数值。比如从0 到 1， 只有 四个量化值可以用0， 0.25， 0.5， 0.75的话， 量化就是选择最近的量化值来表示。</p><p><strong>编码 （coding</strong>）：编码就是把每个数值用二进制的方式表示， 比如上面的例子， 就可以用2bit 二进制表示, 00, 01, 10, 11。 这样的数值用来保存在计算机上。</p><p>采样频率和采样量化级数是数字化声音的两个主要指标，直接影响声音的效果。 对于语音合成也是同样， 生成更高的采样频率和更多多的量化级数（比如16 bit）, 会产生更真实的声音。 通常有三个采样频率标准：</p><p><strong>1.</strong> 44.1kHz 采样， 用于高品质CD 音乐</p><p><strong>2.</strong> 22.05kHz 采样， 用于语音通话， 中品质音乐</p><p><strong>3</strong>. 11.025kHz 采样， 用于低品质声音。</p><p>而量化标准一般有8位字长（256阶）低品质量化 和16位字长（65536阶）高品质量化。</p><p>还有一个重要参数就是通道（channel）, 一次只采样一个声音波形为单通道， 一次采样多个声音波形就是多通道。</p><p>所以在语音合成的时候，产生的数据量是 <em>数据量=采样频率\</em> 量化位数*声道数<em>， 单位是bit/s。 一般声道数都假设为1.。 <em>*采样率和量化位数都是语音合成里的重要指标，也就是设计好的神经网络1秒钟必须生成的数据量</em></em>。</p><h2 id="语音合成流程"><a href="#语音合成流程" class="headerlink" title="语音合成流程"></a>语音合成流程</h2><p><img src="/DeepLearningApplications/语音合成/语音合成模型/webp-20220604233848795" alt="img" style="zoom:67%;"></p><p>Fig. 2 Two stage text-to-speech synthsis (source [2]) </p><h3 id="文本分析（text-analysis）"><a href="#文本分析（text-analysis）" class="headerlink" title="文本分析（text analysis）"></a>文本分析（text analysis）</h3><p>文本分析就是把文字转成类似音标的东西。 比如下图就是一个文本分析，用来分析 “PG&amp;E will file schedules on April 20. ” 文本分析主要有三个步骤：文字规范化， 语音分析， 还有韵律分析。 下面一一道来。 </p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/webp-20220604233951462" alt="img"></p><p>Fig. 3 文本分析</p><h4 id="文本规范化-Text-normalization"><a href="#文本规范化-Text-normalization" class="headerlink" title="文本规范化 (Text normalization)"></a>文本规范化 (Text normalization)</h4><p>文本分析首先是要确认单词和句子的结束。 空格会被用来当做隔词符. 句子的结束一般用标点符号来确定， 比如问号和感叹号 （？！）, 但是句号有的时候要特别处理。 因为有些单词的缩写也包含句号， 比如 str. “My place on Main Str. is around the corner”. 这些特别情况一般都会采取规则（rule）的方式过滤掉。</p><p>接下来 是把非文字信息变成对应的文字， 比如句子中里有日期， 电话号码， 或者其他阿拉伯数字和符号。 这里就举个例子， 比如， I was born April 14. 就要变成， I was born April fourteen.  这个过程其实非常繁琐，现实文字中充满了 缩写，比如CS, 拼写错误， 网络用语， tmr —&gt; tomorrow. 解决方式还是主要依靠rule based method， 建立各种各样的判断关系来转变。</p><h4 id="语音分析-Phonetic-analysis"><a href="#语音分析-Phonetic-analysis" class="headerlink" title="语音分析 (Phonetic analysis)"></a>语音分析 (Phonetic analysis)</h4><p>语音分析就是把每个单词中的发音单词标出来， 比如Fig. 3 中的P, 就对应p和iy, 作为发音。 这个时候也很容易发现，发音的音标和对应的字母 不是一一对应的关系，反而需要音标去对齐 （allignment）。 这个对齐问题很经典， 可以用很多机器学习的方法去解决， 比如Expectation–maximization algorithm.</p><h4 id="韵律分析-Prosody-analysis"><a href="#韵律分析-Prosody-analysis" class="headerlink" title="韵律分析 (Prosody analysis)"></a>韵律分析 (Prosody analysis)</h4><p>韵律分析就是英语里的语音语调， 汉语中的抑扬顿挫。 我们还是以英语为例， 韵律分析主要包含了： 重音 (Accent)，边界 (boundaries), 音长 (duration)，主频率 (F0)。</p><p><strong>重音（Accent）</strong>就是指哪个音节发生重一点。 对于一个句子或者一个单词都有重音。 单词的重音一般都会标出来，英语语法里面有学过， 比如banana 这个单词， 第二个音节就是重音。 而对于句子而言，一样有的单词会重音，有的单词会发轻音。 一般有新内容的名词， 动词， 或者形容词会做重音处理。 比如下面的英语句子， surprise 就会被重音了， 而句子的重音点也会落到单词的重音上， 第二个音节rised, 就被重音啦。 英语的重音规则是一套英语语法，读者可以自行百度搜索。</p><p>I’m a little    sur<strong>prised</strong>  to hear it <strong>cha</strong>racterized    as up<strong>beat</strong>.</p><p><strong>边界 （Boundaries）</strong> 就是用来判断声调的边界的。 一般都是一个短语结束后，有个语调的边界。 比如下面的句子， For language, 就有一个边界， 而I 后面也是一个边界.</p><p>For language, I , the author of the blog, like Chinese.</p><p><strong>音长（Duration）</strong>就是每个音节的发声长度。 这个通俗易懂。 NLP 里可以假定每个音节单词长度相同都是 100ms, 或者根据英语语法， 动词， 形容词之类的去确定。 也可以通过大量的数据集去寻找规律。</p><p><strong>主频率 （F0</strong>）就是声音的主频率。 应该说做傅里叶转换后， 值 (magnitude) 最大的那个。 也是人耳听到声音认定的频率。一个成年人的声音主频率在 100-300Hz 之间。 这个值可以用 线性回归来预测， 机器学习的方法预测也可以。一般会认为，人的声音频率是连续变化的，而且一个短语说完频率是下降趋势。</p><p>文本分析就介绍完了，这个方向比较偏语言学， 传统上是语言学家的研究方向，但是随着人工智能的兴起，这些feature 已经不用人为设计了，可以用端到端学习的方法来解决。 比如谷歌的文章 <a href="https://arxiv.org/pdf/1703.10135.pdf" target="_blank" rel="noopener">TACOTRON: TOWARDS END-TO-END SPEECH SYNTHESIS</a> 就解救了我们。</p><h3 id="声波生成（waveform-synthesis）"><a href="#声波生成（waveform-synthesis）" class="headerlink" title="声波生成（waveform synthesis）"></a>声波生成（waveform synthesis）</h3><p>这个部分就比较像我们算法工程师的工作内容了。 在下面， 会详细介绍如何用Wavenet 和WaveRNN 来实现这一步骤的。 </p><p>这里说所谓的waveform synthesis 就是用这些 语言特征值（text features）去生成对应的声波，也就是生成前文所说的采样频率 和 振幅大小（对应的数字信号）。 这里面主要有两个算法。</p><p><strong>串接合成（concatenative speech synthesis）</strong>： 这个方法呢， 就是把记录下来的音节拼在一起来组成一句话，在通过调整语音语调让它听起来自然些。 比较有名的有双音节拼接（Diphone Synthesis） 和单音节拼接（Unit Selection Synthesis）。这个方法比较繁琐， 需要对音节进行对齐（alignment）， 调整音节的长短之类的。</p><p><strong>参数合成 （Parametric Synthesis）</strong>： 这个方法呢， 需要的内存比较小，是通过统计的方法来生成对应的声音。 模型一般有隐马尔科夫模型 （HMM），还有最近提出的神经网络算法Wavenet, WaveRNN. </p><p>对于隐马尔科夫模型的算法， 一般都会生成梅尔频率倒谱系数 （MFCC），这个是声音的特征值。 感兴趣的可以参考<a href="https://www.cnblogs.com/BaroC/p/4283380.html" target="_blank" rel="noopener">这篇博客</a>去了解 MFCC。</p><p>对于神经网络的算法来说， 一般都是生成256 个 quantized values 基于softmax 的分类器， 对应 声音的 256 个量化值。 WaveRNN 和wavenet 就是用这种方法生成的。</p><h2 id="Tacotron和Tacotron2"><a href="#Tacotron和Tacotron2" class="headerlink" title="Tacotron和Tacotron2"></a>Tacotron和Tacotron2</h2><p>以下内容主要来源于<a href="https://www.dengbocong.cn/Paper-Reading/cea2357273fe/" target="_blank" rel="noopener">论文阅读笔记：Tacotron和Tacotron2</a>。</p><p>我们首先对 Tacotron 和 Tacotron2 论文中的关键部分进行阐述和总结，之所以两篇论文放在一起，是因为方便比较模型结构上的不同点，更清晰的了解 Tacotron2 因为改进了哪些部分，在性能上表现的比 Tacotron 更好。</p><p>语音合成系统通常包含多个阶段，例如 TTS Frontend（文本前端），Acoustic model（声学模型） 和 Vocoder（声码器），如下图更直观清晰一点：  </p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/t_70-20220604204302965.png" alt="在这里插入图片描述" style="zoom: 67%;"></p><p>构建这些组件通常需要广泛的领域专业知识，并且可能包含脆弱的设计选择。在很多人困扰于繁杂的特征处理的时候，Google 推出了 Tacotron，一种从文字直接合成语音的端到端的语音合成模型，虽然在效果上相较于传统方法要好，但是相比 Wavenet 并没有明显的提升（甚至不如 Wavenet），不过它更重要的意义在于 end-to-end（Wavenet 是啥将在后面对比 vocoder 的时候讲解，顺便提一下 Tacotron 使用的是 Griffin-Lim 算法，而 Tacotron2 使用的是修改版 Wavenet)。此外，相较于其他<strong>样本级自回归方法合成语音</strong>，Tacotron 和 Tacotron2 是<strong>在帧级生成语音</strong>，因此要快得多。</p><p>在传统的 Pipeline 的统计参数 TTS，通常有一个文本前端提取各种语言特征，持续时间模型，声学特征预测模型和基于复杂信号处理的声码器。而端到端的语音合成模型，只需要对文本语音进行简单的处理，就能喂给模型进行学习，极大的减少的人工干预，对文本的处理只需要进行文本规范化以及分词 token 转换（论文中使用 character，不过就语音合成而言，使用 Phoneme 字典更佳），关于文本规范化（数字、货币、时间、日期转完整单词序列）以及 text-to-phoneme 可以参见<a href="https://zhuanlan.zhihu.com/p/336872753" target="_blank" rel="noopener">利器：TTS Frontend 中英 Text-to-Phoneme Converter，附代码</a>。端到端语音合成系统的优点如下：</p><ul><li>减少对特征工程的需求</li><li>更容易适应新数据（不同语言、说话者等）</li><li>单个模型可能比组合模型更健壮，在组合模型中，每个组件的错误都可能叠加而变得更加复杂</li></ul><p><strong>端到端语音合成模型的困难所在：</strong>  </p><p>不同 Speaker styles 以及不同 pronunciations 导致的对于给定的输入，模型必须对不同的信号有着更大的健壮性，除此之外 Tacotron 原本下描述：</p><blockquote><p>TTS is a large-scale inverse problem: a highly compressed source (text) is “decompressed” into audio</p></blockquote><p>上面这句是 Tacotron 原文中说的，简单来说就是 TTS 输出是连续的，并且输出序列（音频）通常比输入序列（文本）长得多，导致预测误差迅速累积。想要了解更多关于语音合成的背景知识，可以参考文章 <a href="https://www.jianshu.com/p/46888767dcef" target="_blank" rel="noopener">Text-to-speech</a>。</p><h3 id="Tacotron模型结构"><a href="#Tacotron模型结构" class="headerlink" title="Tacotron模型结构"></a>Tacotron模型结构</h3><p>Tacotron 的基础架构是带有注意力机制（Attention Mechanism）的 Seq2Seq 模型，下图是模型的总体架构。网络部分大体可分为 4 部分，分别是左：Encoder、中：Attention、右下：Decoder、右上：Post-processing。从高层次上讲，模型将字符作为输入，并生成频谱图，然后将其转换为波形。  </p><p><img src="https://unisound.github.io/end-to-end_tts/images/tacotron.jpg" alt="Tacotron" style="zoom:50%;"></p><p>要特别说明的是架构中，raw text 经过 pre-net 后，将会把输出喂给一个叫 CBHG 的模块以映射为 hidden representation，再之后 decoder 会生成 Linear-Spectrum，再经过 Griffin-Lim 转换为波形。</p><p>raw text的选择可以可以有多种选择，以中文和英文合成系统为例：</p><ol><li><p>英文文本，训练英文模型，最直观的想法是直接将英文文本当做输入，<a href="https://arxiv.org/abs/1703.10135" target="_blank" rel="noopener">Tacotron1</a> 也是这么做的。但这样可能会引入一些问题，比如未登录词发音问题。</p></li><li><p>英文注音符，用英文注音符(比如 <a href="http://www.speech.cs.cmu.edu/cgi-bin/cmudict" target="_blank" rel="noopener">CMUDict</a> )作为输入可以提高发音稳定性，除了注音词典，还可以引入注音前端，增强对模型的控制。 中文拼音，由于中文汉字数量多，且存在大量多音字，直接通过文本训练</p></li><li><p>中文拼音，由于中文汉字数量多，且存在大量多音字，直接通过文本训练是不现实的。所以我们退而求其次，通过拼音训练模型，拼音有注音前端生成，既去掉了汉字的冗余发音又提高了模型的可控性。</p></li><li><p>中文|英文 <a href="http://www.internationalphoneticalphabet.org/" target="_blank" rel="noopener">IPA (International Phonetic Alphabet)</a> 音标，IPA 音标是一种更强的注音体系，一套注音体系可以标注多种语言。对于中文，IPA 音标的标注粒度比拼音更细，实验中，我们观察到用 IPA 作为输入，可以略微提升对齐稳定性。另外，在中文发音人+英文发音人混合训练试验中，我们观察到了一个有意思的现象：由于中英文 IPA 标注中共享了部分发音单元，导致跨语种发音人可以学会对方的语言，也就是中文发音人可以合成英文，英文发音人可以合成中文。在这个联合学习过程中存在着迁移学习的味道。</p></li></ol><blockquote><p>根据不同的用途，Tacotron 可以输出 Linear-Spectrum 或 Mel-Spectrum，如果使用 Griffin-Lim 需要 Tacotron 输出 Linear-Spectrum；如果使用 WaveNet 做 Vocoder（即Tacotron2，下文会介绍） ，则 Tacotron 输出 Linear-Spectrum 或 Mel-Spectrum 均可，但 Mel-Spectrum 的计算代价显然更小，Tacotron2 中，作者使用 80 维 Mel-Spectrum 作为 WaveNet Vocoder 的输入。</p></blockquote><h4 id="Character-Embedding"><a href="#Character-Embedding" class="headerlink" title="Character Embedding"></a>Character Embedding</h4><p>我们知道在训练模型的时候，我们拿到的数据是一条长短不一的(text, audio)的数据，深度学习的核心其实就是大量的矩阵乘法，对于模型而言，文本类型的数据是不被接受的，所以这里我们需要先把文本转化为对应的向量。这里涉及到如下几个操作</p><p><strong>构造字典</strong></p><p>因为纯文本数据是没法作为深度学习输入的，所以我们首先得把文本转化为一个个对应的向量，这里我使用字典下标作为字典中每一个字对应的id，然后每一条文本就可以通过遍历字典转化成其对应的向量了。所以字典主要是应用在将文本转化成其在字典中对应的id，根据语料库构造，这里我使用的方法是根据语料库中的字频构造字典(我使用的是基于语料库中的字构造字典，有的人可能会先分词，基于词构造。不使用基于词是现在就算是最好的分词都会有一些误分词问题，而且基于字还可以在一定程度上缓解OOV的问题)。</p><p>然后我们就可以将文本数据转化成对应的向量作为模型的输入。</p><p><strong>embed layer</strong></p><p>光有对应的id，没法很好的表征文本信息，这里就涉及到构造词向量，关于词向量不在说明，网上有很多资料，模型中使用词嵌入层，通过训练不断的学习到语料库中的每个字的词向量。</p><p>值得注意的是，这里是随机初始化词嵌入层，另一种方法是引入预先在语料库训练的词向量(word2vec)，可以在一定程度上提升模型的效果。</p><h4 id="音频特征提取"><a href="#音频特征提取" class="headerlink" title="音频特征提取"></a>音频特征提取</h4><p>对于音频，我们主要是提取出它的mel-spectrogram，然后变换得到比较常用的音频特征MFCC。对于声音来说，它其实是一个一维的时域信号，直观上很难看出频域的变化规律，我们知道，可以使用傅里叶变化，得到它的频域信息，但是又丢失了时域信息，无法看到频域随时域的变化，这样就没法很好的描述声音， 为了解决这个问题，很多时频分析手段应运而生。短时傅里叶，小波，Wigner分布等都是常用的时频域分析方法。这里我们使用短时傅里叶。</p><p>所谓短时傅里叶变换，顾名思义，是对短时的信号做傅里叶变化。那么短时的信号怎么得到的? 是长时的信号分帧得来的。这么一想，STFT的原理非常简单，把一段长信号分帧(傅里叶变换适用于分析平稳的信号。我们假设在较短的时间跨度范围内，语音信号的变换是平坦的，这就是为什么要分帧的原因)、加窗，再对每一帧做傅里叶变换（FFT），最后把每一帧的结果沿另一个维度堆叠起来，得到类似于一幅图的二维信号形式。如果我们原始信号是声音信号，那么通过STFT展开得到的二维信号就是所谓的声谱图。</p><p>声谱图往往是很大的一张图，为了得到合适大小的声音特征，往往把它通过梅尔标度滤波器组（mel-scale filter banks），变换为梅尔频谱（mel-spectrogram）。在梅尔频谱上做倒谱分析（取对数，做DCT变换）就得到了梅尔倒谱系数（MFCC，Mel Frequency Cepstral Coefficents）。我们主要使用第三方库librosa提取MFCC特征。</p><h4 id="CBHG-内部结构说明"><a href="#CBHG-内部结构说明" class="headerlink" title="CBHG 内部结构说明"></a>CBHG 内部结构说明</h4><p>所谓 CBHG 就是作者使用的一种用来从序列中提取高层次特征的模块，如下图所示：  </p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/t_70-20220604203914117.png" alt></p><p>CBHG 使用了 1D 卷积、highway、残差链接和双向 GRU 的组合，输入序列，输出同样也是序列，因此，它从序列中提取表示非常强大。CBHG 架构流程如下：</p><ul><li>首先使用 $K$ 组 1D 卷积对输入序列进行卷积，其中第 $k$ 组表示为$C_k$ ，其卷积核的宽度为 $k$（即$k=1,2,…,K$）。 这些卷积层显式地对本地和上下文信息进行建模（类似于对 unigram，bigrams 以及 K-gram 的建模）</li><li>然后将卷积输出堆叠在一起（注意：在做卷积时，运用了padding，因此这k个卷积核输出的大小均是相同的），并进行最大化池，以增加局部不变性。注意了，最大化池使用 stride 为 1 来保留原始时间分辨率</li><li>接着将处理后的序列传递给一些固定宽度的 1D 卷积，其输出通过残差连接与原始输入序列相加，同时批量归一化用于所有卷积层</li><li>然后将输出喂到多层 highway 网络中以提取高级特征。highway nets的每一层结构为：把输入同时放入到两个一层的全连接网络中，这两个网络的激活函数分别采用了ReLu和sigmoid函数，假定输入为input，ReLu的输出为output1，sigmoid的输出为output2，那么highway layer的输出为output=output1∗output2+input∗（1−output2)。为什么要使用highway network的结构呢，其实说白了也是一种减少缓解网络加深带来过拟合问题，以及减少较深网络的训练难度的一个trick。它主要受到LSTM门限机制的启发。</li><li>最后，在顶部堆叠双向 GRU RNN，以从前向和后向上下文中提取顺序特征。</li></ul><p>在 Encoder 中，输入被 CBHG 处理之前还需要经过 pre-net 进行预处理，作者设计 pre-net（pre-net 是由全连接层 + dropout 组成的模块）的意图是让它成为一个 bottleneck layer 来提升模型的泛化能力，以及加快收敛速度。</p><h4 id="Decoder-结构说明"><a href="#Decoder-结构说明" class="headerlink" title="Decoder 结构说明"></a>Decoder 结构说明</h4><p>随后就是 Decoder 了，论文中使用两个 decoder</p><ul><li>attention decoder：attention decoder 用来生成 query vector 作为 attention 的输入，交由注意力模块生成 context vector。它用于学习如何对齐文本序列和语音帧，序列中的每个字符编码通常对应多个语音帧并且相邻的语音帧一般也具有相关性。</li><li>output decoder：output decoder 则将 query vector 和 context vector 组合在一起作为输入。</li></ul><p>作者并没有选择直接用 output decoder 来生成 spectrogram，而是生成了 80-band mel-scale spectrogram，也就是我们之前提到的 mel-spectrogram，熟悉信号处理的同学应该知道，spectrogram 的 size 通常是很大的，因此直接生成会非常耗时，而 mel-spectrogram 虽然损失了信息，但是相比 spectrogram 就小了很多，且由于它是针对人耳来设计的，因此对最终生成的波形的质量不会有很多影响。</p><p>随后使用 post-processing network（下面会讲）将 seq2seq 目标转换为波形，然后使用一个全连接层来预测 decoder 输出。Decoder 中有一个 <strong>trick 就是在每个 decoder step 预测多个 (r 个)非重叠frame，这样做可以缩减计算量，且作者发现这样做还可以加速模型的收敛</strong>。</p><blockquote><p>预测多个非重叠帧的直观解释：因为就像我们前面说到的提取音频特征的时候，我们会先分帧，相邻的帧其实是有一定的关联性的，所以每个字符在发音的时候，可能对应了多个帧，因此每个GRU单元输出为多个帧的音频文件。</p><p>论文提到 scheduled sampling 在这里使用会损失音频质量</p></blockquote><h4 id="post-processing-net-和-waveform-synthesis"><a href="#post-processing-net-和-waveform-synthesis" class="headerlink" title="post-processing net 和 waveform synthesis"></a>post-processing net 和 waveform synthesis</h4><p>和seq2seq网络不同的是，tacotron在decoder-RNN输出之后并没有直接将其作为输出通过Griffin-Lim算法合成音频，而是添加了一层post-processing模块。为什么要添加这一层呢？</p><p>首先是因为我们使用了Griffin-Lim重建算法，根据频谱生成音频，Griffin-Lim原理是：我们知道相位是描述波形变化的，我们从频谱生成音频的时候，需要考虑连续帧之间相位变化的规律，如果找不到这个规律，生成的信号和原来的信号肯定是不一样的，Griffin Lim算法解决的就是如何不弄坏左右相邻的幅度谱和自身幅度谱的情况下，求一个近似的相位，因为相位最差和最好情况下天壤之别，所有应该会有一个相位变化的迭代方案会比上一次更好一点，而Griffin Lim算法找到了这个方案。这里说了这么多，其实就是Griffin-Lim算法需要看到所有的帧。post-processing可以在一个线性频率范围内预测幅度谱（spectral magnitude)。</p><p>其次，post-processing能看到整个解码的序列，而不像seq2seq那样，只能从左至右的运行。它能够通过正向传播和反向传播的结果来修正每一帧的预测错误。</p><p>论文中使用了CBHG的结构来作为post-processing net，前面已经详细介绍过。实际上这里 post-processing net 中的 CBHG 是可以被替换成其它模块用来生成其它东西的，比如直接生成 waveform，在 Tacotron2 中，CBHG 就被替换为 Wavenet 来直接生成波形。</p><h4 id="模型详细的配置"><a href="#模型详细的配置" class="headerlink" title="模型详细的配置"></a>模型详细的配置</h4><p><img src="/DeepLearningApplications/语音合成/语音合成模型/t_70.png" alt></p><p>对 Decoder 和 post-processing net 使用 L1 损失，并取平均。作者使用 32batch，并将序列 padding 到最大长度。关于 padding 的说明，Tacotron 原文如下：</p><blockquote><p>It’s a common practice to train sequence models with a loss mask, which masks loss on zero-padded frames. However, we found that models trained this way don’t know when to stop emitting outputs, causing repeated sounds towards the end. One simple trick to get around this problem is to also reconstruct the zero-padded frames.</p></blockquote><h3 id="Tacotron2模型结构"><a href="#Tacotron2模型结构" class="headerlink" title="Tacotron2模型结构"></a>Tacotron2模型结构</h3><p>Tacotron有啥缺点呢？</p><ul><li><strong>CBHG模块的去与留？</strong></li></ul><p>Tacotron中使用了CBHG模块（包括编码器部分和解码器部分），虽然在实验中发现该模块可以一定程度上减轻过拟合问题，和减少合成语音中的发音错误，但是该模块本身比较复杂，能否用其余更简单的模块替换该模块？</p><ul><li><strong>Attention出现错误对齐的现象</strong></li></ul><p>Tacotron中使用的Attention机制能够隐式的进行语音声学参数序列与文本语言特征序列的隐式对齐，但是由于Tacotron中使用的Attention机制没有添加任何的约束，导致模型在训练的时候可能会出现错误对齐的现象，使得合成出的语音出现部分发音段发音不清晰、漏读、重复、无法结束还有误读等问题。</p><ul><li><strong>r值如何设定？</strong></li></ul><p>Tacotron中一次可生成r帧梅尔谱，r可以看成一个超参数，r可以设置的大一点，这样可以加快训练速度和合成语音的速度，但是r值如果设置的过大会破坏Attention RNN隐状态的连续性，也会导致错误对齐的现象。</p><ul><li><strong>声码器的选择</strong></li></ul><p>Tacotron使用Griffin-Lim作为vocoder来生成语音波形，这一过程会存在一定的信息丢失，导致合成出的语音音质有所下降（不够自然）。Tacotron 中作者也提到了，这个算法只是一个简单、临时的 neural vocoder 的替代，因此要改进 Tacotron 就需要有一个更好更强大的 vocoder。</p><p>接下来我们来看看 Tacotron2，它的模型大体上分为两个部分：</p><ul><li>具有注意力的循环序列到序列特征预测网络，该网络根据输入字符序列预测梅尔谱帧的序列</li><li>WaveNet 的修改版，可生成以预测的梅尔谱帧为条件的 time-domain waveform 样本</li></ul><p>结构图如下：  </p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/t_70-20220604203914399.png" style="zoom: 67%;"></p><ul><li><strong>CBHG模块的去与留？</strong></li></ul><p>在Tacotron2中，对于编码器部分的CBHG模块，作者采用了一个3<em>Conv1D+BiLSTM模块进行替代，如图2下方蓝色部分所示；对于解码器部分的CBHG模块，作者使用了Post-Net（5</em>Conv1D）和残差连接进行替代。</p><ul><li><strong>Attention出现错误对齐的现象</strong></li></ul><p>在Tacotron2中，作者使用了Location-sensitive Attention代替了原有的基于内容的注意力机制，前者在考虑内容信息的同时，也考虑了位置信息，这样就使得训练模型对齐的过程更加的容易。一定程度上缓解了部分合成的语音发音不清晰、漏读、重复等问题。对于Tacotron中无法在适当的时间结束而导致合成的语音末尾有静音段的问题，作者在Tacotron2中设计了一个stop token进行预测模型应该在什么时候进行停止解码操作。</p><ul><li><strong>r值如何设定？</strong></li></ul><p>在Tacotron2中，r值被设定为1，发现模型在一定时间内也是可以被有效训练的。猜测这归功于模型整体的复杂度下降，使得训练变得相对容易。</p><ul><li><strong>声码器的选择</strong></li></ul><p>Tacotron2 选择预测 a low-level acoustic 表示，即 mel-frequency spectrograms（Tacotron 使用 linear-frequency scale spectrograms)，Tacotron2 原文描述如下：</p><blockquote><p>This representation is also smoother than waveform samples and is easier to train using a squared error loss because it is invariant to phase within each frame.</p></blockquote><p>mel-frequency spectrogram 与 linear-frequency spectrograms 有关，即短时傅立叶变换（STFT）幅度。mel-frequency 是通过对 STFT 的频率轴进行非线性变换而获得的，同时受到人类听觉系统的启发，用较少的维度表示频率内容，原因很好理解，低频中的细节对于音频质量至关重要，而高频中往往包含摩擦音等噪音，因此通常不需要对高频细节建模。</p><p>虽然 linear spectrograms 会丢弃相位信息（因此是有损的），但是诸如 Griffin-Lim 之类的算法能够估算此丢弃的信息，从而可以通过短时傅立叶逆变换进行时域转换。而 <strong>mel spectrogram 会丢弃更多信息，因此它的逆问题更具有挑战性</strong>，这个时候作者想到了 WaveNet替换了原先的Griffin-Lim，进一步加快了模型训练和推理的速度，因为wavenet可以直接将梅尔谱转换成原始的语音波形。（Tacotron2合成语音音质的提升貌似<em>主要</em>归功于Wavenet替换了原有的Griffin-Lim）。</p><p>除了 Wavenet，Tacotron2 和 Tacotron 的主要不同在于：</p><ul><li>不使用 CBHG，而是使用普通的 LSTM 和 Convolution layer</li><li>decoder 每一步只生成一个 frame</li><li>增加 post-net，即一个 5 层 CNN 来精调 mel-spectrogram</li></ul><h3 id="Tacotron实验结果"><a href="#Tacotron实验结果" class="headerlink" title="Tacotron实验结果"></a>Tacotron实验结果</h3><p>下图展示 Decoder step 中，使用不同组件学习到 attention alignment 的效果：  </p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/t_70-20220604205845238.png" style="zoom:90%;"></p><p>  下图展示了 post-processing net 的实验效果，可以看到有 post-processing net 的网络效果更好：  </p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/t_70-20220604203914098.png" style="zoom: 67%;"></p><p>  MOS 分数对比如下表：  </p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/20201215105516463.png" alt></p><h3 id="Tacotron2实验结果"><a href="#Tacotron2实验结果" class="headerlink" title="Tacotron2实验结果"></a>Tacotron2实验结果</h3><p>下表展示了 Tacotron2 与各种现有系统的 MOS 分数比较。Tacotron2 的分数已经和人类不相上下了，这在很大程度上要归功于 Wavenet。  </p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/t_70-20220604203914133.png" alt></p><p> 下表是对合成的音频的评价：  </p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/t_70-20220604203914151.png" alt></p><p>文中提到，Wavenet 在这个模型中是和剩下的模型分开训练的，Wavenet 的输入是 mel-spectrogram，输出是 waveform，这个时候就需要考虑输入的 mel-spectrogram 是选择 ground truth，还是选用 prediction，作者做了相关实验，结果如下图所示：  </p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/t_70-20220604203914172.png" alt></p><p>  可以看到使用模型生成的 mel-spectrogram 来训练的 Wavenet 取得了最好的结果，作者认为这是因为这种做法保证了数据的一致性。下表是生成 mel-spectrogram 和 linear spectrogram 的区别（结果证明 mel-spectrogram 是最好的，同时还能够减少计算，加快 inference 的时间）：  </p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/t_70-20220604203914204-4346354.png" alt></p><p>  下表是对 WaveNet 简化之后的 MOS 分数情况：  </p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/t_70-20220604203914223.png" alt></p><h3 id="关于-vocoder"><a href="#关于-vocoder" class="headerlink" title="关于 vocoder"></a>关于 vocoder</h3><p>声码器（Vocoder）在语音合成中往往被用于将生成的语音特征转换为我们所需要的语音波形。在Tacotron中，由于前端的神经网络所预测出的梅尔谱图仅包含了幅值信息而缺乏相应的相位信息，我们难以直接通过短时傅里叶变换（STFT）的逆变换将梅尔谱图还原为声音波形文件；因此，我们需要使用声码器进行相位估计，并将输入的梅尔谱图转换为语音波形。</p><p>Tacotron 使用的是 Griffin-Lim 算法，Griffin-Lim 是一种声码器，常用于语音合成，用于将语音合成系统生成的声学参数转换成语音波形，这种声码器不需要训练，不需要预知相位谱，而是通过帧与帧之间的关系估计相位信息，从而重建语音波形。更正式一点的解释是 Griffin-Lim 算法是一种已知幅度谱，未知相位谱，通过迭代生成相位谱，并用已知的幅度谱和计算得出的相位谱，重建语音波形的方法，具体可参考这篇 <a href="https://zhuanlan.zhihu.com/p/66809424" target="_blank" rel="noopener">Griffin-Lim 声码器介绍</a>。</p><p>Griffin-Lim 的优点是算法简单，可以快速建立调研环境，缺点是速度慢，很难在 CPU 上做到实时，无法实时解码也就意味着系统无法在生产环境使用。而且通过Griffin-Lim生成波形过于平滑，空洞较多，听感不佳。</p><p>种种迹象表明，Griffin-Lim 算法是音质瓶颈，经过一些列工作尤其是 <a href="https://arxiv.org/abs/1712.05884" target="_blank" rel="noopener">Tacotron2</a> ，人们逐渐意识到，Mel-Spectrogram 可以作为采样点自回归模型的 condition，利用强大的采样点自回归模型提高合成质量。</p><p>目前公认的效果有保障的采样点自回归模型主要如下几种，1) SampleRNN、2)WaveNet、3)WaveRNN。我们重点介绍前两种。</p><h4 id="SampleRNN"><a href="#SampleRNN" class="headerlink" title="SampleRNN"></a>SampleRNN</h4><p>其模型结构如下：</p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/samplernn.jpg" alt="samplernn" style="zoom: 67%;"></p><p>图3: SampleRNN 模型结构</p><p>SampleRNN 是一个精心设计的 RNN 自回归模型。标准的 RNN 模型包括 LSTM、GRU，可以用来处理一些长距离依赖的场景，比如语言模型。但对于音频采样点这样的超长距离依赖场景（比如：24k采样率，意味着 1s 中包含 24000 个采样点），RNN 处理起来已经非常困难了 。SampleRNN 的作者，将问题分解，分辨率由低到高逐层建模，例如图中，Tier3 层每时刻输入16个采样点，输出状态 S1；Tier2 层每时刻输入 4 个采样点，同时输入 Tier3 输出的 S1，输出状态 S2 ； Tier1 层每时刻输入 4 个采样点，同时输入 Tier2 输出的 S2，输出一个采样点，由于 Tier1 没有循环结构，同一时刻可以输出 4 个采样点。</p><p>如果有兴趣，可以点击 <a href="https://pan.baidu.com/s/1o8M8bGI" target="_blank" rel="noopener">SampleRNN Samples</a>，在里面你能找到总长度为 1小时 的 Samples。</p><p>总体来看模型的波形生成能力相当了得，发音、音色以及韵律风格的还原度都非常高。但 SampleRNN 也存在一些问题，最主要的是训练收敛速度太慢了，导致调参优化效率低下，我们将介绍另一个采样点自回归模型 WaveNet，相比 SampleRNN ，WaveNet 不但保留了高水平的波形生成能力，而且还提升了训练速度，单卡训练一天就能获得较好的效果。</p><h4 id="WaveNet"><a href="#WaveNet" class="headerlink" title="WaveNet"></a>WaveNet</h4><p>其模型结构如下</p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/wavenet.gif" alt="wavenet"></p><p>图4: 采样点自回归 WaveNet</p><p>图4, 描述了 WaveNet 这类采样点自回归模型的工作方式，模型输入若干历史采样点，输出下一采样点的预测值，也就是根据历史预测未来。如果你对 NLP 较为熟悉，一定会觉得这种工作方式很像语言模型，没错，只不过音频采样点自回归更难一些罢了，需要考虑更长的历史信息才能保证足够的预测准确率。</p><p>WaveNet 最初由 DeepMind 推出，是基于 CNN 的采样点自回归模型，由于 CNN 结构的限制，为了解决长距离依赖问题，必须想办法扩大感受野，但扩大感受野又会增加参数量。为了在扩大感受野和控制参数量间寻找平衡，作者引入所谓“扩展卷积”的结构。如上图所示，“扩张卷积”，也可以称为“空洞卷积”，顾名思义就是计算卷积时跨越若干个点，WaveNet 层叠了多层这种 1D 扩张卷积，卷积核宽度为 2 （Parallel WaveNet 为 3），Dilated 宽度随层数升高而逐渐加大。可以想象，通过这种结构，CNN 感受野随着层数的增多而指数级增加。</p><p>训练好了 WaveNet ，我们就可以来合成音频波形了。但是，你会发现这时合成的音频完全没有语义信息，听起来更像是鹦鹉学舌，效果就如上一节 SampleRNN 的样例一样。 要使 WaveNet 合成真正的语音，那么就需要为其添加 condition ，condition 包含了文本的语义信息，这些语义信息可以帮助 WaveNet 合成我们需要的波形，condition 的形式并不唯一，但本文中我们只介绍 Mel-Spectrum condition 。</p><p><strong>Mel-Spectrum condition</strong></p><p>为什么要引入 Mel-Spectrum condition 呢？有两个原因：其一是为了和 Tacotron 打通，Tacotron 的输出可以直接作为 WaveNet 的输入，构成一套完整的端到端语音合成流水线；其二是因为 Mel-Spectrum 本身包含了丰富的语音语义信息，这些语音语义信息可以支持后期的多人混合训练、以及韵律风格迁移等工作。</p><p>下面我们将着重介绍如何在模型中融入 Mel-Spectrum condition 。</p><p>由于采样点长度和 Mel-Spectrum 长度不匹配，我们需要想办法将长度对齐，完成这一目标有两种方法：一种是将 Mel-Spectrum 反卷积上采样到采样点长度，另一种是将 Mel-Spectrum 直接复制上采样到采样点长度，两种方案效果差异很小。我们希望模型尽量简洁，故而采用第二种方法，如图6所示。</p><p>方便起见，我们借用 Deep Voice1 （图5）来说明。经过复制上采样的 Mel-Spectrum condition，首先需要经过一个 1x1 卷积，使 Mel-Spectrum condition 维度与 WaveNet GAU 输入维度相同，然后分两部分累加送入 GAU 即可，注意，WaveNet 每层 GAU 都需要独立添加 Mel-Spectrum condition。</p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/deepvoice.jpg" alt="wavenet" style="zoom:67%;"></p><p>图5: Mel-Spectrum condition 计算方法</p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/image2018-1-12 11_43_38.png" alt="wavenet" style="zoom:80%;"></p><p>图6: Mel-Spectrum 时间分辨率对齐</p><p>WaveNet 有很多优点，训练快、效果好、网络结构清晰简洁。但 WaveNet 也引入了新问题：inference 性能差，在 CPU 平台通常需要数十秒时间合成一秒语音，这让商业化几乎不可能。</p><p>针对这一问题，DeepMind 推出了 WaveNet 加速方案 Parallel WaveNet，Parallel WaveNet 将 inference 速度提升上千倍。</p><h2 id="Transformer-TTS"><a href="#Transformer-TTS" class="headerlink" title="Transformer TTS"></a>Transformer TTS</h2><h3 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h3><p>该方法来自于<a href="https://arxiv.org/abs/1809.08895" target="_blank" rel="noopener">Neural Speech Synthesis with Transformer Network (2018)</a>。</p><p>虽然Tacotron2解决了一些在Tacotron中存在的问题，但是Tacotron2和Tacotron整体结构依然一样，二者都是一个自回归模型，也就是每一次的解码操作都需要先前的解码信息，导致模型难以进行并行计算训练和推理过程中的效率低下。其次，二者在编码上下文信息的时候，都使用了LSTM进行建模。理论上，LSTM可以建模长距离的上下文信息，但是实际应用上，LSTM对于建模较长距离的上下文信息能力并不强。</p><h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="/DeepLearningApplications/语音合成/语音合成模型/v2-08d2694c3119102d90c87d46e4baa6b6_b.jpg" alt="img" style="zoom:70%;"></p><p>如果对Tacotron2和Transformer比较熟悉的话，可以从上图3中看出，其实Transformer TTS就是Tacotron2和Transformer的结合体。其中，一方面，Transformer TTS继承了Transformer Encoder，MHAttention，Decoder的整体架构；另一方面，Transformer TTS的Encoder Pre-net、Decoder Pre-net、Post-net、stop Linear皆来自于Tacotron2，所起的作用也都一致。换句话说，</p><blockquote><p>将Tacotron2: Encoder BiLSTM ——&gt;Transformer: Multi-head Attention（+positional encoding）;</p><p>Tacotron2: Decoder Location-sensitive Attention + LSTM ——&gt;Transformer: Multi-head Attention （+positional encoding）;<br>其余保持不变，就变成了Transformer TTS。</p></blockquote><p>也正是Transformer相对于LSTM的优势，使得Transformer TTS解决了Tacotron2中存在的训练速度低下和难以建立长依赖性模型的问题。</p><p>其中值得一提的是，Transformer TTS保留了原始Transformer中的scaled positional encoding信息。为什么非得保留这个呢？原因就是Multi-head Attention无法对序列的时序信息进行建模。可以用下列公式表示：</p><script type="math/tex; mode=display">\begin{array}{r}P E(p o s, 2 i)=\sin \left(\frac{\text { pos }}{10000 \frac{2 i}{d_{\text {model }}}}\right) \\P E(\text { pos }, 2 i+1)=\cos \left(\frac{\text { pos }}{10000^{\frac{2 i}{d_{\text {model }}}}}\right) \\x_{i}=\operatorname{prenet}\left(\text { phoneme } e_{i}\right)+\alpha P E(i)\end{array}</script><p>其中，$ \alpha $ 是可训练的权重，使得编码器和解码器预处理网络可以学习到输入音素级别对梅尔谱帧级别的尺度适应关系。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文作者结合Tacotron2和Transformer提出了Transformer TTS，在一定程度上解决了Tacotron2中存在的一些问题。但仍然存在一些问题：如1）在训练的时候可以并行计算，但是在推理的时候，模型依旧是自回归结构，运算无法并行化处理；2）相比于Tacotron2，位置编码导致模型无法合成任意长度的语音；3）Attention encoder-decoder依旧存在错误对齐的现象。</p><p>有关代码解读可以参考<a href="https://zhuanlan.zhihu.com/p/512240545" target="_blank" rel="noopener">声学模型（02）：Transformer based TTS</a></p><h2 id="Fastspeech"><a href="#Fastspeech" class="headerlink" title="Fastspeech"></a>Fastspeech</h2><p>该算法来自于<a href="https://arxiv.org/abs/1905.09263" target="_blank" rel="noopener"> FastSpeech: Fast, Robust and Controllable Text to Speech (2019)</a>。</p><h3 id="动机-1"><a href="#动机-1" class="headerlink" title="动机"></a>动机</h3><p>在先前基于神经网络的TTS系统中，mel-spectrogram是以自回归（auto-regressive）方式产生的。由于mel-spectrogram的长序列和自回归性质，这些系统依旧面临着几个问题：</p><ul><li>在推理阶段，mel-spectrogram生成的<strong>速度很慢（slow inference speed）</strong>。尽管Transformer TTS相比较基于RNN的模型显著加快了训练速度，但是这些模型在推理阶段都会基于先前生成的mel-spectrogram帧来生成当前时刻的mel-spectrogram帧，导致推理速度较慢。</li><li>合成语音通常<strong>不够稳定（not robust）</strong>。由于自回归生成中的错误传播和文本与语音之间存在的错误注意力对齐（传统语音合成系统的Alignment是隐式的导致的），生成的mel-spectrogram通常存在跳词和重复（skip and repeat）问题。</li><li>合成语音<strong>缺乏可控性（lack of controllability）</strong>，如语速和韵律方面的可控性（这里笔者的可控应该主要指的是生成的语速方面，因为在Prosody的层面已经有工作做到了很好的效果）。</li></ul><p>基于以上动机，作者提出了Fastspeech。作者描述到：与自回归TTS模型相比，FastSpeech在mel谱图生成上实现了270倍的加速，在最终语音合成上实现了38倍的加速，几乎消除了跳词和重复的问题，并且可以平滑地调整语音速度。</p><h3 id="模型结构-1"><a href="#模型结构-1" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="/DeepLearningApplications/语音合成/语音合成模型/v2-63c3336ca59567f5a2599a1a4c2036e9_b.jpg" alt="img"></p><p>如图1所示，Fastspeech的整体框架和Transformer的Encoder很像，可以简单的理解为是移除了Decoder部分的Transformer模块，以此实现了模型的并行训练和加快推理速度（采用了non auto-regressive的seq-to-seq模型（如上图(a)），不需要依赖上一个时间步的输入，可以让整个模型真正的并行化）。可以看出，Fastspeech主要由三部分构成：FFT Block，Length Regulator和Duration Predictor。</p><blockquote><p>从图1（a）中可以看出，Fastspeech的整体流程和先前的自回归模型还是有几分相似之处的。</p><p>先前的自回归模型流程是：Encoder+Attention（隐式alignment）+Decoder；</p><p>Fastspeech的流程是FFT Block+Length Regulator+FFT Block；其中第一个FFT Block可以看成是Encoder部分，第二个FFT Block可以看成是Decoder部分。明显不同的是Length Regulator，可以看成是一种显式的Attention alignment方式，至于为什么下文有介绍。</p></blockquote><ul><li><strong>Feed-Forward Block</strong></li></ul><p>从上图b可以看出，其实这个模块和Transformer中Multihead attention+Feed-forward结构很相似。稍微有点不同的是作者把原始Feed-forward中的全连接层换成了1D卷积层。为什么要这么做呢？作者描述到：其动机是，在语音任务中，相邻的隐藏状态在字符/音素和mel谱图序列中的关系更为密切。说白了就是作者认为在合成语音的时候局部范围的上下文信息更为重要，较远距离的上下文信息则不那么重要。</p><blockquote><p>The motivation is that the adjacent hidden states are more closely related in the character/phoneme and mel-spectrogram sequence in speech tasks.</p></blockquote><p>其余的部分均和Transformer中的一致，包括positional encoding、multi-head attention、LayerNorm、residual connections。</p><ul><li><strong>Length Regulator</strong></li></ul><p>正上图a所示，第一个FFT Block模块可以简单理解为把因素序列转为一个隐状态，而第二FFT Block模块可以简单理解为把隐状态转换为mel谱图。这就意味着一个问题，要知道因素序列的长度是普遍远远短于mel谱图的长度，那么模型是怎么知道每一个因素应该到底对应多长时间的mel谱帧呢？</p><p>基于以上考虑，作者设计了长度调节器模块（如上图c所示），其作用也就显而易见了，主要是用于解决转换过程中音素和mel谱图序列之间的长度不匹配问题，并且还可以控制语音合成的速度（如何控制下文会有介绍）。</p><p>形式上，一个音素映射到mel谱图上帧的个数称为音素的持续时间。根据音素的持续时间d，长度调节器将音素序列的隐藏状态扩大d倍，同时确保隐藏状态的总长度等于mel谱图的长度。可以用公式表示：</p><script type="math/tex; mode=display">\mathcal{H}_{m e l}=\mathcal{L R}\left(\mathcal{H}_{p h o}, \mathcal{D}, \alpha\right)</script><p>其中 $ \mathcal{H}_{p h o}=\left[h_{1}, h_{2}, \ldots, h_{n}\right]， \mathcal{D}=\left[d_{1}, d_{2}, \ldots, d_{n}\right]， \mathrm{n} $ 表示音素序列的长度，$\quad \sum_{i=1}^{n} d_{i}=m$ ， $ \mathrm{m} $ 表示mel谱图的长度，而 $ \alpha $ 就是用来控制合成mel谱图长度的超参数, 以此来控制合成语音的语速。举个例子, 比如说音素序列 $ \mathcal{H}_{p h o}=\left[h_{1}, h_{2}, h_{3}, h_{4}\right] $ 对应的每个音素的持续时间为 $ \mathcal{D}=[2,2,3,1] $， 如果 $ \alpha=1 $，那么长度调节器模块就会将h1复制1次、h2复制1次、h3复制2次、 $ \mathrm{h} 4 $ 不复制，最终得到 $ \mathcal{H}_{m e l}=\left[h_{1}, h_{1}, h_{2}, h_{2}, h_{3}, h_{3}, h_{3}, h_{4}\right] $ 。如果 $ \alpha=0 $.5代表合成的语速为原先的两倍（变快）, 则每个音素对应的持续时间为 $ \mathcal{D}=[1,1,1.5,0.5] $，因为时间对应的是mel谱图的帧数，帧数不存在小数之说，所以在实际处理的时候会进行向上取整，也就是<br>$ \mathcal{D}=[1,1,2,1] $，因此最终得到的 $ \mathcal{H}_{m e l}=\left[h_{1}, h_{2}, h_{3}, h_{3}, h_{4}\right] $ 。如果 $ \alpha=2 $ 代表合成的语速为原先的0.5倍（变慢），原理和上述分析类似, 此处不再阐述。</p><ul><li><strong>Duration Predictor</strong></li></ul><p>那么问题就来了，模型应该如何确定每个音素的持续时间呢？为了解决这个问题，作者设计了一个持续时间预测器模块。如图1d所示，持续时间预测器包括一个具有ReLU激活函数的2层1D卷积网络，每层后面都有归一化和dropout层，还有一个额外的线性层来输出一个标量，这个标量就表示预测的音素对应的持续时间。</p><p>值得一提的是，训练后的长度预测器只用于TTS推理阶段。在训练阶段，直接使用从训练好的自回归teacher模型中提取的音素长度。</p><p>具体来说就是在训练阶段，首先用训练一个auto-regressive的TTS模型，这个时候我们不需要知道phoneme duration。</p><p>接下来我们用这个TTS模型来为每个训练数据对儿生成attention alignment（也就是说真实的音素持续时间是由已经训练好的Transformer TTS的multi-head attention提供）。因为multi-head attention，包含多种注意力排列，而不是所有的注意头都表现出对角线的特性（即attention weight分布在对角上）。所以，作者制定了一种方式：$ F=\frac{1}{S} \sum_{s=1}^{S} \max _{1 \leq t \leq T} a_{s, t} $，其中S和T分别代表真实的mel谱图和音素序列的长度、 $ a_{s, t} $ 表示 attention矩阵中第s行第t列的元素的数值，最终选择F最大的head用作attention alignment。</p><p>有了上面得到的alignment，我们用下面的式子计算$ \mathcal{D}=\left[d_{1}, d_{2}, \ldots, d_{n}\right] $：</p><script type="math/tex; mode=display">d_{i}=\sum_{s=1}^{S}\left[\arg \max _{t} a_{s, t}=i\right]</script><blockquote><p>That is, the duration of a phoneme is the number of mel-spectrograms attended to it according to the attention head selected in the above step.</p></blockquote><p>在训练过程中，Duration Predictor模块与Fastspeech一起做联合训练，其预测结果与目标做Loss。</p><blockquote><p>也就是在这个模块中，作者抛弃了传统Encoder+attention+Decoder模型中隐式的attention alignment方式，加入了显式的alignment标签。</p></blockquote><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>在两个小节中我们分析了FastSpeech主要解决了以下三个问题：</p><p>1）解决已有自回归模型推理过程中合成语音速度慢的问题；</p><p>2）取消了先前模型中编码器-解码器之间的隐式注意力机制，从而避免因为注意力对齐不准而带来的合成语句不稳定的问题；</p><p>3）在音素持续时间预测模块中引入了$\alpha$因子，使得合成语音的时长（语速)可控。</p><p>但是一些不足也很明显，如：</p><p>1）合成语音的质量（上限）会受到teacher模型的严重影响；</p><p>2）只能控制合成语音的速度，可控性依旧有限。</p><p>代码解读可以参考<a href="https://zhuanlan.zhihu.com/p/517028509" target="_blank" rel="noopener">声学模型（03）：Fastspeech</a>。</p><p>个人补充一下关于注意力对齐：注意力对齐应该是文本和音频的对齐。假设我们的输入时音素和对应的音频，由于对齐不准，可能导致其中一个音素包含了其它音素的音频或者缺失了一部分，导致跳词和重复的问题。</p><h2 id="Fastspeech2"><a href="#Fastspeech2" class="headerlink" title="Fastspeech2"></a>Fastspeech2</h2><h3 id="动机-2"><a href="#动机-2" class="headerlink" title="动机"></a>动机</h3><p>虽然FastSpeech作为一个non-autogressive TTS模型已经取得了比auto-regressive模型如Tacotron更快的生成速度和类似的语音质量，但是FastSpeech仍然存在一些缺点，比如</p><ol><li><p>使用一个auto-regressive的TTS模型作为teacher，训练模型非常耗费时间；</p></li><li><p>使用知识蒸馏的方式来训练模型会导致信息损失，从而对合成出的语音的音质造成影响。</p></li></ol><p>在<a href="https://arxiv.org/abs/2006.04558" target="_blank" rel="noopener">FastSpeech 2: Fast and High-Quality End-to-End Text to Speech</a>文章中，作者针对这些问题进行了改进，作者首先摒弃了知识蒸馏的teacher-student训练，采用了直接在ground-truth上训练的方式。其次在模型中引入了更多的可以控制语音的输入，其中既包括我们在FastSpeech中提到的phoneme duration，也包括energy、pitch等新的量。作者将这个模型命名为FastSpeech2。作者在此基础之上提出了FastSpeech2s，这个模型可以直接从text生成语音而不是mel-spectrogram。实验结果证明FastSpeech2的训练速度比FastSpeech加快了3倍，FastSpeech2s有比其它模型更快的合成速度。在音质方面，FastSpeech2和2s都超过了之前auto-regressive模型。</p><h3 id="模型结构-2"><a href="#模型结构-2" class="headerlink" title="模型结构"></a>模型结构</h3><p>模型的整体架构如下图所示：</p><p><img src="/DeepLearningApplications/语音合成/语音合成模型/image-20220605010039989.png" alt="image-20220605010039989" style="zoom: 43%;"></p><p>整体上来说（上图(a)），FastSpeech2在encoder和decoder上采用了和FastSpeech类似的基于self-attention和1D卷积的结构。</p><p>不同的是，FastSpeech2使用了variance adaptor（上图(b)）用来引入更多的输入来控制合成出的语音，正如之前提到的，这里不仅有phoneme duration也有energy和pitch，我们看到这个adaptor的结构使得它可以引入任意多的额外输入。最后，作者没有使用之前的从attention matrix中推断phoneme duration的方法，而是使用了forced alignment得到的duration作为训练的ground truth，实验结果也证明这种方法得到的duration会更加精确。</p><p>这里可能一部分的读者不清楚forced alignment是什么。其实这是一种TTS中常用的技术，用来推断音素对应的音频，比如Montreal Forced Aligner (MFA)库。</p><h4 id="Variance-Adaptor"><a href="#Variance-Adaptor" class="headerlink" title="Variance Adaptor"></a>Variance Adaptor</h4><p>Variance Adaptor（VA）是给phoneme hidden seq加上变化信息（各种声学特征），对于TTS的one-to-many映射提供帮助。作者在这里加上了三种：duration，pitch和energy。此外像emotion、style、speaker等信息都可以加到VA上。</p><p>VA的设计如图（b）所示，GT的duration、pitch、energy一方面被用来在训练时作为condition预测mel谱，另一方面被用来训练声学特征预测器Duration Predictor（DP）、Pitch Predictor（PP）和Energy Predictor（EP）。</p><p>Duration Predictor用到了forced alignment抽出的phoneme duration作为训练目标。输入phoneme hidden seq，输出每个音素对应的预测帧数（为便于预测转换成对数域）。DP训练用的是MSE loss，GT 音素时长是通过<strong>Montreal Forced Alignment（MFA）</strong>工具从原音频中提取的。</p><p>Pitch Predictor需要语音的pitch信息作为训练目标，一般情况下会使用pitch contour（基频轮廓），不过这里作者认为pitch contour的variation很大，不好预测。因此作者使用了pitch spectrogram作为训练目标。作者首先使用continuous wavelet transform (连续小波变换，CWT) 获得pitch spectrogram，然后训练predictor去预测它。在合成语音的时候，作者使用inverse CWT (iCWT)，即CWT的逆运算来将pitch spectrogram转换称pitch contour。作者进一步根据pitch F0的大小把它们映射到对数域的256个值上 ，最后把值对应的pitch embedding加在phoneme hidden state上，以此为GT target计算MSE loss。</p><p>Energy Predictor：对于每一STFT帧计算其幅度的L2范数作为能量值，然后将energy均匀量化成256个可能值，最后将值对应的embedding加到hidden state上。这里训练的时候predictor会直接预测映射之前的energy，并计算MSE loss。</p><h4 id="FastSpeech2s"><a href="#FastSpeech2s" class="headerlink" title="FastSpeech2s"></a>FastSpeech2s</h4><p>作者希望实现text-to-waveform而不是text-to-mel-to-waveform的合成方式，因此扩展FastSpeech2提出了FastSpeech2s。在上一节的架构图的子图(a)中我们可以看到，FastSpeech2s直接从hidden state中生成waveform，而不使用mel-spectrogram decoder。</p><p>架构图的子图(d)给出了waveform decoder的架构，作者使用类似WaveNet的结构，其中包含了dilated卷积和gated activation。这里作者使用了WaveGAN中的对抗训练的方法来让模型隐式地学习到恢复phase information的方法。值得注意的是这里作者在训练FastSpeech2s的时候也同时训练FastSpeech2的mel-spectrogram decoder，作者认为这样可以从text中提取更多的信息。</p><h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><p>本文介绍了FastSpeech的改进版FastSpeech2/2s，FastSpeech2改进了FastSpeech的训练方法，通过引入forced alignment以及pitch和energy信息提升了模型的训练速度和精度。FastSpeech2s进一步实现了text-to-waveform的训练方式，因此提升了合成速度。实验结果证明FastSpeech2的训练速度比FastSpeech快了3倍，另外FastSpeech2s由于不需要生成mel-spectrogram因此有更快的合成速度。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.dengbocong.cn/Paper-Reading/cea2357273fe/" target="_blank" rel="noopener">论文阅读笔记：Tacotron和Tacotron2</a><br><a href="https://www.jianshu.com/p/ba30cc13093a" target="_blank" rel="noopener">语音合成(三)：端到端的TTS深度学习模型tacotron</a><br><a href="https://blog.csdn.net/junbaba_/article/details/118357486" target="_blank" rel="noopener">Tacotron以及Tacotron2详解</a><br><a href="https://unisound.github.io/end-to-end_tts/" target="_blank" rel="noopener">端到端语音合成及其优化实践(上)</a><br><a href="https://www.jianshu.com/p/46888767dcef" target="_blank" rel="noopener">语音合成简介 Text-to-speech</a><br><a href="https://www.cnblogs.com/mengnan/p/9474111.html" target="_blank" rel="noopener">语音合成技术综述</a><br><a href="https://zhuanlan.zhihu.com/p/512240545" target="_blank" rel="noopener">声学模型（02）：Transformer based TTS</a><br><a href="https://zhuanlan.zhihu.com/p/517028509" target="_blank" rel="noopener">声学模型（03）：Fastspeech</a><br><a href="https://zhuanlan.zhihu.com/p/67325775" target="_blank" rel="noopener">FastSpeech阅读笔记</a><br><a href="https://zhuanlan.zhihu.com/p/363808377" target="_blank" rel="noopener">FastSpeech2——快速高质量语音合成</a><br><a href="https://zhuanlan.zhihu.com/p/371094738" target="_blank" rel="noopener">TTS paper阅读：FastSpeech 2</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇介绍几个经典的语音合成模型。&lt;/p&gt;
&lt;h2 id=&quot;什么是语音合成&quot;&gt;&lt;a href=&quot;#什么是语音合成&quot; class=&quot;headerlink&quot; title=&quot;什么是语音合成&quot;&gt;&lt;/a&gt;什么是语音合成&lt;/h2&gt;&lt;p&gt;语音合成是通过文字人工生成人类声音， 也可以说语音生成是给定一段文字去生成对应的人类读音。 这里声音是一个连续的模拟的信号。而合成过程是通过计算机， 数字信号去模拟。 这里就需要数字信号处理模拟信号信息，详细内容可参考 [1]。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/DeepLearningApplications/语音合成/语音合成模型/webp&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;p&gt;Fig. 1 an example of voice signal. &lt;/p&gt;
    
    </summary>
    
    
      <category term="DeepLearningApplications" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/"/>
    
      <category term="语音合成" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90/"/>
    
    
      <category term="语音合成" scheme="https://www.zdaiot.com/tags/%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90/"/>
    
  </entry>
  
  <entry>
    <title>语音基础知识</title>
    <link href="https://www.zdaiot.com/DeepLearningApplications/%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90/%E8%AF%AD%E9%9F%B3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <id>https://www.zdaiot.com/DeepLearningApplications/语音合成/语音基础知识/</id>
    <published>2022-06-04T07:22:03.000Z</published>
    <updated>2022-06-04T07:22:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>开新坑了，最近在攻击语音合成系统，现在学习一下语音基础知识。</p><h2 id="辅音和元音的区别"><a href="#辅音和元音的区别" class="headerlink" title="辅音和元音的区别"></a>辅音和元音的区别</h2><ul><li>辅音发音时，气流在通过咽头、口腔的过程中， 要受到某部位的阻碍；元音发音时，气流在咽头、 口腔不受阻碍。这是元音和辅音最主要的区别。</li><li>辅音发音时，发音器官成阻的部位特别紧张； 元音发音时发音器官各部位保持均衡的紧张状态。</li><li>辅音发音时，气流较强；元音发音时，气流较 弱。</li><li>辅音发音时，声带不一定振动，声音一般不响亮；元音发音时，声带振动，声音比辅音响亮。</li></ul><blockquote><p>一般只有元音（一些介于元音辅音中间分类不明的音暂不讨论）才会有共振峰，而元音的音质由声道的形状决定，而声道的形状又通过发音的动作来塑造（articulatory+movements）。</p></blockquote><h2 id="清音和浊音"><a href="#清音和浊音" class="headerlink" title="清音和浊音"></a>清音和浊音</h2><ul><li>清音：声带不振动</li><li>浊音：声带振动而发音</li><li>元音都是浊音、辅音有清音也有浊音。</li></ul><h2 id="波形、频谱和语谱（声谱）"><a href="#波形、频谱和语谱（声谱）" class="headerlink" title="波形、频谱和语谱（声谱）"></a>波形、频谱和语谱（声谱）</h2><p>以下内容主要来源于<a href="https://www.zhihu.com/question/27126800/answer/35376174" target="_blank" rel="noopener">不同元音辅音在声音频谱的表现是什么样子？ - 王赟 Maigo的回答 - 知乎</a>。</p><h3 id="波形"><a href="#波形" class="headerlink" title="波形"></a>波形</h3><p>声音最直接的表示方式是波形，英文叫waveform。另外两种表示方式（频谱和语谱图）下文再说。波形的横轴是时间（所以波形也叫声音的时域表示），纵轴的含义并不重要，可以理解成位移（声带或者耳机膜的位置）或者压强。</p><p>当横轴的分辨率不高的时候，语音的波形看起来就是像你贴的图中一样，呈现一个个的三角形。这些三角形的轮廓叫作波形的<strong>包络（envelope）</strong>。包络的大小代表了声音的响度。一般来说，每一个音节会对应着一个三角形，因为一般地每个音节含有一个元音，而元音比辅音听起来响亮。但例外也是有的，比如：1) 像/s/这样的音，持续时间比较长，也会形成一个三角形；2) 爆破音（尤其是送气爆破音，如/p/）可能会在瞬时聚集大量能量，在波形的包络上就体现为一个脉冲。</p><p>下面这张图中上方的子图，是读单词pass /pæs/的录音。它的横坐标已经被拉开了一些，但其实这个波形是由两个“三角形”组成的。0.05秒处那个小突起是爆破音/p/，0.05秒到0.3秒是元音/æ/，0.3到0.58秒是辅音/s/。</p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/69e0842536f5cb23b16e05e2cc8402f5_720w.jpg" data-rawwidth="675" data-rawheight="328" class="origin_image zh-lightbox-thumb" width="675" data-original="https://pica.zhimg.com/69e0842536f5cb23b16e05e2cc8402f5_r.jpg?source=1940ef5c"></p><p>如果你把横轴的分辨率调高，比如只观察0.02s秒甚至更短时间内的波形，你就可以看到波形的精细结构（fine structure），像上图的下面两个子图。波形的精细结构可能呈现两种情况：一种是有周期性的，比如左边那段波形（图中显示了两个周期多一点），这种波形一般是元音或者辅音中的鼻音、浊擦音以及/l/、/r/等；另一种是乱的，比如右边那段波形，这种波形一般是辅音中的清擦音。辅音中的爆破音，则往往表现为一小段静音加一个脉冲（如pass开头的/p/）。</p><h3 id="频谱"><a href="#频谱" class="headerlink" title="频谱"></a>频谱</h3><p>看完了声音的<strong>时域</strong>表示，我们再来看它的<strong>频域</strong>表示——<strong>频谱（spectrum）</strong>。它是由一小段波形做傅里叶变换（Fourier transform）之后取模得到的。注意，必须是一小段波形，太长了弄出来的东西（比如你贴的右边的图）就没意义了！这样的一小段波形（通常在0.02~0.05s这样的数量级）称为<strong>一帧（frame）</strong>。下面是读的pass的波形中，以0.17s和0.4s为中心截取0.04s波形经傅里叶变换得到的频谱。频谱的横轴是频率；录音的采样率用的是16000 Hz，频谱的频率范围也是0 ~ 16000 Hz。但由于0 ~ 8000 Hz和8000 ~ 16000 Hz的频谱是对称的，所以一般只画0 ~ 8000 Hz的部分。</p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/7301a5be8a003cdaa272a5eba362d43a_1440w.jpg" alt="img"></p><p>频谱跟波形一样，也有包络和精细结构。你把横轴压缩，看到的就是包络；把横轴拉开，看到的就是精细结构。我上面这两张图使得二者都能看到。</p><p>第一个频谱是元音/æ/的频谱，可以看到它的精细结构是有周期性的，每隔108 Hz出现一个峰。从这儿也可以看出来，语音不是一个单独的频率，而是由许多频率的简谐振动叠加而成的。第一个峰叫<strong>基音</strong>，其余的峰叫<strong>泛音</strong>。第一个峰的频率（也是相邻峰的间隔）叫作<strong>基频（fundamental frequency），也叫音高（pitch）</strong>，常记作$f_0$。有时说“一个音的频率”，就是特指基频。基频的倒数叫<strong>基音周期</strong>。你再看看上面元音/æ/的波形的周期，大约是0.009 s，跟基频108 Hz吻合。频谱上每个峰的高度是不一样的，这些峰的高度之比决定了<strong>音色（timbre）</strong>。不过对于语音来说，一般没有必要精确地描写每个峰的高度，而是用<strong>“共振峰”（formant）</strong>来描述音色。共振峰指的是包络的峰。在我这个图中，忽略精细结构，可以看到0~1000 Hz形成一个比较宽的峰，1800 Hz附近形成一个比较窄的峰。共振峰的频率一般用$f_1$、$f_2$等等来表示。上图中，$f_1$是多少很难精确地读出来，但$f_2  \approx 1800Hz$。当然，在2800 Hz、3800 Hz、5000 Hz处还有第三、四、五共振峰，但它们与第一、二共振峰相比就弱了许多。除了元音以外，辅音中的鼻音、浊擦音以及/l/、/r/等也具有这种频谱，可以讨论基频和共振峰频率（不过浊擦音一般不讨论共振峰频率）。</p><p>第二个频谱是辅音/s/的频谱。可以看出它的精细结构是没有周期性的，所以就无所谓基频。一般也不提这种频谱的共振峰。清擦音的频谱一般都是这样。</p><h3 id="语谱（声谱）"><a href="#语谱（声谱）" class="headerlink" title="语谱（声谱）"></a>语谱（声谱）</h3><p>我们最后来看一下声音的第三种表示方式——<strong>语谱图</strong>（<strong>spectrogram</strong>）。上面说过，频谱只能表示一小段声音。那么，如果我想观察一整段语音信号的频域特性，要怎么办呢？我们可以把一整段语音信号截成许多帧，把它们各自的频谱“竖”起来（即用纵轴表示频率），用颜色的深浅来代替频谱强度，再把所有帧的频谱横向并排起来（即用横轴表示时间），就得到了<strong>语谱图</strong>，它可以称为声音的<strong>时频域</strong>表示。下面我就偷懒，不用Matlab自己画语谱图，而用Cool Edit绘制上面“pass”的语谱图，如下：</p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/fd6436356cdd4647bfabff165d24df1c_1440w.jpg" alt="img"></p><p>注意横轴是时间，纵轴是频率，颜色越亮代表强度越大。可以观察一下0.17s和0.4s处，是不是跟我上面画的频谱相似？然后再试着从这张语谱图上读出元音/æ/的第二共振峰频率。</p><p>语谱图的好处是可以直观地看出共振峰频率的变化。我上面读的“pass”中只有一个单元音，如果有双元音就会非常明显了。比如下面这张我读的“eye” /aɪ/，可以非常明显地看出在元音从/a/向/ɪ/过渡的阶段（0.2 ~ 0.25s），$f_1$在降低，而$f_2$在升高。</p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/5c20e251d868c7d535ab9c4e4e8a5a16_1440w.jpg" alt="img"></p><p>元音与共振峰的关系已经研究得比较透彻了，简单地说：</p><p>1) 开口度越大, $ f_{1} $ 越高;<br>2) 舌位越靠前, $ f_{2} $ 越高;<br>3) 不圆唇元音的 $ f_{3} $ 比圆唇元音高。例如, $ / \mathrm{a} / $ 是开、后、不圆唇元音, 所以 $ f_{1} $ 高, $ f_{2} $ 低, $ f_{3} $ 高；/y/（即汉语拼音的ü）是闭、前、圆 唇元音, 所以 $ f_{1} $ 低, $ f_{2} $ 高, $ f_{3} $ 低。也许大家见过下图那样的元音图Q (vowel chart) , 我把 $ f_{1} $ 和 $ f_{2} $ 的变化方向标 $ Q $ 上去。</p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/791ea703a54bac444deacdce9f039cb1_1440w.jpg" alt="img" style="zoom:75%;"></p><p>$f_3$最明显的体现其实是在英语的辅音/r/中，例如下面我读的erase /ɪ’reɪz/的语谱图，可以看到辅音/r/处（0.19s左右）$f_3$明显低，把$f_2$也压下去了。</p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/517c32cad639c6f66721060bf2f3aa9e_1440w.jpg" alt="img"></p><p>清擦音可以根据能量集中的频段来分辨。下面是我读的/f/, /θ/, /s/, /ʃ/的语谱图。浊擦音会在清擦音的基础上有周期性的精细结构。</p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/25ccd5ecb60a5dcd0acf414e67b12594_1440w.jpg" alt="img"></p><p>爆破音的爆破时间很短，在语谱图上一般较难分辨。</p><p>“两个音之间的音是什么样子”，就要分情况讨论了。</p><p>1) 如果是两个元音，那么可以在元音图上找到两个元音，取它们连线的中点。这对应着把$f_1$、$f_2$分别取平均。<br>2) 如果是两个清擦音，那么可以把它们的频谱取平均，这样听起来应该是个四不像（后来我做了实验，结果见这里：<a href="http://maigoakisame.github.io/fricative-mix/" target="_blank" rel="noopener">Mixture of Unvoiced Fricatives</a>）。<br>3) /t/和/ʃ/属于不同类型的辅音，很难定义它们“之间”是什么东西。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="/DeepLearningApplications/语音合成/语音基础知识/6169076_1625140337.jpg" alt="img" style="zoom: 33%;"></p><h2 id="语音基本概念"><a href="#语音基本概念" class="headerlink" title="语音基本概念"></a>语音基本概念</h2><p>以下内容主要来源于<a href="https://zhuanlan.zhihu.com/p/510550742" target="_blank" rel="noopener">语音基础知识（附相关实现代码）</a>。在不理解的地方我会加上自己的注释。</p><p>声波通过空气传播，被麦克风接收，通过<strong>采样、量化、编码</strong>转换为离散的数字信号，即波形文件。<strong>音量、音高和音色是声音的基本属性。</strong></p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/v2-0b6dcfd913268a433bf3abaee8948cd1_b.jpg" alt></p><p><strong>1）采样</strong>：原始的语音信号是连续的模拟信号，需要对语音进行采样，转化为时间轴上离散的数据。 </p><p><strong>采样后</strong>，模拟信号被等间隔地取样，这时信号在时间上就不再连续了，但在幅度上还是连续的。经过采样处理之后，模拟信号变成了离散时间信号。</p><p><strong>采样频率</strong>是指一秒钟内对声音信号的采样次数，采样频率越高声音的还原就越真实越自然。</p><p>在当今的主流采集卡上，采样频率一般共分为 22.05KHz、44.1KHz、48KHz 三个等级，22.05KHz 只能达到 FM 广播的声音品质，44.1KHz 则是理论上的 CD 音质界限（人耳一般可以感觉到 20-20K Hz 的声音，根据香农采样定理，采样频率应该不小于最高频率的两倍，所以 40KHz 是能够将人耳听见的声音进行很好的还原的一个数值，于是 CD 公司把采样率定为 44.1KHz），48KHz 则更加精确一些。</p><p>对于高于 48KHz 的采样频率人耳已无法辨别出来了，所以在电脑上没有多少使用价值。</p><p><strong>2）量化</strong>：进行分级量化，将信号采样的幅度划分成几个区段，把落在某区段的采样到的样品值归成一类，并给出相应的量化值。根据量化间隔是否均匀划分，又分为均匀量化和非均匀量化。</p><p><strong>均匀量化</strong>的特点为 “大信号的信噪比大，小信号的信噪比小”。缺点为 “为了保证信噪比要求，编码位数必须足够大，但是这样导致了信道利用率低，如果减少编码位数又不能满足信噪比的要求”（根据信噪比公式，编码位数越大，信噪比越大，通信质量越好）。</p><p>通常对语音信号采用<strong>非均匀量化</strong>，基本方法是对大信号使用大的量化间隔，对小信号使用小的量化间隔。由于小信号时量化间隔变小，其相应的量化噪声功率也减小（根据量化噪声功率公式），从而使小信号时的量化信噪比增大，改善了小信号时的信噪比。</p><p><strong>量化后</strong>，信号不仅在时间上不再连续，在幅度上也不连续了。经过量化处理之后，离散时间信号变成了数字信号。</p><p><strong>3）编码</strong>：在量化之后信号已经变成了数字信号，需要将数字信号编码成二进制。<strong>“</strong>CD 质量<strong>”</strong> 的语音采用 44100 个样本每秒的采样率，每个样本 16 比特，这个 16 比特就是编码的位数。</p><p>采样，量化，编码的过程称为 A/D（从模拟信号到数字信号）转换，如上图 1 所示。</p><p>补充<strong>比特率</strong>的概念：比特率是指每秒传送的比特(bit)数。单位为 bps(Bit Per Second)，比特率越高，传送的数据越大，音质越好。以电话为例，每秒3000点取样，每个样本是7比特，那么电话的比特率是21000。而CD是每秒44100点取样，两个声道，每个取样是13位PCM编码，所以CD的比特率是$44100<em>2</em>13=1146600$，也就是说CD每秒的数据量大约是144KB，而一张CD的容量是74分等于4440秒，就是639360KB＝640MB。</p><h3 id="能量"><a href="#能量" class="headerlink" title="能量"></a>能量</h3><p><strong>音频的能量通常指的是时域上每帧的能量，幅度的平方。</strong>在简单的语音活动检测（Voice Activity Detection，VAD）中，直接利用能量特征：能量大的音频片段是语音，能量小的音频片段是非语音（包括噪音、静音段等）。这种 VAD 的局限性比较大，正确率也不高，对噪音非常敏感。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_file, sr=None, frame_len=<span class="number">512</span>, n_fft=None, win_step=<span class="number">2</span> / <span class="number">3</span>, window=<span class="string">"hamming"</span>)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        初始化</span></span><br><span class="line"><span class="string">        :param input_file: 输入音频文件</span></span><br><span class="line"><span class="string">        :param sr: 所输入音频文件的采样率，默认为None</span></span><br><span class="line"><span class="string">        :param frame_len: 帧长，默认512个采样点(32ms,16kHz),与窗长相同</span></span><br><span class="line"><span class="string">        :param n_fft: FFT窗口的长度，默认与窗长相同</span></span><br><span class="line"><span class="string">        :param win_step: 窗移，默认移动2/3，512*2/3=341个采样点(21ms,16kHz)</span></span><br><span class="line"><span class="string">        :param window: 窗类型，默认汉明窗</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.input_file = input_file</span><br><span class="line">        self.frame_len = frame_len  <span class="comment"># 帧长，单位采样点数</span></span><br><span class="line">        self.wave_data, self.sr = librosa.load(self.input_file, sr=sr)</span><br><span class="line">        self.window_len = frame_len  <span class="comment"># 窗长512</span></span><br><span class="line">        <span class="keyword">if</span> n_fft <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.fft_num = self.window_len  <span class="comment"># 设置NFFT点数与窗长相等</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.fft_num = n_fft</span><br><span class="line">        self.win_step = win_step</span><br><span class="line">        self.hop_length = round(self.window_len * win_step)  <span class="comment"># 重叠部分采样点数设置为窗长的1/3（1/3~1/2）,即帧移(窗移)2/3</span></span><br><span class="line">        self.window = window</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">energy</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        每帧内所有采样点的幅值平方和作为能量值</span></span><br><span class="line"><span class="string">        :return: 每帧能量值，np.ndarray[shape=(1，n_frames), dtype=float64]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        mag_spec = np.abs(librosa.stft(self.wave_data, n_fft=self.fft_num, hop_length=self.hop_length,</span><br><span class="line">                                       win_length=self.frame_len, window=self.window))</span><br><span class="line">        pow_spec = np.square(mag_spec) <span class="comment"># [frequency, time (n_frames)]</span></span><br><span class="line">        energy = np.sum(pow_spec, axis=<span class="number">0</span>) <span class="comment"># [n_frames]</span></span><br><span class="line">        energy = np.where(energy == <span class="number">0</span>, np.finfo(np.float64).eps, energy)  <span class="comment"># 避免能量值为0，防止后续取log出错(eps是取非负的最小值), 即np.finfo(np.float64).eps = 2.220446049250313e-16</span></span><br><span class="line">        <span class="keyword">return</span> energy</span><br></pre></td></tr></table></figure><h3 id="短时能量"><a href="#短时能量" class="headerlink" title="短时能量"></a>短时能量</h3><p>短时能量体现的是信号在不同时刻的强弱程度。设第 n 帧语音信号的短时能量用$E_n$表示，则其计算公式为：</p><script type="math/tex; mode=display">E_n = \sum_{m=0}^{M-1}x_n^2(m)</script><p>上式中，M 为帧长，$x_n(m)$为该帧中的样本点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">short_time_energy</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        计算语音短时能量：每一帧中所有语音信号的平方和</span></span><br><span class="line"><span class="string">        :return: 语音短时能量列表(值范围0-每帧归一化后能量平方和，这里帧长512，则最大值为512)，</span></span><br><span class="line"><span class="string">        np.ndarray[shape=(1，无加窗，帧移为0的n_frames), dtype=float64]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        energy = []  <span class="comment"># 语音短时能量列表</span></span><br><span class="line">        energy_sum_per_frame = <span class="number">0</span>  <span class="comment"># 每一帧短时能量累加和</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.wave_data)):  <span class="comment"># 遍历每一个采样点数据</span></span><br><span class="line">            energy_sum_per_frame += self.wave_data[i] ** <span class="number">2</span>  <span class="comment"># 求语音信号能量的平方和</span></span><br><span class="line">            <span class="keyword">if</span> (i + <span class="number">1</span>) % self.frame_len == <span class="number">0</span>:  <span class="comment"># 一帧所有采样点遍历结束</span></span><br><span class="line">                energy.append(energy_sum_per_frame)  <span class="comment"># 加入短时能量列表</span></span><br><span class="line">                energy_sum_per_frame = <span class="number">0</span>  <span class="comment"># 清空和</span></span><br><span class="line">            <span class="keyword">elif</span> i == len(self.wave_data) - <span class="number">1</span>:  <span class="comment"># 不满一帧，最后一个采样点</span></span><br><span class="line">                energy.append(energy_sum_per_frame)  <span class="comment"># 将最后一帧短时能量加入列表</span></span><br><span class="line">        energy = np.array(energy)</span><br><span class="line">        energy = np.where(energy == <span class="number">0</span>, np.finfo(np.float64).eps, energy)  <span class="comment"># 避免能量值为0，防止后续取log出错(eps是取非负的最小值)</span></span><br><span class="line">        <span class="keyword">return</span> energy</span><br></pre></td></tr></table></figure><h3 id="声强和声强级（声压和声压级）"><a href="#声强和声强级（声压和声压级）" class="headerlink" title="声强和声强级（声压和声压级）"></a>声强和声强级（声压和声压级）</h3><p>单位时间内通过垂直于声波传播方向的单位面积的平均声能，称作声强，声强用 P 表示，单位为 “瓦 / 平米”。实验研究表明，人对声音的强弱感觉并不是与声强成正比，而是与其对数成正比，所以一般<strong>声强用声强级来表示</strong>：</p><script type="math/tex; mode=display">L = 10 \text{log}\left(\frac{P}{P'} \right)</script><p>其中，P 为声强， $P’=10e^{-12}$单位（$w/m^2$）称为基本声强，声强级的常用单位是分贝 (dB)。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">intensity</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        计算声音强度，用声压级表示：每帧语音在空气中的声压级Sound Pressure Level(SPL)，单位dB</span></span><br><span class="line"><span class="string">        公式：20*lg(P/Pref)，P为声压（Pa），Pref为参考压力(听力阈值压力)，一般为1.0*10-6 Pa</span></span><br><span class="line"><span class="string">        这里P认定为声音的幅值：求得每帧所有幅值平方和均值，除以Pref平方，再取10倍lg</span></span><br><span class="line"><span class="string">        :return: 每帧声压级，dB，np.ndarray[shape=(1，无加窗，帧移为0的n_frames), dtype=float64]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        p0 = <span class="number">1.0e-6</span>  <span class="comment"># 听觉阈限压力auditory threshold pressure: 2.0*10-5 Pa</span></span><br><span class="line">        e = self.short_time_energy()</span><br><span class="line">        spl = <span class="number">10</span> * np.log10(<span class="number">1</span> / (np.power(p0, <span class="number">2</span>) * self.frame_len) * e)</span><br><span class="line">        <span class="keyword">return</span> spl</span><br></pre></td></tr></table></figure><h3 id="过零率"><a href="#过零率" class="headerlink" title="过零率"></a>过零率</h3><p>过零率体现的是信号过零点的次数，体现的是频率特性。</p><script type="math/tex; mode=display">Z_{n}=\sum_{n=0}^{N-1} \sum_{m=0}^{M-1}\left|\operatorname{sgn}\left(x_{n}(m)\right)-\operatorname{sgn}\left(x_{n}(m-1)\right)\right|</script><p>其中，N 表示帧数，M 表示每一帧中的样本点个数，sgn 为符号函数，即：</p><script type="math/tex; mode=display">\operatorname{sgn}=\left\{\begin{array}{c}1, x \geq 0 \\-1, x<0\end{array}\right.</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zero_crossing_rate</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        计算语音短时过零率：单位时间(每帧)穿过横轴（过零）的次数</span></span><br><span class="line"><span class="string">        :return: 每帧过零率次数列表，np.ndarray[shape=(1，无加窗，帧移为0的n_frames), dtype=uint32]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        zcr = []  <span class="comment"># 语音短时过零率列表</span></span><br><span class="line">        counting_sum_per_frame = <span class="number">0</span>  <span class="comment"># 每一帧过零次数累加和，即过零率</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.wave_data)):  <span class="comment"># 遍历每一个采样点数据</span></span><br><span class="line">            <span class="keyword">if</span> i % self.frame_len == <span class="number">0</span>:  <span class="comment"># 开头采样点无过零，因此每一帧的第一个采样点跳过</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> self.wave_data[i] * self.wave_data[i - <span class="number">1</span>] &lt; <span class="number">0</span>:  <span class="comment"># 相邻两个采样点乘积小于0，则说明穿过横轴</span></span><br><span class="line">                counting_sum_per_frame += <span class="number">1</span>  <span class="comment"># 过零次数加一</span></span><br><span class="line">            <span class="keyword">if</span> (i + <span class="number">1</span>) % self.frame_len == <span class="number">0</span>:  <span class="comment"># 一帧所有采样点遍历结束</span></span><br><span class="line">                zcr.append(counting_sum_per_frame)  <span class="comment"># 加入短时过零率列表</span></span><br><span class="line">                counting_sum_per_frame = <span class="number">0</span>  <span class="comment"># 清空和</span></span><br><span class="line">            <span class="keyword">elif</span> i == len(self.wave_data) - <span class="number">1</span>:  <span class="comment"># 不满一帧，最后一个采样点</span></span><br><span class="line">                zcr.append(counting_sum_per_frame)  <span class="comment"># 将最后一帧短时过零率加入列表</span></span><br><span class="line">        <span class="keyword">return</span> np.array(zcr, dtype=np.uint32)</span><br></pre></td></tr></table></figure><h3 id="基频和基音周期"><a href="#基频和基音周期" class="headerlink" title="基频和基音周期"></a>基频和基音周期</h3><p>基音周期反映了声门相邻两次开闭之间的时间间隔，基频（fundamental frequency， F0）则是基音周期的倒数，对应着声带振动的频率，代表声音的音高，声带振动越快，基频越高。如图 2 所示，蓝色箭头指向的就是基频的位置，决定音高。它是语音激励源的一个重要特征，比如可以通过基频区分性别。一般来说，成年男性基频在 100-250Hz 左右，成年女性基频在 150-350Hz 左右，女声的音高一般比男声稍高。 人类可感知声音的频率大致在 20-20000Hz 之间，人类对于基频的感知遵循对数律，也就是说，人们会感觉 100Hz 到 200Hz 的差距，与 200Hz 到 400Hz 的差距相同。因此，<strong>音高常常用基频的对数来表示。</strong></p><blockquote><p>这部分的详细介绍可以看前面的<code>波形、频谱和语谱（声谱）</code>小节。</p></blockquote><p><img src="/DeepLearningApplications/语音合成/语音基础知识/v2-624ccef5c445fe5b2502d65de1ee38bd_r.jpg" alt></p><h3 id="音高"><a href="#音高" class="headerlink" title="音高"></a>音高</h3><p>音高（pitch）是由声音的基频决定的，音高和基频常常混用。可以这样认为，<strong>音高（pitch）是稀疏离散化的基频（F0）</strong>。由规律振动产生的声音一般都会有基频，比如语音中的元音和浊辅音；也有些声音没有基频，比如人类通过口腔挤压气流的清辅音。在汉语中，元音有 a/e/i/o/u，浊辅音有 y/w/v，其余音素比如 b/p/q/x 等均为清辅音，在发音时，可以通过触摸喉咙感受和判断发音所属音素的种类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pitch</span><span class="params">(self, ts_mag=<span class="number">0.25</span>)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        获取每帧音高，即基频，这里应该包括基频和各次谐波，最小的为基频（一次谐波），其他的依次为二次、三次...谐波</span></span><br><span class="line"><span class="string">        各次谐波等于基频的对应倍数，因此基频也等于各次谐波除以对应的次数，精确些等于所有谐波之和除以谐波次数之和</span></span><br><span class="line"><span class="string">        :param ts_mag: 幅值倍乘因子阈值，&gt;0，大于np.average(np.nonzero(magnitudes)) * ts_mag则认为对应的音高有效,默认0.25</span></span><br><span class="line"><span class="string">        :return: 每帧基频及其对应峰的幅值(&gt;0)，</span></span><br><span class="line"><span class="string">                 np.ndarray[shape=(1 + n_fft/2，n_frames), dtype=float32]，（257，全部采样点数/(512*2/3)+1）</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        mag_spec = np.abs(librosa.stft(self.wave_data, n_fft=self.fft_num, hop_length=self.hop_length,</span><br><span class="line">                                       win_length=self.frame_len, window=self.window))</span><br><span class="line">        pitches, magnitudes = librosa.piptrack(S=mag_spec, sr=self.sr, threshold=<span class="number">1.0</span>, ref=np.mean,</span><br><span class="line">                                               fmin=<span class="number">50</span>, fmax=<span class="number">500</span>)  <span class="comment"># 人类正常说话基频最大可能范围50-500Hz</span></span><br><span class="line">        ts = np.average(magnitudes[np.nonzero(magnitudes)]) * ts_mag</span><br><span class="line">        pit_likely = pitches</span><br><span class="line">        mag_likely = magnitudes</span><br><span class="line">        pit_likely[magnitudes &lt; ts] = <span class="number">0</span></span><br><span class="line">        mag_likely[magnitudes &lt; ts] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> pit_likely, mag_likely</span><br><span class="line">pitches, mags = self.pitch()  <span class="comment"># 获取每帧基频</span></span><br><span class="line">f0_likely = []  <span class="comment"># 可能的基频F0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(pitches.shape[<span class="number">1</span>]):  <span class="comment"># 按列遍历非0最小值，作为每帧可能的F0</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        f0_likely.append(np.min(pitches[np.nonzero(pitches[:, i]), i]))</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        f0_likely.append(np.nan)  <span class="comment"># 当一列，即一帧全为0时，赋值最小值为nan</span></span><br><span class="line">f0_all = np.array(f0_likely)</span><br></pre></td></tr></table></figure><h3 id="共振峰"><a href="#共振峰" class="headerlink" title="共振峰"></a>共振峰</h3><p>声门处的准周期激励进入声道时会引起共振特性，产生一组共振频率，这一组共振频率称为共振峰频率或简称共振峰。共振峰包含在语音的频谱包络中，频谱极大值就是共振峰。<strong>频率最低的共振峰称为第一共振峰，对应的频率也称作基频，决定语音的 F0，其它的共振峰统称为谐波</strong>，如上图 2 所示，蓝色箭头指向频谱的第一共振峰，也就是基频的位置，决定音高；而绿框则是其它共振峰，统称为谐波。谐波是基频对应的整数次频率成分，由声带发声带动空气共振形成的，对应着声音三要素的音色。谐波的位置，相邻的距离共同形成了音色特征。谐波之间距离近听起来则偏厚粗，之间距离远听起来偏清澈。在男声变女声的时候，除了基频的移动，还需要调整谐波间的包络，距离等，否则将会丢失音色信息。</p><h3 id="汇总"><a href="#汇总" class="headerlink" title="汇总"></a>汇总</h3><p>为了有一个直观的图来解释上述的理论，可以把语音波形、短时能量、声强级、过零率、音高绘制在一张图上，如下图 3 所示：</p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/v2-4cb311bf47a663f26f2f78ff4b59cb78_r.jpg" style="zoom:67%;"></p><h2 id="语音信号的预处理操作"><a href="#语音信号的预处理操作" class="headerlink" title="语音信号的预处理操作"></a>语音信号的预处理操作</h2><p>以下内容主要来源于<a href="https://zhuanlan.zhihu.com/p/510550742" target="_blank" rel="noopener">语音基础知识（附相关实现代码）</a>。在不理解的地方我会加上自己的注释。</p><p>在进行语音特征（如 MFCC、频谱图、声谱图等）提取之前一般要进行语音信号的预处理操作，主要包括：预加重、分帧、加窗。</p><h3 id="预加重"><a href="#预加重" class="headerlink" title="预加重"></a>预加重</h3><p>语音经过说话人的口唇辐射发出，受到唇端辐射抑制，高频能量明显降低。一般来说，当语音信号的频率提高两倍时，其功率谱的幅度下降约 6dB，即语音信号的高频部分受到的抑制影响较大。比如像元音等一些因素的发音包含了较多的高频信号的成分，高频信号的丢失，可能会导致音素的共振峰并不明显，使得声学模型对这些音素的建模能力不强。预加重（pre-emphasis）是个一阶高通滤波器，可以提高信号高频部分的能量，给定时域输入信号$x[n]$，预加重之后信号为：</p><script type="math/tex; mode=display">x'[n]=x[n]-a\times x[n-1]</script><p>其中，a 是预加重系数，一般取 0.97 或 0.95。如下图 4 所示，元音音素 /aa/ 原始的频谱图（左）和经过预加重之后的频谱图（右）。</p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/v2-8aaf99cbab0e57fb43597277da4f716f_r.jpg" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preemphasis</span><span class="params">(y, coef=<span class="number">0.97</span>, zi=None, return_zf=False)</span>:</span></span><br><span class="line">    <span class="string">"""Pre-emphasize an audio signal with a first-order auto-regressive filter:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        y[n] -&gt; y[n] - coef * y[n-1]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    y : np.ndarray</span></span><br><span class="line"><span class="string">        Audio signal</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    coef : positive number</span></span><br><span class="line"><span class="string">        Pre-emphasis coefficient.  Typical values of ``coef`` are between 0 and 1.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        At the limit ``coef=0``, the signal is unchanged.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        At ``coef=1``, the result is the first-order difference of the signal.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        The default (0.97) matches the pre-emphasis filter used in the HTK</span></span><br><span class="line"><span class="string">        implementation of MFCCs [#]_.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        .. [#] http://htk.eng.cam.ac.uk/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    zi : number</span></span><br><span class="line"><span class="string">        Initial filter state.  When making successive calls to non-overlapping</span></span><br><span class="line"><span class="string">        frames, this can be set to the ``zf`` returned from the previous call.</span></span><br><span class="line"><span class="string">        (See example below.)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        By default ``zi`` is initialized as ``2*y[0] - y[1]``.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    return_zf : boolean</span></span><br><span class="line"><span class="string">        If ``True``, return the final filter state.</span></span><br><span class="line"><span class="string">        If ``False``, only return the pre-emphasized signal.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    y_out : np.ndarray</span></span><br><span class="line"><span class="string">        pre-emphasized signal</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    zf : number</span></span><br><span class="line"><span class="string">        if ``return_zf=True``, the final filter state is also returned</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    b = np.asarray([<span class="number">1.0</span>, -coef], dtype=y.dtype)</span><br><span class="line">    a = np.asarray([<span class="number">1.0</span>], dtype=y.dtype)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> zi <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># Initialize the filter to implement linear extrapolation</span></span><br><span class="line">        zi = <span class="number">2</span> * y[..., <span class="number">0</span>] - y[..., <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    zi = np.atleast_1d(zi)</span><br><span class="line"></span><br><span class="line">    y_out, z_f = scipy.signal.lfilter(b, a, y, zi=np.asarray(zi, dtype=y.dtype))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> return_zf:</span><br><span class="line">        <span class="keyword">return</span> y_out, z_f</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> y_out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">wave_data, self.sr = librosa.load(input_file, sr=sr)  <span class="comment"># 音频全部采样点的归一化数组形式数据</span></span><br><span class="line">wave_data = preemphasis(wave_data, coef=preemph)  <span class="comment"># 预加重，系数0.97</span></span><br></pre></td></tr></table></figure><h3 id="分帧"><a href="#分帧" class="headerlink" title="分帧"></a>分帧</h3><p>语音信号是非平稳信号，考虑到发浊音时声带有规律振动，即基音频率在短时范围内时相对固定的，因此可以认为语音信号具有短时平稳特性，一般认为 10ms~50ms 的语音信号片段是一个准稳态过程。_短时分析_采用分帧方式，一般每帧帧长为 20ms 或 50ms。假设语音采样率为 16kHz，帧长为 20ms，则一帧有 16000×0.02=320 个样本点。</p><p>相邻两帧之间的基音有可能发生变化，如两个音节之间，或者声母向韵母过渡。为确保声学特征参数的平滑性，一般采用重叠取帧的方式，即相邻帧之间存在重叠部分。一般来说，帧长和帧移的比例为 1:4 或 1:5。</p><blockquote><p>短时分析：虽然语音信号具有时变特性，但是在一个短时间范围内（一般认为在 10-30ms）其特性基本保持相对稳定，即语音具有短时平稳性。所以任何语音信号的分析和处理必须建立在 “短时” 的基础上，即进行“短时分析”。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">framesig</span><span class="params">(sig,frame_len,frame_step)</span>:</span></span><br><span class="line">    <span class="string">"""Frame a signal into overlapping frames.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param sig: the audio signal to frame.</span></span><br><span class="line"><span class="string">    :param frame_len: length of each frame measured in samples.</span></span><br><span class="line"><span class="string">    :param frame_step: number of samples after the start of the previous frame that the next frame should begin.</span></span><br><span class="line"><span class="string">    :returns: an array of frames. Size is NUMFRAMES by frame_len.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    slen = len(sig)</span><br><span class="line">    frame_len = int(round_half_up(frame_len))</span><br><span class="line">    frame_step = int(round_half_up(frame_step))</span><br><span class="line">    <span class="keyword">if</span> slen &lt;= frame_len:</span><br><span class="line">        numframes = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        numframes = <span class="number">1</span> + int(math.ceil((<span class="number">1.0</span>*slen - frame_len)/frame_step))</span><br><span class="line"></span><br><span class="line">    padlen = int((numframes<span class="number">-1</span>)*frame_step + frame_len)</span><br><span class="line"></span><br><span class="line">    zeros = numpy.zeros((padlen - slen,))</span><br><span class="line">    padsignal = numpy.concatenate((sig,zeros))</span><br><span class="line"></span><br><span class="line">    indices = numpy.tile(numpy.arange(<span class="number">0</span>,frame_len),(numframes,<span class="number">1</span>)) + numpy.tile(numpy.arange(<span class="number">0</span>,numframes*frame_step,frame_step),(frame_len,<span class="number">1</span>)).T</span><br><span class="line">    indices = numpy.array(indices,dtype=numpy.int32)</span><br><span class="line">    frames = padsignal[indices]</span><br><span class="line">    <span class="keyword">return</span> frames</span><br><span class="line"></span><br><span class="line">frames = framesig(sig=sig, frame_len=<span class="number">0.030</span> * sample_rate, <span class="comment"># 取帧长为30ms</span></span><br><span class="line">                                          frame_step=<span class="number">0.006</span> * sample_rate, <span class="comment"># 取帧移为6ms</span></span><br><span class="line">                                          )</span><br></pre></td></tr></table></figure><h3 id="加窗"><a href="#加窗" class="headerlink" title="加窗"></a>加窗</h3><p>分帧相当于对语音信号加矩形窗（用矩形窗其实就是不加窗），矩形窗在时域上对信号进行截断，在边界处存在多个旁瓣，会发生频谱泄露。为了减少频谱泄露，通常对分帧之后的信号进行其它形式的加窗操作。常用的窗函数有：汉明（Hamming）窗、汉宁（Hanning）窗和布莱克曼（Blackman）窗等。 <strong>加窗主要是为了使时域信号似乎更好地满足 FFT 处理的周期性要求，减少泄漏（加窗不能消除泄漏，只能减少， 如下图 5 所示）。</strong></p><blockquote><p>什么是频谱泄露？</p><p>音频处理中，经常需要利用傅里叶变换将时域信号转换到频域，而一次快速傅里叶变换（FFT）只能处理有限长的时域信号，但语音信号通常是长的，所以需要将原始语音截断成一帧一帧长度的数据块。这个过程叫信号截断，也叫分帧。分完帧后再对每帧做 FFT，得到对应的频域信号。FFT 是离散傅里叶变换（DFT）的快速计算方式，而<strong>做 DFT 有一个先验条件：分帧得到的数据块必须是整数周期的信号，也即是每次截断得到的信号要求是周期主值序列。</strong>但做分帧时，很难满足周期截断，因此就会导致频谱泄露。一句话，频谱泄露就是分析结果中，出现了本来没有的频率分量。比如说，50Hz 的纯正弦波，本来只有一种频率分量，分析结果却包含了与 50Hz 频率相近的其它频率分量。</p><p>非周期的无限长序列，任意截取一段有限长的序列，都不能代表实际信号，分析结果当然与实际信号不一致！也就是会造成频谱泄露。而周期的无限长序列，假设截取的是正好一个或整数个信号周期的序列，这个有限长序列就可以代表原无限长序列，如果分析的方法得当的话，分析结果应该与实际信号一致！因此也就不会造成频谱泄露。</p></blockquote><p><img src="/DeepLearningApplications/语音合成/语音基础知识/v2-ab5db002d1d5126c1b5bf3e0a20b7af8_r.jpg" alt></p><p>汉明窗的窗函数为: $ W_{\mathrm{ham}}[n]=0.54-0.46 \cos \left(\frac{2 \pi n}{N}-1\right) $；汉宁窗的窗函数为: $ W_{h a n}[n]=0.5\left[1-\cos \left(\frac{2 \pi n}{N}-1\right)\right] $ ，其中$n$介于0到$ \mathrm{N}-1 $ 之间，$ \mathrm{N} $ 是窗的长度。</p><p>加窗就是用一定的窗函数$ w(n) $来乘$ s(n) $， 从而形成加窗语音信号$s_{w}(n)=\mathrm{s}(\mathrm{n}) * w(\mathrm{n}) $。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">framesig</span><span class="params">(sig,frame_len,frame_step,winfunc=lambda x:numpy.ones<span class="params">(<span class="params">(x,)</span>)</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Frame a signal into overlapping frames.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param sig: the audio signal to frame.</span></span><br><span class="line"><span class="string">    :param frame_len: length of each frame measured in samples.</span></span><br><span class="line"><span class="string">    :param frame_step: number of samples after the start of the previous frame that the next frame should begin.</span></span><br><span class="line"><span class="string">    :param winfunc: the analysis window to apply to each frame. By default no window is applied.</span></span><br><span class="line"><span class="string">    :returns: an array of frames. Size is NUMFRAMES by frame_len.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    slen = len(sig)</span><br><span class="line">    frame_len = int(round_half_up(frame_len))</span><br><span class="line">    frame_step = int(round_half_up(frame_step))</span><br><span class="line">    <span class="keyword">if</span> slen &lt;= frame_len:</span><br><span class="line">        numframes = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        numframes = <span class="number">1</span> + int(math.ceil((<span class="number">1.0</span>*slen - frame_len)/frame_step))</span><br><span class="line"></span><br><span class="line">    padlen = int((numframes<span class="number">-1</span>)*frame_step + frame_len)</span><br><span class="line"></span><br><span class="line">    zeros = numpy.zeros((padlen - slen,))</span><br><span class="line">    padsignal = numpy.concatenate((sig,zeros))</span><br><span class="line"></span><br><span class="line">    indices = numpy.tile(numpy.arange(<span class="number">0</span>,frame_len),(numframes,<span class="number">1</span>)) + numpy.tile(numpy.arange(<span class="number">0</span>,numframes*frame_step,frame_step),(frame_len,<span class="number">1</span>)).T</span><br><span class="line">    indices = numpy.array(indices,dtype=numpy.int32)</span><br><span class="line">    frames = padsignal[indices]</span><br><span class="line">    <span class="comment"># 加窗操作</span></span><br><span class="line">    win = numpy.tile(winfunc(frame_len),(numframes,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> frames*win</span><br><span class="line"></span><br><span class="line">frames = framesig(sig=sig, frame_len=<span class="number">0.030</span> * sample_rate, <span class="comment"># 取帧长为30ms</span></span><br><span class="line">                  frame_step=<span class="number">0.006</span> * sample_rate, <span class="comment"># 取帧移为6ms</span></span><br><span class="line">                  winfunc=np.hamming</span><br><span class="line">                  )</span><br></pre></td></tr></table></figure><h2 id="语音声学特征介绍"><a href="#语音声学特征介绍" class="headerlink" title="语音声学特征介绍"></a>语音声学特征介绍</h2><p>以下内容主要来源于<a href="https://www.cnblogs.com/liaohuiqiang/p/10159429.html" target="_blank" rel="noopener">论文笔记：语音情感识别（四）语音特征之声谱图，log梅尔谱，MFCC，deltas</a></p><p>声音信号本是一维的时域信号，直观上很难看出频率变化规律。傅里叶变换可把它变到频域上，虽然可看出信号的频率分布，但是丢失了时域信息，无法看出频率分布随时间的变化。为了解决这个问题，很多时频分析手段应运而生，如短时傅里叶，小波，Wigner分布等都是常用的<strong>时频域分析方法</strong>。</p><h3 id="原始信号"><a href="#原始信号" class="headerlink" title="原始信号"></a>原始信号</h3><p>从音频文件中读取出来的原始语音信号通常称为 raw waveform，是一个一维数组，长度是由音频长度和采样率决定，比如采样率 Fs 为 16KHz，表示一秒钟内采样 16000 个点，这个时候如果音频长度是 10 秒，那么 raw waveform 中就有 160000 个值，<strong>值的大小通常表示的是振幅。</strong></p><h3 id="（线性）声谱图"><a href="#（线性）声谱图" class="headerlink" title="（线性）声谱图"></a>（线性）声谱图</h3><p>（1）对原始信号进行分帧加窗后，可以得到很多帧，对每一帧做 FFT（快速傅里叶变换），傅里叶变换的作用是把时域信号转为频域信号，把每一帧 FFT 后的频域信号（频谱图）在时间上堆叠起来就可以得到声谱图，其直观理解可以形象地表示为以下几个图，图源见<a href="http://www.speech.cs.cmu.edu/15-492/slides/03_mfcc.pdf" target="_blank" rel="noopener">CMU 语音课程 slides</a>。</p><p>（2）有些论文提到的 DCT（离散傅里叶变换）和 STFT（短时傅里叶变换）其实是差不多的东西。STFT 就是对一系列加窗数据做 FFT。而 DCT 跟 FFT 的关系就是：FFT 是实现 DCT 的一种快速算法。 </p><p>（3）FFT 有个参数 N，表示对多少个点做 FFT，如果一帧里面的点的个数小于 N 就会 zero-padding 到 N 的长度。对一帧信号做 FFT 后会得到 N 点的复数，这个点的模值就是该频率值下的幅度特性。每个点对应一个频率点，某一点 n（n 从 1 开始）表示的频率为$F_n = (n-1)*Fs/N$，第一个点（n=1，Fn 等于 0）表示直流信号，最后一个点 N 的下一个点（n=N+1，Fn=Fs 时，实际上这个点是不存在的）表示采样频率 Fs。</p><p>（4）FFT 后我们可以得到 N 个频点，频率间隔（也叫频率分辨率或）为 Fs / N，比如，采样频率为 16000，N 为 1600，那么 FFT 后就会得到 1600 个点，频率间隔为 10Hz，FFT 得到的 1600 个值的模可以表示 1600 个频点对应的振幅。因为 FFT 具有对称性，当 N 为偶数时取 N/2+1 个点，当 N 为奇数时，取 (N+1)/2 个点，比如 N 为 512 时最后会得到 257 个值。</p><p>（5）用 python_speech_feature 库时可以看到有三种声谱图，包括振幅谱，功率谱（有些资料称为能量谱，是一个意思，功率就是单位时间的能量），log 功率谱。振幅谱就是 fft 后取绝对值。功率谱就是在振幅谱的基础上平方然后除以 N。log 功率谱就是在功率谱的基础上取 10 倍 lg，然后减去最大值。得到声谱图矩阵后可以通过 matplotlib 来画图。</p><p>（6）常用的声谱图都是 STFT 得到的，另外也有用 CQT（constant-Q transform）得到的，为了区分，将它们分别称为 STFT 声谱图和 CQT 声谱图。</p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/1160281-20181221224530922-479480973.png" style="zoom: 67%;"> </p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/1160281-20181221224541923-1780314401.png" style="zoom:67%;"> </p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/1160281-20181221224554397-162344585.png" style="zoom:67%;"></p><h3 id="梅尔声谱图"><a href="#梅尔声谱图" class="headerlink" title="梅尔声谱图"></a>梅尔声谱图</h3><p>梅尔频谱的英文为Mel-spectrogram。</p><p>（1）人耳听到的声音高低和实际（Hz）频率不呈线性关系，用 Mel 频率更符合人耳的听觉特性（这正是用 Mel 声谱图的一个动机，由人耳听力系统启发），即在 1000Hz 以下呈线性分布，1000Hz 以上呈对数增长，Mel 频率与 Hz 频率的关系为$f_{mel} = 2595 \cdot lg(1+\frac{f}{700Hz})$，如下图所示，图源见<a href="http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/" target="_blank" rel="noopener">一个 MFCC 的介绍教程</a>。有另一种计算方式为$f_{mel} = 1125 \cdot ln(1+\frac{f}{700Hz})$。下面给出一个计算 Mel 声谱图的例子。另，python 中可以用 librosa 调包得到梅尔声谱图。</p><blockquote><p>通过实际的主观实验，科学家发现人耳对低频信号的区别更加敏感，而对高频信号的区别则不那么敏感。也就是说低频段上的两个频度和高频段上的两个频度，人们会更容易区分前者。因此我们就明白了，频域上相等距离的两对频度，对于人耳来说他们的距离不一定相等。那么，能不能调整频域的刻度，使得这个新的刻度上相等距离的两对频度，对于人耳来说也相等呢？答案是可以的，这就是梅尔刻度。</p><p>下图展示了梅尔频度-正常频度的对应关系，正如之前所说明的，低频段的部分，梅尔刻度和正常频度几乎呈线性关系，而在高频段，因为人耳的感知变弱，因此两者呈对数关系。</p></blockquote><p><img src="/DeepLearningApplications/语音合成/语音基础知识/1160281-20181221224622095-1486888859.png" style="zoom:67%;"></p><p>（2）假设现在用 10 个 Mel filterbank（一些论文会用 40 个，如果求 MFCC 一般是用 26 个然后在最后取前 13 个），为了获得 filterbanks 需要选择一个 lower 频率和 upper 频率，用 300 作为 lower，8000 作为 upper 是不错的选择。如果采样率是 8000Hz 那么 upper 频率应该限制为 4000。然后用公式把 lower 和 upper 转为 Mel 频率，我们使用上述第二个公式（ln 那条），可以得到 401.25Mel 和 2834.99Mel。</p><p>（3）因为用 10 个滤波器，所以需要 12 个点来划分出 10 个区间，在 401.25Mel 和 2834.99Mel 之间划分出 12 个点，m(i) = (401.25, 622.50, 843.75, 1065.00, 1286.25, 1507.50, 1728.74, 1949.99, 2171.24, 2392.49, 2613.74, 2834.99)。</p><p>（4）然后把这些点转回 Hz 频率，h(i) = (300, 517.33, 781.90, 1103.97, 1496.04, 1973.32, 2554.33, 3261.62, 4122.63, 5170.76, 6446.70, 8000)。</p><p>（5）把这些频率转为 fft bin，f(i) = floor( (N+1)*h(i)/Fs)，N 为 FFT 长度，默认为 512，Fs 为采样频率，默认为 16000Hz，则 f(i) = (9, 16, 25, 35, 47, 63, 81, 104, 132, 165, 206, 256)。这里 256 刚好对应 512 点 FFT 的 8000Hz。 </p><p>（6）然后创建滤波器，第一个滤波器从第一个点开始，在第二个点到达最高峰，第三个点跌回零。第二个滤波器从第二个点开始，在第三个点到达最大值，在第四个点跌回零。以此类推。滤波器的示意图如下图所示，图源见<a href="https://blog.csdn.net/xiaoding133/article/details/8106672" target="_blank" rel="noopener">csdn-MFCC 计算过程</a>。可以看到随着频率的增加，滤波器的宽度也增加。 </p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/1160281-20181221224736710-1682561520.png" alt></p><p>（7）接下来给出滤波器输出的计算公式，如下所示，其中 m 从 1 到 M，M 表示滤波器数量，这里是 10。k 表示点的编号，一个 fft 内 256 个点，k 从 1 到 256，表示了 fft 中的 256 个频点（k=0 表示直流信号，算进来就是 257 个频点，为了简单起见这里省略 k=0 的情况）。</p><script type="math/tex; mode=display">H_m(k) = \left\{\begin{matrix} \frac{k-f(m-1)}{f(m)-f(m-1)} & f(m-1) \leq k \leq f(m)\\ \frac{f(m+1)-k}{f(m+1)-f(m)} & f(m) \leq k \leq f(m+1) \\ 0 & others \\ \end{matrix}\right.</script><p>（8）最后还要乘上 fft 计算出来的能量谱，关于能量谱在前一节（线性）声谱图中已经讲过了。将滤波器的输出应用到能量谱后得到的就是梅尔谱，具体应用公式如下，其中 $|X(k)|^2$表示能量谱中第 k 个点的能量。以每个滤波器的频率范围内的输出作为权重，乘以能量谱中对应频率的对应能量，然后把这个滤波器范围内的能量加起来。举个例子，比如第一个滤波器负责的是 9 和 16 之间的那些点（在其它范围的点滤波器的输出为 0），那么只对这些点对应的频率对应的能量做加权和。</p><script type="math/tex; mode=display">MelSpec(m) = \sum_{k=f(m-1)}^{f(m+1)} H_m(k) * |X(k)|^2</script><p>（9）这样计算后，对于一帧会得到 M 个输出。经常会在论文中看到说 40 个梅尔滤波器输出，指的就是这个（实际上前面说的梅尔滤波器输出是权重 H，但是这里的意思应该是将滤波器输出应用到声谱后得到的结果，根据上下文可以加以区分）。然后在时间上堆叠多个 “40 个梅尔滤波器输出” 就得到了梅尔尺度的声谱（梅尔谱），如果再取个 log，就是 log 梅尔谱，log-Mels。 </p><p>（10）把滤波器范围内的能量加起来，可以解决一个问题，这个问题就是人耳是很难理解两个靠的很近的线性频率（就是和梅尔频率相对应的赫兹频率）之间不同。如果把一个频率区域的能量加起来，只关心在每个频率区域有多少能量，这样人耳就比较能区分，我们希望这种方式得到的（Mel）声谱图可以更加具有辨识度。最后取 log 的 motivation 也是源于人耳的听力系统，人对声音强度的感知也不是线性的，一般来说，要使声音的音量翻倍，我们需要投入 8 倍的能量，为了把能量进行压缩，所以取了 log，这样，当 x 的 log 要翻倍的话，就需要增加很多的 x。另外一个取 log 的原因是为了做倒谱分析得到 MFCC，具体细节见下面 MFCC 的介绍。</p><h3 id="MFCC"><a href="#MFCC" class="headerlink" title="MFCC"></a>MFCC</h3><p>（1）MFCC，梅尔频率的倒谱系数（Mel Frequency Cepstral Coefficents），是广泛应用于语音领域的特征，在这之前常用的是线性预测系数 Linear Prediction Coefficients（LPCs）和线性预测倒谱系数（LPCCs），特别是用在 HMM 上。 </p><p>（2）先说一下获得 MFCC 的步骤，首先分帧加窗，然后对每一帧做 FFT 后得到（单帧）能量谱（具体步骤见上面线性声谱图的介绍），对线性声谱图应用梅尔滤波器后然后取 log 得到 log 梅尔声谱图（具体步骤见上面梅尔声谱图的介绍），然后对 log 滤波能量（log 梅尔声谱）做 DCT，离散余弦变换（傅里叶变换的一种），然后保留第二个到第 13 个系数，得到的这 12 个系数就是 MFCC。 </p><p>（3）然后再大致说说 MFCC 的含义，下图第一个图（图源见参考资料 [1]）是语音的频谱图，峰值是语音的主要频率成分，这些峰值称为共振峰，共振峰携带了声音的辨识（相当于人的身份证）。把这些峰值平滑地连起来得到的曲线称为频谱包络，包络描述了携带声音辨识信息的共振峰，所以我们希望能够得到这个包络来作为语音特征。频谱由频谱包络和频谱细节组成，如下第二个图（图源见参考资料[1]）所示，其中 log X[k] 代表频谱（注意图中给出的例子是赫兹谱，这里只是举例子，实际我们做的时候通常都是用梅尔谱），log H[k]代表频谱包络，log E[k]代表频谱细节。我们要做的就是从频谱中分离得到包络，这个过程也称为倒谱分析，下面就说说倒谱分析是怎么做的。 </p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/1160281-20181221224852822-1848315135.png" style="zoom:67%;"></p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/1160281-20181221224902529-1572460338.png" style="zoom:67%;"></p><p>（4）要做的其实就是对频谱做 FFT，在频谱上做 FFT 这个操作称为逆 FFT，需要注意的是我们是在频谱的 log 上做的，因为这样做 FFT 后的结果 x[k]可以分解成 h[k]和 e[k]的和。我们先看下图（图源见参考资料 [1]），对包络 log H[k] 做 IFFT 的结果，可以看成 “每秒 4 个周期的正弦波”，于是我们在伪频率轴上的 4Hz 上给一个峰值，记作 h[k]。对细节 log E[k] 做 IFFT 的结果，可以看成 “每秒 100 个周期的正弦波”，于是我们在伪频率轴上的 100Hz 上给一个峰值，记作 e[k]。对频谱 log X[k] 做 IFFT 后的结果记作 x[k]，这就是我们说的倒谱，它会等于 h[k]和 e[k]的叠加，如下第二个图所示。我们想要得到的就是包络对应的 h[k]，而 h[k]是 x[k]的低频部分，只需要对 x[k]取低频部分就可以得到了。 </p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/1160281-20181221224927630-2116898656.png" style="zoom:67%;"></p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/1160281-20181221224944430-837617222.png" style="zoom:67%;"></p><p>（5）最后再总结一下得到 MFCC 的步骤，求线性声谱图，做梅尔滤波得到梅尔声谱图，求个 log 得到 log 梅尔谱，做倒谱分析也就是对 log X[k] 做 DCT 得到 x[k]，取低频部分就可以得到倒谱向量，通常会保留第 2 个到第 13 个系数，得到 12 个系数，这 12 个系数就是常用的 MFCC。图源见参考资料 [1]。 </p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/1160281-20181221225011597-1988899505.png" style="zoom:67%;"></p><h3 id="deltas，deltas-deltas"><a href="#deltas，deltas-deltas" class="headerlink" title="deltas，deltas-deltas"></a>deltas，deltas-deltas</h3><p>（1）deltas 和 deltas-deltas，看到很多人翻译成一阶差分和二阶差分，也被称为微分系数和加速度系数。使用它们的原因是，MFCC 只是描述了一帧语音上的能量谱包络，但是语音信号似乎有一些动态上的信息，也就是 MFCC 随着时间的改变而改变的轨迹。有证明说计算 MFCC 轨迹并把它们加到原始特征中可以提高语音识别的表现。</p><p>（2）以下是 deltas 的一个计算公式，其中 t 表示第几帧，N 通常取 2，c 指的就是 MFCC 中的某个系数。deltas-deltas 就是在 deltas 上再计算以此 deltas。</p><script type="math/tex; mode=display">d_t = \frac{\sum_{n=1}^{N} n(c_{t+n}-c_{t-n})}{2 \sum_{n=1}^{N} n^2}</script><p>（3）对 MFCC 中每个系数都做这样的计算，最后会得到 12 个一阶差分和 12 个二阶差分，我们通常在论文中看到的 “MFCC 以及它们的一阶差分和二阶差分” 指的就是这个。</p><p>（4）值得一提的是 deltas 和 deltas-deltas 也可以用在别的参数上来表述动态特性，有论文中是直接在 log Mels 上做一阶差分和二阶差分的，<a href="https://www.cnblogs.com/liaohuiqiang/p/10128835.html" target="_blank" rel="noopener">论文笔记：语音情感识别（二）声谱图 + CRNN</a> 中 3-D Convolutional Recurrent Neural Networks with Attention Model for Speech Emotion Recognition 这篇论文就是这么做的。</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p><strong>1.频谱</strong>：时域信号（一维）短时傅里叶变换后的频域信号（一维）。</p><p><strong>2.声谱图/语谱图</strong>：把一整段语音信号截成许多帧，把它们各自的频谱“竖”起来（即用纵轴表示频率），用颜色的深浅来代替频谱强度，再把所有帧的频谱横向并排起来（即用横轴表示时间），就得到了<strong>语谱图</strong>，它可以称为声音的<strong>时频域</strong>表示。</p><p><strong>3.倒谱</strong>：也叫做倒频谱，二次谱，对数功率谱等。对声谱图取对数后，再DFT变回时域，此时不是完全意义上的时域，应叫做倒谱域。</p><p><strong>4.MFCC</strong>：对线性声谱图应用mel滤波器后，取log，得到log梅尔声谱图，然后对log滤波能量（log梅尔声谱）做DCT离散余弦变换（傅里叶变换的一种），然后保留第2到第13个系数，得到的这12个系数就是MFCC。</p><p><img src="/DeepLearningApplications/语音合成/语音基础知识/watermark.png" alt="在这里插入图片描述"></p><p><strong>附加：</strong></p><p><strong>1.能量谱</strong>：也叫做能量密度谱。是原信号傅里叶变化的平方。用于描述时间序列的能量随频率的分布。</p><p><strong>2.功率谱</strong>：将频谱或时频谱（语谱）中的幅值进行平方，得到功率谱。</p><p><strong>3.功率谱密度</strong>：定义为单位频带内的吸纳后功率。其推导公式较为复杂，但维纳-辛欣定理证明了：一段信号的功率谱等于这段信号自相关函数的傅里叶变换。</p><p>注：信号分为确定和随机，确定信号又分为能量和功率，随机信号一定是功率信号。语音信号是随机信号。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>[1] <a href="http://www.speech.cs.cmu.edu/15-492/slides/03_mfcc.pdf" target="_blank" rel="noopener">CMU 语音课程 slides</a></p><p>[2] <a href="http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/" target="_blank" rel="noopener">一个 MFCC 的介绍教程</a></p><p>[3] <a href="https://blog.csdn.net/xiaoding133/article/details/8106672" target="_blank" rel="noopener">csdn-MFCC 计算过程</a></p><p>[4] <a href="https://www.cnblogs.com/BaroC/p/4283380.html" target="_blank" rel="noopener">博客园 - MFCC 学习笔记</a></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/cnlinxi/book-text-to-speech" target="_blank" rel="noopener">cnlinxi/book-text-to-speech: A book about Text-to-Speech (TTS) in Chinese. (github.com)</a><br><a href="https://blog.csdn.net/qq_36002089/article/details/108378796" target="_blank" rel="noopener">声谱图，梅尔语谱，倒谱，梅尔倒谱系数</a><br><a href="https://www.cnblogs.com/liaohuiqiang/p/10159429.html" target="_blank" rel="noopener">论文笔记：语音情感识别（四）语音特征之声谱图，log梅尔谱，MFCC，deltas</a><br><a href="https://zhuanlan.zhihu.com/p/510550742" target="_blank" rel="noopener">语音基础知识（附相关实现代码）</a><br><a href="https://www.zhihu.com/question/27126800/answer/35376174" target="_blank" rel="noopener">不同元音辅音在声音频谱的表现是什么样子？ - 王赟 Maigo的回答 - 知乎</a><br><a href="https://audiosns.com/1571.html" target="_blank" rel="noopener">搬运工：波形、频谱和声谱的关系</a><br><a href="https://zhuanlan.zhihu.com/p/421460202" target="_blank" rel="noopener">语音合成基础(3)——关于梅尔频谱你想知道的都在这里</a><br><a href="https://zhuanlan.zhihu.com/p/99122527" target="_blank" rel="noopener">语音合成基础(1)——语音和TTS</a><br><a href="https://www.jianshu.com/p/2b83e68a055b" target="_blank" rel="noopener">《语音信号处理》整理</a><br><a href="https://www.cnblogs.com/guanghe/p/10020120.html" target="_blank" rel="noopener">MP3的采样率和比特率</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;开新坑了，最近在攻击语音合成系统，现在学习一下语音基础知识。&lt;/p&gt;
&lt;h2 id=&quot;辅音和元音的区别&quot;&gt;&lt;a href=&quot;#辅音和元音的区别&quot; class=&quot;headerlink&quot; title=&quot;辅音和元音的区别&quot;&gt;&lt;/a&gt;辅音和元音的区别&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;辅音发音时，气流在通过咽头、口腔的过程中， 要受到某部位的阻碍；元音发音时，气流在咽头、 口腔不受阻碍。这是元音和辅音最主要的区别。&lt;/li&gt;
&lt;li&gt;辅音发音时，发音器官成阻的部位特别紧张； 元音发音时发音器官各部位保持均衡的紧张状态。&lt;/li&gt;
&lt;li&gt;辅音发音时，气流较强；元音发音时，气流较 弱。&lt;/li&gt;
&lt;li&gt;辅音发音时，声带不一定振动，声音一般不响亮；元音发音时，声带振动，声音比辅音响亮。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;一般只有元音（一些介于元音辅音中间分类不明的音暂不讨论）才会有共振峰，而元音的音质由声道的形状决定，而声道的形状又通过发音的动作来塑造（articulatory+movements）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;清音和浊音&quot;&gt;&lt;a href=&quot;#清音和浊音&quot; class=&quot;headerlink&quot; title=&quot;清音和浊音&quot;&gt;&lt;/a&gt;清音和浊音&lt;/h2&gt;
    
    </summary>
    
    
      <category term="DeepLearningApplications" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/"/>
    
      <category term="语音合成" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90/"/>
    
    
      <category term="语音合成" scheme="https://www.zdaiot.com/tags/%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90/"/>
    
      <category term="语音基础知识" scheme="https://www.zdaiot.com/tags/%E8%AF%AD%E9%9F%B3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>bert模型详解</title>
    <link href="https://www.zdaiot.com/DeepLearningApplications/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/bert%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/"/>
    <id>https://www.zdaiot.com/DeepLearningApplications/自然语言处理/bert模型详解/</id>
    <published>2022-05-02T10:07:03.000Z</published>
    <updated>2022-05-02T10:07:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近终于搞懂了transformer和原理和实现，可以看bert了。事先声明，本文的大部分内容来自<a href="http://fancyerii.github.io/2019/03/09/bert-theory/" target="_blank" rel="noopener">BERT模型详解</a>。大佬写的太好了，本来不想复制粘贴的，但是有部分内容看不明白，必须加点笔记。</p><h2 id="背景简介"><a href="#背景简介" class="headerlink" title="背景简介"></a>背景简介</h2><p>2018年深度学习在NLP领域取得了比较大的突破，最大的新闻当属Google的BERT模型横扫各大比赛的排行榜。作者认为，深度学习在NLP领域比较重点的三大突破为：Word Embedding、RNN/LSTM/GRU+Seq2Seq+Attention+Self-Attention机制和Contextual Word Embedding(Universal Sentence Embedding)。</p><p>Word Embedding解决了传统机器学习方法的特征稀疏问题，它通过把一个词映射到一个低维稠密的语义空间，从而使得相似的词可以共享上下文信息，从而提升泛化能力。而且通过无监督的训练可以获得高质量的词向量(比如Word2vec和Glove等方法)，从而把这些语义知识迁移到数据较少的具体任务上。但是Word Embedding学到的是一个词的所有语义，比如bank可以是”银行”也可以是”水边。如果一定要用一个固定的向量来编码其语义，那么我们只能把这两个词的语义都编码进去，但是实际一个句子中只有一个语义是合理的，这显然是有问题的。</p><p>这时我们可以通过RNN/LSTM/GRU来编码上下文的语义，这样它能学到如果周围是money，那么bank更可能是”银行”的语义。最原始的RNN由于梯度消失和梯度爆炸等问题很难训练，后来引入了LSTM和GRU等模型来解决这个问题。最早的RNN只能用于分类、回归和序列标注等任务，通过引入两个RNN构成的Seq2Seq模型可以解决序列的变换问题。比如机器翻译、摘要、问答和对话系统都可以使用这个模型。尤其机器翻译这个任务的训练数据比较大，使用深度学习的方法的效果已经超过传统的机器学习方法，而且模型结构更加简单。到了2017年，Google提出了Transformer模型，引入了Self-Attention。Self-Attention的初衷是为了用Attention替代LSTM，从而可以更好的并行(因为LSTM的时序依赖特效很难并行)，从而可以处理更大规模的语料。Transformer出来之后被广泛的用于以前被RNN/LSTM/GRU霸占的地盘，Google更是在Transformer的论文里使用”Attention is all you need”这样霸气的标题。现在Transformer已经成为Encoder/Decoder的霸主。</p><p>虽然RNN可以学到上下文的信息，但是这些上下文的语义是需要通过特定任务的标注数据使用来有监督的学习。很多任务的训练数据非常少并且获取成本很高，因此在实际任务中RNN很难学到复杂的语义关系。当然通过Multi-Task Learning，我们可以利用其它相关任务的数据。比如我们要做文本分类，我们可以利用机器翻译的训练数据，通过同时优化两个(多个)目标，让模型同时学到两个任务上的语义信息，因为这两个任务肯定是共享很多基础语义信息的，所以它的效果要比单个任务好。但即使这样，标注的数据量还是非常有限的。</p><p>因此2018年的研究热点就变成了怎么利用无监督的数据学习Contextual Word Embedding(也叫做Universal Sentence Embedding)，也就是通过无监督的方法，让模型能够学到一个词在不同上下文的不同语义表示方法。当然这个想法很早就有了，比如2015年的Skip Thought Vector，但是它只使用了BookCorpus，这只有一万多本书，七千多万个句子，因此效果并没有太明显的提升。</p><p>在BERT之前比较大的进展是ELMo、ULMFiT和OpenAI GPT。尤其是OpenAI GPT，它在BERT出现之前已经横扫过各大排行榜一次了，当然Google的BERT又横扫了一次。</p><p>UMLFiT比较复杂，而且效果也不是特别好，我们暂且不提。ELMo和OpenAI GPT的思想其实非常非常简单，就是用海量的无标注数据学习语言模型，在学习语言模型的过程中自然而然的就学到了上下文的语义关系。它们都是来学习一个语言模型，前者使用的是LSTM而后者使用Transformer，在进行下游任务处理的时候也有所不同，ELMo是把它当成特征。拿分类任务来说，输入一个句子，ELMo用LSTM把它扫一次，这样就可以得到每个词的表示，这个表示是考虑上下文的，因此”He deposited his money in this bank”和”His soldiers were arrayed along the river bank”中的两个bank的向量是不同的。下游任务用这些向量来做分类，它会增加一些网络层，但是ELMo语言模型的参数是固定的。而OpenAI GPT不同，它直接用特定任务来Fine-Tuning Transformer的参数。因为用特定任务的数据来调整Transformer的参数，这样它更可能学习到与这个任务特定的上下文语义关系，因此效果也更好。</p><p>而BERT和OpenAI GPT的方法类似，也是Fine-Tuning的思路，但是它解决了OpenAI GPT(包括ELMo)单向信息流的问题，同时它的模型和语料库也更大。依赖Google强大的计算能力和工程能力，BERT横扫了OpenAI GPT。成王败寇，很少还有人记得OpenAI GPT的贡献了。但是BERT的很多思路都是沿用OpenAI GPT的，要说BERT的学术贡献，最多是利用了Mask LM(这个模型在上世纪就存在了)和Predicting Next Sentence这个Multi-task Learning而已。</p><h2 id="Skip-Thought-Vector"><a href="#Skip-Thought-Vector" class="headerlink" title="Skip Thought Vector"></a>Skip Thought Vector</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>我们之前学习过word2vec，其中一种模型是Skip-Gram模型，根据中心词预测周围的(context)词，这样我们可以学到词向量。那怎么学习到句子向量呢？一种很自然想法就是用一个句子预测它周围的句子，这就是Skip Thought Vector的思路。它需要有连续语义相关性的句子，比如论文中使用的书籍。一本书由很多句子组成，前后的句子是有关联的。那么我们怎么用一个句子预测另一个句子呢？这可以使用Encoder-Decoder，类似于机器翻译。</p><p>比如一本书里有3个句子”I got back home”、”I could see the cat on the steps”和”This was strange”。我们想用中间的句子”I could see the cat on the steps.”来预测前后两个句子。如下图所示，输入是句子”I could see the cat on the steps.”，输出是两个句子”I got back home.”和”This was strange.”。</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/skip-thought-1-16514865427645.png" alt="img"></p><p><em>图：Skip Thought Vector</em></p><p>我们首先用一个Encoder(比如LSTM或者GRU)把输入句子编码成一个向量。而右边是两个Decoder(我们任务前后是不对称的，因此用两个Decoder)。因为我们不需要预测(像机器翻译那样生成一个句子)，所以我们只考虑Decoder的训练。Decoder的输入是”&lt;eos&gt; I got back home”，而Decoder的输出是”I got back home &lt;eos&gt;”。</p><p>经过训练之后，我们就得到了一个Encoder(Decoder不需要了)。给定一个新的句子，我们可以把它编码成一个向量。这个向量可以用于下游(down stream)的任务，比如情感分类，语义相似度计算等等。</p><h3 id="训练数据集"><a href="#训练数据集" class="headerlink" title="训练数据集"></a>训练数据集</h3><p>和训练Word2Vec不同，Word2Vec只需要提供句子，而Skip Thought Vector需要文章(至少是段落)。论文使用的数据集是BookCorpus(<a href="http://yknzhu.wixsite.com/mbweb)，目前网站已经不提供下载了。BookCorpus的统计信息如下图所示，有一万多本书，七千多万个句子。" target="_blank" rel="noopener">http://yknzhu.wixsite.com/mbweb)，目前网站已经不提供下载了。BookCorpus的统计信息如下图所示，有一万多本书，七千多万个句子。</a></p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/skip-thought-2-16514865564837.png" alt="img"></p><p><em>图：BookCorpus统计信息</em></p><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>接下来我们介绍一些论文中使用的模型，注意这是2015年的论文，过去好几年了，其实我们是可以使用更新的模型。但是基本的思想还是一样的。</p><p>Encoder是一个GRU。假设句子$s_i=w_i^1…w_i^N$，t时刻的隐状态是$h_i^t$认为编码了字符串$w_i^1…w_i^t$的语义，因此$h_i^N$可以看成对整个句子语义的编码。t时刻GRU的计算公式为：</p><script type="math/tex; mode=display">\begin{split}r^t & =\sigma(W_rx^t+U_rh^{t-1}) \\z^t & =\sigma(W_zx^t+U_zh^{t-1}) \\\bar{h}^t & =tanh(Wx^t+U(r^t \odot h^{t-1})) \\h^t & =(1-z^t) \odot h^{t-1} + z^t \odot \bar{h}^t\end{split}</script><p>这就是标准的GRU，其中$x^t$是$w_i^t$的Embedding向量，$r^t$是重置(reset)门，$z^t$是更新(update)门，$\odot$是element-wise的乘法。Decoder是一个神经网络语言模型。</p><script type="math/tex; mode=display">\begin{split}r^t & = \sigma(W_r^dx^{t-1} + U_r^dh^{t-1} + C_rh_i) \\z^t & = \sigma(W_z^dx^{t-1} + U_z^dh^{t-1} + C_zh_i) \\\bar{h}^t & =tanh(W^dx^{t-1} + U^d(r^t \odot h^{t-1}) +Ch_i) \\h^t & =(1-z^t) \odot h^{t-1} + z^t \odot \bar{h}^t\end{split}</script><p>和之前我们在机器翻译里介绍的稍微有一些区别。标准Encoder-Decoder里Decoder每个时刻的输入是$x^{t-1}$和$h^{t-1}$，Decoder的初始状态设置为Encoder的输出$h_i$。而这里Decodert时刻的输入除了$x^{t-1}$和$h^{t-1}$，还有Encoder的输出$h_i$。</p><p>计算出Decoder每个时刻的隐状态$h^t$之后，我们在用一个矩阵V把它投影到词的空间，输出的是预测每个词的概率分布。注意：预测前一个句子和后一个句子是两个GRU模型，它们的参数是不共享的，但是投影矩阵V是共享的。当然输入$w^t$到Embedding $x^t$的Embedding矩阵也是共享的。和Word2Vec对比的话，V是输出向量(矩阵)而这个Embedding(这里没有起名字)是输入向量(矩阵)。</p><h3 id="词汇扩展"><a href="#词汇扩展" class="headerlink" title="词汇扩展"></a>词汇扩展</h3><p>这篇论文还有一个比较重要的方法就是词汇扩展。因为BookCorpus相对于训练Word2Vec等的语料来说还是太小，很多的词都根本没有在这个语料中出现，因此直接使用的话效果肯定不好。</p><p>本文使用了词汇扩展的办法。具体来说我们可以先用海量的语料训练一个Word2Vec，这样可以把一个词映射到一个语义空间，我们把这个向量叫作$\mathcal{V}_{w2v}$。而我们之前训练的得到的输入向量也是把一个词映射到另外一个语义空间，我们记作<script type="math/tex">\mathcal{V}_{rnn}</script>。</p><p>我们假设它们之间存在一个线性变换<script type="math/tex">f: \mathcal{V}_{w2v} \rightarrow \mathcal{V}_{rnn}</script>。这个线性变换的参数是矩阵W，使得<script type="math/tex">v_{rnn}=Wv_{w2v}</script>。那怎么求这个变换矩阵W呢？因为两个训练语料会有公共的词(通常训练word2vec的语料比skip vector大得多，从而词也多得多)。因此我们可以用这些公共的词来寻找W。寻找的依据是：遍历所有可能的W，使得$Wv_{w2v}$和$v_{rnn}$尽量接近。用数学语言描述就是：</p><script type="math/tex; mode=display">W^* = \underset{W}{argmin} \sum_{w \in both set} |Wv_{w2v}(w)-v_{rnn}(w)|^2</script><h3 id="训练细节"><a href="#训练细节" class="headerlink" title="训练细节"></a>训练细节</h3><p>首先训练了单向的GRU，向量的维度是2400，我们把它叫作uni-skip向量。此外还训练了bi-skip向量，它是这样得到的：首先训练1200维的uni-skip，然后句子倒过来，比如原来是”aa bb”、”cc dd”和”ee ff”，我们是用”cc dd”来预测”aa bb”以及”ee ff”，现在反过来变成”ff ee”、”dd cc”和”bb aa”。这样也可以训练一个模型，当然也就得到一个encoder(两个decoder不需要了)，给定一个句子我们把它倒过来然后也编码成1200为的向量，最后把这个两个1200维的向量拼接成2400维的向量。</p><p>模型训练完成之后还需要进行词汇扩展。通过BookCorpus学习到了20,000个词，而word2vec共选择了930,911词，通过它们共同的词学习出变换矩阵W，从而使得我们的Skip Thought Vector可以处理930,911个词。</p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>为了验证效果，本文把Sentence Embedding作为下游任务的输入特征，任务包括分类(情感分类)，SNI(RTE)等。前者的输入是一个句子，而后者的输入是两个句子。</p><h4 id="Semantic-relatedness任务"><a href="#Semantic-relatedness任务" class="headerlink" title="Semantic relatedness任务"></a>Semantic relatedness任务</h4><p>这里使用了SICK(SemEval 2014 Task 1，给定两个句子，输出它们的语义相关性1-5五个分类)和Microsoft Paraphrase Corpus(给定两个句子，判断它们是否一个意思/两分类)。</p><p>它们的输入是两个句子，输出是分类数。对于输入的两个句子，我们用Skip Thought Vector把它们编码成两个向量u和v，然后计算$u \cdot v$与$\vert u-v \vert $，然后把它们拼接起来，最后接一个logistic regression层(全连接加softmax)。</p><p>使用这么简单的分类模型的原因是想看看Sentence Embedding是否能够学习到复杂的非线性的语义关系。使用结果如下图所示。可以看到效果还是非常不错的，和(当时)最好的结果差别不大，而那些结果都是使用非常复杂的模型得到结果，而这里只使用了简单的逻辑回归模型。</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/skip-thought-3-16514865823989.png" alt="img" style="zoom:80%;"></p><p><em>图：Semantic relatedness的效果</em> </p><h4 id="COCO图像检索任务"><a href="#COCO图像检索任务" class="headerlink" title="COCO图像检索任务"></a>COCO图像检索任务</h4><p>这个任务的输入是一幅图片和一个句子，模型输出的是它们的相关性(句子是否描述了图片的内容)。句子我们可以用Skip Thought Vector编码成一个向量；而图片也可以用预训练的CNN编码成一个向量。模型细节这里不再赘述了，最终的结果如下图所示。</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/skip-thought-4-165148662203611.png" alt="img" style="zoom:80%;"></p><p><em>图：Image Retrieval的效果</em> </p><h4 id="分类任务"><a href="#分类任务" class="headerlink" title="分类任务"></a>分类任务</h4><p>这里比较了5个分类任务： 电影评论情感分类(MR), 商品评论情感分类(CR) , 主观/客观分类(SUBJ), 意见分类(MPQA)和TREC问题类型分类。结果如下图所示。</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/skip-thought-5-165148663978213.png" alt="img" style="zoom:80%;"></p><p><em>图：分类任务的效果</em></p><h2 id="ELMo"><a href="#ELMo" class="headerlink" title="ELMo"></a>ELMo</h2><h3 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h3><p>ELMo是Embeddings from Language Models的缩写，意思就是语言模型得到的(句子)Embedding。另外Elmo是美国儿童教育电视节目芝麻街(Sesame Street)里的小怪兽的名字。原始论文是<a href="https://arxiv.org/abs/1802.05365" target="_blank" rel="noopener">Deep contextualized word representations</a>，这个标题是很合适的，也就是用深度的Transformer模型来学习上下文相关的词表示。</p><p>这篇论文的想法其实非常非常简单，但是取得了非常好的效果。它的思路是用深度的双向RNN(LSTM)在大量未标注数据上训练语言模型，如下图所示。然后在实际的任务中，对于输入的句子，我们使用这个语言模型来对它处理，得到输出的向量，因此这可以看成是一种特征提取。但是和普通的Word2Vec或者GloVe的pretraining不同，ELMo得到的Embedding是有上下文的。比如我们使用Word2Vec也可以得到词”bank”的Embedding，我们可以认为这个Embedding包含了bank的语义。但是bank有很多意思，可以是银行也可以是水边，使用普通的Word2Vec作为Pretraining的Embedding，只能同时把这两种语义都编码进向量里，然后靠后面的模型比如RNN来根据上下文选择合适的语义——比如上下文有money，那么它更可能是银行；而如果上下文是river，那么更可能是水边的意思。但是RNN要学到这种上下文的关系，需要这个任务有大量相关的标注数据，这在很多时候是没有的。而ELMo的特征提取可以看成是上下文相关的，如果输入句子有money，那么它就(或者我们期望)应该能知道bank更可能的语义，从而帮我们选择更加合适的编码。</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/elmo-3-165148666130915.png" alt="img"></p><p><em>图：RNN语言模型</em></p><h3 id="无监督的预训练"><a href="#无监督的预训练" class="headerlink" title="无监督的预训练"></a>无监督的预训练</h3><p>给定一个长度为N的句子，假设为$t_1,t_2,…,t_N$，语言模型会计算给定$t_1,…,t_{k-1}$的条件下出现$t_k$的概率：</p><script type="math/tex; mode=display">p(t_1,...,t_N)=\prod_{i=1}^{k}p(t_k|t_1,...,t_{k-1})</script><p>传统的N-gram语言模型不能考虑很长的历史，因此现在的主流是使用多层双向的RNN(LSTM/GRU)来实现语言模型。在每个时刻k，RNN的第j层会输出一个隐状态<script type="math/tex">\overrightarrow{h}_{kj}^{LM}</script>，其中$j=1,2,…,L$，L是RNN的层数。最上层是<script type="math/tex">\overrightarrow{h}_{kL}^{LM}</script>，对它进行softmax之后就可以预测输出词的概率。类似的，我们可以用一个反向的RNN来计算概率：</p><script type="math/tex; mode=display">p(t_1,...,t_N)=\prod_{i=1}^{k}p(t_k|t_{k+1},...,t_N)</script><p>通过这个RNN，我们可以得到$\overleftarrow{h}_{kj}^{LM}$。我们把这两个方向的RNN合并起来就得到Bi-LSTM。我们优化的损失函数是两个LSTM的交叉熵加起来是最小的：</p><script type="math/tex; mode=display">Loss=\sum_{k=1}^{N}(logp(t_k|t_1,...,t_{k-1};\Theta_x,\overrightarrow{\Theta}_{LSTM},\Theta_s) + logp(t_k|t_{k+1},...,t_N;\Theta_x,\overleftarrow{\Theta}_{LSTM},\Theta_s)</script><p>这两个LSTM有各自的参数<script type="math/tex">\overrightarrow{\Theta}_{LSTM}</script>和<script type="math/tex">\overleftarrow{\Theta}_{LSTM}</script>，但是word embedding参数$\Theta_x$和softmax参数$\Theta_s$是共享的。</p><h3 id="应用ELMo"><a href="#应用ELMo" class="headerlink" title="应用ELMo"></a>应用ELMo</h3><p>ELMo会根据不同的任务，把上面得到的双向的LSTM的不同层的隐状态组合起来。对于输入的词$t_k$，我们可以得到2L+1个向量，分别是<script type="math/tex">\{x_k^{LM}, \overrightarrow{h}_{kj}^{LM}, \overleftarrow{h}_{kj}^{LM}, j=1,2,...,L\}</script>，我们把它记作<script type="math/tex">R_k=\{h_{kj}^{LM}, j=0,1,...,L\}</script>。其中<script type="math/tex">h_{k0}^{LM}</script>是词的Embedding，它与上下文无关，而其它的<script type="math/tex">h_{kj}^{LM}=[\overrightarrow{h}_{kj}^{LM}; \overleftarrow{h}_{kj}^{LM}], j>0</script>是把双向的LSTM的输出拼接起来的，它们与上下文相关的。为了用于下游(downstream)的特定任务，我们会把不同层的隐状态组合起来，组合的参数是根据特定任务学习出来的，公式如下：</p><script type="math/tex; mode=display">ELMo_k^{task}=E(R_k;\Theta_{task})=\gamma^{task}\sum_{j=0}^{L}s_j^{task}h_{kj}^{LM}</script><p>这里的$\gamma^{task}$是一个缩放因子，而$s_j^{task}$用于把不同层的输出加权组合出来。在实际的任务中，RNN的参数$h_{kj}^{LM}$都是固定的，可以调的参数只是$\gamma^{task}$和$s_j^{task}$。当然这里ELMo只是一个特征提取，实际任务会再加上一些其它的网络结构，那么那些参数也是一起调整的。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>下图是ELMo在SQuAD、SNLI等常见任务上的效果，相对于Baseline系统都有不小的提高。</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/elmo-1-165148667717217.png" alt="img" style="zoom:80%;"></p><p><em>图：ELMo的效果</em> </p><h2 id="OpenAI-GPT"><a href="#OpenAI-GPT" class="headerlink" title="OpenAI GPT"></a>OpenAI GPT</h2><p>OpenAI GPT是来自OpenAI的论文<a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">Improving Language Understanding by Generative Pre-Training</a>，BERT借鉴了很多它的方法。</p><h3 id="简介-2"><a href="#简介-2" class="headerlink" title="简介"></a>简介</h3><p>和前面的ELMo不同，GPT得到的语言模型的参数不是固定的，它会根据特定的任务进行调整(通常是微调)，这样得到的句子表示能更好的适配特定任务。它的思想其实也很简单，使用Transformer来学习一个语言模型，对句子进行无监督的Embedding，然后根据具体任务对Transformer的参数进行微调。</p><h3 id="无监督的Pretraining"><a href="#无监督的Pretraining" class="headerlink" title="无监督的Pretraining"></a>无监督的Pretraining</h3><p>之前我们介绍的Transformer模型是用来做机器翻译的，它有一个Encoder和一个Decoder。这里使用的是Encoder，只不过Encoder的输出不是给Decoder使用，而是直接用它来预测下一个词，如下图所示。但是直接用Self-Attention来训练语言模型是有问题的，因为在k时刻$p(t_k \vert t_1,..,t_{k-1})$，也就是计算$t_k$的时候只能利用它之前的词(或者逆向的语言模型只能用它之后的词)。但是Transformer的Self-Attention是可以利用整个句子的信息的，这显然不行，因为你让它根据”it is a”来预测后面的词，而且还告诉它整个句子是”it is a good day”，它就可能”作弊”，直接把下一个词输出了，这样loss是零。</p><p>因此这里要借鉴Decoder的Mask技巧，通过Mask让它在编码$t_k$的时候只能利用k之前(包括k本身)的信息。具体来说，给定一个未标注的语料库$\mathcal{U}=\\{u_1,…,u_n\\}$，我们训练一个语言模型，对参数进行最大(对数)似然估计：</p><script type="math/tex; mode=display">L_1(\mathcal{U})=\sum_i logP(u_i|u_1,...,u_{k-1})</script><p>我们这里使用多层的Transformer来实现语言模型，具体为：</p><script type="math/tex; mode=display">\begin{split}h_0 & =UW_e+W_p \\h_l & = transformer\_block(h_{l-1}) \\P(u) & = softmax(h_n W_e^T)\end{split}</script><p>这里的$W_e$是词的Embedding Matrix，$W_p$是位置Embedding Matrix。注意这里的位置编码没有使用前面Transformer的固定编码方式，而是采用类似词的Embedding Matrix，让它自己根据任务学习出合适的位置编码。</p><h3 id="监督的Fine-Tuning"><a href="#监督的Fine-Tuning" class="headerlink" title="监督的Fine-Tuning"></a>监督的Fine-Tuning</h3><p>无监督的Pretraining之后，我们还需要针对特定任务进行Fine-Tuning。我们先假设监督数据集合$\mathcal{C}$的输入x是一个词序列(后面会讲到怎么处理相似度计算或者问答这种输入有两个序列的问题)$x^1,…,x^m$，输出是一个分类的标签y，比如情感分类(Sentiment Classification)任务就是满足上述的条件。</p><p>我们把$x^1,…,x^m$输入Transformer模型，得到最上层的最后一个时刻的输出$h_l^m$，然后我们再加一个softmax层(参数为$W_y$)进行分类，最后用交叉熵损失函数计算损失，从而根据标准数据调整Transformer的参数以及softmax的参数$W_y$。这等价于最大似然估计：</p><script type="math/tex; mode=display">L_2(\mathcal{C})=\sum{x,y}logP(y|x^1,...,x^m)</script><p>正常我们应该调整参数使得$L_2$最大，但是为了提高训练速度和模型的泛化能力，我们使用Multi-task Learning，同时让它最大似然$L_1$和$L_2$：</p><script type="math/tex; mode=display">L_3(\mathcal{C})=L_2(\mathcal{C})+\lambda \times L_1(\mathcal{C})</script><p>注意，这里使用的$L_1$还是之前的语言模型的损失(似然)，但是使用的数据不是前面无监督的数据$\mathcal{U}$，而是使用简单的数据$\mathcal{C}$，而且只使用其中的x，而不需要标签y。</p><h3 id="其它任务"><a href="#其它任务" class="headerlink" title="其它任务"></a>其它任务</h3><p>前面讲了，我们能够处理的任务要求输入是一个序列，而输出是一个分类标签。对于有些任务，比如情感分类，这是没有问题的，但是对于相似度计算或者问答，输入是两个序列。为了能够使用GPT，我们需要一些特殊的技巧把两个输入序列变成一个输入序列。</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/gpt-1-165148669057419.png" alt="img" style="zoom:80%;"></p><p><em>图：处理其它任务</em> </p><p>如图上图所示，对于输入是一个序列的任务，我们在序列前后增加两个特殊token——“start”和”extract”，分别表示开始和结束；而如果输入是两个序列，那么在它们中间增加一个特殊的token “delim”。比如Entailment，输入是Premise和Hypothesis，输出是3个分类标签中的一个。</p><p>如果是相似度计算，因为对称性，我们把它们交换顺序，然后输入两个Transformer。如果是多选题，比如给定一个问题和N个答案，那么我们可以把问题和N个答案分别输入N个Transformer。</p><h3 id="实验结果-1"><a href="#实验结果-1" class="headerlink" title="实验结果"></a>实验结果</h3><p>下图是部分实验结果，相对于之前的baseline对很多任务都有提高。</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/gpt-2-165148670241221.png" alt="img" style="zoom:80%;"></p><p><em>图：OpenAI GPT的部分实验结果</em> </p><h2 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h2><h3 id="ELMo和OpenAI-GPT的问题"><a href="#ELMo和OpenAI-GPT的问题" class="headerlink" title="ELMo和OpenAI GPT的问题"></a>ELMo和OpenAI GPT的问题</h3><p>ELMo和GPT最大的问题就是传统的语言模型是单向的——我们是根据之前的历史来预测当前词。但是我们不能利用后面的信息。比如句子”The animal didn’t cross the street because it was too tired”。我们在编码it的语义的时候需要同时利用前后的信息，因为在这个句子中，it可能指代animal也可能指代street。根据tired，我们推断它指代的是animal，因为street是不能tired。但是如果把tired改成wide，那么it就是指代street了。传统的语言模型，不管是RNN还是Transformer，它都只能利用单方向的信息。比如前向的RNN，在编码it的时候它看到了animal和street，但是它还没有看到tired，因此它不能确定it到底指代什么。如果是后向的RNN，在编码的时候它看到了tired，但是它还根本没看到animal，因此它也不能知道指代的是animal。Transformer的Self-Attention理论上是可以同时attend to到这两个词的，但是根据前面的介绍，由于我们需要用Transformer来学习语言模型，因此必须用Mask来让它看不到未来的信息，所以它也不能解决这个问题的。</p><p>注意：即使ELMo训练了双向的两个RNN，但是一个RNN只能看一个方向，因此也是无法”同时”利用前后两个方向的信息的。也许有的读者会问，我的RNN有很多层，比如第一层的正向RNN在编码it的时候编码了animal和street的语义，反向RNN编码了tired的语义，然后第二层的RNN就能同时看到这两个语义，然后判断出it指代animal。理论上是有这种可能，但是实际上很难。举个反例，理论上一个三层(一个隐层)的全连接网络能够拟合任何函数，那我们还需要更多层词的全连接网络或者CNN、RNN干什么呢？如果数据不是足够足够多，如果不对网络结构做任何约束，那么它有很多中拟合的方法，其中很多是过拟合的。但是通过对网络结构的约束，比如CNN的局部特效，RNN的时序特效，多层网络的层次结构，对它进行了很多约束，从而使得它能够更好的收敛到最佳的参数。我们研究不同的网络结构(包括resnet、dropout、batchnorm等等)都是为了对网络增加额外的(先验的)约束。</p><h3 id="BERT简介"><a href="#BERT简介" class="headerlink" title="BERT简介"></a>BERT简介</h3><p>BERT来自Google的论文<a href="https://arxiv.org/abs/1810.04805" target="_blank" rel="noopener">Pre-training of Deep Bidirectional Transformers for Language Understanding</a>，BERT是”Bidirectional Encoder Representations from Transformers”的首字母缩写。如下图所示，BERT能够同时利用前后两个方向的信息，而ELMo和GPT只能使用单个方向的。</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/bert-1-165148671588823.png" alt="img"></p><p><em>图：BERT vs ELMo and GPT</em></p><p>BERT仍然使用的是Transformer模型，那它是怎么解决语言模型只能利用一个方向的信息的问题呢？答案是它的pretraining训练的不是普通的语言模型，而是Mask语言模型。在介绍Mask语言模型之前我们先介绍BERT的输入表示。</p><h3 id="输入表示"><a href="#输入表示" class="headerlink" title="输入表示"></a>输入表示</h3><p>BERT的输入表示如图下图所示。比如输入的是两个句子”my dog is cute”，”he likes playing”。后面会解释为什么需要两个句子。这里采用类似GPT的两个句子的表示方法，首先会在第一个句子的开头增加一个特殊的Token [CLS]，在cute的后面增加一个[SEP]表示第一个句子结束，在##ing后面也会增加一个[SEP]。注意这里的分词会把”playing”分成”play”和”##ing”两个Token，这种把词分成更细粒度的Word Piece的方法在前面的机器翻译部分介绍过了，这是一种解决未登录词的常见办法，后面的代码部分也会简单介绍。接着对每个Token进行3个Embedding：词的Embedding；位置的Embedding和Segment的Embedding。词的Embedding大家都很熟悉了，而位置的Embedding和词类似，把一个位置(比如2)映射成一个低维稠密的向量。而Segment只有两个，要么是属于第一个句子(segment)要么属于第二个句子，不管那个句子，它都对应一个Embedding向量。同一个句子的Segment Embedding是共享的，这样它能够学习到属于不同Segment的信息。对于情感分类这样的任务，只有一个句子，因此Segment id总是0；而对于Entailment任务，输入是两个句子，因此Segment是0或者1。</p><p>BERT模型要求有一个固定的Sequence的长度，比如128。如果不够就在后面padding，否则就截取掉多余的Token，从而保证输入是一个固定长度的Token序列，后面的代码会详细的介绍。第一个Token总是特殊的[CLS]，它本身没有任何语义，因此它会(必须)编码整个句子(其它词)的语义。</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/bert-2-165148673188125.png" alt="img" style="zoom:80%;"></p><p><em>图：BERT的输入表示</em></p><p>segment embeddings示意图：</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/1135245-20190227235737504-479706108.png" alt="img" style="zoom:80%;"></p><h3 id="Mask-LM"><a href="#Mask-LM" class="headerlink" title="Mask LM"></a>Mask LM</h3><p>为了解决只能利用单向信息的问题，BERT使用的是Mask语言模型而不是普通的语言模型。Mask语言模型有点类似与完形填空——给定一个句子，把其中某个词遮挡起来，让人猜测可能的词。这里会随机的Mask掉15%的词，然后让BERT来预测这些Mask的词，通过调整模型的参数使得模型预测正确的概率尽可能大，这等价于交叉熵的损失函数。这样的Transformer在编码一个词的时候会(必须)参考上下文的信息。</p><p>但是这有一个问题：在Pretraining Mask LM时会出现特殊的Token [MASK]，但是在后面的fine-tuning时却不会出现，这会出现Mismatch的问题。因此BERT中，如果某个Token在被选中的15%个Token里，则按照下面的方式随机的执行：</p><ul><li>80%的概率替换成[MASK]，比如my dog is hairy → my dog is [MASK]</li><li>10%的概率替换成随机的一个词，比如my dog is hairy → my dog is apple</li><li>10%的概率替换成它本身，比如my dog is hairy → my dog is hairy</li></ul><p>这样做的好处是，BERT并不知道[MASK]替换的是哪一个词，而且任何一个词都有可能是被替换掉的，比如它看到的apple可能是被替换的词。这样强迫模型在编码当前时刻的时候不能太依赖于当前的词，而要考虑它的上下文，甚至更加上下文进行”纠错”。比如上面的例子模型在编码apple是根据上下文my dog is应该把apple(部分)编码成hairy的语义而不是apple的语义。</p><h3 id="预测句子关系"><a href="#预测句子关系" class="headerlink" title="预测句子关系"></a>预测句子关系</h3><p>在有些任务中，比如问答，前后两个句子有一定的关联关系，我们希望BERT Pretraining的模型能够学习到这种关系。因此BERT还增加了一个新的任务——预测两个句子是否有关联关系。这是一种Multi-Task Learing。BERT要求的Pretraining的数据是一个一个的”文章”，比如它使用了BookCorpus和维基百科的数据，BookCorpus是很多本书，每本书的前后句子是有关联关系的；而维基百科的文章的前后句子也是有关系的。对于这个任务，BERT会以50%的概率抽取有关联的句子(注意这里的句子实际只是联系的Token序列，不是语言学意义上的句子)，另外以50%的概率随机抽取两个无关的句子，然后让BERT模型来判断这两个句子是否相关。比如下面的两个相关的句子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP]</span><br></pre></td></tr></table></figure><p>下面是两个不相关的句子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[CLS] the man [MASK] to the store [SEP] penguin [MASK] are flight ##less birds [SEP]</span><br></pre></td></tr></table></figure></p><h3 id="Fine-Tuning"><a href="#Fine-Tuning" class="headerlink" title="Fine-Tuning"></a>Fine-Tuning</h3><p>BERT的Fine-Tuning如下图所示，共分为4类任务。</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/v2-a8de0f4b233bd5d267737689db32388e_r.jpg" alt="preview" style="zoom: 50%;"></p><p><em>图：BERT的Fine-Tuning</em></p><p>对于普通的分类任务，输入是一个序列，如图中右上所示，所有的Token都是属于同一个Segment(Id=0)，我们用第一个特殊Token [CLS]的最后一层输出接上softmax进行分类，用分类的数据来进行Fine-Tuning。</p><p>对于相似度计算等输入为两个序列的任务，过程如图左上所示。两个序列的Token对应不同的Segment(Id=0/1)。我们也是用第一个特殊Token [CLS]的最后一层输出接上softmax进行分类，然后用分类数据进行Fine-Tuning。</p><p>第三类任务是序列标注，比如命名实体识别，输入是一个句子(Token序列)，除了[CLS]和[SEP]的每个时刻都会有输出的Tag，比如B-PER表示人名的开始，本章的序列标注部分已经介绍过怎么把NER变成序列标注的问题了，这里不再赘述。然后用输出的Tag来进行Fine-Tuning，过程如图右下所示。</p><p>第四类是问答类问题，比如SQuAD v1.1数据集，输入是一个问题和一段很长的包含答案的文字(Paragraph)，输出在这段文字里找到问题的答案。</p><p>比如输入的问题是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Where do water droplets collide with ice crystals to form precipitation?</span><br></pre></td></tr></table></figure></p><p>包含答案的文字是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">... Precipitation forms as smaller droplets coalesce via collision with other rain drops or ice crystals within a cloud. ...</span><br></pre></td></tr></table></figure></p><p>正确答案是”within a cloud”。</p><p>我们怎么用BERT处理这样的问题呢？我们首先把问题和Paragraph表示成一个长的序列，中间用[SEP]分开，问题对应一个Segment(id=0)，包含答案的文字对于另一个Segment(id=1)。这里有一个假设，那就是答案是Paragraph里的一段连续的文字(Span)。BERT把寻找答案的问题转化成寻找这个Span的开始下标和结束下标的问题。</p><p>如<a href="#bert-3">上图</a>的左下所示。对于Paragraph的第i个Token，BERT的最后一层把它编码成$T_i$，然后我们用一个向量S(这是模型的参数，需要根据训练数据调整)和它相乘(内积)计算它是开始位置的得分，因为Paragraph的每一个Token(当然WordPiece的中间，比如##ing是不可能是开始的)都有可能是开始可能，我们用softmax把它变成概率，然后选择概率最大的作为答案的开始：</p><script type="math/tex; mode=display">P_i=\frac{e^{S \cdot T_i}}{\sum_j e^{S \cdot T_j} }</script><p>类似的有一个向量T，用于计算答案结束的位置。</p><h3 id="实验结果-2"><a href="#实验结果-2" class="headerlink" title="实验结果"></a>实验结果</h3><p>在GLUE评测平台上的结果如下图所示，我们可以发现BERT比之前最好的OpenAI GPT还提高了很多。</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/bert-4-165148679408228.png" alt="img" style="zoom:80%;"></p><p><em>图：BERT在GLUE上的结果</em> </p><p>在SQuAD数据集上，BERT之前最好的结果F1=89.3%，而7个BERT的ensembling能达到93.2%的F1得分。</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/bert-5-165148680783330.png" alt="img" style="zoom:80%;"></p><p><em>图：BERT在SQuAD上的结果</em> </p><p>在CoNLL-2003命名实体识别任务上，之前最好的结果是ELMo+Bi-LSTM-CRF(本书前面介绍过Bi-LSTM-CRF)，F1是92.2，而BERT没有使用CRF，也没有使用Bi-LSTM，只是一个Softmax就可以达到92.8的F1得分，如果加上CRF可能还会有一些提高(这是我的猜测，论文并没有尝试)。</p><h3 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h3><p>BERT的效果比好的原因是什么呢？从算法上说，它只有两点改动：Mask LM和预测句子关系的Multi-Task Learning。为了知道每个改动的贡献，文章做了如下的<a href="https://zhidao.baidu.com/question/1865645172350926907.html" target="_blank" rel="noopener">对照(Ablation)实验</a>。</p><p>如下图所示，$BERT_{BASE}$是小参数的一个BERT参考模型；No NSP是没有预测句子关系(只有Mask LM)的BERT模型；LTR &amp; No NSP基本等同于OpenAI GPT，它是基于Transoformer的从左到右的普通语言模型；而最后一行+BiLSTM是指在Fine-Tuning OpenAI GPT的时候多加一个双向LSTM层(通常的Fine-Tuning都是只有一个线性层)。</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/bert-7-165148682078032.png" alt="img" style="zoom:80%;"></p><p><em>图：不同模型的比较</em> </p><p>从上图可以看出，BERT比双向的OpenAI GPT好不少。</p><p>另外文章也对比了不同的参数的效果，如下图所示。</p><p><img src="/DeepLearningApplications/自然语言处理/bert模型详解/bert-8-165148683133934.png" alt="img" style="zoom:80%;"></p><p><em>图：模型参数的比较</em> </p><p>可以看出，模型的参数越多，效果也更好。</p><p>但是和OpenAI GPT相比，还有一点很重要的区别就是训练数据。OpenAI GPT使用的是BooksCorpus语料，总的词数800M；而BERT还增加了wiki语料，其词数是2,500M，所以BERT训练数据的总词数是3,300M。因此BERT的训练数据是OpenAI GPT的4倍多，这是非常重要的一点。我谨慎的怀疑BERT效果好的很大原因是数据量造成的，这从模型参数比较实验可以看出，参数越多效果越好，但是如果训练数据不够，参数再多也是没有用的。文章并没有给出和较大BERT模型等价参数的OpenAI GPT模型的效果，不知是忽略了还是有意为之？</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cnblogs.com/d0main/p/10447853.html#segment-embeddings" target="_blank" rel="noopener">【译】为什么BERT有3个嵌入层，它们都是如何实现的</a><br><a href="http://fancyerii.github.io/2019/03/09/bert-theory/" target="_blank" rel="noopener">BERT模型详解</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近终于搞懂了transformer和原理和实现，可以看bert了。事先声明，本文的大部分内容来自&lt;a href=&quot;http://fancyerii.github.io/2019/03/09/bert-theory/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;BERT模型详解&lt;/a&gt;。大佬写的太好了，本来不想复制粘贴的，但是有部分内容看不明白，必须加点笔记。&lt;/p&gt;
&lt;h2 id=&quot;背景简介&quot;&gt;&lt;a href=&quot;#背景简介&quot; class=&quot;headerlink&quot; title=&quot;背景简介&quot;&gt;&lt;/a&gt;背景简介&lt;/h2&gt;&lt;p&gt;2018年深度学习在NLP领域取得了比较大的突破，最大的新闻当属Google的BERT模型横扫各大比赛的排行榜。作者认为，深度学习在NLP领域比较重点的三大突破为：Word Embedding、RNN/LSTM/GRU+Seq2Seq+Attention+Self-Attention机制和Contextual Word Embedding(Universal Sentence Embedding)。&lt;/p&gt;
&lt;p&gt;Word Embedding解决了传统机器学习方法的特征稀疏问题，它通过把一个词映射到一个低维稠密的语义空间，从而使得相似的词可以共享上下文信息，从而提升泛化能力。而且通过无监督的训练可以获得高质量的词向量(比如Word2vec和Glove等方法)，从而把这些语义知识迁移到数据较少的具体任务上。但是Word Embedding学到的是一个词的所有语义，比如bank可以是”银行”也可以是”水边。如果一定要用一个固定的向量来编码其语义，那么我们只能把这两个词的语义都编码进去，但是实际一个句子中只有一个语义是合理的，这显然是有问题的。&lt;/p&gt;
&lt;p&gt;这时我们可以通过RNN/LSTM/GRU来编码上下文的语义，这样它能学到如果周围是money，那么bank更可能是”银行”的语义。最原始的RNN由于梯度消失和梯度爆炸等问题很难训练，后来引入了LSTM和GRU等模型来解决这个问题。最早的RNN只能用于分类、回归和序列标注等任务，通过引入两个RNN构成的Seq2Seq模型可以解决序列的变换问题。比如机器翻译、摘要、问答和对话系统都可以使用这个模型。尤其机器翻译这个任务的训练数据比较大，使用深度学习的方法的效果已经超过传统的机器学习方法，而且模型结构更加简单。到了2017年，Google提出了Transformer模型，引入了Self-Attention。Self-Attention的初衷是为了用Attention替代LSTM，从而可以更好的并行(因为LSTM的时序依赖特效很难并行)，从而可以处理更大规模的语料。Transformer出来之后被广泛的用于以前被RNN/LSTM/GRU霸占的地盘，Google更是在Transformer的论文里使用”Attention is all you need”这样霸气的标题。现在Transformer已经成为Encoder/Decoder的霸主。&lt;/p&gt;
    
    </summary>
    
    
      <category term="DeepLearningApplications" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/"/>
    
      <category term="自然语言处理" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
      <category term="NLP" scheme="https://www.zdaiot.com/tags/NLP/"/>
    
      <category term="bert" scheme="https://www.zdaiot.com/tags/bert/"/>
    
      <category term="transformer" scheme="https://www.zdaiot.com/tags/transformer/"/>
    
  </entry>
  
  <entry>
    <title>Transformer</title>
    <link href="https://www.zdaiot.com/DeepLearningApplications/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/Transformer%E5%AE%9E%E6%88%98/"/>
    <id>https://www.zdaiot.com/DeepLearningApplications/自然语言处理/Transformer实战/</id>
    <published>2022-04-28T12:18:03.000Z</published>
    <updated>2022-04-28T12:18:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>前面我们详细的介绍了Transformer的原理，但是有的细节还是一头雾水，所以我们接下来介绍一下Transformer的实现，主要参考了文章<a href="https://nlp.seas.harvard.edu/2018/04/03/attention.html" target="_blank" rel="noopener">The Annotated Transformer</a>，<a href="https://github.com/harvardnlp/annotated-transformer" target="_blank" rel="noopener">github地址</a>。</p><blockquote><p>本文的代码部分来自于github，而图来源于<a href="https://nlp.seas.harvard.edu/2018/04/03/attention.html" target="_blank" rel="noopener">The Annotated Transformer</a>。</p></blockquote><h2 id="Prelims"><a href="#Prelims" class="headerlink" title="Prelims"></a>Prelims</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> exists</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn.functional <span class="keyword">import</span> log_softmax, pad</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> LambdaLR</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> altair <span class="keyword">as</span> alt</span><br><span class="line"><span class="keyword">from</span> torchtext.data.functional <span class="keyword">import</span> to_map_style_dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchtext.vocab <span class="keyword">import</span> build_vocab_from_iterator</span><br><span class="line"><span class="keyword">import</span> torchtext.datasets <span class="keyword">as</span> datasets</span><br><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line"><span class="keyword">import</span> GPUtil</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.utils.data.distributed <span class="keyword">import</span> DistributedSampler</span><br><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"><span class="keyword">import</span> torch.multiprocessing <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">from</span> torch.nn.parallel <span class="keyword">import</span> DistributedDataParallel <span class="keyword">as</span> DDP</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set to False to skip notebook execution (e.g. for debugging)</span></span><br><span class="line">RUN_EXAMPLES = <span class="literal">True</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Some convenience helper functions used throughout the notebook</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_interactive_notebook</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> __name__ == <span class="string">"__main__"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_example</span><span class="params">(fn, args=[])</span>:</span></span><br><span class="line">    <span class="keyword">if</span> __name__ == <span class="string">"__main__"</span> <span class="keyword">and</span> RUN_EXAMPLES:</span><br><span class="line">        <span class="keyword">return</span> fn(*args)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">execute_example</span><span class="params">(fn, args=[])</span>:</span></span><br><span class="line">    <span class="keyword">if</span> __name__ == <span class="string">"__main__"</span> <span class="keyword">and</span> RUN_EXAMPLES:</span><br><span class="line">        fn(*args)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DummyOptimizer</span><span class="params">(torch.optim.Optimizer)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.param_groups = [&#123;<span class="string">"lr"</span>: <span class="number">0</span>&#125;]</span><br><span class="line">        <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">zero_grad</span><span class="params">(self, set_to_none=False)</span>:</span></span><br><span class="line">        <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DummyScheduler</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="literal">None</span></span><br></pre></td></tr></table></figure><h2 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h2><p>大多数的neural sequence transduction模型都使用了encoder-decoder结构，encoder结构将一个用符号（symbols）表示的输入系列$(x_1, …, x_n)$，表示成为连续表征$\mathbf{z} = (z_1, …, z_n)$。给出$\mathbf{z}$，decoder生成输出序列$(y_1,…,y_m)$，并且一次生成一个元素。在每一步，模型都是自回归的（auto-regressive），在生成下一步时，使用先前生成的符号作为附加输入。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderDecoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    A standard Encoder-Decoder architecture. Base for this and many</span></span><br><span class="line"><span class="string">    other models.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, encoder, decoder, src_embed, tgt_embed, generator)</span>:</span></span><br><span class="line">        super(EncoderDecoder, self).__init__()</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line">        self.src_embed = src_embed</span><br><span class="line">        self.tgt_embed = tgt_embed</span><br><span class="line">        self.generator = generator</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, src, tgt, src_mask, tgt_mask)</span>:</span></span><br><span class="line">        <span class="string">"Take in and process masked src and target sequences."</span></span><br><span class="line">        <span class="keyword">return</span> self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">encode</span><span class="params">(self, src, src_mask)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.encoder(self.src_embed(src), src_mask)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decode</span><span class="params">(self, memory, src_mask, tgt, tgt_mask)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)</span><br><span class="line">      </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Define standard linear + softmax generation step."</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, vocab)</span>:</span></span><br><span class="line">        super(Generator, self).__init__()</span><br><span class="line">        self.proj = nn.Linear(d_model, vocab)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> log_softmax(self.proj(x), dim=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure><p>Transformer总体结构如下，encoder和decoder结构都是堆叠self-attention and point-wise, fully connected layers。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer实战/the-annotated-transformer_14_0.png" alt="png"></p><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p>Encoder由$N=6$个一模一样的层（EncoderLayer）组成。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clones</span><span class="params">(module, N)</span>:</span></span><br><span class="line">    <span class="string">"Produce N identical layers."</span></span><br><span class="line">    <span class="keyword">return</span> nn.ModuleList([copy.deepcopy(module) <span class="keyword">for</span> _ <span class="keyword">in</span> range(N)])</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Core encoder is a stack of N layers"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, layer, N)</span>:</span></span><br><span class="line">        super(Encoder, self).__init__()</span><br><span class="line">        self.layers = clones(layer, N)</span><br><span class="line">        self.norm = LayerNorm(layer.size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, mask)</span>:</span></span><br><span class="line">        <span class="string">"Pass the input (and mask) through each layer in turn."</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = layer(x, mask)</span><br><span class="line">        <span class="keyword">return</span> self.norm(x)</span><br></pre></td></tr></table></figure><p>我们在each of the two sub-layers使用残差连接，并且后接layer normalization。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LayerNorm</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Construct a layernorm module (See citation for details)."</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, features, eps=<span class="number">1e-6</span>)</span>:</span></span><br><span class="line">        super(LayerNorm, self).__init__()</span><br><span class="line">        self.a_2 = nn.Parameter(torch.ones(features))</span><br><span class="line">        self.b_2 = nn.Parameter(torch.zeros(features))</span><br><span class="line">        self.eps = eps</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        mean = x.mean(<span class="number">-1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        std = x.std(<span class="number">-1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> self.a_2 * (x - mean) / (std + self.eps) + self.b_2</span><br></pre></td></tr></table></figure><p>因此，每一个sub-layer的输出是$\mathrm{LayerNorm}(x + \mathrm{Sublayer}(x))$。我们还添加了Dropout层。为了facilitate这些残差连接，模型中所有sub-layer和embedding layers的输出维度均是$d_{\text{model}}=512$。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SublayerConnection</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    A residual connection followed by a layer norm.</span></span><br><span class="line"><span class="string">    Note for code simplicity the norm is first as opposed to last.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, dropout)</span>:</span></span><br><span class="line">        super(SublayerConnection, self).__init__()</span><br><span class="line">        self.norm = LayerNorm(size)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, sublayer)</span>:</span></span><br><span class="line">        <span class="string">"Apply residual connection to any sublayer with the same size."</span></span><br><span class="line">        <span class="keyword">return</span> x + self.dropout(sublayer(self.norm(x)))</span><br></pre></td></tr></table></figure><p>每一个layer含有两个sub-layers，第一个是multi-head self-attention mechanism，第二个是simple, position-wise fully connected feed-forward network。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Encoder is made up of self-attn and feed forward (defined below)"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, self_attn, feed_forward, dropout)</span>:</span></span><br><span class="line">        super(EncoderLayer, self).__init__()</span><br><span class="line">        self.self_attn = self_attn</span><br><span class="line">        self.feed_forward = feed_forward</span><br><span class="line">        self.sublayer = clones(SublayerConnection(size, dropout), <span class="number">2</span>)</span><br><span class="line">        self.size = size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, mask)</span>:</span></span><br><span class="line">        <span class="string">"Follow Figure 1 (left) for connections."</span></span><br><span class="line">        x = self.sublayer[<span class="number">0</span>](x, <span class="keyword">lambda</span> x: self.self_attn(x, x, x, mask))</span><br><span class="line">        <span class="keyword">return</span> self.sublayer[<span class="number">1</span>](x, self.feed_forward)</span><br></pre></td></tr></table></figure><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>decoder同样由$N=6$个一模一样的层（encoder layer）组成。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Generic N layer decoder with masking."</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, layer, N)</span>:</span></span><br><span class="line">        super(Decoder, self).__init__()</span><br><span class="line">        self.layers = clones(layer, N)</span><br><span class="line">        self.norm = LayerNorm(layer.size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, memory, src_mask, tgt_mask)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = layer(x, memory, src_mask, tgt_mask)</span><br><span class="line">        <span class="keyword">return</span> self.norm(x)</span><br></pre></td></tr></table></figure><p>在每个encoder layer除了两个 sub-layers 外，还插入了第三个sub-layer，它在encoder stack的输出上执行multi-head attention。与encoder相同，我们在each of the two sub-layers使用残差连接，并且后接layer normalization。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecoderLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Decoder is made of self-attn, src-attn, and feed forward (defined below)"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, self_attn, src_attn, feed_forward, dropout)</span>:</span></span><br><span class="line">        super(DecoderLayer, self).__init__()</span><br><span class="line">        self.size = size</span><br><span class="line">        self.self_attn = self_attn</span><br><span class="line">        self.src_attn = src_attn</span><br><span class="line">        self.feed_forward = feed_forward</span><br><span class="line">        self.sublayer = clones(SublayerConnection(size, dropout), <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, memory, src_mask, tgt_mask)</span>:</span></span><br><span class="line">        <span class="string">"Follow Figure 1 (right) for connections."</span></span><br><span class="line">        m = memory</span><br><span class="line">        x = self.sublayer[<span class="number">0</span>](x, <span class="keyword">lambda</span> x: self.self_attn(x, x, x, tgt_mask))</span><br><span class="line">        x = self.sublayer[<span class="number">1</span>](x, <span class="keyword">lambda</span> x: self.src_attn(x, m, m, src_mask))</span><br><span class="line">        <span class="keyword">return</span> self.sublayer[<span class="number">2</span>](x, self.feed_forward)</span><br></pre></td></tr></table></figure><p>我们还修改了decoder中的self-attention sub-layer，以防止它利用到后续位置的信息。This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position  $i$  can depend only on the known outputs at positions less than $i$ .</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">subsequent_mask</span><span class="params">(size)</span>:</span></span><br><span class="line">    <span class="string">"Mask out subsequent positions."</span></span><br><span class="line">    attn_shape = (<span class="number">1</span>, size, size)</span><br><span class="line">    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=<span class="number">1</span>).type(</span><br><span class="line">        torch.uint8</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> subsequent_mask == <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">example_mask</span><span class="params">()</span>:</span></span><br><span class="line">    LS_data = pd.concat(</span><br><span class="line">        [</span><br><span class="line">            pd.DataFrame(</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">"Subsequent Mask"</span>: subsequent_mask(<span class="number">20</span>)[<span class="number">0</span>][x, y].flatten(),</span><br><span class="line">                    <span class="string">"Window"</span>: y,</span><br><span class="line">                    <span class="string">"Masking"</span>: x,</span><br><span class="line">                &#125;</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">for</span> y <span class="keyword">in</span> range(<span class="number">20</span>)</span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">20</span>)</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        alt.Chart(LS_data)</span><br><span class="line">        .mark_rect()</span><br><span class="line">        .properties(height=<span class="number">250</span>, width=<span class="number">250</span>)</span><br><span class="line">        .encode(</span><br><span class="line">            alt.X(<span class="string">"Window:O"</span>),</span><br><span class="line">            alt.Y(<span class="string">"Masking:O"</span>),</span><br><span class="line">            alt.Color(<span class="string">"Subsequent Mask:Q"</span>, scale=alt.Scale(scheme=<span class="string">"viridis"</span>)),</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">show_example(example_mask)</span><br></pre></td></tr></table></figure><p>下图展示了each tgt word（row），被允许看到的信息（column）。单词在训练过程中被遮挡，使模型关注预测下一个words。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer实战/the-annotated-transformer_31_0.png" alt="png"></p><h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><p>attention函数可以被描述为 mapping a query and a set of key-value pairs to an output，其中query, keys, values, and output都是向量。output是values的加权求和，其中每个value的权重是通过query with the corresponding key的compatibility function计算得到。</p><p>我们将这种特别的attention称为“Scaled Dot-Product Attention”。它的输入由$d_k$维度的queries、keys，$d_v$维度的values组成。 We compute the dot products of the query with all keys, divide each by $\sqrt{d_k}$, and apply a softmax function to obtain the weights on the values。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer实战/the-annotated-transformer_33_0.png" alt="png"></p><p>实际上我们会同时在一系列的的queries上计算attention 函数，对应的会有一系列的keys $K$、values $V$。attention函数的输出为：</p><script type="math/tex; mode=display">\mathrm{Attention}(Q, K, V) = \mathrm{softmax}(\frac{QK^T}{\sqrt{d_k}})V</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention</span><span class="params">(query, key, value, mask=None, dropout=None)</span>:</span></span><br><span class="line">    <span class="string">"Compute 'Scaled Dot Product Attention'"</span></span><br><span class="line">    d_k = query.size(<span class="number">-1</span>)</span><br><span class="line">    scores = torch.matmul(query, key.transpose(<span class="number">-2</span>, <span class="number">-1</span>)) / math.sqrt(d_k)</span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        scores = scores.masked_fill(mask == <span class="number">0</span>, <span class="number">-1e9</span>)</span><br><span class="line">    p_attn = scores.softmax(dim=<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">if</span> dropout <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        p_attn = dropout(p_attn)</span><br><span class="line">    <span class="keyword">return</span> torch.matmul(p_attn, value), p_attn</span><br></pre></td></tr></table></figure><p>最常用的两个attention函数是additive attention和dot-product (multiplicative) attention。后者除了没有缩放$\frac{1}{\sqrt{d_k}}$，其余与我们的相同。而Additive attention computes the compatibility function using a feed-forward network with a single hidden layer.  虽然两者在理论复杂性上相似，但dot-product attention在实践中要快得多，空间效率更高，因为它可以使用高度优化的矩阵乘法代码来实现。</p><p>虽然对于较小的$d_k$值，这两种机制的性能相似，但对于较大的$d_k$值，additive attention优于dot product attention。我们怀疑较大的$d_k$值，dot product的幅度会增大，从而将Softmax函数推入其梯度极小的区域。(To illustrate why the dot products get large, assume that the components of $q$ and $k$ are independent random variables with mean $0$ and variance $1$.  Then their dot product, $q \cdot k = \sum_{i=1}^{d_k} q_ik_i$, has mean $0$ and variance$d_k$.). 为了抵消这种影响，我们使用$\frac{1}{\sqrt{d_k}}$对dot products进行缩放。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer实战/the-annotated-transformer_38_0.png" alt="png"></p><p>Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. 当仅有一个 attention head，平均化抑制了这一点。</p><script type="math/tex; mode=display">\mathrm{MultiHead}(Q, K, V) =    \mathrm{Concat}(\mathrm{head_1}, ..., \mathrm{head_h})W^O \\    \text{where}~\mathrm{head_i} = \mathrm{Attention}(QW^Q_i, KW^K_i, VW^V_i)</script><p>Where the projections are parameter matrices $W^Q_i \in \mathbb{R}^{d_{\text{model}} \times d_k}$, $W^K_i \in \mathbb{R}^{d_{\text{model}} \times d_k}$, $W^V_i \in \mathbb{R}^{d_{\text{model}} \times d_v}$ and $W^O \in \mathbb{R}^{hd_v \times d_{\text{model}}}$。在本工作中，我们使用了$h=8$个平行attention layers, or heads。对于其中每一个，我们使用了$d_k=d_v=d_{\text{model}}/h=64$。由于each head的维度降低了，所以总的计算量与full dimensionality的single-head attention相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiHeadedAttention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, h, d_model, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        <span class="string">"Take in model size and number of heads."</span></span><br><span class="line">        super(MultiHeadedAttention, self).__init__()</span><br><span class="line">        <span class="keyword">assert</span> d_model % h == <span class="number">0</span></span><br><span class="line">        <span class="comment"># We assume d_v always equals d_k</span></span><br><span class="line">        self.d_k = d_model // h</span><br><span class="line">        self.h = h</span><br><span class="line">        self.linears = clones(nn.Linear(d_model, d_model), <span class="number">4</span>)</span><br><span class="line">        self.attn = <span class="literal">None</span></span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, query, key, value, mask=None)</span>:</span></span><br><span class="line">        <span class="string">"Implements Figure 2"</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># Same mask applied to all h heads.</span></span><br><span class="line">            mask = mask.unsqueeze(<span class="number">1</span>)</span><br><span class="line">        nbatches = query.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1) Do all the linear projections in batch from d_model =&gt; h x d_k</span></span><br><span class="line">        query, key, value = [</span><br><span class="line">            lin(x).view(nbatches, <span class="number">-1</span>, self.h, self.d_k).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">            <span class="keyword">for</span> lin, x <span class="keyword">in</span> zip(self.linears, (query, key, value))</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2) Apply attention on all the projected vectors in batch.</span></span><br><span class="line">        x, self.attn = attention(</span><br><span class="line">            query, key, value, mask=mask, dropout=self.dropout</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3) "Concat" using a view and apply a final linear.</span></span><br><span class="line">        x = (</span><br><span class="line">            x.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">            .contiguous()</span><br><span class="line">            .view(nbatches, <span class="number">-1</span>, self.h * self.d_k)</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">del</span> query</span><br><span class="line">        <span class="keyword">del</span> key</span><br><span class="line">        <span class="keyword">del</span> value</span><br><span class="line">        <span class="keyword">return</span> self.linears[<span class="number">-1</span>](x)</span><br></pre></td></tr></table></figure><h3 id="Applications-of-Attention-in-our-Model"><a href="#Applications-of-Attention-in-our-Model" class="headerlink" title="Applications of Attention in our Model"></a>Applications of Attention in our Model</h3><p>Transformer以三种不同的方式使用了multi-head attention。</p><ol><li>在“encoder-decoder attention” layers中，queries来自于之前的decoder layer， memory keys and values 来自encoder的输出。This allows every position in the decoder to attend over all positions in the input sequence.  这模仿了sequence-to-sequence模型中典型的encoder-decoder attention机制。</li><li>encoder中的self-attention layers. 这里的self-attention layers中，所有的 keys, values and queries均来自于上一层的输出。Each position in the encoder can attend to all positions in the previous layer of the encoder.</li><li>decoder中的self-attention layers.  self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position（up to and including：直到并包括）。我们需要防止信息在decoder中向左流动，以保持自回归（auto-regressive）特性。我们在scaled dot-product attention中实现了这一点，通过屏蔽Softmax输入中对应于非法连接的所有值（设置为$-\infty$）。</li></ol><h3 id="Position-wise-Feed-Forward-Networks"><a href="#Position-wise-Feed-Forward-Networks" class="headerlink" title="Position-wise Feed-Forward Networks"></a>Position-wise Feed-Forward Networks</h3><p>除了attention sub-layers，encoder and decoder中的每一层都包含一个fully connected feed-forward network（完全连接的前馈网络），该网络分别且相同地应用于每个位置。它由两个线性变换组成，中间有一个ReLU激活。</p><script type="math/tex; mode=display">\mathrm{FFN}(x)=\max(0, xW_1 + b_1) W_2 + b_2</script><p>虽然在不同位置上都是线性变换，但它们在不同的层之间使用不同的参数。另一种描述方式是将其描述为核大小为1的两个卷积。input和output的维度为$d_{\text{model}}=512$，内层的维度为$d_{ff}=2048$。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionwiseFeedForward</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Implements FFN equation."</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, d_ff, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        super(PositionwiseFeedForward, self).__init__()</span><br><span class="line">        self.w_1 = nn.Linear(d_model, d_ff)</span><br><span class="line">        self.w_2 = nn.Linear(d_ff, d_model)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.w_2(self.dropout(self.w_1(x).relu()))</span><br></pre></td></tr></table></figure><h3 id="Embeddings-and-Softmax"><a href="#Embeddings-and-Softmax" class="headerlink" title="Embeddings and Softmax"></a>Embeddings and Softmax</h3><p>与其它的sequence transduction models相似，we use learned embeddings to convert the input tokens and output tokens to vectors of dimension  $d_{\text{model}}$。我们还使用常用的 linear transformation and softmax function 将 decoder output转换为 predicted next-token probabilities. 在我们的模型中，我们在two embedding layers 和pre-softmax linear transformation共享相同的权重矩阵。在embedding layers，我们multiply those weights by $\sqrt{d_{\text{model}}}$。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Embeddings</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, vocab)</span>:</span></span><br><span class="line">        super(Embeddings, self).__init__()</span><br><span class="line">        self.lut = nn.Embedding(vocab, d_model)</span><br><span class="line">        self.d_model = d_model</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.lut(x) * math.sqrt(self.d_model)</span><br></pre></td></tr></table></figure><h3 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h3><p>由于我们的模型不包含recurrence和卷积，为了使模型利用序列的顺序，我们必须注入一些关于tokens in the sequence的相对或绝对位置的信息。为此，我们将“positional encodings”添加到 encoder 和 decoder 堆栈底部的input embeddings中。 positional encodings具有与embeddings相同的维度$d_{\text{model}}$，因此这两个模型可以求和。positional encodings有许多选择，学习的和固定的。</p><p>在这项工作中，我们使用不同频率的正弦和余弦函数。其中$pos$表示单词在句子中的位置，$2i$ 表示偶数的维度，$2i+1$ 表示奇数维度。也就是说，位置编码的每个维度对应于一个正弦。波长形成从2π到10000⋅2π的几何级数。我们选择这个函数是因为我们假设它将允许模型更容易学习相对位置，因为对于任何固定的偏移量$k$，$PE_{pos+k}$可以表示为$PE_{pos}$的线性函数。</p><script type="math/tex; mode=display">PE_{(pos,2i)} = sin(pos / 10000^{2i/d_{\text{model}}}) \\PE_{(pos,2i+1)} = cos(pos / 10000^{2i/d_{\text{model}}})</script><p>初次之外，我们还将dropout应用于the sums of the embeddings and the positional encodings in both the encoder and decoder stacks. 这里dropout的比例为$P_{drop}=0.1$。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionalEncoding</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Implement the PE function."</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, dropout, max_len=<span class="number">5000</span>)</span>:</span></span><br><span class="line">        super(PositionalEncoding, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute the positional encodings once in log space.</span></span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(</span><br><span class="line">            torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>) * -(math.log(<span class="number">10000.0</span>) / d_model)</span><br><span class="line">        )</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        self.register_buffer(<span class="string">"pe"</span>, pe)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = x + self.pe[:, : x.size(<span class="number">1</span>)].requires_grad_(<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">return</span> self.dropout(x)</span><br></pre></td></tr></table></figure><p>Below the positional encoding will add in a sine wave based on position. The frequency and offset of the wave is different for each dimension.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">example_positional</span><span class="params">()</span>:</span></span><br><span class="line">    pe = PositionalEncoding(<span class="number">20</span>, <span class="number">0</span>)</span><br><span class="line">    y = pe.forward(torch.zeros(<span class="number">1</span>, <span class="number">100</span>, <span class="number">20</span>))</span><br><span class="line"></span><br><span class="line">    data = pd.concat(</span><br><span class="line">        [</span><br><span class="line">            pd.DataFrame(</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">"embedding"</span>: y[<span class="number">0</span>, :, dim],</span><br><span class="line">                    <span class="string">"dimension"</span>: dim,</span><br><span class="line">                    <span class="string">"position"</span>: list(range(<span class="number">100</span>)),</span><br><span class="line">                &#125;</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">for</span> dim <span class="keyword">in</span> [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        alt.Chart(data)</span><br><span class="line">        .mark_line()</span><br><span class="line">        .properties(width=<span class="number">800</span>)</span><br><span class="line">        .encode(x=<span class="string">"position"</span>, y=<span class="string">"embedding"</span>, color=<span class="string">"dimension:N"</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">show_example(example_positional)</span><br></pre></td></tr></table></figure><p><img src="/DeepLearningApplications/自然语言处理/Transformer实战/the-annotated-transformer_49_0.png" alt="png"></p><p>我们还试验了使用学习的positional embeddings，发现两个版本产生的结果几乎相同。我们选择正弦版本是因为它可能允许模型推广到比训练期间遇到的序列长度更长的序列长度。</p><h3 id="Full-Model"><a href="#Full-Model" class="headerlink" title="Full Model"></a>Full Model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_model</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    src_vocab, tgt_vocab, N=<span class="number">6</span>, d_model=<span class="number">512</span>, d_ff=<span class="number">2048</span>, h=<span class="number">8</span>, dropout=<span class="number">0.1</span></span></span></span><br><span class="line"><span class="function"><span class="params">)</span>:</span></span><br><span class="line">    <span class="string">"Helper: Construct a model from hyperparameters."</span></span><br><span class="line">    c = copy.deepcopy</span><br><span class="line">    attn = MultiHeadedAttention(h, d_model)</span><br><span class="line">    ff = PositionwiseFeedForward(d_model, d_ff, dropout)</span><br><span class="line">    position = PositionalEncoding(d_model, dropout)</span><br><span class="line">    model = EncoderDecoder(</span><br><span class="line">        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),</span><br><span class="line">        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),</span><br><span class="line">        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),</span><br><span class="line">        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),</span><br><span class="line">        Generator(d_model, tgt_vocab),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># This was important from their code.</span></span><br><span class="line">    <span class="comment"># Initialize parameters with Glorot / fan_avg.</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line">        <span class="keyword">if</span> p.dim() &gt; <span class="number">1</span>:</span><br><span class="line">            nn.init.xavier_uniform_(p)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><p><img src="/DeepLearningApplications/自然语言处理/Transformer实战/v2-680089c6c10bec7cb81b99640536de16_b.jpg" alt="img" style="zoom: 80%;"></p><h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><p>在这里，我们执行一个forward，以生成模型的预测。我们尝试使用我们的transformer来记忆输入。正如您将看到的，由于模型尚未经过训练，因此输出是随机生成的。在下一个教程中，我们将构建训练函数，并尝试训练我们的模型记住从1到10的数字。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference_test</span><span class="params">()</span>:</span></span><br><span class="line">    test_model = make_model(<span class="number">11</span>, <span class="number">11</span>, <span class="number">2</span>)</span><br><span class="line">    test_model.eval()</span><br><span class="line">    src = torch.LongTensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>]])</span><br><span class="line">    src_mask = torch.ones(<span class="number">1</span>, <span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    memory = test_model.encode(src, src_mask)</span><br><span class="line">    ys = torch.zeros(<span class="number">1</span>, <span class="number">1</span>).type_as(src)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">9</span>):</span><br><span class="line">        out = test_model.decode(</span><br><span class="line">            memory, src_mask, ys, subsequent_mask(ys.size(<span class="number">1</span>)).type_as(src.data)</span><br><span class="line">        )</span><br><span class="line">        prob = test_model.generator(out[:, <span class="number">-1</span>])</span><br><span class="line">        _, next_word = torch.max(prob, dim=<span class="number">1</span>)</span><br><span class="line">        next_word = next_word.data[<span class="number">0</span>]</span><br><span class="line">        ys = torch.cat(</span><br><span class="line">            [ys, torch.empty(<span class="number">1</span>, <span class="number">1</span>).type_as(src.data).fill_(next_word)], dim=<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Example Untrained Model Prediction:"</span>, ys)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_tests</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        inference_test()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">show_example(run_tests)</span><br></pre></td></tr></table></figure><h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>接下来我们来介绍训练流程，在此之前我们先介绍train a standard encoder decoder model所需的工具。首先我们定义一个batch object保存用于训练的 src and target sentences、masks。</p><h3 id="Batches-and-Masking"><a href="#Batches-and-Masking" class="headerlink" title="Batches and Masking"></a>Batches and Masking</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Batch</span>:</span></span><br><span class="line">    <span class="string">"""Object for holding a batch of data with mask during training."""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, src, tgt=None, pad=<span class="number">2</span>)</span>:</span>  <span class="comment"># 2 = &lt;blank&gt; for IWST</span></span><br><span class="line">        self.src = src</span><br><span class="line">        self.src_mask = (src != pad).unsqueeze(<span class="number">-2</span>)</span><br><span class="line">        <span class="keyword">if</span> tgt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.tgt = tgt[:, :<span class="number">-1</span>]</span><br><span class="line">            self.tgt_y = tgt[:, <span class="number">1</span>:]</span><br><span class="line">            self.tgt_mask = self.make_std_mask(self.tgt, pad)</span><br><span class="line">            self.ntokens = (self.tgt_y != pad).data.sum()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_std_mask</span><span class="params">(tgt, pad)</span>:</span></span><br><span class="line">        <span class="string">"Create a mask to hide padding and future words."</span></span><br><span class="line">        tgt_mask = (tgt != pad).unsqueeze(<span class="number">-2</span>)</span><br><span class="line">        tgt_mask = tgt_mask &amp; subsequent_mask(tgt.size(<span class="number">-1</span>)).type_as(</span><br><span class="line">            tgt_mask.data</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> tgt_mask</span><br></pre></td></tr></table></figure><h3 id="Training-Loop"><a href="#Training-Loop" class="headerlink" title="Training Loop"></a>Training Loop</h3><p>接下来我们创建一个通用的训练和打分函数，来跟踪损失。我们传入一个损失函数，它还会执行参数更新。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TrainState</span>:</span></span><br><span class="line">    <span class="string">"""Track number of steps, examples, and tokens processed"""</span></span><br><span class="line"></span><br><span class="line">    step: int = <span class="number">0</span>  <span class="comment"># Steps in the current epoch</span></span><br><span class="line">    accum_step: int = <span class="number">0</span>  <span class="comment"># Number of gradient accumulation steps</span></span><br><span class="line">    samples: int = <span class="number">0</span>  <span class="comment"># total # of examples used</span></span><br><span class="line">    tokens: int = <span class="number">0</span>  <span class="comment"># total # of tokens processed</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_epoch</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    data_iter,</span></span></span><br><span class="line"><span class="function"><span class="params">    model,</span></span></span><br><span class="line"><span class="function"><span class="params">    loss_compute,</span></span></span><br><span class="line"><span class="function"><span class="params">    optimizer,</span></span></span><br><span class="line"><span class="function"><span class="params">    scheduler,</span></span></span><br><span class="line"><span class="function"><span class="params">    mode=<span class="string">"train"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    accum_iter=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    train_state=TrainState<span class="params">()</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">)</span>:</span></span><br><span class="line">    <span class="string">"""Train a single epoch"""</span></span><br><span class="line">    start = time.time()</span><br><span class="line">    total_tokens = <span class="number">0</span></span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    tokens = <span class="number">0</span></span><br><span class="line">    n_accum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i, batch <span class="keyword">in</span> enumerate(data_iter):</span><br><span class="line">        out = model.forward(</span><br><span class="line">            batch.src, batch.tgt, batch.src_mask, batch.tgt_mask</span><br><span class="line">        )</span><br><span class="line">        loss, loss_node = loss_compute(out, batch.tgt_y, batch.ntokens)</span><br><span class="line">        <span class="comment"># loss_node = loss_node / accum_iter</span></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">"train"</span> <span class="keyword">or</span> mode == <span class="string">"train+log"</span>:</span><br><span class="line">            loss_node.backward()</span><br><span class="line">            train_state.step += <span class="number">1</span></span><br><span class="line">            train_state.samples += batch.src.shape[<span class="number">0</span>]</span><br><span class="line">            train_state.tokens += batch.ntokens</span><br><span class="line">            <span class="keyword">if</span> i % accum_iter == <span class="number">0</span>:</span><br><span class="line">                optimizer.step()</span><br><span class="line">                optimizer.zero_grad(set_to_none=<span class="literal">True</span>)</span><br><span class="line">                n_accum += <span class="number">1</span></span><br><span class="line">                train_state.accum_step += <span class="number">1</span></span><br><span class="line">            scheduler.step()</span><br><span class="line"></span><br><span class="line">        total_loss += loss</span><br><span class="line">        total_tokens += batch.ntokens</span><br><span class="line">        tokens += batch.ntokens</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">40</span> == <span class="number">1</span> <span class="keyword">and</span> (mode == <span class="string">"train"</span> <span class="keyword">or</span> mode == <span class="string">"train+log"</span>):</span><br><span class="line">            lr = optimizer.param_groups[<span class="number">0</span>][<span class="string">"lr"</span>]</span><br><span class="line">            elapsed = time.time() - start</span><br><span class="line">            print(</span><br><span class="line">                (</span><br><span class="line">                    <span class="string">"Epoch Step: %6d | Accumulation Step: %3d | Loss: %6.2f "</span></span><br><span class="line">                    + <span class="string">"| Tokens / Sec: %7.1f | Learning Rate: %6.1e"</span></span><br><span class="line">                )</span><br><span class="line">                % (i, n_accum, loss / batch.ntokens, tokens / elapsed, lr)</span><br><span class="line">            )</span><br><span class="line">            start = time.time()</span><br><span class="line">            tokens = <span class="number">0</span></span><br><span class="line">        <span class="keyword">del</span> loss</span><br><span class="line">        <span class="keyword">del</span> loss_node</span><br><span class="line">    <span class="keyword">return</span> total_loss / total_tokens, train_state</span><br></pre></td></tr></table></figure><h3 id="Training-Data-and-Batching"><a href="#Training-Data-and-Batching" class="headerlink" title="Training Data and Batching"></a>Training Data and Batching</h3><p>我们在标准的WMT 2014英语-德语数据集上进行了训练，该数据集由大约450万个句子对组成。Sentences were encoded using byte-pair encoding, which has a shared source-target vocabulary of about 37000 tokens.  对于英语-法语，我们使用了更大的2014年WMT英语-法语数据集，包括3600万个句子和split tokens into a 32000 word-piece vocabulary. </p><p>Sentence pairs were batched together by approximate sequence length. 每个训练批次包含一组句子对，其中包含大约25000个source tokens和25000个target tokens。</p><h3 id="Hardware-and-Schedule"><a href="#Hardware-and-Schedule" class="headerlink" title="Hardware and Schedule"></a>Hardware and Schedule</h3><p>我们在一台配备8个NVIDIA P100图形处理器的机器上训练了我们的模型。对于使用本文中描述的超参数的基本模型，每个训练步骤大约需要0.4秒。我们对基础模型进行了总共100,000步或12小时的培训。对于我们的大型模型，step time是1.0秒。这些大模型接受了300,000步(3.5天)的训练。</p><h3 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h3><p>我们使用adam作为优化器，$\beta_1=0.9$, $\beta_2=0.98$ and $\epsilon=10^{-9}$，在训练中学习率也是变化的，变化方式是：</p><script type="math/tex; mode=display">lrate = d_{\text{model}}^{-0.5} \cdot \min({step\_num}^{-0.5},  {step\_num} \cdot {warmup\_steps}^{-1.5})</script><p>这对应于在前面$warmup_steps$线性增加学习率，此后按与步数的平方根倒数成比例递减。这里$warmup_steps=4000$。</p><blockquote><p>注意：这部分非常重要。 需要使用这种模型设置进行训练。</p><p>该模型曲线的示例，用于不同的模型大小和优化超参数。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def rate(step, model_size, factor, warmup):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    we have to default the step to 1 for LambdaLR function</span><br><span class="line">    to avoid zero raising to negative power.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if step == 0:</span><br><span class="line">        step = 1</span><br><span class="line">    return factor * (</span><br><span class="line">        model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">example_learning_schedule</span><span class="params">()</span>:</span></span><br><span class="line">    opts = [</span><br><span class="line">        [<span class="number">512</span>, <span class="number">1</span>, <span class="number">4000</span>],  <span class="comment"># example 1</span></span><br><span class="line">        [<span class="number">512</span>, <span class="number">1</span>, <span class="number">8000</span>],  <span class="comment"># example 2</span></span><br><span class="line">        [<span class="number">256</span>, <span class="number">1</span>, <span class="number">4000</span>],  <span class="comment"># example 3</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    dummy_model = torch.nn.Linear(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    learning_rates = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># we have 3 examples in opts list.</span></span><br><span class="line">    <span class="keyword">for</span> idx, example <span class="keyword">in</span> enumerate(opts):</span><br><span class="line">        <span class="comment"># run 20000 epoch for each example</span></span><br><span class="line">        optimizer = torch.optim.Adam(</span><br><span class="line">            dummy_model.parameters(), lr=<span class="number">1</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>), eps=<span class="number">1e-9</span></span><br><span class="line">        )</span><br><span class="line">        lr_scheduler = LambdaLR(</span><br><span class="line">            optimizer=optimizer, lr_lambda=<span class="keyword">lambda</span> step: rate(step, *example)</span><br><span class="line">        )</span><br><span class="line">        tmp = []</span><br><span class="line">        <span class="comment"># take 20K dummy training steps, save the learning rate at each step</span></span><br><span class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">20000</span>):</span><br><span class="line">            tmp.append(optimizer.param_groups[<span class="number">0</span>][<span class="string">"lr"</span>])</span><br><span class="line">            optimizer.step()</span><br><span class="line">            lr_scheduler.step()</span><br><span class="line">        learning_rates.append(tmp)</span><br><span class="line"></span><br><span class="line">    learning_rates = torch.tensor(learning_rates)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Enable altair to handle more than 5000 rows</span></span><br><span class="line">    alt.data_transformers.disable_max_rows()</span><br><span class="line"></span><br><span class="line">    opts_data = pd.concat(</span><br><span class="line">        [</span><br><span class="line">            pd.DataFrame(</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">"Learning Rate"</span>: learning_rates[warmup_idx, :],</span><br><span class="line">                    <span class="string">"model_size:warmup"</span>: [<span class="string">"512:4000"</span>, <span class="string">"512:8000"</span>, <span class="string">"256:4000"</span>][</span><br><span class="line">                        warmup_idx</span><br><span class="line">                    ],</span><br><span class="line">                    <span class="string">"step"</span>: range(<span class="number">20000</span>),</span><br><span class="line">                &#125;</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">for</span> warmup_idx <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        alt.Chart(opts_data)</span><br><span class="line">        .mark_line()</span><br><span class="line">        .properties(width=<span class="number">600</span>)</span><br><span class="line">        .encode(x=<span class="string">"step"</span>, y=<span class="string">"Learning Rate"</span>, color=<span class="string">"model_size:warmup:N"</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">example_learning_schedule()</span><br></pre></td></tr></table></figure><p><img src="/DeepLearningApplications/自然语言处理/Transformer实战/the-annotated-transformer_69_0.png" alt="png"></p><h3 id="Regularization（Label-Smoothing）"><a href="#Regularization（Label-Smoothing）" class="headerlink" title="Regularization（Label Smoothing）"></a>Regularization（Label Smoothing）</h3><p>在训练过程中我们使用了label smoothing，$\epsilon_{ls}=0.1$。虽然模型学会了更多的不确定，但提高了准确性和BLEU的分数。</p><p>我们使用KL div loss实现label smoothing. Instead of using a one-hot target distribution, we create a distribution that has confidence of the correct word and the rest of the smoothing mass distributed throughout the vocabulary.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LabelSmoothing</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Implement label smoothing."</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, padding_idx, smoothing=<span class="number">0.0</span>)</span>:</span></span><br><span class="line">        super(LabelSmoothing, self).__init__()</span><br><span class="line">        self.criterion = nn.KLDivLoss(reduction=<span class="string">"sum"</span>)</span><br><span class="line">        self.padding_idx = padding_idx</span><br><span class="line">        self.confidence = <span class="number">1.0</span> - smoothing</span><br><span class="line">        self.smoothing = smoothing</span><br><span class="line">        self.size = size</span><br><span class="line">        self.true_dist = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, target)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> x.size(<span class="number">1</span>) == self.size</span><br><span class="line">        true_dist = x.data.clone()</span><br><span class="line">        true_dist.fill_(self.smoothing / (self.size - <span class="number">2</span>))</span><br><span class="line">        true_dist.scatter_(<span class="number">1</span>, target.data.unsqueeze(<span class="number">1</span>), self.confidence)</span><br><span class="line">        true_dist[:, self.padding_idx] = <span class="number">0</span></span><br><span class="line">        mask = torch.nonzero(target.data == self.padding_idx)</span><br><span class="line">        <span class="keyword">if</span> mask.dim() &gt; <span class="number">0</span>:</span><br><span class="line">            true_dist.index_fill_(<span class="number">0</span>, mask.squeeze(), <span class="number">0.0</span>)</span><br><span class="line">        self.true_dist = true_dist</span><br><span class="line">        <span class="keyword">return</span> self.criterion(x, true_dist.clone().detach())</span><br></pre></td></tr></table></figure><p>Here we can see an example of how the mass is distributed to the words based on confidence.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Example of label smoothing.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">example_label_smoothing</span><span class="params">()</span>:</span></span><br><span class="line">    crit = LabelSmoothing(<span class="number">5</span>, <span class="number">0</span>, <span class="number">0.4</span>)</span><br><span class="line">    predict = torch.FloatTensor(</span><br><span class="line">        [</span><br><span class="line">            [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>],</span><br><span class="line">            [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>],</span><br><span class="line">            [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>],</span><br><span class="line">            [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>],</span><br><span class="line">            [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>],</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line">    crit(x=predict.log(), target=torch.LongTensor([<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">3</span>]))</span><br><span class="line">    LS_data = pd.concat(</span><br><span class="line">        [</span><br><span class="line">            pd.DataFrame(</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">"target distribution"</span>: crit.true_dist[x, y].flatten(),</span><br><span class="line">                    <span class="string">"columns"</span>: y,</span><br><span class="line">                    <span class="string">"rows"</span>: x,</span><br><span class="line">                &#125;</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">for</span> y <span class="keyword">in</span> range(<span class="number">5</span>)</span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">5</span>)</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        alt.Chart(LS_data)</span><br><span class="line">        .mark_rect(color=<span class="string">"Blue"</span>, opacity=<span class="number">1</span>)</span><br><span class="line">        .properties(height=<span class="number">200</span>, width=<span class="number">200</span>)</span><br><span class="line">        .encode(</span><br><span class="line">            alt.X(<span class="string">"columns:O"</span>, title=<span class="literal">None</span>),</span><br><span class="line">            alt.Y(<span class="string">"rows:O"</span>, title=<span class="literal">None</span>),</span><br><span class="line">            alt.Color(</span><br><span class="line">                <span class="string">"target distribution:Q"</span>, scale=alt.Scale(scheme=<span class="string">"viridis"</span>)</span><br><span class="line">            ),</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">show_example(example_label_smoothing)</span><br></pre></td></tr></table></figure><p><img src="/DeepLearningApplications/自然语言处理/Transformer实战/the-annotated-transformer_74_0.png" alt="png"></p><p>Label smoothing actually starts to penalize the model if it gets very confident about a given choice.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(x, crit)</span>:</span></span><br><span class="line">    d = x + <span class="number">3</span> * <span class="number">1</span></span><br><span class="line">    predict = torch.FloatTensor([[<span class="number">0</span>, x / d, <span class="number">1</span> / d, <span class="number">1</span> / d, <span class="number">1</span> / d]])</span><br><span class="line">    <span class="keyword">return</span> crit(predict.log(), torch.LongTensor([<span class="number">1</span>])).data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">penalization_visualization</span><span class="params">()</span>:</span></span><br><span class="line">    crit = LabelSmoothing(<span class="number">5</span>, <span class="number">0</span>, <span class="number">0.1</span>)</span><br><span class="line">    loss_data = pd.DataFrame(</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"Loss"</span>: [loss(x, crit) <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">100</span>)],</span><br><span class="line">            <span class="string">"Steps"</span>: list(range(<span class="number">99</span>)),</span><br><span class="line">        &#125;</span><br><span class="line">    ).astype(<span class="string">"float"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        alt.Chart(loss_data)</span><br><span class="line">        .mark_line()</span><br><span class="line">        .properties(width=<span class="number">350</span>)</span><br><span class="line">        .encode(</span><br><span class="line">            x=<span class="string">"Steps"</span>,</span><br><span class="line">            y=<span class="string">"Loss"</span>,</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">show_example(penalization_visualization)</span><br></pre></td></tr></table></figure><p><img src="/DeepLearningApplications/自然语言处理/Transformer实战/the-annotated-transformer_76_0.png" alt="png"></p><h2 id="A-First-Example"><a href="#A-First-Example" class="headerlink" title="A First Example"></a>A First Example</h2><p>我们可以从尝试一项简单的抄写任务开始。给定一组来自较小词汇表的随机输入symbols，目标是生成相同的symbols。</p><h3 id="Synthetic-Data"><a href="#Synthetic-Data" class="headerlink" title="Synthetic Data"></a>Synthetic Data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_gen</span><span class="params">(V, batch_size, nbatches)</span>:</span></span><br><span class="line">    <span class="string">"Generate random data for a src-tgt copy task."</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(nbatches):</span><br><span class="line">        data = torch.randint(<span class="number">1</span>, V, size=(batch_size, <span class="number">10</span>))</span><br><span class="line">        data[:, <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">        src = data.requires_grad_(<span class="literal">False</span>).clone().detach()</span><br><span class="line">        tgt = data.requires_grad_(<span class="literal">False</span>).clone().detach()</span><br><span class="line">        <span class="keyword">yield</span> Batch(src, tgt, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h3 id="Loss-Computation"><a href="#Loss-Computation" class="headerlink" title="Loss Computation"></a>Loss Computation</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleLossCompute</span>:</span></span><br><span class="line">    <span class="string">"A simple loss compute and train function."</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, generator, criterion)</span>:</span></span><br><span class="line">        self.generator = generator</span><br><span class="line">        self.criterion = criterion</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, x, y, norm)</span>:</span></span><br><span class="line">        x = self.generator(x)</span><br><span class="line">        sloss = (</span><br><span class="line">            self.criterion(</span><br><span class="line">                x.contiguous().view(<span class="number">-1</span>, x.size(<span class="number">-1</span>)), y.contiguous().view(<span class="number">-1</span>)</span><br><span class="line">            )</span><br><span class="line">            / norm</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> sloss.data * norm, sloss</span><br></pre></td></tr></table></figure><h3 id="Greedy-Decoding"><a href="#Greedy-Decoding" class="headerlink" title="Greedy Decoding"></a>Greedy Decoding</h3><p>为简单起见，此代码使用Greedy Decoding来预测翻译。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greedy_decode</span><span class="params">(model, src, src_mask, max_len, start_symbol)</span>:</span></span><br><span class="line">    memory = model.encode(src, src_mask)</span><br><span class="line">    ys = torch.zeros(<span class="number">1</span>, <span class="number">1</span>).fill_(start_symbol).type_as(src.data)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(max_len - <span class="number">1</span>):</span><br><span class="line">        out = model.decode(</span><br><span class="line">            memory, src_mask, ys, subsequent_mask(ys.size(<span class="number">1</span>)).type_as(src.data)</span><br><span class="line">        )</span><br><span class="line">        prob = model.generator(out[:, <span class="number">-1</span>])</span><br><span class="line">        _, next_word = torch.max(prob, dim=<span class="number">1</span>)</span><br><span class="line">        next_word = next_word.data[<span class="number">0</span>]</span><br><span class="line">        ys = torch.cat(</span><br><span class="line">            [ys, torch.zeros(<span class="number">1</span>, <span class="number">1</span>).type_as(src.data).fill_(next_word)], dim=<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">return</span> ys</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train the simple copy task.</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">example_simple_model</span><span class="params">()</span>:</span></span><br><span class="line">    V = <span class="number">11</span></span><br><span class="line">    criterion = LabelSmoothing(size=V, padding_idx=<span class="number">0</span>, smoothing=<span class="number">0.0</span>)</span><br><span class="line">    model = make_model(V, V, N=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    optimizer = torch.optim.Adam(</span><br><span class="line">        model.parameters(), lr=<span class="number">0.5</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>), eps=<span class="number">1e-9</span></span><br><span class="line">    )</span><br><span class="line">    lr_scheduler = LambdaLR(</span><br><span class="line">        optimizer=optimizer,</span><br><span class="line">        lr_lambda=<span class="keyword">lambda</span> step: rate(</span><br><span class="line">            step, model_size=model.src_embed[<span class="number">0</span>].d_model, factor=<span class="number">1.0</span>, warmup=<span class="number">400</span></span><br><span class="line">        ),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    batch_size = <span class="number">80</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">        model.train()</span><br><span class="line">        run_epoch(</span><br><span class="line">            data_gen(V, batch_size, <span class="number">20</span>),</span><br><span class="line">            model,</span><br><span class="line">            SimpleLossCompute(model.generator, criterion),</span><br><span class="line">            optimizer,</span><br><span class="line">            lr_scheduler,</span><br><span class="line">            mode=<span class="string">"train"</span>,</span><br><span class="line">        )</span><br><span class="line">        model.eval()</span><br><span class="line">        run_epoch(</span><br><span class="line">            data_gen(V, batch_size, <span class="number">5</span>),</span><br><span class="line">            model,</span><br><span class="line">            SimpleLossCompute(model.generator, criterion),</span><br><span class="line">            DummyOptimizer(),</span><br><span class="line">            DummyScheduler(),</span><br><span class="line">            mode=<span class="string">"eval"</span>,</span><br><span class="line">        )[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    model.eval()</span><br><span class="line">    src = torch.LongTensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line">    max_len = src.shape[<span class="number">1</span>]</span><br><span class="line">    src_mask = torch.ones(<span class="number">1</span>, <span class="number">1</span>, max_len)</span><br><span class="line">    print(greedy_decode(model, src, src_mask, max_len=max_len, start_symbol=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">execute_example(example_simple_model)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">3.023465</span> Tokens per Sec: <span class="number">403.074173</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.920030</span> Tokens per Sec: <span class="number">641.689380</span></span><br><span class="line"><span class="number">1.9274832487106324</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.940011</span> Tokens per Sec: <span class="number">432.003378</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.699767</span> Tokens per Sec: <span class="number">641.979665</span></span><br><span class="line"><span class="number">1.657595729827881</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.860276</span> Tokens per Sec: <span class="number">433.320240</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.546011</span> Tokens per Sec: <span class="number">640.537198</span></span><br><span class="line"><span class="number">1.4888023376464843</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.682198</span> Tokens per Sec: <span class="number">432.092305</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.313169</span> Tokens per Sec: <span class="number">639.441857</span></span><br><span class="line"><span class="number">1.3485562801361084</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.278768</span> Tokens per Sec: <span class="number">433.568756</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.062384</span> Tokens per Sec: <span class="number">642.542067</span></span><br><span class="line"><span class="number">0.9853351473808288</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.269471</span> Tokens per Sec: <span class="number">433.388727</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.590709</span> Tokens per Sec: <span class="number">642.862135</span></span><br><span class="line"><span class="number">0.5686767101287842</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.997076</span> Tokens per Sec: <span class="number">433.009746</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.343118</span> Tokens per Sec: <span class="number">642.288427</span></span><br><span class="line"><span class="number">0.34273059368133546</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.459483</span> Tokens per Sec: <span class="number">434.594030</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.290385</span> Tokens per Sec: <span class="number">642.519464</span></span><br><span class="line"><span class="number">0.2612409472465515</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.031042</span> Tokens per Sec: <span class="number">434.557008</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.437069</span> Tokens per Sec: <span class="number">643.630322</span></span><br><span class="line"><span class="number">0.4323212027549744</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.617165</span> Tokens per Sec: <span class="number">436.652626</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.258793</span> Tokens per Sec: <span class="number">644.372296</span></span><br><span class="line"><span class="number">0.27331129014492034</span></span><br><span class="line"></span><br><span class="line">    <span class="number">1</span>     <span class="number">2</span>     <span class="number">3</span>     <span class="number">4</span>     <span class="number">5</span>     <span class="number">6</span>     <span class="number">7</span>     <span class="number">8</span>     <span class="number">9</span>    <span class="number">10</span></span><br><span class="line">[torch.LongTensor of size <span class="number">1</span>x10]</span><br></pre></td></tr></table></figure><h2 id="A-Real-World-Example"><a href="#A-Real-World-Example" class="headerlink" title="A Real World Example"></a>A Real World Example</h2><p>现在，我们考虑一个使用IWSLT德语-英语翻译任务的真实世界示例。这项任务比本文考虑的WMT任务小得多，但它能说明整个流程。我们还展示了如何使用多GPU处理来实现真正的速度。</p><h3 id="Data-Loading"><a href="#Data-Loading" class="headerlink" title="Data Loading"></a>Data Loading</h3><p>We will load the dataset using torchtext and spacy for tokenization.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load spacy tokenizer models, download them if they haven't been</span></span><br><span class="line"><span class="comment"># downloaded already</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_tokenizers</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        spacy_de = spacy.load(<span class="string">"de_core_news_sm"</span>)</span><br><span class="line">    <span class="keyword">except</span> IOError:</span><br><span class="line">        os.system(<span class="string">"python -m spacy download de_core_news_sm"</span>)</span><br><span class="line">        spacy_de = spacy.load(<span class="string">"de_core_news_sm"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        spacy_en = spacy.load(<span class="string">"en_core_web_sm"</span>)</span><br><span class="line">    <span class="keyword">except</span> IOError:</span><br><span class="line">        os.system(<span class="string">"python -m spacy download en_core_web_sm"</span>)</span><br><span class="line">        spacy_en = spacy.load(<span class="string">"en_core_web_sm"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> spacy_de, spacy_en</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize</span><span class="params">(text, tokenizer)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> tokenizer.tokenizer(text)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">yield_tokens</span><span class="params">(data_iter, tokenizer, index)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> from_to_tuple <span class="keyword">in</span> data_iter:</span><br><span class="line">        <span class="keyword">yield</span> tokenizer(from_to_tuple[index])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_vocabulary</span><span class="params">(spacy_de, spacy_en)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize_de</span><span class="params">(text)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tokenize(text, spacy_de)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize_en</span><span class="params">(text)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tokenize(text, spacy_en)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Building German Vocabulary ..."</span>)</span><br><span class="line">    train, val, test = datasets.IWSLT2016(language_pair=(<span class="string">"de"</span>, <span class="string">"en"</span>))</span><br><span class="line">    vocab_src = build_vocab_from_iterator(</span><br><span class="line">        yield_tokens(train + val + test, tokenize_de, index=<span class="number">0</span>),</span><br><span class="line">        min_freq=<span class="number">2</span>,</span><br><span class="line">        specials=[<span class="string">"&lt;s&gt;"</span>, <span class="string">"&lt;/s&gt;"</span>, <span class="string">"&lt;blank&gt;"</span>, <span class="string">"&lt;unk&gt;"</span>],</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Building English Vocabulary ..."</span>)</span><br><span class="line">    train, val, test = datasets.IWSLT2016(language_pair=(<span class="string">"de"</span>, <span class="string">"en"</span>))</span><br><span class="line">    vocab_tgt = build_vocab_from_iterator(</span><br><span class="line">        yield_tokens(train + val + test, tokenize_en, index=<span class="number">1</span>),</span><br><span class="line">        min_freq=<span class="number">2</span>,</span><br><span class="line">        specials=[<span class="string">"&lt;s&gt;"</span>, <span class="string">"&lt;/s&gt;"</span>, <span class="string">"&lt;blank&gt;"</span>, <span class="string">"&lt;unk&gt;"</span>],</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    vocab_src.set_default_index(vocab_src[<span class="string">"&lt;unk&gt;"</span>])</span><br><span class="line">    vocab_tgt.set_default_index(vocab_tgt[<span class="string">"&lt;unk&gt;"</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> vocab_src, vocab_tgt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_vocab</span><span class="params">(spacy_de, spacy_en)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> exists(<span class="string">"vocab.pt"</span>):</span><br><span class="line">        vocab_src, vocab_tgt = build_vocabulary(spacy_de, spacy_en)</span><br><span class="line">        torch.save((vocab_src, vocab_tgt), <span class="string">"vocab.pt"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        vocab_src, vocab_tgt = torch.load(<span class="string">"vocab.pt"</span>)</span><br><span class="line">    print(<span class="string">"Finished.\nVocabulary sizes:"</span>)</span><br><span class="line">    print(len(vocab_src))</span><br><span class="line">    print(len(vocab_tgt))</span><br><span class="line">    <span class="keyword">return</span> vocab_src, vocab_tgt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> is_interactive_notebook():</span><br><span class="line">    <span class="comment"># global variables used later in the script</span></span><br><span class="line">    spacy_de, spacy_en = show_example(load_tokenizers)</span><br><span class="line">    vocab_src, vocab_tgt = show_example(load_vocab, args=[spacy_de, spacy_en])</span><br></pre></td></tr></table></figure><h3 id="Iterators"><a href="#Iterators" class="headerlink" title="Iterators"></a>Iterators</h3><p>Batching对训练速度很重要。我们希望非常均匀的划分批次（with absolutely minimal padding）。要做到这一点，我们必须修改一下默认的torchtext batching。这段代码修改了它们的默认批处理，以确保我们搜索足够多的句子来找到紧凑的批处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collate_batch</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    batch,</span></span></span><br><span class="line"><span class="function"><span class="params">    src_pipeline,</span></span></span><br><span class="line"><span class="function"><span class="params">    tgt_pipeline,</span></span></span><br><span class="line"><span class="function"><span class="params">    src_vocab,</span></span></span><br><span class="line"><span class="function"><span class="params">    tgt_vocab,</span></span></span><br><span class="line"><span class="function"><span class="params">    device,</span></span></span><br><span class="line"><span class="function"><span class="params">    max_padding=<span class="number">128</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    pad_id=<span class="number">2</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">)</span>:</span></span><br><span class="line">    bs_id = torch.tensor([<span class="number">0</span>], device=device)  <span class="comment"># &lt;s&gt; token id</span></span><br><span class="line">    eos_id = torch.tensor([<span class="number">1</span>], device=device)  <span class="comment"># &lt;/s&gt; token id</span></span><br><span class="line">    src_list, tgt_list = [], []</span><br><span class="line">    <span class="keyword">for</span> (_src, _tgt) <span class="keyword">in</span> batch:</span><br><span class="line">        processed_src = torch.cat(</span><br><span class="line">            [</span><br><span class="line">                bs_id,</span><br><span class="line">                torch.tensor(</span><br><span class="line">                    src_vocab(src_pipeline(_src)),</span><br><span class="line">                    dtype=torch.int64,</span><br><span class="line">                    device=device,</span><br><span class="line">                ),</span><br><span class="line">                eos_id,</span><br><span class="line">            ],</span><br><span class="line">            <span class="number">0</span>,</span><br><span class="line">        )</span><br><span class="line">        processed_tgt = torch.cat(</span><br><span class="line">            [</span><br><span class="line">                bs_id,</span><br><span class="line">                torch.tensor(</span><br><span class="line">                    tgt_vocab(tgt_pipeline(_tgt)),</span><br><span class="line">                    dtype=torch.int64,</span><br><span class="line">                    device=device,</span><br><span class="line">                ),</span><br><span class="line">                eos_id,</span><br><span class="line">            ],</span><br><span class="line">            <span class="number">0</span>,</span><br><span class="line">        )</span><br><span class="line">        src_list.append(</span><br><span class="line">            <span class="comment"># warning - overwrites values for negative values of padding - len</span></span><br><span class="line">            pad(</span><br><span class="line">                processed_src,</span><br><span class="line">                (</span><br><span class="line">                    <span class="number">0</span>,</span><br><span class="line">                    max_padding - len(processed_src),</span><br><span class="line">                ),</span><br><span class="line">                value=pad_id,</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        tgt_list.append(</span><br><span class="line">            pad(</span><br><span class="line">                processed_tgt,</span><br><span class="line">                (<span class="number">0</span>, max_padding - len(processed_tgt)),</span><br><span class="line">                value=pad_id,</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    src = torch.stack(src_list)</span><br><span class="line">    tgt = torch.stack(tgt_list)</span><br><span class="line">    <span class="keyword">return</span> (src, tgt)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataloaders</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    device,</span></span></span><br><span class="line"><span class="function"><span class="params">    vocab_src,</span></span></span><br><span class="line"><span class="function"><span class="params">    vocab_tgt,</span></span></span><br><span class="line"><span class="function"><span class="params">    spacy_de,</span></span></span><br><span class="line"><span class="function"><span class="params">    spacy_en,</span></span></span><br><span class="line"><span class="function"><span class="params">    batch_size=<span class="number">12000</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    max_padding=<span class="number">128</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    is_distributed=True,</span></span></span><br><span class="line"><span class="function"><span class="params">)</span>:</span></span><br><span class="line">    <span class="comment"># def create_dataloaders(batch_size=12000):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize_de</span><span class="params">(text)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tokenize(text, spacy_de)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize_en</span><span class="params">(text)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tokenize(text, spacy_en)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">collate_fn</span><span class="params">(batch)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> collate_batch(</span><br><span class="line">            batch,</span><br><span class="line">            tokenize_de,</span><br><span class="line">            tokenize_en,</span><br><span class="line">            vocab_src,</span><br><span class="line">            vocab_tgt,</span><br><span class="line">            device,</span><br><span class="line">            max_padding=max_padding,</span><br><span class="line">            pad_id=vocab_src.get_stoi()[<span class="string">"&lt;blank&gt;"</span>],</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    train_iter, valid_iter, test_iter = datasets.IWSLT2016(</span><br><span class="line">        language_pair=(<span class="string">"de"</span>, <span class="string">"en"</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    train_iter_map = to_map_style_dataset(</span><br><span class="line">        train_iter</span><br><span class="line">    )  <span class="comment"># DistributedSampler needs a dataset len()</span></span><br><span class="line">    train_sampler = (</span><br><span class="line">        DistributedSampler(train_iter_map) <span class="keyword">if</span> is_distributed <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    )</span><br><span class="line">    valid_iter_map = to_map_style_dataset(valid_iter)</span><br><span class="line">    valid_sampler = (</span><br><span class="line">        DistributedSampler(valid_iter_map) <span class="keyword">if</span> is_distributed <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    train_dataloader = DataLoader(</span><br><span class="line">        train_iter_map,</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        shuffle=(train_sampler <span class="keyword">is</span> <span class="literal">None</span>),</span><br><span class="line">        sampler=train_sampler,</span><br><span class="line">        collate_fn=collate_fn,</span><br><span class="line">    )</span><br><span class="line">    valid_dataloader = DataLoader(</span><br><span class="line">        valid_iter_map,</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        shuffle=(valid_sampler <span class="keyword">is</span> <span class="literal">None</span>),</span><br><span class="line">        sampler=valid_sampler,</span><br><span class="line">        collate_fn=collate_fn,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> train_dataloader, valid_dataloader</span><br></pre></td></tr></table></figure><h2 id="Training-the-System"><a href="#Training-the-System" class="headerlink" title="Training the System"></a>Training the System</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_worker</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    gpu, ngpus_per_node, vocab_src, vocab_tgt, spacy_de, spacy_en, config</span></span></span><br><span class="line"><span class="function"><span class="params">)</span>:</span></span><br><span class="line">    print(<span class="string">f"Train worker process using GPU: <span class="subst">&#123;gpu&#125;</span> for training"</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    torch.cuda.set_device(gpu)</span><br><span class="line">    is_main_process = gpu == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    pad_idx = vocab_tgt[<span class="string">"&lt;blank&gt;"</span>]</span><br><span class="line">    d_model = <span class="number">512</span></span><br><span class="line">    model = make_model(len(vocab_src), len(vocab_tgt), N=<span class="number">6</span>)</span><br><span class="line">    model.cuda(gpu)</span><br><span class="line">    module = model</span><br><span class="line"></span><br><span class="line">    dist.init_process_group(</span><br><span class="line">        <span class="string">"nccl"</span>, init_method=<span class="string">"env://"</span>, rank=gpu, world_size=ngpus_per_node</span><br><span class="line">    )</span><br><span class="line">    model = DDP(model, device_ids=[gpu])</span><br><span class="line">    module = model.module</span><br><span class="line"></span><br><span class="line">    criterion = LabelSmoothing(</span><br><span class="line">        size=len(vocab_tgt), padding_idx=pad_idx, smoothing=<span class="number">0.1</span></span><br><span class="line">    )</span><br><span class="line">    criterion.cuda(gpu)</span><br><span class="line"></span><br><span class="line">    train_dataloader, valid_dataloader = create_dataloaders(</span><br><span class="line">        gpu,</span><br><span class="line">        vocab_src,</span><br><span class="line">        vocab_tgt,</span><br><span class="line">        spacy_de,</span><br><span class="line">        spacy_en,</span><br><span class="line">        batch_size=config[<span class="string">"batch_size"</span>] // ngpus_per_node,</span><br><span class="line">        max_padding=config[<span class="string">"max_padding"</span>],</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    optimizer = torch.optim.Adam(</span><br><span class="line">        model.parameters(), lr=config[<span class="string">"base_lr"</span>], betas=(<span class="number">0.9</span>, <span class="number">0.98</span>), eps=<span class="number">1e-9</span></span><br><span class="line">    )</span><br><span class="line">    lr_scheduler = LambdaLR(</span><br><span class="line">        optimizer=optimizer,</span><br><span class="line">        lr_lambda=<span class="keyword">lambda</span> step: rate(</span><br><span class="line">            step, d_model, factor=<span class="number">1</span>, warmup=config[<span class="string">"warmup"</span>]</span><br><span class="line">        ),</span><br><span class="line">    )</span><br><span class="line">    train_state = TrainState()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(config[<span class="string">"num_epochs"</span>]):</span><br><span class="line"></span><br><span class="line">        train_dataloader.sampler.set_epoch(epoch)</span><br><span class="line">        valid_dataloader.sampler.set_epoch(epoch)</span><br><span class="line"></span><br><span class="line">        model.train()</span><br><span class="line">        print(<span class="string">f"[GPU<span class="subst">&#123;gpu&#125;</span>] Epoch <span class="subst">&#123;epoch&#125;</span> Training ===="</span>, flush=<span class="literal">True</span>)</span><br><span class="line">        _, train_state = run_epoch(</span><br><span class="line">            (Batch(b[<span class="number">0</span>], b[<span class="number">1</span>], pad_idx) <span class="keyword">for</span> b <span class="keyword">in</span> train_dataloader),</span><br><span class="line">            model,</span><br><span class="line">            SimpleLossCompute(module.generator, criterion),</span><br><span class="line">            optimizer,</span><br><span class="line">            lr_scheduler,</span><br><span class="line">            mode=<span class="string">"train+log"</span>,</span><br><span class="line">            accum_iter=config[<span class="string">"accum_iter"</span>],</span><br><span class="line">            train_state=train_state,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        GPUtil.showUtilization()</span><br><span class="line">        <span class="keyword">if</span> is_main_process:</span><br><span class="line">            file_path = <span class="string">"%s%.2d.pt"</span> % (config[<span class="string">"file_prefix"</span>], epoch)</span><br><span class="line">            torch.save(module.state_dict(), file_path)</span><br><span class="line">        torch.cuda.empty_cache()</span><br><span class="line"></span><br><span class="line">        print(<span class="string">f"[GPU<span class="subst">&#123;gpu&#125;</span>] Epoch <span class="subst">&#123;epoch&#125;</span> Validation ===="</span>, flush=<span class="literal">True</span>)</span><br><span class="line">        model.eval()</span><br><span class="line">        sloss = run_epoch(</span><br><span class="line">            (Batch(b[<span class="number">0</span>], b[<span class="number">1</span>], pad_idx) <span class="keyword">for</span> b <span class="keyword">in</span> valid_dataloader),</span><br><span class="line">            model,</span><br><span class="line">            SimpleLossCompute(module.generator, criterion),</span><br><span class="line">            DummyOptimizer(),</span><br><span class="line">            DummyScheduler(),</span><br><span class="line">            mode=<span class="string">"eval"</span>,</span><br><span class="line">        )</span><br><span class="line">        print(sloss)</span><br><span class="line">        torch.cuda.empty_cache()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> is_main_process:</span><br><span class="line">        file_path = <span class="string">"%sfinal.pt"</span> % config[<span class="string">"file_prefix"</span>]</span><br><span class="line">        torch.save(module.state_dict(), file_path)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(vocab_src, vocab_tgt, spacy_de, spacy_en, config)</span>:</span></span><br><span class="line">    <span class="keyword">from</span> the_annotated_transformer <span class="keyword">import</span> train_worker</span><br><span class="line"></span><br><span class="line">    ngpus = torch.cuda.device_count()</span><br><span class="line">    os.environ[<span class="string">"MASTER_ADDR"</span>] = <span class="string">"localhost"</span></span><br><span class="line">    os.environ[<span class="string">"MASTER_PORT"</span>] = <span class="string">"12356"</span></span><br><span class="line">    print(<span class="string">f"Number of GPUs detected: <span class="subst">&#123;ngpus&#125;</span>"</span>)</span><br><span class="line">    print(<span class="string">"Spawning training processes ..."</span>)</span><br><span class="line">    mp.spawn(</span><br><span class="line">        train_worker,</span><br><span class="line">        nprocs=ngpus,</span><br><span class="line">        args=(</span><br><span class="line">            ngpus,</span><br><span class="line">            vocab_src,</span><br><span class="line">            vocab_tgt,</span><br><span class="line">            spacy_de,</span><br><span class="line">            spacy_en,</span><br><span class="line">            config,</span><br><span class="line">        ),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_trained_model</span><span class="params">(create_model)</span>:</span></span><br><span class="line">    config = &#123;</span><br><span class="line">        <span class="string">"batch_size"</span>: <span class="number">150</span>,</span><br><span class="line">        <span class="string">"num_epochs"</span>: <span class="number">8</span>,</span><br><span class="line">        <span class="string">"accum_iter"</span>: <span class="number">10</span>,</span><br><span class="line">        <span class="string">"base_lr"</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">"max_padding"</span>: <span class="number">72</span>,</span><br><span class="line">        <span class="string">"warmup"</span>: <span class="number">3000</span>,</span><br><span class="line">        <span class="string">"file_prefix"</span>: <span class="string">"iwslt_model_"</span>,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> create_model:</span><br><span class="line">        train_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config)</span><br><span class="line"></span><br><span class="line">    model = make_model(len(vocab_src), len(vocab_tgt), N=<span class="number">6</span>)</span><br><span class="line">    model.load_state_dict(torch.load(<span class="string">"iwslt_model_final.pt"</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> is_interactive_notebook():</span><br><span class="line">    model = load_trained_model(create_model=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>一旦经过训练，我们就可以对模型进行decode，以产生一组翻译。在这里，我们只需翻译验证集中的第一句话。这个数据集非常小，因此使用greedy search的翻译相当准确。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Translation:&lt;unk&gt; &lt;unk&gt; . In my language , that means , thank you very much . </span><br><span class="line">Gold:&lt;unk&gt; &lt;unk&gt; . It means in my language , thank you very much .</span><br></pre></td></tr></table></figure><h2 id="Additional-Components-BPE-Search-Averaging"><a href="#Additional-Components-BPE-Search-Averaging" class="headerlink" title="Additional Components: BPE, Search, Averaging"></a>Additional Components: BPE, Search, Averaging</h2><p>上述代码主要介绍了Transformer自身的实现，还有四个函数我们没有实现。</p><h3 id="BPE-Word-piece"><a href="#BPE-Word-piece" class="headerlink" title="BPE/ Word-piece"></a>BPE/ Word-piece</h3><p>我们使用了subword units库对数据进行预处理。它将把训练数据转换成如下所示的形式：▁Die ▁Protokoll datei ▁kann ▁ heimlich ▁per ▁E - Mail ▁oder ▁FTP ▁an ▁einen ▁bestimmte n ▁Empfänger ▁gesendet ▁werden .</p><h3 id="Shared-Embeddings"><a href="#Shared-Embeddings" class="headerlink" title="Shared Embeddings"></a>Shared Embeddings</h3><p>当使用共享vocabulary的BPE时，我们可以在source / target / generator之间共享权重向量。详细信息可以阅读<a href="https://arxiv.org/abs/1608.05859" target="_blank" rel="noopener">cite</a>。要将此想法实现到模型中，只需执行以下操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="literal">False</span>:</span><br><span class="line">    model.src_embed[<span class="number">0</span>].lut.weight = model.tgt_embeddings[<span class="number">0</span>].lut.weight</span><br><span class="line">    model.generator.lut.weight = model.tgt_embed[<span class="number">0</span>].lut.weight</span><br></pre></td></tr></table></figure><h3 id="Beam-Search"><a href="#Beam-Search" class="headerlink" title="Beam Search"></a>Beam Search</h3><p>详情可以看<a href="https://github.com/OpenNMT/OpenNMT-py/blob/onmt/translate/Beam.py" target="_blank" rel="noopener">OpenNMT-py</a>。</p><h3 id="Model-Averaging"><a href="#Model-Averaging" class="headerlink" title="Model Averaging"></a>Model Averaging</h3><p>文章中平均了最后k个checkpoints来达到集成效果。如果我们有一堆checkpoint，我们可以在事后做这件事：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">average</span><span class="params">(model, models)</span>:</span></span><br><span class="line">    <span class="string">"Average models into model"</span></span><br><span class="line">    <span class="keyword">for</span> ps <span class="keyword">in</span> zip(*[m.params() <span class="keyword">for</span> m <span class="keyword">in</span> [model] + models]):</span><br><span class="line">        ps[<span class="number">0</span>].copy_(torch.sum(*ps[<span class="number">1</span>:]) / len(ps[<span class="number">1</span>:]))</span><br></pre></td></tr></table></figure><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>在WMT 2014英德翻译任务中，big transformer模型(表2中的Transformer (big) )的表现超过了已有的最好的模型(包括集成)，BLEU的表现高上了2.0%，创造了最好的BLEU 28.4分的新纪录。表3的底部列出了该模型参数配置。在8个P100 GPU上进行了3.5天的训练。甚至我们的base model模型也超过了已有的所有模型和集成模型，而训练成本只是任何已有模型的一小部分。</p><p>在2014年WMT英法翻译任务中，我们的大模型达到了BLEU的41.0分，超过了之前已有的所有单一模型，培训成本不到以前最好模型的四分之一。用于英法翻译的Transformer (big) 的dropout 系数等于0.1，而不是0.3。</p><blockquote><p>我们在这里编写的代码是base model的一个版本。完整版本可以看 <a href="http://opennmt.net/Models-py/" target="_blank" rel="noopener">(Example Models)</a>。</p><p>使用上以小节的附加扩展，OpenNMT-py 在EN-DE WMT数据集上达到了26.9的BLEU。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load data and model for output checks</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_outputs</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    valid_dataloader,</span></span></span><br><span class="line"><span class="function"><span class="params">    model,</span></span></span><br><span class="line"><span class="function"><span class="params">    vocab_src,</span></span></span><br><span class="line"><span class="function"><span class="params">    vocab_tgt,</span></span></span><br><span class="line"><span class="function"><span class="params">    n_examples=<span class="number">15</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    pad_idx=<span class="number">2</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    eos_string=<span class="string">"&lt;/s&gt;"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">)</span>:</span></span><br><span class="line">    results = [()] * n_examples</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> range(n_examples):</span><br><span class="line">        print(<span class="string">"\nExample %d ========\n"</span> % idx)</span><br><span class="line">        b = next(iter(valid_dataloader))</span><br><span class="line">        rb = Batch(b[<span class="number">0</span>], b[<span class="number">1</span>], pad_idx)</span><br><span class="line">        greedy_decode(model, rb.src, rb.src_mask, <span class="number">64</span>, <span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        src_tokens = [</span><br><span class="line">            vocab_src.get_itos()[x] <span class="keyword">for</span> x <span class="keyword">in</span> rb.src[<span class="number">0</span>] <span class="keyword">if</span> x != pad_idx</span><br><span class="line">        ]</span><br><span class="line">        tgt_tokens = [</span><br><span class="line">            vocab_tgt.get_itos()[x] <span class="keyword">for</span> x <span class="keyword">in</span> rb.tgt[<span class="number">0</span>] <span class="keyword">if</span> x != pad_idx</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        print(</span><br><span class="line">            <span class="string">"Source Text (Input)        : "</span></span><br><span class="line">            + <span class="string">" "</span>.join(src_tokens).replace(<span class="string">"\n"</span>, <span class="string">""</span>)</span><br><span class="line">        )</span><br><span class="line">        print(</span><br><span class="line">            <span class="string">"Target Text (Ground Truth) : "</span></span><br><span class="line">            + <span class="string">" "</span>.join(tgt_tokens).replace(<span class="string">"\n"</span>, <span class="string">""</span>)</span><br><span class="line">        )</span><br><span class="line">        model_out = greedy_decode(model, rb.src, rb.src_mask, <span class="number">72</span>, <span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">        model_txt = (</span><br><span class="line">            <span class="string">" "</span>.join(</span><br><span class="line">                [vocab_tgt.get_itos()[x] <span class="keyword">for</span> x <span class="keyword">in</span> model_out <span class="keyword">if</span> x != pad_idx]</span><br><span class="line">            ).split(eos_string, <span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">            + eos_string</span><br><span class="line">        )</span><br><span class="line">        print(<span class="string">"Model Output               : "</span> + model_txt.replace(<span class="string">"\n"</span>, <span class="string">""</span>))</span><br><span class="line">        results[idx] = (rb, src_tokens, tgt_tokens, model_out, model_txt)</span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_model_example</span><span class="params">(n_examples=<span class="number">5</span>)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> vocab_src, vocab_tgt, spacy_de, spacy_en</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Preparing Data ..."</span>)</span><br><span class="line">    _, valid_dataloader = create_dataloaders(</span><br><span class="line">        torch.device(<span class="string">"cpu"</span>),</span><br><span class="line">        vocab_src,</span><br><span class="line">        vocab_tgt,</span><br><span class="line">        spacy_de,</span><br><span class="line">        spacy_en,</span><br><span class="line">        batch_size=<span class="number">1</span>,</span><br><span class="line">        is_distributed=<span class="literal">False</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Loading Trained Model ..."</span>)</span><br><span class="line"></span><br><span class="line">    model = make_model(len(vocab_src), len(vocab_tgt), N=<span class="number">6</span>)</span><br><span class="line">    model.load_state_dict(</span><br><span class="line">        torch.load(<span class="string">"iwslt_model_final.pt"</span>, map_location=torch.device(<span class="string">"cpu"</span>))</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Checking Model Outputs:"</span>)</span><br><span class="line">    example_data = check_outputs(</span><br><span class="line">        valid_dataloader, model, vocab_src, vocab_tgt, n_examples=n_examples</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> model, example_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">execute_example(run_model_example)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Translation:&lt;s&gt; ▁Die ▁Protokoll datei ▁kann ▁ heimlich ▁per ▁E - Mail ▁oder ▁FTP ▁an ▁einen ▁bestimmte n ▁Empfänger ▁gesendet ▁werden .</span><br></pre></td></tr></table></figure><h3 id="Attention-Visualization"><a href="#Attention-Visualization" class="headerlink" title="Attention Visualization"></a>Attention Visualization</h3><p>即使使用greedy decoder，翻译看起来也很好。我们可以进一步把它形象化，看看注意力的每一层都在发生什么。</p><h3 id="Encoder-Self-Attention"><a href="#Encoder-Self-Attention" class="headerlink" title="Encoder Self Attention"></a>Encoder Self Attention</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mtx2df</span><span class="params">(m, max_row, max_col, row_tokens, col_tokens)</span>:</span></span><br><span class="line">    <span class="string">"convert a dense matrix to a data frame with row and column indices"</span></span><br><span class="line">    <span class="keyword">return</span> pd.DataFrame(</span><br><span class="line">        [</span><br><span class="line">            (</span><br><span class="line">                r,</span><br><span class="line">                c,</span><br><span class="line">                float(m[r, c]),</span><br><span class="line">                <span class="string">"%.3d %s"</span></span><br><span class="line">                % (r, row_tokens[r] <span class="keyword">if</span> len(row_tokens) &gt; r <span class="keyword">else</span> <span class="string">"&lt;blank&gt;"</span>),</span><br><span class="line">                <span class="string">"%.3d %s"</span></span><br><span class="line">                % (c, col_tokens[c] <span class="keyword">if</span> len(col_tokens) &gt; c <span class="keyword">else</span> <span class="string">"&lt;blank&gt;"</span>),</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">for</span> r <span class="keyword">in</span> range(m.shape[<span class="number">0</span>])</span><br><span class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> range(m.shape[<span class="number">1</span>])</span><br><span class="line">            <span class="keyword">if</span> r &lt; max_row <span class="keyword">and</span> c &lt; max_col</span><br><span class="line">        ],</span><br><span class="line">        <span class="comment"># if float(m[r,c]) != 0 and r &lt; max_row and c &lt; max_col],</span></span><br><span class="line">        columns=[<span class="string">"row"</span>, <span class="string">"column"</span>, <span class="string">"value"</span>, <span class="string">"row_token"</span>, <span class="string">"col_token"</span>],</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attn_map</span><span class="params">(attn, layer, head, row_tokens, col_tokens, max_dim=<span class="number">30</span>)</span>:</span></span><br><span class="line">    df = mtx2df(</span><br><span class="line">        attn[<span class="number">0</span>, head].data,</span><br><span class="line">        max_dim,</span><br><span class="line">        max_dim,</span><br><span class="line">        row_tokens,</span><br><span class="line">        col_tokens,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        alt.Chart(data=df)</span><br><span class="line">        .mark_rect()</span><br><span class="line">        .encode(</span><br><span class="line">            x=alt.X(<span class="string">"col_token"</span>, axis=alt.Axis(title=<span class="string">""</span>)),</span><br><span class="line">            y=alt.Y(<span class="string">"row_token"</span>, axis=alt.Axis(title=<span class="string">""</span>)),</span><br><span class="line">            color=<span class="string">"value"</span>,</span><br><span class="line">            tooltip=[<span class="string">"row"</span>, <span class="string">"column"</span>, <span class="string">"value"</span>, <span class="string">"row_token"</span>, <span class="string">"col_token"</span>],</span><br><span class="line">        )</span><br><span class="line">        .properties(height=<span class="number">200</span>, width=<span class="number">200</span>)</span><br><span class="line">        .interactive()</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_encoder</span><span class="params">(model, layer)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> model.encoder.layers[layer].self_attn.attn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_decoder_self</span><span class="params">(model, layer)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> model.decoder.layers[layer].self_attn.attn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_decoder_src</span><span class="params">(model, layer)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> model.decoder.layers[layer].src_attn.attn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize_layer</span><span class="params">(model, layer, getter_fn, ntokens, row_tokens, col_tokens)</span>:</span></span><br><span class="line">    <span class="comment"># ntokens = last_example[0].ntokens</span></span><br><span class="line">    attn = getter_fn(model, layer)</span><br><span class="line">    n_heads = attn.shape[<span class="number">1</span>]</span><br><span class="line">    charts = [</span><br><span class="line">        attn_map(</span><br><span class="line">            attn,</span><br><span class="line">            <span class="number">0</span>,</span><br><span class="line">            h,</span><br><span class="line">            row_tokens=row_tokens,</span><br><span class="line">            col_tokens=col_tokens,</span><br><span class="line">            max_dim=ntokens,</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> range(n_heads)</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">assert</span> n_heads == <span class="number">8</span></span><br><span class="line">    <span class="keyword">return</span> alt.vconcat(</span><br><span class="line">        charts[<span class="number">0</span>]</span><br><span class="line">        | charts[<span class="number">1</span>]</span><br><span class="line">        | charts[<span class="number">2</span>]</span><br><span class="line">        | charts[<span class="number">3</span>]</span><br><span class="line">        | charts[<span class="number">4</span>]</span><br><span class="line">        | charts[<span class="number">5</span>]</span><br><span class="line">        | charts[<span class="number">6</span>]</span><br><span class="line">        | charts[<span class="number">7</span>]</span><br><span class="line">        <span class="comment"># layer + 1 due to 0-indexing</span></span><br><span class="line">    ).properties(title=<span class="string">"Layer %d"</span> % (layer + <span class="number">1</span>))</span><br></pre></td></tr></table></figure><h3 id="Encoder-Self-Attention-1"><a href="#Encoder-Self-Attention-1" class="headerlink" title="Encoder Self Attention"></a>Encoder Self Attention</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">viz_encoder_self</span><span class="params">()</span>:</span></span><br><span class="line">    model, example_data = run_model_example(n_examples=<span class="number">1</span>)</span><br><span class="line">    example = example_data[</span><br><span class="line">        len(example_data) - <span class="number">1</span></span><br><span class="line">    ]  <span class="comment"># batch object for the final example</span></span><br><span class="line"></span><br><span class="line">    layer_viz = [</span><br><span class="line">        visualize_layer(</span><br><span class="line">            model, layer, get_encoder, len(example[<span class="number">1</span>]), example[<span class="number">1</span>], example[<span class="number">1</span>]</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> range(<span class="number">6</span>)</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">return</span> alt.hconcat(</span><br><span class="line">        layer_viz[<span class="number">0</span>]</span><br><span class="line">        &amp; layer_viz[<span class="number">1</span>]</span><br><span class="line">        &amp; layer_viz[<span class="number">2</span>]</span><br><span class="line">        &amp; layer_viz[<span class="number">3</span>]</span><br><span class="line">        &amp; layer_viz[<span class="number">4</span>]</span><br><span class="line">        &amp; layer_viz[<span class="number">5</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">show_example(viz_encoder_self)</span><br></pre></td></tr></table></figure><h3 id="Decoder-Self-Attention"><a href="#Decoder-Self-Attention" class="headerlink" title="Decoder Self Attention"></a>Decoder Self Attention</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">viz_decoder_self</span><span class="params">()</span>:</span></span><br><span class="line">    model, example_data = run_model_example(n_examples=<span class="number">1</span>)</span><br><span class="line">    example = example_data[len(example_data) - <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    layer_viz = [</span><br><span class="line">        visualize_layer(</span><br><span class="line">            model,</span><br><span class="line">            layer,</span><br><span class="line">            get_decoder_self,</span><br><span class="line">            len(example[<span class="number">1</span>]),</span><br><span class="line">            example[<span class="number">1</span>],</span><br><span class="line">            example[<span class="number">1</span>],</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> range(<span class="number">6</span>)</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">return</span> alt.hconcat(</span><br><span class="line">        layer_viz[<span class="number">0</span>]</span><br><span class="line">        &amp; layer_viz[<span class="number">1</span>]</span><br><span class="line">        &amp; layer_viz[<span class="number">2</span>]</span><br><span class="line">        &amp; layer_viz[<span class="number">3</span>]</span><br><span class="line">        &amp; layer_viz[<span class="number">4</span>]</span><br><span class="line">        &amp; layer_viz[<span class="number">5</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">show_example(viz_decoder_self)</span><br></pre></td></tr></table></figure><h3 id="Decoder-Src-Attention"><a href="#Decoder-Src-Attention" class="headerlink" title="Decoder Src Attention"></a>Decoder Src Attention</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">viz_decoder_src</span><span class="params">()</span>:</span></span><br><span class="line">    model, example_data = run_model_example(n_examples=<span class="number">1</span>)</span><br><span class="line">    example = example_data[len(example_data) - <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    layer_viz = [</span><br><span class="line">        visualize_layer(</span><br><span class="line">            model,</span><br><span class="line">            layer,</span><br><span class="line">            get_decoder_src,</span><br><span class="line">            max(len(example[<span class="number">1</span>]), len(example[<span class="number">2</span>])),</span><br><span class="line">            example[<span class="number">1</span>],</span><br><span class="line">            example[<span class="number">2</span>],</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> range(<span class="number">6</span>)</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">return</span> alt.hconcat(</span><br><span class="line">        layer_viz[<span class="number">0</span>]</span><br><span class="line">        &amp; layer_viz[<span class="number">1</span>]</span><br><span class="line">        &amp; layer_viz[<span class="number">2</span>]</span><br><span class="line">        &amp; layer_viz[<span class="number">3</span>]</span><br><span class="line">        &amp; layer_viz[<span class="number">4</span>]</span><br><span class="line">        &amp; layer_viz[<span class="number">5</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">show_example(viz_decoder_src)</span><br></pre></td></tr></table></figure><h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><h3 id="Transformer-mask"><a href="#Transformer-mask" class="headerlink" title="Transformer mask"></a>Transformer mask</h3><p>在《<a href="https://github.com/harvardnlp/annotated-transformer" target="_blank" rel="noopener">the annotated transformer</a>》中有多个mask，这里总结一下。</p><p>整个模型中使用到的mask主要就是source mask和target mask，其各自的作用如下所示：</p><ol><li>source mask：</li></ol><ul><li><p>source长短不一而无法形成batch，因此引入了pad。将source mask传入到encoder中，让attention在计算$\mathrm{softmax}(\frac{QK^T}{\sqrt{d_k}})$时，pad位置的值不起作用。</p></li><li><p>同时这个mask还需要传入每个decoderLayer第二个multi-head attention模块中，就是防止来自encoder的key和来自decoder的query在计算多头注意力的时候算了target中的词和source中pad的权重</p></li></ul><ol><li>target mask：需要分training和testing进行讨论</li></ol><ul><li><strong>训练</strong>时，用于防止target的ground truth长短不一引入pad造成的误差，以及<strong>避免在自回归时看到正在预测的字和以后字的ground truth</strong></li><li><strong>测试</strong>时，逻辑上decoder不需要target mask，但出于编程方便的考虑引入mask，假装用于防止看到后面的ground truth，target mask的最后两维的shape和目前生成出来的序列长度相同，但实际上每次都会有一些重复运算在里面，比如目前在预测第10个词时，第1-9个词还需要重新算一遍。核心原因是：模型在写的时候主要考虑的是训练，执行一次attention函数翻译完一个batch的所有句子，而测试时必须是单个或多个句子word by word进行计算</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/harvardnlp/annotated-transformer" target="_blank" rel="noopener">annotated-transformer</a><br><a href="https://zhuanlan.zhihu.com/p/504408727" target="_blank" rel="noopener">the annotated transformer中的关于mask的问题 - lumino的文章 - 知乎</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前面我们详细的介绍了Transformer的原理，但是有的细节还是一头雾水，所以我们接下来介绍一下Transformer的实现，主要参考了文章&lt;a href=&quot;https://nlp.seas.harvard.edu/2018/04/03/attention.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;The Annotated Transformer&lt;/a&gt;，&lt;a href=&quot;https://github.com/harvardnlp/annotated-transformer&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;github地址&lt;/a&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本文的代码部分来自于github，而图来源于&lt;a href=&quot;https://nlp.seas.harvard.edu/2018/04/03/attention.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;The Annotated Transformer&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Prelims&quot;&gt;&lt;a href=&quot;#Prelims&quot; class=&quot;headerlink&quot; title=&quot;Prelims&quot;&gt;&lt;/a&gt;Prelims&lt;/h2&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; os.path &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; exists&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; torch.nn &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; torch.nn.functional &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; log_softmax, pad&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; math&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; copy&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; time&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; torch.optim.lr_scheduler &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; LambdaLR&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; altair &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; alt&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; torchtext.data.functional &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; to_map_style_dataset&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; torchtext.vocab &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; build_vocab_from_iterator&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; torchtext.datasets &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; datasets&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; spacy&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; GPUtil&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; torch.utils.data.distributed &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; DistributedSampler&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; torch.distributed &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; dist&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; torch.multiprocessing &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; mp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; torch.nn.parallel &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; DistributedDataParallel &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; DDP&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Set to False to skip notebook execution (e.g. for debugging)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;RUN_EXAMPLES = &lt;span class=&quot;literal&quot;&gt;True&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Some convenience helper functions used throughout the notebook&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;is_interactive_notebook&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; __name__ == &lt;span class=&quot;string&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;show_example&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(fn, args=[])&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; __name__ == &lt;span class=&quot;string&quot;&gt;&quot;__main__&quot;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; RUN_EXAMPLES:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; fn(*args)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;execute_example&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(fn, args=[])&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; __name__ == &lt;span class=&quot;string&quot;&gt;&quot;__main__&quot;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; RUN_EXAMPLES:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        fn(*args)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;DummyOptimizer&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(torch.optim.Optimizer)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.param_groups = [&amp;#123;&lt;span class=&quot;string&quot;&gt;&quot;lr&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&amp;#125;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;literal&quot;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;literal&quot;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, set_to_none=False)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;literal&quot;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;DummyScheduler&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;literal&quot;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="DeepLearningApplications" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/"/>
    
      <category term="自然语言处理" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
      <category term="NLP" scheme="https://www.zdaiot.com/tags/NLP/"/>
    
      <category term="Transformer" scheme="https://www.zdaiot.com/tags/Transformer/"/>
    
  </entry>
  
  <entry>
    <title>fairseq翻译任务解读</title>
    <link href="https://www.zdaiot.com/DeepLearningApplications/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/fairseq%E7%BF%BB%E8%AF%91%E4%BB%BB%E5%8A%A1%E8%A7%A3%E8%AF%BB/"/>
    <id>https://www.zdaiot.com/DeepLearningApplications/自然语言处理/fairseq翻译任务解读/</id>
    <published>2022-04-27T02:42:03.000Z</published>
    <updated>2022-04-27T02:42:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近需要用到<a href="https://github.com/pytorch/fairseq" target="_blank" rel="noopener">fairseq</a>框架中的翻译任务，这里记录一下。</p><h2 id="从实战开始"><a href="#从实战开始" class="headerlink" title="从实战开始"></a>从实战开始</h2><p>首先下载翻译模型：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p model</span><br><span class="line"><span class="built_in">cd</span> model</span><br><span class="line">wget https://dl.fbaipublicfiles.com/fairseq/models/wmt16.en-de.joined-dict.transformer.tar.bz2</span><br><span class="line"></span><br><span class="line">bunzip2 wmt16.en-de.joined-dict.transformer.tar.bz2</span><br><span class="line">tar -xvf wmt16.en-de.joined-dict.transformer.tar</span><br></pre></td></tr></table></figure><p>解压后的文件如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">./model</span><br><span class="line">├── wmt16.en-de.joined-dict.transformer</span><br><span class="line">│   ├── bpecodes</span><br><span class="line">│   ├── dict.de.txt</span><br><span class="line">│   ├── dict.en.txt</span><br><span class="line">│   └── model.pt</span><br></pre></td></tr></table></figure><p>然后调用翻译模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fairseq.models.transformer <span class="keyword">import</span> TransformerModel</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_fairseq_tm</span><span class="params">(path, device)</span>:</span></span><br><span class="line">    <span class="comment"># data_name_or_path和bpe_codes可以省略</span></span><br><span class="line">    model = TransformerModel.from_pretrained(</span><br><span class="line">        path,</span><br><span class="line">        checkpoint_file=<span class="string">'model.pt'</span>,</span><br><span class="line">        data_name_or_path=<span class="string">'.'</span>,</span><br><span class="line">        bpe=<span class="string">'subword_nmt'</span>,</span><br><span class="line">        bpe_codes=path+<span class="string">"/bpecode"</span></span><br><span class="line">    )</span><br><span class="line">    model.cuda(device=device)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">bt_model = load_fairseq_tm(<span class="string">'./model/wmt16.en-de.joined-dict.transformer'</span>, <span class="number">0</span>)</span><br><span class="line">output = bt_model.translate(<span class="string">'Hello world!'</span>)</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure><p>得到的结果是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hallo Welt !</span><br></pre></td></tr></table></figure><p>那么，这个过程都干了哪些事呢？我们对此进行了详细的分析。</p><h2 id="BPE"><a href="#BPE" class="headerlink" title="BPE"></a>BPE</h2><p>在分析之前，我们先介绍一下BPE算法。以下内容来源于<a href="http://txshi-mt.com/2019/02/28/NMT-Tutorial-3e2-subword/" target="_blank" rel="noopener">NMT Tutorial 3扩展e第2部分. Subword</a></p><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>按照布隆菲尔德的理论，词被认为是人类语言中能自行独立存在的最小单位，是“最小自由形式”。因此，对西方语言做NLP时，以词为基石是一个很自然的想法。</p><p>但是将某个语言的词穷举出来是不太现实的。首先，名词、动词、形容词、副词这四种属于开放词类，总会有新的词加入进来。其次，网络用语会创造出更多新词，或者为某个词给出不规则的变形。最后，以德语为代表的语言通常会将几个基本词组合起来，形成一个复合词，例如Abwasserbehandlungsanlage “污水处理厂”可以被细分为Abwasser、behandlungs和Anlage三个部分。</p><p>即便是存在某个语言能获得其完整词表，词表的数量也会非常庞大，使得模型复杂度很高，训练起来很难。对于以德语、西班牙语、俄语为代表的<strong>屈折语</strong>，也会存在类似的问题（例如西班牙语动词可能有80种变化）。</p><p>因此，在机器翻译等任务中，从训练语料构造词表时，通常会过滤掉出现频率很低的单词，并将这些单词统一标记为<strong>UNK（Unknown）</strong>。根据Zipf定律，这种做法能筛掉很多不常见词，简化模型结构，而且可以起到部分防止过拟合的作用。此外，模型上线做推断时，也有很大概率会遇到在训练语料里没见过的词，这些词也会被标为UNK。所有不在词表里被标记为UNK的词，通常被称作<strong>集外词</strong>（Out Of Vocabulary，OOV）或者<strong>未登录词</strong>。</p><p>对未登录词的处理是机器翻译领域里一个十分重要的问题。<a href="https://arxiv.org/pdf/1508.07909.pdf" target="_blank" rel="noopener">sennrich2016</a>认为，对于某些未登录词的翻译可能是”透明“的，包括</p><ul><li>命名实体，例如人名、地名等。对于这些词，如果目标语言和源语言的字母体系相同，可能可以直接抄写；如果不同，需要做些转写。例如将英语的Barack Obama转写成俄语的Барак Обама</li><li>借词，可以通过字母级别的翻译做到，例如将claustrophobia翻译成德语的Klaustrophobie和俄语的Клаустрофобия</li><li>词素复杂的词，例如通过组合或者屈折变化得到的词，可以将其进一步拆分为词素，通过分别翻译各个词素的得到结果。例如将英语的solar system翻译成德语的Sonnensystem或者匈牙利语的Naprendszer</li></ul><p>因此，将词拆分为更细粒度的subword，可以有助于处理OOV问题。另外传统tokenization方法不利于模型学习词缀之间的关系。E.g. 模型学到的“old”, “older”, and “oldest”之间的关系无法泛化到“smart”, “smarter”, and “smartest”。</p><p>由此，<a href="https://arxiv.org/pdf/1508.07909.pdf" target="_blank" rel="noopener">sennrich2016</a>文章还同时指出使用一种称为<strong>“比特对编码”（Byte Pair Encoding——BPE）</strong>的算法可以将词拆分为更细粒度的subword。但是BPE对单词的划分是纯基于统计的，得到的subword所蕴含的词素，或者说形态学信息，并不明显。除此BPE之外，Morfessor是一种基于形态学的分词器，它使用的是无监督学习的方法，能达到不错的准确率。最后，2016年FAIR提出的一种基于subword的词嵌入表示方法fastText。但是本文只关注BPE算法，其余可以参考文章<a href="http://txshi-mt.com/2019/02/28/NMT-Tutorial-3e2-subword/" target="_blank" rel="noopener">NMT Tutorial 3扩展e第2部分. Subword</a>。</p><p>除去subword方法以外，还可以将词拆成字符，为每个字符训练一个字符向量。这种方法很直观，也很有效，不过无需太费笔墨来描述。关于字符向量的优秀工作，可以参考<a href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00051/43387/Enriching-Word-Vectors-with-Subword-Information" target="_blank" rel="noopener">Bojanowski2017</a>的“相关工作”部分。</p><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>BPE算法[gage1994]的本质实际上是一种数据压缩算法。<strong>数据压缩的一般做法都是将常见比特串替换为更短的表示方法</strong>，而BPE也不例外。更具体地说，BPE是找出最常出现的相邻字节对，将其替换成一个在原始数据里没有出现的字节，一直循环下去，直到找不到最常出现的字节对或者所有字节都用光了为止。后期使用时需要一个替换表来重建原始数据。例如，对”lwlwlwlwrr”使用BPE算法，会先把lw替换为a，得到”aaaarr”，然后把”aa”替换为”b”，得到”bbrr”。此时所有相邻字节对”bb”、”br”、”rr”的出现次数相等，迭代结束，输出替换表{“b” -&gt; “aa”, “a” -&gt; “lw”}。</p><ul><li>优点：可以有效地平衡词汇表大小和步数(编码句子所需的token数量)。</li><li>缺点：基于贪婪和确定的符号替换，不能提供带概率的多个分片结果。</li></ul><h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><ol><li>准备足够大的训练语料</li><li>确定期望的subword词表大小</li><li>将单词拆分为字符序列并在末尾添加后缀“ &lt;/ w&gt;”，统计单词频率。 本阶段的subword的粒度是字符。 例如，“ low”的频率为5，那么我们将其改写为“ l o w &lt;/ w&gt;”：5</li><li>统计每一个连续字节对的出现频率，选择最高频者合并成新的subword</li><li>重复第4步直到达到第2步设定的subword词表大小或下一个最高频的字节对出现频率为1</li></ol><p>停止符”&lt;/w&gt;”的意义在于表示subword是词后缀。举例来说：”st”字词不加”&lt;/w&gt;”可以出现在词首如”st ar”，加了”&lt;/w&gt;”表明改字词位于词尾，如”wide st&lt;/w&gt;”，二者意义截然不同。</p><p>每次合并后词表可能出现3种变化：</p><ul><li>+1，表明加入合并后的新字词，同时原来的2个子词还保留（2个字词不是完全同时连续出现）</li><li>+0，表明加入合并后的新字词，同时原来的2个子词中一个保留，一个被消解（一个字词完全随着另一个字词的出现而紧跟着出现）</li><li>-1，表明加入合并后的新字词，同时原来的2个子词都被消解（2个字词同时连续出现）</li></ul><p>实际上，随着合并的次数增加，词表大小通常先增加后减小。</p><p><strong>例子</strong></p><p>输入：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w e s t &lt;/w&gt;': 6, 'w i d e s t &lt;/w&gt;': 3&#125;</span><br></pre></td></tr></table></figure><p>Iter 1, 最高频连续字节对”e”和”s”出现了6+3=9次，合并成”es”。输出：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w es t &lt;/w&gt;': 6, 'w i d es t &lt;/w&gt;': 3&#125;</span><br></pre></td></tr></table></figure><p>Iter 2, 最高频连续字节对”es”和”t”出现了6+3=9次, 合并成”est”。输出：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w est &lt;/w&gt;': 6, 'w i d est &lt;/w&gt;': 3&#125;</span><br></pre></td></tr></table></figure><p>Iter 3, 以此类推，最高频连续字节对为”est”和”&lt;/w&gt;” 输出：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w est&lt;/w&gt;': 6, 'w i d est&lt;/w&gt;': 3&#125;</span><br></pre></td></tr></table></figure><p>……</p><p>Iter n, 继续迭代直到达到预设的subword词表大小或下一个最高频的字节对出现频率为1。</p><p>BPE算法的核心学习过程可以写做如下Python代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re, collections</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_stats</span><span class="params">(vocab)</span>:</span></span><br><span class="line">    pairs = collections.defaultdict(int)</span><br><span class="line">    <span class="keyword">for</span> word, freq <span class="keyword">in</span> vocab.items():</span><br><span class="line">        symbols = word.split()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(symbols)<span class="number">-1</span>):</span><br><span class="line">            pairs[symbols[i],symbols[i+<span class="number">1</span>]] += freq</span><br><span class="line">    <span class="keyword">return</span> pairs</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_vocab</span><span class="params">(pair, v_in)</span>:</span></span><br><span class="line">    v_out = &#123;&#125;</span><br><span class="line">    bigram = re.escape(<span class="string">' '</span>.join(pair))</span><br><span class="line">    p = re.compile(<span class="string">r'(?&lt;!\S)'</span> + bigram + <span class="string">r'(?!\S)'</span>)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> v_in:</span><br><span class="line">        w_out = p.sub(<span class="string">''</span>.join(pair), word)</span><br><span class="line">        v_out[w_out] = v_in[word]</span><br><span class="line">    <span class="keyword">return</span> v_out</span><br><span class="line"></span><br><span class="line">vocab = &#123;<span class="string">'l o w &lt;/w&gt;'</span>: <span class="number">5</span>, <span class="string">'l o w e r &lt;/w&gt;'</span>: <span class="number">2</span>, <span class="string">'n e w e s t &lt;/w&gt;'</span>: <span class="number">6</span>, <span class="string">'w i d e s t &lt;/w&gt;'</span>: <span class="number">3</span>&#125;</span><br><span class="line">num_merges = <span class="number">1000</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(num_merges):</span><br><span class="line">    pairs = get_stats(vocab)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> pairs:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    best = max(pairs, key=pairs.get)</span><br><span class="line">    vocab = merge_vocab(best, vocab)</span><br><span class="line">    print(best)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print output</span></span><br><span class="line"><span class="comment"># ('e', 's')</span></span><br><span class="line"><span class="comment"># ('es', 't')</span></span><br><span class="line"><span class="comment"># ('est', '&lt;/w&gt;')</span></span><br><span class="line"><span class="comment"># ('l', 'o')</span></span><br><span class="line"><span class="comment"># ('lo', 'w')</span></span><br><span class="line"><span class="comment"># ('n', 'e')</span></span><br><span class="line"><span class="comment"># ('ne', 'w')</span></span><br><span class="line"><span class="comment"># ('new', 'est&lt;/w&gt;')</span></span><br><span class="line"><span class="comment"># ('low', '&lt;/w&gt;')</span></span><br><span class="line"><span class="comment"># ('w', 'i')</span></span><br><span class="line"><span class="comment"># ('wi', 'd')</span></span><br><span class="line"><span class="comment"># ('wid', 'est&lt;/w&gt;')</span></span><br><span class="line"><span class="comment"># ('low', 'e')</span></span><br><span class="line"><span class="comment"># ('lowe', 'r')</span></span><br><span class="line"><span class="comment"># ('lower', '&lt;/w&gt;')</span></span><br></pre></td></tr></table></figure><h3 id="编码和解码"><a href="#编码和解码" class="headerlink" title="编码和解码"></a>编码和解码</h3><h4 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h4><p>在之前的算法中，我们已经得到了subword的词表（即常说的<code>code</code>文件），且该词表已经按照频率从高到低进行排序了。那么我们就可以对单词进行编码（下文的<code>subword-nmt</code>小节中，利用得到的<code>code.file</code>对<code>./en.txt</code>进行编码得到<code>result1.txt</code>就利用了当前要介绍的编码过程）。</p><p>以单词“where”为例，首先按照字符拆分开，然后查找<code>code</code>文件，逐对合并，优先合并频率靠前的字符对。<code>85 319 9 15</code> 表示在该字符对在<code>code</code>文件中的频率排名。</p><blockquote><p>根据我自己的实验，<code>e&lt;/w&gt;</code>可以直接合并，所以这里的频率排名直接是1，即使<code>code</code>文件中无<code>e &lt;/w&gt;</code>。</p></blockquote><p><img src="/DeepLearningApplications/自然语言处理/fairseq翻译任务解读/2019051614192910.jpg" alt="img" style="zoom: 67%;"></p><p> 如果仍然有子字符串没被替换但所有token都已迭代完毕，则有两种做法，一种是将剩余的子词替换为特殊token，如<unk>。另外一种比较常用，由于未登录词通常会被这种方法拆成若干个subword，因此通常会向不在原来词表的subword后面写明一个分隔符，通常是@@。例如，假如要编码的词是said</unk></p><ol><li>若这个词的子词<code>s a</code>在词表中，但是<code>sa i</code>和<code>i d&lt;/w&gt;</code>不在词表里，<code>encode</code>只能得到<code>(&#39;sa&#39;, &#39;i&#39;, &#39;d&#39;)</code>，那么输出会是<code>sa@@ i@@ d</code>。</li><li>若子词<code>s a</code>和<code>i d</code>在词表中，但是<code>sa i</code>和<code>i d&lt;/w&gt;</code>不在词表里，那么输出仍然是<code>sa@@ i@@ d</code>。</li><li>若子词<code>s a</code>和<code>i d&lt;/w&gt;</code>在词表中，但是<code>sa id&lt;/w&gt;</code>不在词表里，那么输出是<code>sa@@ id</code>。</li><li>若子词<code>s a</code>，<code>i d&lt;/w&gt;</code>和<code>sa id&lt;/w&gt;</code>在词表中，那么输出是<code>said</code>。</li><li>若仅有<code>sa id&lt;/w&gt;</code>在词表中，那么输出是<code>s@@ a@@ i@@ d</code>。</li><li>若仅有<code>i d&lt;/w&gt;</code>和<code>sa id&lt;/w&gt;</code>在词表中，那么输出是<code>s@@ a@@ id</code>。</li></ol><p>编码的计算量很大。 在实践中，我们可以pre-tokenize所有单词，并在词典中保存单词tokenize的结果。</p><h4 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h4><p>将所有的tokens拼在一起，如果有<code>@@</code>符号则去除（下文的<code>后处理</code>小节中<code>self.remove_bpe</code>函数，就利用了当前小节要介绍的解码过程）。</p><p>例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 编码序列</span><br><span class="line">[“the&lt;/w&gt;”, “high”, “est&lt;/w&gt;”, “moun”, “tain&lt;/w&gt;”]</span><br><span class="line"></span><br><span class="line"># 解码序列</span><br><span class="line">“the&lt;/w&gt; highest&lt;/w&gt; mountain&lt;/w&gt;”</span><br></pre></td></tr></table></figure><h3 id="subword-nmt"><a href="#subword-nmt" class="headerlink" title="subword-nmt"></a>subword-nmt</h3><p>安装subword-nmt</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install subword-nmt</span><br></pre></td></tr></table></figure><h4 id="命令行接口"><a href="#命令行接口" class="headerlink" title="命令行接口"></a>命令行接口</h4><p>先准备一个语料库。例如：链接：<a href="https://pan.baidu.com/s/1BAWDeAw5QYXS7xCrLIBIAw，提取码：kfy9" target="_blank" rel="noopener">https://pan.baidu.com/s/1BAWDeAw5QYXS7xCrLIBIAw，提取码：kfy9</a></p><p><strong>生成codevocabulary和：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">subword-nmt learn-joint-bpe-and-vocab -i ./en.txt -o ./code.file --write-vocabulary voc.txt</span><br></pre></td></tr></table></figure><p>说明：</p><ul><li>-i后面的参数是输入文件名</li><li>-o后面是输出的code文件文件名</li><li>—write-vocabulary后面是输出字典的文件名</li></ul><p>其他参数说明：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">usage: subword-nmt learn-joint-bpe-<span class="keyword">and</span>-vocab [-h] --input PATH [PATH ...]</span><br><span class="line">                                             --output PATH [--symbols SYMBOLS]</span><br><span class="line">                                             [--separator STR]</span><br><span class="line">                                             --write-vocabulary PATH</span><br><span class="line">                                             [PATH ...] [--min-frequency FREQ]</span><br><span class="line">                                             [--total-symbols] [--verbose]</span><br><span class="line"></span><br><span class="line">learn BPE-based word segmentation</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --help            show this help message <span class="keyword">and</span> exit</span><br><span class="line">  --input PATH [PATH ...], -i PATH [PATH ...]</span><br><span class="line">                        Input texts (multiple allowed).</span><br><span class="line">  --output PATH, -o PATH</span><br><span class="line">                        Output file <span class="keyword">for</span> BPE codes.</span><br><span class="line">  --symbols SYMBOLS, -s SYMBOLS</span><br><span class="line">                        Create this many new symbols (each representing a</span><br><span class="line">                        character n-gram) (default: <span class="number">10000</span>))</span><br><span class="line">  --separator STR       Separator between non-final subword units (default:</span><br><span class="line">                        <span class="string">'@@'</span>))</span><br><span class="line">  --write-vocabulary PATH [PATH ...]</span><br><span class="line">                        Write to these vocabulary files after applying BPE.</span><br><span class="line">                        One per input text. Used <span class="keyword">for</span> filtering <span class="keyword">in</span> apply_bpe.py</span><br><span class="line">  --min-frequency FREQ  Stop <span class="keyword">if</span> no symbol pair has frequency &gt;= FREQ (default:</span><br><span class="line">                        <span class="number">2</span>))</span><br><span class="line">  --total-symbols, -t   subtract number of characters <span class="keyword">from</span> the symbols to be</span><br><span class="line">                        generated (so that <span class="string">'--symbols'</span> becomes an estimate <span class="keyword">for</span></span><br><span class="line">                        the total number of symbols needed to encode text).</span><br><span class="line">  --verbose, -v         verbose mode.</span><br></pre></td></tr></table></figure><p>我们可以看一下生成的code.file和voc.txt。</p><p>code.file:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#version: 0.2</span><br><span class="line">t h</span><br><span class="line">i n</span><br><span class="line">th e&lt;/w&gt;</span><br><span class="line">a n</span><br><span class="line">r e</span><br><span class="line">t i</span><br><span class="line">e n</span><br><span class="line">o n</span><br><span class="line">an d&lt;/w&gt;</span><br><span class="line">e r</span><br><span class="line">···</span><br></pre></td></tr></table></figure><p>voc.txt部分内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">···</span><br><span class="line">ary 14</span><br><span class="line">apart 14</span><br><span class="line">conscientiously 14</span><br><span class="line">flight 14</span><br><span class="line">association 14</span><br><span class="line">represent 14</span><br><span class="line">th 14</span><br><span class="line">activity 14</span><br><span class="line">standard 14</span><br><span class="line">call 14</span><br><span class="line">jia 14</span><br><span class="line">solid 14</span><br><span class="line">seven 14</span><br><span class="line">···</span><br></pre></td></tr></table></figure><p>这里需要注意的是，<code>code.file</code>文件一共有10001行，而<code>voc.txt</code>文件一共有8760行，并且<code>voc.txt</code>含有一部分带有<code>@@</code>的行。</p><p>那么这里的<code>code.file</code>和<code>voc.txt</code>有什么关系呢？我们继续进行探索。</p><p>安装完subword-nmt之后，我们可以在终端输入<code>subword-nmt -h</code>，得到内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">(base) PS E:\Working\learn_bpe&gt; subword-nmt -h</span><br><span class="line">usage: subword-nmt [-h] &#123;learn-bpe,apply-bpe,get-vocab,learn-joint-bpe-and-vocab&#125; ...</span><br><span class="line"></span><br><span class="line">subword-nmt: unsupervised word segmentation <span class="keyword">for</span> neural machine translation and text generation</span><br><span class="line"></span><br><span class="line">positional arguments:</span><br><span class="line">  &#123;learn-bpe,apply-bpe,get-vocab,learn-joint-bpe-and-vocab&#125;</span><br><span class="line">                        <span class="built_in">command</span> to run. Run one of the commands with <span class="string">'-h'</span> <span class="keyword">for</span> more info.</span><br><span class="line"></span><br><span class="line">                        apply-bpe: apply given BPE operations to input text.</span><br><span class="line">                        learn-joint-bpe-and-vocab: executes recommended workflow <span class="keyword">for</span> joint BPE.</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --<span class="built_in">help</span>            show this <span class="built_in">help</span> message and <span class="built_in">exit</span></span><br></pre></td></tr></table></figure><p>也就是说，<code>subword-nmt</code>有<code>learn-bpe,apply-bpe,get-vocab,learn-joint-bpe-and-vocab</code>方法，继续输入<code>subword-nmt learn-bpe -h</code>可以查看子函数的用法。</p><p>详细的探索这几个函数的用法之后，可以发现如下结论。</p><ol><li><code>learn-joint-bpe-and-vocab</code>其实是三条指令的合体。</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">subword-nmt learn-joint-bpe-and-vocab -i ./en.txt -o ./code.file --write-vocabulary voc.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 上述指令等价于</span></span><br><span class="line">subword-nmt learn-bpe -i ./en.txt  -o ./code.file</span><br><span class="line">subword-nmt apply-bpe -i ./en.txt -c ./code.file -o result1.txt</span><br><span class="line">subword-nmt get-vocab -i ./result1.txt -o voc.txt</span><br></pre></td></tr></table></figure><ol><li><p><code>get-vocab</code>函数会对文件中出现的单词以及对应的频率进行统计，得到<code>voc.txt</code>文件，该过程不需要<code>code.file</code>文件。</p></li><li><p><code>code.file</code>和<code>voc.txt</code>关系是：首先利用<code>learn-bpe</code>从<code>en.txt</code>文件中学习bpe分词规则，然后利用该规则对<code>en.txt</code>编码，统计编码之后文件的词语和词频得到<code>voc.txt</code>文件。所以两者并不是意义对应的关系，而且哪个文件行数更多也不一定。</p></li></ol><p><strong>使用bpe编码</strong></p><p>在使用learn-bpe功能得到code后，可以使用apply-bpe来对语料进行编码。值得注意的是，这里解码时并不需要用到<code>voc.txt</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">subword-nmt apply-bpe -i ./en.test.txt -c ./code.file -o result.txt</span><br></pre></td></tr></table></figure><p>说明：</p><ul><li><code>-i</code> 后面是输入的待解码文件名</li><li><code>-c</code> 后面跟着learn-bpe步骤得到的code文件</li><li><code>-o</code> 结果输出文件</li></ul><p>我们可以查看结果，就会自动根据bpe生成的code文件对语料进行分割。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">beijing , 1 mar ( xinhua ) -- tian feng@@ shan , former heilongjiang governor who is 5@@ 9 years old , was appointed minister of land and resources today .</span><br><span class="line">tian feng@@ shan , who was born in zhao@@ yuan county , heilongjiang province , took part in work since july 196@@ 1 and joined the cpc in march 1970 .</span><br><span class="line">this should be a natural process set off by economic development ; the &quot; third tier construction &quot; of the 1960s involving fac@@ tory relocation was something entirely different .</span><br><span class="line">we must also realize however that from the angle of changing the pattern of resource allocation , we have not yet made the big breakthrough in reform .</span><br><span class="line">with regard to joining the world trade organization , one recent reaction has been blind optim@@ ism and the belief that china will profit whatever it does .</span><br><span class="line">since these areas where objective conditions are not particularly good can achieve this , other areas where conditions are better can naturally do the same .</span><br><span class="line">the objective trend of globalization is calling for international cooperation on a global scale , and a global cooperation has far exceeded the scope of the economy .</span><br></pre></td></tr></table></figure><p><strong>解码</strong></p><p>那么我们的文件怎么恢复到bpe编码之前的结果呢？</p><p>只需要执行下面指令即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sed -r <span class="string">'s/(@@ )|(@@ ?$)//g'</span> result.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将解码结果保存到文件中</span></span><br><span class="line">sed -r <span class="string">'s/(@@ )|(@@ ?$)//g'</span> result.txt &gt; restore.txt</span><br></pre></td></tr></table></figure><p>我们恢复之后的结果是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">beijing , 1 mar ( xinhua ) -- tian fengshan , former heilongjiang governor who is 59 years old , was appointed minister of land and resources today .</span><br><span class="line">tian fengshan , who was born in zhaoyuan county , heilongjiang province , took part in work since july 1961 and joined the cpc in march 1970 .</span><br><span class="line">this should be a natural process set off by economic development ; the &quot; third tier construction &quot; of the 1960s involving factory relocation was something entirely different .</span><br><span class="line">we must also realize however that from the angle of changing the pattern of resource allocation , we have not yet made the big breakthrough in reform .</span><br><span class="line">with regard to joining the world trade organization , one recent reaction has been blind optimism and the belief that china will profit whatever it does .</span><br><span class="line">since these areas where objective conditions are not particularly good can achieve this , other areas where conditions are better can naturally do the same .</span><br><span class="line">the objective trend of globalization is calling for international cooperation on a global scale , and a global cooperation has far exceeded the scope of the economy .</span><br></pre></td></tr></table></figure><h4 id="Python接口"><a href="#Python接口" class="headerlink" title="Python接口"></a>Python接口</h4><p>可以用命令<code>pip install subword-nmt</code>安装包<code>subword-nmt</code>以后，可以使用如下代码得到BPE的分词结果，以及将BPE的分词方法用到测试语料上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> subword_nmt <span class="keyword">import</span> apply_bpe, learn_bpe</span><br><span class="line"><span class="comment"># 得到分词结果，写到../data/toy_bpe.txt这个文件中</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'../data/toy_vocab.txt'</span>, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> in_file, \</span><br><span class="line">        open(<span class="string">'../data/toy_bpe.txt'</span>, <span class="string">'w+'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> out_file:</span><br><span class="line">    <span class="comment"># 得到分词结果，写到../data/toy_bpe.txt这个文件中</span></span><br><span class="line">    <span class="comment"># 1500是最后BPE词表大小，is_dict说明输入文件是个词表文件，格式为"&lt;单词&gt; &lt;次数&gt;"</span></span><br><span class="line">    learn_bpe.learn_bpe(in_file, out_file, <span class="number">1500</span>, verbose=<span class="literal">True</span>, is_dict=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取../data/toy_bpe.txt分词结果，并作用于../data/bpe_test_raw.txt中的文本，最后写到../data/bpe_test_processed.txt文件中</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'../data/bpe_test_raw.txt'</span>, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> in_file, \</span><br><span class="line">        open(<span class="string">'../data/bpe_test_processed.txt'</span>, <span class="string">'w+'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> out_file, \</span><br><span class="line">        open(<span class="string">'../data/toy_bpe.txt'</span>, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> code_file:</span><br><span class="line">    <span class="comment"># 构造BPE词表</span></span><br><span class="line">    bpe = apply_bpe.BPE(code_file)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> in_file:</span><br><span class="line">        <span class="comment"># 使用BPE分词</span></span><br><span class="line">        out_file.write(bpe.process_line(line))</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>subword可以平衡词汇量和对未知词的覆盖。 极端的情况下，我们只能使用26个token（即字符）来表示所有英语单词。一般情况，建议使用16k或32k子词足以取得良好的效果，Facebook <a href="https://github.com/pytorch/fairseq/tree/main/examples/roberta" target="_blank" rel="noopener">RoBERTa</a>甚至建立的多达50k的词表。</p><h2 id="模型加载"><a href="#模型加载" class="headerlink" title="模型加载"></a>模型加载</h2><p>补充完毕BPE算法的原理之后，我们开始对该源码进行分析。首先来看模型加载部分。</p><p>模型加载的核心函数为<code>fairseq/hub_utils.py: from_pretrained</code>函数。在该函数的会调用<code>checkpoint_utils.load_model_ensemble_and_task</code>函数。该函数不仅加载了模型权重，而且会初始化task。我们重点关注这个初始化过程。初始化该task时，默认会初始化为<code>translation</code>任务。</p><p>然后跳入函数<code>fairseq/tasks/translation.py</code>中，可以看到在<code>setup_task</code>函数中，会读取<code>model/wmt16.en-de.joined-dict.transformer/dict.en.txt</code>和<code>model/wmt16.en-de.joined-dict.transformer/dict.de.txt</code>文件，然后放到<code>fairseq.tasks.translation.TranslationTask</code>的<code>src_dict</code>和<code>tgt_dict</code>中。另外值得注意的是<code>fairseq.data.dictionary.Dictionary</code>的实例，在实例化该类的时候，会在最前面加上<code>bos=&quot;&lt;s&gt;&quot;, pad=&quot;&lt;pad&gt;&quot;, eos=&quot;&lt;/s&gt;&quot;, unk=&quot;&lt;unk&gt;&quot;</code>，因此虽然这两个txt文件中都有32764行（两个文件内容一模一样），最终都会有32768行，与翻译模型的输出维度一致。</p><p><img src="/DeepLearningApplications/自然语言处理/fairseq翻译任务解读/image-20220427221019923.png" alt="image-20220427221019923" style="zoom:50%;"></p><p>加载模型并初始化task之后，<code>from_pretrained</code>函数接着实例化了<code>hub_utils.GeneratorHubInterface</code>。我们接着看该类在实例化的时候会做些什么。</p><p>从下图可以看到该初始化函数依次做了：从task中创建<code>src_dict</code>和<code>tgt_dict</code>属性（与<code>fairseq.tasks.translation.TranslationTask</code>的<code>src_dict</code>和<code>tgt_dict</code>一致），然后加载了<code>align_dict、tokenizer、bpe</code>。</p><p><img src="/DeepLearningApplications/自然语言处理/fairseq翻译任务解读/image-20220427223531357.png" alt="image-20220427223531357" style="zoom:50%;"></p><p>我们这里重点关注一下<code>bpe</code>的初始化过程，单步调试进入到<code>fairseq/registry.py</code>文件后，可以发现fairseq支持的所有bpe有：<code>dict_keys([&#39;bytes&#39;, &#39;gpt2&#39;, &#39;hf_byte_bpe&#39;, &#39;bert&#39;, &#39;characters&#39;, &#39;fastbpe&#39;, &#39;byte_bpe&#39;, &#39;sentencepiece&#39;, &#39;subword_nmt&#39;])</code>。我们这里在初始化模型时传入了<code>bpe=&#39;subword_nmt</code>参数，所以我们重点关注一下<code>subword_nmt</code>的初始化方式。</p><p>该初始化过程的详细过程在<code>fairseq/data/encoders/subword_nmt_bpe.py</code>文件的<code>SubwordNMTBPE</code>类的<code>__init__</code>函数中。从下图中可以看出，该函数会读取<code>args.bpe_codes</code>对应的文件，也就是<code>&#39;./model/wmt16.en-de.joined-dict.transformer/bpecodes&#39;</code>文件，用于实例化<code>subword_nmt.apply_bpe.BPE</code>得到对应<code>self.bpe</code>，同时<code>SubwordNMTBPE</code>类还有对应的<code>encode</code>和<code>decode</code>函数。</p><p><img src="/DeepLearningApplications/自然语言处理/fairseq翻译任务解读/image-20220427233419637.png" alt="image-20220427233419637" style="zoom:50%;"></p><p>介绍完BPE的初始化，我们接着回到<code>hub_utils.GeneratorHubInterface</code>类中，此时的<code>self.bpe</code>的类型为<code>fairseq.data.encoders.subword_nmt_bpe.SubwordNMTBPE</code>。</p><p>由此，翻译模型的模型加载部分已经介绍完了。</p><h2 id="前向推理"><a href="#前向推理" class="headerlink" title="前向推理"></a>前向推理</h2><p>从上面的调用关系来看，翻译模型进行推理的函数是<code>translate</code>。我们调试进入该函数，发现该函数位于<code>/root/anaconda3/lib/python3.8/site-packages/fairseq/hub_utils.py</code>文件中。核心代码如下：</p><p><img src="/DeepLearningApplications/自然语言处理/fairseq翻译任务解读/image-20220427105444788.png" alt="image-20220427105444788" style="zoom:50%;"></p><p>可以看到，翻译时需要经过三个关键步骤：<code>encode</code>、<code>generate</code>和<code>decode</code>。这里我们先关注预处理和后处理步骤。关键代码如下：</p><p><img src="/DeepLearningApplications/自然语言处理/fairseq翻译任务解读/image-20220427110136773.png" alt="image-20220427110136773" style="zoom:50%;"></p><p>可以看出来预处理主要流程为<code>分词-&gt;BPE-&gt;binarize</code>，后处理的主要步骤是<code>string-&gt;去除bpe-&gt;去分词</code>。</p><h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><p>我们接着来看预处理过程。在使用该模型的时候，并没有用到分词，而是直接使用了BPE的方式，所以我们跳过<code>self.tokenize</code>函数，首先来看<code>self.apply_bpe</code>函数。该函数会调用<code>SubwordNMTBPE.encode of &lt;fairseq.data.encoders.subword_nmt_bpe.SubwordNMTBPE&gt;</code>，我们这里先不管这个函数干了啥，先介绍它的输入输出。其输入为：<code>&#39;Hello world!&#39;</code>，输出为<code>&#39;H@@ ello world@@ !&#39;</code>。</p><p>接着我们来看<code>self.binarize</code>，它的输入是<code>&#39;H@@ ello world@@ !&#39;</code>，输出是<code>tensor([  190,  7016, 29382,    88,     2])</code>。该函数会调用<code>Dictionary.encode_line of &lt;fairseq.data.dictionary.Dictionary&gt;</code>。查询前面的<code>src_dict</code>，将字符串映射到唯一ID上（ID简单理解为<code>model/wmt16.en-de.joined-dict.transformer/dict.en.txt</code>中的行数+4）。</p><h2 id="模型推理"><a href="#模型推理" class="headerlink" title="模型推理"></a>模型推理</h2><p>介绍完预处理流程，我们来看下网络结构，网络结构如下（因为该网络结构很长，所以只摘出来关键部分）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">GeneratorHubInterface(</span><br><span class="line">  (models): ModuleList(</span><br><span class="line">    (<span class="number">0</span>): TransformerModel(</span><br><span class="line">      (encoder): TransformerEncoder(</span><br><span class="line">        (dropout_module): FairseqDropout()</span><br><span class="line">        (embed_tokens): Embedding(<span class="number">32768</span>, <span class="number">1024</span>, padding_idx=<span class="number">1</span>)</span><br><span class="line">        (embed_positions): SinusoidalPositionalEmbedding()</span><br><span class="line">        (layers): ModuleList(</span><br><span class="line">          (<span class="number">0</span>): TransformerEncoderLayer(</span><br><span class="line">            (self_attn): MultiheadAttention(</span><br><span class="line">              (dropout_module): FairseqDropout()</span><br><span class="line">              (k_proj): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">              (v_proj): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">              (q_proj): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">              (out_proj): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            )</span><br><span class="line">            (self_attn_layer_norm): LayerNorm((<span class="number">1024</span>,), eps=<span class="number">1e-05</span>, elementwise_affine=<span class="literal">True</span>)</span><br><span class="line">            (dropout_module): FairseqDropout()</span><br><span class="line">            (activation_dropout_module): FairseqDropout()</span><br><span class="line">            (fc1): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            (fc2): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            (final_layer_norm): LayerNorm((<span class="number">1024</span>,), eps=<span class="number">1e-05</span>, elementwise_affine=<span class="literal">True</span>)</span><br><span class="line">          )</span><br><span class="line">          <span class="comment"># 省略(1~5)TransformerEncoderLayer</span></span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">      (decoder): TransformerDecoder(</span><br><span class="line">        (dropout_module): FairseqDropout()</span><br><span class="line">        (embed_tokens): Embedding(<span class="number">32768</span>, <span class="number">1024</span>, padding_idx=<span class="number">1</span>)</span><br><span class="line">        (embed_positions): SinusoidalPositionalEmbedding()</span><br><span class="line">        (layers): ModuleList(</span><br><span class="line">          (<span class="number">0</span>): TransformerDecoderLayer(</span><br><span class="line">            (dropout_module): FairseqDropout()</span><br><span class="line">            (self_attn): MultiheadAttention(</span><br><span class="line">              (dropout_module): FairseqDropout()</span><br><span class="line">              (k_proj): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">              (v_proj): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">              (q_proj): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">              (out_proj): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            )</span><br><span class="line">            (activation_dropout_module): FairseqDropout()</span><br><span class="line">            (self_attn_layer_norm): LayerNorm((<span class="number">1024</span>,), eps=<span class="number">1e-05</span>, elementwise_affine=<span class="literal">True</span>)</span><br><span class="line">            (encoder_attn): MultiheadAttention(</span><br><span class="line">              (dropout_module): FairseqDropout()</span><br><span class="line">              (k_proj): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">              (v_proj): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">              (q_proj): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">              (out_proj): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            )</span><br><span class="line">            (encoder_attn_layer_norm): LayerNorm((<span class="number">1024</span>,), eps=<span class="number">1e-05</span>, elementwise_affine=<span class="literal">True</span>)</span><br><span class="line">            (fc1): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            (fc2): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">1024</span>, bias=<span class="literal">True</span>)</span><br><span class="line">            (final_layer_norm): LayerNorm((<span class="number">1024</span>,), eps=<span class="number">1e-05</span>, elementwise_affine=<span class="literal">True</span>)</span><br><span class="line">          )</span><br><span class="line">          <span class="comment"># 省略(1~5)TransformerDecoderLayer</span></span><br><span class="line">        )</span><br><span class="line">        (output_projection): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">32768</span>, bias=<span class="literal">False</span>)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>总结概括一下该结构，如下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">TransformerEncoder(</span><br><span class="line">    FairseqDropout(), </span><br><span class="line">    Embedding(<span class="number">32768</span>, <span class="number">1024</span>, padding_idx=<span class="number">1</span>), </span><br><span class="line">    SinusoidalPositionalEmbedding(), </span><br><span class="line">    <span class="number">6</span>个TransformerEncoderLayer</span><br><span class="line">)</span><br><span class="line">TransformerDecoder(</span><br><span class="line">    FairseqDropout(), </span><br><span class="line">    Embedding(<span class="number">32768</span>, <span class="number">1024</span>, padding_idx=<span class="number">1</span>), </span><br><span class="line">    SinusoidalPositionalEmbedding(), </span><br><span class="line">    <span class="number">6</span>个TransformerDecoderLayer, </span><br><span class="line">    Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">32768</span>, bias=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>也就是说，在该模型中，使用了<a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html" target="_blank" rel="noopener">torch.nn.Embedding</a>层对输入进行了Embedding并学习。</p><p>接着我们看下模型推理部分——<code>generate</code>函数。</p><p>该函数首先会调用<code>FairseqTask.build_generator of &lt;fairseq.tasks.translation.TranslationTask&gt;</code>函数，并传入<code>gen_args</code>参数（该参数中包含了<code>beam</code>）。在该函数会执行<code>search_strategy = search.BeamSearch(self.target_dictionary)</code>函数实例化BeamSearch（使用到了<code>model/wmt16.en-de.joined-dict.transformer/dict.de.txt</code>），并与模型一块放到<code>SequenceGenerator</code>中进行实例化，而实际进行推理时也是调用的<code>SequenceGenerator.generate of SequenceGenerator</code>，同时进行模型推理+BeamSearch过程。</p><p>具体细节我们先不关注，先说下输入输出。其输入为</p><p><img src="/DeepLearningApplications/自然语言处理/fairseq翻译任务解读/image-20220428003141180.png" alt="image-20220428003141180" style="zoom:50%;"></p><p>经过推理之后，输出结果为（下面5个结果的tokens是不一样的，这里显示不出来）：</p><p><img src="/DeepLearningApplications/自然语言处理/fairseq翻译任务解读/image-20220428003252483.png" alt="image-20220428003252483" style="zoom:50%;"></p><h2 id="后处理"><a href="#后处理" class="headerlink" title="后处理"></a>后处理</h2><p>最后，我们来看下后处理流程。后处理的对应的代码是<code>[self.decode(hypos[0][&quot;tokens&quot;]) for hypos in batched_hypos]</code>。也就是将<code>tensor([12006,   165,   488,    88,     2], device=&#39;cuda:0&#39;)</code>输入到<code>self.decode</code>函数中。该函数的主要流程是<code>string-&gt;去除bpe-&gt;去分词</code>。</p><p>我们先来看<code>self.string</code>函数，该函数与<code>self.binarize</code>函数相反，它会调用<code>Dictionary.string of &lt;fairseq.data.dictionary.Dictionary&gt;</code>，查询前面的<code>tgt_dict</code>，将ID映射回字符串（ID简单理解为<code>model/wmt16.en-de.joined-dict.transformer/dict.de.txt</code>中的行数+4）。它的输入为<code>tensor([12006,   165,   488,    88,     2], device=&#39;cuda:0&#39;)</code>，输出为<code>&#39;Hall@@ o Welt !&#39;</code>。</p><p>接着来看<code>self.remove_bpe</code>函数，它与<code>self.apply_bpe</code>函数作用相反，该函数会调用<code>SubwordNMTBPE.decode of &lt;fairseq.data.encoders.subword_nmt_bpe.SubwordNMTBPE&gt;</code>，我们这里先不管这个函数干了啥，先介绍它的输入输出。其输入为：<code>&#39;Hall@@ o Welt !&#39;</code>，输出为<code>&#39;Hallo Welt !&#39;</code>。</p><p>同样的，最后，该过程并没有调用<code>self.detokenize</code>，这里先不管。</p><h2 id="训练数据准备"><a href="#训练数据准备" class="headerlink" title="训练数据准备"></a>训练数据准备</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>下文主要来源于<a href="https://www.cnblogs.com/mmxy/p/14076930.html" target="_blank" rel="noopener">WMT14 en-de翻译数据集预处理步骤</a></p><p>fairseq提供了一份wmt14英德数翻译据集的<a href="https://github.com/pytorch/fairseq/blob/master/examples/translation/prepare-wmt14en2de.sh" target="_blank" rel="noopener">预处理脚本</a>，简单结合其代码分析一下其处理步骤：</p><p>1、下载mosesdecoder。mosesdecoder的使用文档在<a href="http://www.statmt.org/moses/?n=Moses.Baseline" target="_blank" rel="noopener">这里</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">'Cloning Moses github repository (for tokenization scripts)...'</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/moses-smt/mosesdecoder.git</span><br></pre></td></tr></table></figure><p>2、下载subword nmt。这个开源库是用于构造bpecodes及其字典的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">'Cloning Subword NMT repository (for BPE pre-processing)...'</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/rsennrich/subword-nmt.git</span><br></pre></td></tr></table></figure><p>3、</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">SCRIPTS</span>=mosesdecoder/scripts      <span class="comment"># 定义SCRIPTS变量，指向mosesdecoder的脚本文件夹</span></span><br><span class="line"><span class="attr">TOKENIZER</span>=<span class="variable">$SCRIPTS</span>/tokenizer/tokenizer.perl      <span class="comment"># 定义TOKENIZER变量，指向mosesdecoder的tokenizer.perl, 用来分词</span></span><br><span class="line"><span class="attr">CLEAN</span>=<span class="variable">$SCRIPTS</span>/training/clean-corpus-n.perl      <span class="comment"># 定义CLEAN变量，指向mosesdecoder的clean-corpus-n.perl，clean的主要作用是保留指定长度的数据</span></span><br><span class="line"><span class="attr">NORM_PUNC</span>=<span class="variable">$SCRIPTS</span>/tokenizer/normalize-punctuation.perl      <span class="comment"># 定义NORM_PUNC变量，指向normalize-punctuation.perl,用来将标点符号规范化</span></span><br><span class="line"><span class="attr">REM_NON_PRINT_CHAR</span>=<span class="variable">$SCRIPTS</span>/tokenizer/remove-non-printing-char.perl      <span class="comment"># 定义REM_NON_PRINT_CHAR变量，指向remove-non-printing-char.perl,去除语料中的非打印字符 </span></span><br><span class="line"><span class="attr">BPEROOT</span>=subword-nmt/subword_nmt      <span class="comment"># 定义BPEROOT变量，指向subword_nmt根目录。</span></span><br><span class="line"><span class="attr">BPE_TOKENS</span>=<span class="number">40000</span>      <span class="comment"># 指定BPE TOKENS的数量为40000</span></span><br></pre></td></tr></table></figure><p>4、</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定语料来源，其中包括了训练、验证、测试语料</span></span><br><span class="line">URLS=(</span><br><span class="line">    <span class="string">"http://statmt.org/wmt13/training-parallel-europarl-v7.tgz"</span></span><br><span class="line">    <span class="string">"http://statmt.org/wmt13/training-parallel-commoncrawl.tgz"</span></span><br><span class="line">    <span class="string">"http://data.statmt.org/wmt17/translation-task/training-parallel-nc-v12.tgz"</span></span><br><span class="line">    <span class="string">"http://data.statmt.org/wmt17/translation-task/dev.tgz"</span></span><br><span class="line">    <span class="string">"http://statmt.org/wmt14/test-full.tgz"</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 指定文件名，和上面URLS对应</span></span><br><span class="line">FILES=(</span><br><span class="line">    <span class="string">"training-parallel-europarl-v7.tgz"</span></span><br><span class="line">    <span class="string">"training-parallel-commoncrawl.tgz"</span></span><br><span class="line">    <span class="string">"training-parallel-nc-v12.tgz"</span></span><br><span class="line">    <span class="string">"dev.tgz"</span></span><br><span class="line">    <span class="string">"test-full.tgz"</span>      <span class="comment"># 只要test-full是测试集，上面四个都是训练+验证集。</span></span><br><span class="line">)</span><br><span class="line">CORPORA=(</span><br><span class="line">    <span class="string">"training/europarl-v7.de-en"</span></span><br><span class="line">    <span class="string">"commoncrawl.de-en"</span></span><br><span class="line">    <span class="string">"training/news-commentary-v12.de-en"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>5、</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This will make the dataset compatible to the one used in "Convolutional Sequence to Sequence Learning"</span></span><br><span class="line"><span class="comment"># https://arxiv.org/abs/1705.03122</span></span><br><span class="line"><span class="comment"># 如果指定参数--icml17，就将语料2替换成wmt14的语料，而不是使用wmt17的语料，这是为了和ConvS2S论文保持一致</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$1</span>"</span> == <span class="string">"--icml17"</span> ]; <span class="keyword">then</span></span><br><span class="line">    URLS[2]=<span class="string">"http://statmt.org/wmt14/training-parallel-nc-v9.tgz"</span></span><br><span class="line">    FILES[2]=<span class="string">"training-parallel-nc-v9.tgz"</span></span><br><span class="line">    CORPORA[2]=<span class="string">"training/news-commentary-v9.de-en"</span></span><br><span class="line">    OUTDIR=wmt14_en_de      <span class="comment"># 指定输出文件夹名</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    OUTDIR=wmt17_en_de</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><p>6、</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">src=en      <span class="comment"># 源语言为英文</span></span><br><span class="line">tgt=de      <span class="comment"># 目标语言是德语</span></span><br><span class="line">lang=en-de      <span class="comment"># 语言对为英德</span></span><br><span class="line">prep=<span class="variable">$OUTDIR</span>      <span class="comment"># 文件夹前缀为$OUTDIR</span></span><br><span class="line">tmp=<span class="variable">$prep</span>/tmp      <span class="comment"># 文件夹$OUTDIR内有一个tmp文件夹</span></span><br><span class="line">orig=orig      <span class="comment"># orig=orig</span></span><br><span class="line">dev=dev/newstest2013      <span class="comment"># 开发集使用newstest2013</span></span><br><span class="line"></span><br><span class="line">mkdir -p <span class="variable">$orig</span> <span class="variable">$tmp</span> <span class="variable">$prep</span>      <span class="comment"># 递归创建上面定义的文件夹，包括orig文件夹，$OUTDIR/tmp文件夹，$OUTDIR文件夹</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$orig</span>      <span class="comment"># 切换到orig文件夹中</span></span><br></pre></td></tr></table></figure><p>7、</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> ((i=0;i&lt;<span class="variable">$&#123;#URLS[@]&#125;</span>;++i)); <span class="keyword">do</span>      <span class="comment"># 迭代每一个URLS</span></span><br><span class="line">    file=<span class="variable">$&#123;FILES[i]&#125;</span></span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="variable">$file</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"<span class="variable">$file</span> already exists, skipping download"</span>      <span class="comment"># 如果文件之前已经下载下来了，就跳过</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        url=<span class="variable">$&#123;URLS[i]&#125;</span>      </span><br><span class="line">        wget <span class="string">"<span class="variable">$url</span>"</span>      <span class="comment"># 否则下载</span></span><br><span class="line">        <span class="keyword">if</span> [ -f <span class="variable">$file</span> ]; <span class="keyword">then</span>      </span><br><span class="line">            <span class="built_in">echo</span> <span class="string">"<span class="variable">$url</span> successfully  downloaded."</span>       <span class="comment"># 下载完文件存在表示下载成功</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">"<span class="variable">$url</span> not successfully downloaded."</span>  <span class="comment"># 查无此人，下载失败</span></span><br><span class="line">            <span class="built_in">exit</span> -1</span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">        <span class="keyword">if</span> [ <span class="variable">$&#123;file: -4&#125;</span> == <span class="string">".tgz"</span> ]; <span class="keyword">then</span>      <span class="comment"># 对于.tgz格式的文件，用zxvf命令解压</span></span><br><span class="line">            tar zxvf <span class="variable">$file</span></span><br><span class="line">        <span class="keyword">elif</span> [ <span class="variable">$&#123;file: -4&#125;</span> == <span class="string">".tar"</span> ]; <span class="keyword">then</span>      <span class="comment"># 对于.tar格式的文件，用xvf命令解压</span></span><br><span class="line">            tar xvf <span class="variable">$file</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">cd</span> ..</span><br></pre></td></tr></table></figure><p>执行完毕之后，<code>$OUTDIR</code>文件夹存放的内容有：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">./wmt17_en_de</span><br><span class="line">├── orig  # 原始数据集的tgz文件+解压之后的结果</span><br><span class="line">│   ├── dev</span><br><span class="line">│   ├── test-full</span><br><span class="line">│   └── training</span><br><span class="line">└── tmp</span><br></pre></td></tr></table></figure><p>8、<strong>重点来了</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"pre-processing train data..."</span>      <span class="comment"># 预处理训练语料</span></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    rm <span class="variable">$tmp</span>/train.tags.<span class="variable">$lang</span>.tok.<span class="variable">$l</span>      <span class="comment"># 如果存在，先移除</span></span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;CORPORA[@]&#125;</span>"</span>; <span class="keyword">do</span>      </span><br><span class="line">        cat <span class="variable">$orig</span>/<span class="variable">$f</span>.<span class="variable">$l</span> | \</span><br><span class="line">            perl <span class="variable">$NORM_PUNC</span> <span class="variable">$l</span> | \      <span class="comment"># 先标准化符号</span></span><br><span class="line">            perl <span class="variable">$REM_NON_PRINT_CHAR</span> | \      <span class="comment"># 移除非打印字符</span></span><br><span class="line">            perl <span class="variable">$TOKENIZER</span> -threads 8 -a -l <span class="variable">$l</span> &gt;&gt; <span class="variable">$tmp</span>/train.tags.<span class="variable">$lang</span>.tok.<span class="variable">$l</span>  <span class="comment"># 分词</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"pre-processing test data..."</span>      <span class="comment"># 预处理测试语料</span></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">"<span class="variable">$l</span>"</span> == <span class="string">"<span class="variable">$src</span>"</span> ]; <span class="keyword">then</span>      </span><br><span class="line">        t=<span class="string">"src"</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        t=<span class="string">"ref"</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    grep <span class="string">'&lt;seg id'</span> <span class="variable">$orig</span>/<span class="built_in">test</span>-full/newstest2014-deen-<span class="variable">$t</span>.<span class="variable">$l</span>.sgm | \      <span class="comment">#这一块操作没看懂</span></span><br><span class="line">        sed -e <span class="string">'s/&lt;seg id="[0-9]*"&gt;\s*//g'</span> | \      </span><br><span class="line">        sed -e <span class="string">'s/\s*&lt;\/seg&gt;\s*//g'</span> | \</span><br><span class="line">        sed -e <span class="string">"s/\’/\'/g"</span> | \</span><br><span class="line">    perl <span class="variable">$TOKENIZER</span> -threads 8 -a -l <span class="variable">$l</span> &gt; <span class="variable">$tmp</span>/<span class="built_in">test</span>.<span class="variable">$l</span>      <span class="comment"># 分词</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">""</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>执行完毕之后，得到的文件是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">./wmt17_en_de</span><br><span class="line">├── orig  <span class="comment"># 原始数据集的tgz文件+解压之后的结果</span></span><br><span class="line">│   ├── dev</span><br><span class="line">│   ├── <span class="built_in">test</span>-full</span><br><span class="line">│   └── training</span><br><span class="line">└── tmp</span><br><span class="line">    ├── test.de</span><br><span class="line">    ├── test.en</span><br><span class="line">    ├── train.tags.en-de.tok.de</span><br><span class="line">    └── train.tags.en-de.tok.en</span><br></pre></td></tr></table></figure><p>预处理完毕之后，<code>test.en</code>的其中一条语句为<code>They are not even 100 metres apart : On Tuesday , the new B 33 pedestrian lights in Dorfparkplatz in Gutach became operational - within view of the existing Town Hall traffic lights .</code>。可以看出来，标点符号已经和字母分开了。</p><p>9、</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"splitting train and valid..."</span>      <span class="comment"># 划分训练集和验证集</span></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    awk <span class="string">'&#123;if (NR%100 == 0)  print $0; &#125;'</span> <span class="variable">$tmp</span>/train.tags.<span class="variable">$lang</span>.tok.<span class="variable">$l</span> &gt; <span class="variable">$tmp</span>/valid.<span class="variable">$l</span>      <span class="comment"># 从训练集中，每100个句子抽1个句子作为验证集</span></span><br><span class="line">    awk <span class="string">'&#123;if (NR%100 != 0)  print $0; &#125;'</span> <span class="variable">$tmp</span>/train.tags.<span class="variable">$lang</span>.tok.<span class="variable">$l</span> &gt; <span class="variable">$tmp</span>/train.<span class="variable">$l</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>执行完毕之后，得到的文件结构是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">./wmt17_en_de</span><br><span class="line">├── orig  <span class="comment"># 原始数据集的tgz文件+解压之后的结果</span></span><br><span class="line">│   ├── dev</span><br><span class="line">│   ├── <span class="built_in">test</span>-full</span><br><span class="line">│   └── training</span><br><span class="line">└── tmp</span><br><span class="line">    ├── test.de</span><br><span class="line">    ├── test.en</span><br><span class="line">    ├── train.de</span><br><span class="line">    ├── train.en</span><br><span class="line">    ├── train.tags.en-de.tok.de</span><br><span class="line">    ├── train.tags.en-de.tok.en</span><br><span class="line">    ├── valid.de</span><br><span class="line">    └── valid.en</span><br></pre></td></tr></table></figure><p>10、</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">TRAIN=<span class="variable">$tmp</span>/train.de-en      <span class="comment"># 训练语料（包含src和tgt)</span></span><br><span class="line">BPE_CODE=<span class="variable">$prep</span>/code      <span class="comment"># BPECODE文件</span></span><br><span class="line">rm -f <span class="variable">$TRAIN</span>      <span class="comment"># train.de-en如果存在就删掉</span></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span>      </span><br><span class="line">    cat <span class="variable">$tmp</span>/train.<span class="variable">$l</span> &gt;&gt; <span class="variable">$TRAIN</span>  <span class="comment"># 其实就是简单地将src语料和tgt语料按顺序放到一个文件中，方便后面联合学习bpe</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"learn_bpe.py on <span class="variable">$&#123;TRAIN&#125;</span>..."</span>      <span class="comment"># 学习BPE</span></span><br><span class="line">python <span class="variable">$BPEROOT</span>/learn_bpe.py -s <span class="variable">$BPE_TOKENS</span> &lt; <span class="variable">$TRAIN</span> &gt; <span class="variable">$BPE_CODE</span>       <span class="comment"># 这里是将源语言和目标语言的语料联合起来学BPE的，因为我们用的是train.de-en</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> L <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> train.<span class="variable">$L</span> valid.<span class="variable">$L</span> <span class="built_in">test</span>.<span class="variable">$L</span>; <span class="keyword">do</span>      <span class="comment"># 用学到的bpecode应用到三份语料中（训练语料，验证语料，测试语料）</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"apply_bpe.py to <span class="variable">$&#123;f&#125;</span>..."</span></span><br><span class="line">        python <span class="variable">$BPEROOT</span>/apply_bpe.py -c <span class="variable">$BPE_CODE</span> &lt; <span class="variable">$tmp</span>/<span class="variable">$f</span> &gt; <span class="variable">$tmp</span>/bpe.<span class="variable">$f</span>      <span class="comment"># 输出到tmp中对应的文件，以bpe.作为前缀</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>在执行<code>learn_bpe.py</code>的时候，刚开始的速度特别慢，但是速度会越来越快，最终得到<code>code</code>文件。</p><p>执行完毕之后，得到的文件结构是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">./wmt17_en_de</span><br><span class="line">├── code</span><br><span class="line">├── orig  # 原始数据集的tgz文件+解压之后的结果</span><br><span class="line">│   ├── dev</span><br><span class="line">│   ├── test-full</span><br><span class="line">│   └── training</span><br><span class="line">└── tmp</span><br><span class="line">    ├── bpe.test.de</span><br><span class="line">    ├── bpe.test.en</span><br><span class="line">    ├── bpe.train.de</span><br><span class="line">    ├── bpe.train.en</span><br><span class="line">    ├── bpe.valid.de</span><br><span class="line">    ├── bpe.valid.en</span><br><span class="line">    ├── test.de</span><br><span class="line">    ├── test.en</span><br><span class="line">    ├── train.de</span><br><span class="line">    ├── train.de-en</span><br><span class="line">    ├── train.en</span><br><span class="line">    ├── train.tags.en-de.tok.de</span><br><span class="line">    ├── train.tags.en-de.tok.en</span><br><span class="line">    ├── valid.de</span><br><span class="line">    └── valid.en</span><br></pre></td></tr></table></figure><p>11、</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">perl <span class="variable">$CLEAN</span> -ratio 1.5 <span class="variable">$tmp</span>/bpe.train <span class="variable">$src</span> <span class="variable">$tgt</span> <span class="variable">$prep</span>/train 1 250      <span class="comment"># 按照长度对训练语料和验证语料进行clean，只保留前250个token（cutoff 1-250），并将结果输出到output文件夹中</span></span><br><span class="line">perl <span class="variable">$CLEAN</span> -ratio 1.5 <span class="variable">$tmp</span>/bpe.valid <span class="variable">$src</span> <span class="variable">$tgt</span> <span class="variable">$prep</span>/valid 1 250</span><br></pre></td></tr></table></figure><p>中间输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">zhaodali@ubuntua:wmt14$ perl <span class="variable">$CLEAN</span> -ratio 1.5 <span class="variable">$tmp</span>/bpe.train <span class="variable">$src</span> <span class="variable">$tgt</span> <span class="variable">$prep</span>/train 1 250</span><br><span class="line">clean-corpus.perl: processing /mnt/private_zhaodali_cq/datasets/security/wmt14/tmp/bpe.train.en &amp; .de to /mnt/private_zhaodali_cq/datasets/security/wmt14/train, cutoff 1-250, ratio 1.5</span><br><span class="line">..........(100000)..........(200000)..........(300000)..........(400000)..........(500000)..........(600000)..........(700000)..........(800000)..........(900000)..........(1000000)..........(1100000)..........(1200000)..........(1300000)..........(1400000)..........(1500000)..........(1600000)..........(1700000)..........(1800000)..........(1900000)..........(2000000)..........(2100000)..........(2200000)..........(2300000)..........(2400000)..........(2500000)..........(2600000)..........(2700000)..........(2800000)..........(2900000)..........(3000000)..........(3100000)..........(3200000)..........(3300000)..........(3400000)..........(3500000)..........(3600000)..........(3700000)..........(3800000)..........(3900000)..........(4000000)..........(4100000)..........(4200000)..........(4300000)..........(4400000)..........(4500000)....</span><br><span class="line">Input sentences: 4544200  Output sentences:  3961179</span><br><span class="line">zhaodali@ubuntua:wmt14$ perl <span class="variable">$CLEAN</span> -ratio 1.5 <span class="variable">$tmp</span>/bpe.valid <span class="variable">$src</span> <span class="variable">$tgt</span> <span class="variable">$prep</span>/valid 1 250</span><br><span class="line">clean-corpus.perl: processing /mnt/private_zhaodali_cq/datasets/security/wmt14/tmp/bpe.valid.en &amp; .de to /mnt/private_zhaodali_cq/datasets/security/wmt14/valid, cutoff 1-250, ratio 1.5</span><br><span class="line">....</span><br><span class="line">Input sentences: 45901  Output sentences:  40058</span><br></pre></td></tr></table></figure><p>执行完毕之后，得到的文件结构是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">./wmt17_en_de</span><br><span class="line">├── code</span><br><span class="line">├── orig  # 原始数据集的tgz文件+解压之后的结果</span><br><span class="line">│   ├── dev</span><br><span class="line">│   ├── test-full</span><br><span class="line">│   └── training</span><br><span class="line">└── tmp</span><br><span class="line">│   ├── bpe.test.de</span><br><span class="line">│   ├── bpe.test.en</span><br><span class="line">│   ├── bpe.train.de</span><br><span class="line">│   ├── bpe.train.en</span><br><span class="line">│   ├── bpe.valid.de</span><br><span class="line">│   ├── bpe.valid.en</span><br><span class="line">│   ├── test.de</span><br><span class="line">│   ├── test.en</span><br><span class="line">│   ├── train.de</span><br><span class="line">│   ├── train.de-en</span><br><span class="line">│   ├── train.en</span><br><span class="line">│   ├── train.tags.en-de.tok.de</span><br><span class="line">│   ├── train.tags.en-de.tok.en</span><br><span class="line">│   ├── valid.de</span><br><span class="line">│   └── valid.en</span><br><span class="line">├── train.de</span><br><span class="line">├── train.en</span><br><span class="line">├── valid.de</span><br><span class="line">└── valid.en</span><br></pre></td></tr></table></figure><p>12、</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> L <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    cp <span class="variable">$tmp</span>/bpe.test.<span class="variable">$L</span> <span class="variable">$prep</span>/<span class="built_in">test</span>.<span class="variable">$L</span>      <span class="comment"># 对于test语料，不进行clean，直接放到output文件夹。</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>执行完毕之后，得到的文件结构是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">./wmt17_en_de</span><br><span class="line">├── code</span><br><span class="line">├── orig  # 原始数据集的tgz文件+解压之后的结果</span><br><span class="line">│   ├── dev</span><br><span class="line">│   ├── test-full</span><br><span class="line">│   └── training</span><br><span class="line">└── tmp</span><br><span class="line">│   ├── bpe.test.de  # bpe之后的结果</span><br><span class="line">│   ├── bpe.test.en</span><br><span class="line">│   ├── bpe.train.de</span><br><span class="line">│   ├── bpe.train.en</span><br><span class="line">│   ├── bpe.valid.de</span><br><span class="line">│   ├── bpe.valid.en</span><br><span class="line">│   ├── test.de</span><br><span class="line">│   ├── test.en</span><br><span class="line">│   ├── train.de  # 训练集与验证划分之后的结果</span><br><span class="line">│   ├── train.de-en</span><br><span class="line">│   ├── train.en</span><br><span class="line">│   ├── train.tags.en-de.tok.de  # 训练集与验证集</span><br><span class="line">│   ├── train.tags.en-de.tok.en</span><br><span class="line">│   ├── valid.de</span><br><span class="line">│   └── valid.en</span><br><span class="line">├── train.de  # clean之后的结果</span><br><span class="line">├── train.en</span><br><span class="line">├── valid.de</span><br><span class="line">└── valid.en</span><br><span class="line">├── test.de</span><br><span class="line">├── test.en</span><br></pre></td></tr></table></figure><h3 id="二值化"><a href="#二值化" class="headerlink" title="二值化"></a>二值化</h3><p>执行完上述指令之后，我们需要继续将数据Binarize。并且统计词频，得到vocabulary文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ../</span><br><span class="line">TEXT=./wmt17_en_de  <span class="comment"># 放置前面小节文件的根目录</span></span><br><span class="line">fairseq-preprocess \</span><br><span class="line">    --<span class="built_in">source</span>-lang en --target-lang de \</span><br><span class="line">    --trainpref <span class="variable">$TEXT</span>/train --validpref <span class="variable">$TEXT</span>/valid --testpref <span class="variable">$TEXT</span>/<span class="built_in">test</span> \</span><br><span class="line">    --destdir data-bin/wmt17_en_de --thresholdtgt 0 --thresholdsrc 0 \</span><br><span class="line">    --workers 20</span><br></pre></td></tr></table></figure><p>中间输出为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">2022-04-29 19:38:39 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion=<span class="string">'cross_entropy'</span>, dataset_impl=<span class="string">'mmap'</span>, destdir=<span class="string">'data-bin/wmt17_en_de'</span>, dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler=<span class="string">'fixed'</span>, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path=<span class="string">'/tmp/plasma'</span>, profile=False, quantization_config_path=None, reset_logging=False, scoring=<span class="string">'bleu'</span>, seed=1, simul_type=None, source_lang=<span class="string">'en'</span>, srcdict=None, suppress_crashes=False, target_lang=<span class="string">'de'</span>, task=<span class="string">'translation'</span>, tensorboard_logdir=None, testpref=<span class="string">'wmt14//test'</span>, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=<span class="string">'wmt14//train'</span>, use_plasma_view=False, user_dir=None, validpref=<span class="string">'wmt14//valid'</span>, wandb_project=None, workers=20)</span><br><span class="line">2022-04-29 19:38:57 | INFO | fairseq_cli.preprocess | [en] Dictionary: 40360 types</span><br><span class="line">2022-04-29 19:39:39 | INFO | fairseq_cli.preprocess | [en] wmt14//train.en: 3961179 sents, 116600288 tokens, 0.0% replaced by &lt;unk&gt;</span><br><span class="line">2022-04-29 19:39:39 | INFO | fairseq_cli.preprocess | [en] Dictionary: 40360 types</span><br><span class="line">2022-04-29 19:39:42 | INFO | fairseq_cli.preprocess | [en] wmt14//valid.en: 40058 sents, 1180285 tokens, 0.00322% replaced by &lt;unk&gt;</span><br><span class="line">2022-04-29 19:39:42 | INFO | fairseq_cli.preprocess | [en] Dictionary: 40360 types</span><br><span class="line">2022-04-29 19:39:44 | INFO | fairseq_cli.preprocess | [en] wmt14//test.en: 3003 sents, 81185 tokens, 0.00246% replaced by &lt;unk&gt;</span><br><span class="line">2022-04-29 19:39:44 | INFO | fairseq_cli.preprocess | [de] Dictionary: 42720 types</span><br><span class="line">2022-04-29 19:40:26 | INFO | fairseq_cli.preprocess | [de] wmt14//train.de: 3961179 sents, 119369232 tokens, 0.0% replaced by &lt;unk&gt;</span><br><span class="line">2022-04-29 19:40:26 | INFO | fairseq_cli.preprocess | [de] Dictionary: 42720 types</span><br><span class="line">2022-04-29 19:40:31 | INFO | fairseq_cli.preprocess | [de] wmt14//valid.de: 40058 sents, 1209744 tokens, 0.00116% replaced by &lt;unk&gt;</span><br><span class="line">2022-04-29 19:40:31 | INFO | fairseq_cli.preprocess | [de] Dictionary: 42720 types</span><br><span class="line">2022-04-29 19:40:32 | INFO | fairseq_cli.preprocess | [de] wmt14//test.de: 3003 sents, 84629 tokens, 0.907% replaced by &lt;unk&gt;</span><br><span class="line">2022-04-29 19:40:32 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/wmt17_en_de</span><br></pre></td></tr></table></figure><p>执行完毕之后，可以得到的文件结构如下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── data-bin</span><br><span class="line">│   ├── preprocess.log</span><br><span class="line">│   └── wmt17_en_de</span><br><span class="line">│       ├── dict.de.txt  <span class="comment"># vocabulary文件</span></span><br><span class="line">│       ├── dict.en.txt</span><br><span class="line">│       ├── preprocess.log</span><br><span class="line">│       ├── test.en-de.de.bin</span><br><span class="line">│       ├── test.en-de.de.idx</span><br><span class="line">│       ├── test.en-de.en.bin</span><br><span class="line">│       ├── test.en-de.en.idx</span><br><span class="line">│       ├── train.en-de.de.bin</span><br><span class="line">│       ├── train.en-de.de.idx</span><br><span class="line">│       ├── train.en-de.en.bin</span><br><span class="line">│       ├── train.en-de.en.idx</span><br><span class="line">│       ├── valid.en-de.de.bin</span><br><span class="line">│       ├── valid.en-de.de.idx</span><br><span class="line">│       ├── valid.en-de.en.bin</span><br><span class="line">│       └── valid.en-de.en.idx</span><br><span class="line">└── wmt17_en_de</span><br><span class="line">    ├── code</span><br><span class="line">    ├── orig  <span class="comment"># 原始数据集的tgz文件+解压之后的结果</span></span><br><span class="line">    │   ├── dev</span><br><span class="line">    │   ├── <span class="built_in">test</span>-full</span><br><span class="line">    │   ├── training</span><br><span class="line">    ├── tmp</span><br><span class="line">    │   ├── bpe.test.de</span><br><span class="line">    │   ├── bpe.test.en</span><br><span class="line">    │   ├── bpe.train.de</span><br><span class="line">    │   ├── bpe.train.en</span><br><span class="line">    │   ├── bpe.valid.de</span><br><span class="line">    │   ├── bpe.valid.en</span><br><span class="line">    │   ├── test.de</span><br><span class="line">    │   ├── test.en</span><br><span class="line">    │   ├── train.de</span><br><span class="line">    │   ├── train.de-en</span><br><span class="line">    │   ├── train.en</span><br><span class="line">    │   ├── train.tags.en-de.tok.de</span><br><span class="line">    │   ├── train.tags.en-de.tok.en</span><br><span class="line">    │   ├── valid.de</span><br><span class="line">    │   └── valid.en</span><br><span class="line">    ├── train.de</span><br><span class="line">    ├── train.en</span><br><span class="line">    ├── valid.de</span><br><span class="line">    └── valid.en</span><br><span class="line">    ├── test.de</span><br><span class="line">    ├── test.en</span><br></pre></td></tr></table></figure><p>得到的<code>data-bin</code>文件夹就是我们处理完之后的结果，可以直接用来训练和测试。因为它其中的文件已经使用bpe编码了，所以不需要<code>code</code>文件，但是仍然需要<code>dict.de.txt</code>和<code>dict.en.txt</code>用于字符与ID之间的转换。</p><p>若直接测试句子的话，仍然需要<code>code</code>文件对该句子进行编码，然后需要<code>dict.de.txt</code>和<code>dict.en.txt</code>用于字符与ID之间的转换。</p><p>另外需要注意的是，因为<code>joined_dictionary=False</code>，所以<code>dict.de.txt</code>与<code>dict.en.txt</code>文件内容是不一样的。</p><blockquote><p>joined_dictionary：源端和目标端使用同一个词表，对于相似语言（如英语和西班牙语）来说，有很多的单词是相同的，使用同一个词表可以降低词表和参数的总规模。</p></blockquote><p>所以<a href="https://github.com/pytorch/fairseq/tree/main/examples/translation#iwslt14-german-to-english-transformer" target="_blank" rel="noopener">官方教程</a>在训练时用的<code>--share-decoder-input-output-embed</code>参数。而我看另外一个<code>dict.de.txt</code>与<code>dict.en.txt</code>文件内容一致的，训练时用了<code>--share-all-embeddings</code>参数。</p><blockquote><p>可以看<a href="https://github.com/pytorch/fairseq/issues/2537#issuecomment-683989567" target="_blank" rel="noopener">这里</a>： when you specify —share-all-embeddings then the embedding matrices for encoder input, decoder input and decoder output are all shared. when you specify —share-decoder-input-output-embed, then the matrices for decoder input and output are shared, but encoder has its own embeddings. </p></blockquote><p>补充一下，当<code>--share-decoder-input-output-embed</code>时，实际对应的代码如下（<code>fairseq/models/transformer/transformer_decoder.py</code>文件中的<code>build_output_projection</code>函数）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">elif</span> self.share_input_output_embed:</span><br><span class="line">    self.output_projection = nn.Linear(</span><br><span class="line">        self.embed_tokens.weight.shape[<span class="number">1</span>],</span><br><span class="line">        self.embed_tokens.weight.shape[<span class="number">0</span>],</span><br><span class="line">        bias=<span class="literal">False</span>,</span><br><span class="line">    )</span><br><span class="line">    self.output_projection.weight = self.embed_tokens.weight  <span class="comment"># torch.Size([37056, 512])</span></span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://txshi-mt.com/2019/02/28/NMT-Tutorial-3e2-subword/" target="_blank" rel="noopener">NMT Tutorial 3扩展e第2部分. Subword</a><br><a href="https://zhuanlan.zhihu.com/p/86965595" target="_blank" rel="noopener">深入理解NLP Subword算法：BPE、WordPiece、ULM</a><br><a href="https://blog.csdn.net/weixin_38937984/article/details/103995209" target="_blank" rel="noopener">moses(mosesdecoder)数据预处理&amp;BPE分词&amp;moses用法总结</a><br><a href="https://blog.csdn.net/jmh1996/article/details/89286898" target="_blank" rel="noopener">机器翻译 bpe——bytes-pair-encoding以及开源项目subword-nmt快速入门</a><br><a href="https://leimao.github.io/blog/Byte-Pair-Encoding/" target="_blank" rel="noopener">Byte Pair Encoding</a><br><a href="https://www.dengbocong.cn/Deep-Learning/38fa61dd1a7b/" target="_blank" rel="noopener">有必要了解的Subword算法模型</a><br><a href="http://www.noobyard.com/article/p-kcottpoh-uv.html" target="_blank" rel="noopener">bpe分词算法的原理</a><br><a href="https://juejin.cn/post/7088322473640329230" target="_blank" rel="noopener">BPE 算法原理及使用指南【深入浅出】</a><br><a href="https://wmathor.com/index.php/archives/1517/" target="_blank" rel="noopener">BPE 算法详解</a><br><a href="https://www.cnblogs.com/mmxy/p/14076930.html" target="_blank" rel="noopener">WMT14 en-de翻译数据集预处理步骤</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近需要用到&lt;a href=&quot;https://github.com/pytorch/fairseq&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;fairseq&lt;/a&gt;框架中的翻译任务，这里记录一下。&lt;/p&gt;
&lt;h2 id=&quot;从实战开始&quot;&gt;&lt;a href=&quot;#从实战开始&quot; class=&quot;headerlink&quot; title=&quot;从实战开始&quot;&gt;&lt;/a&gt;从实战开始&lt;/h2&gt;&lt;p&gt;首先下载翻译模型：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mkdir -p model&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; model&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;wget https://dl.fbaipublicfiles.com/fairseq/models/wmt16.en-de.joined-dict.transformer.tar.bz2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bunzip2 wmt16.en-de.joined-dict.transformer.tar.bz2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tar -xvf wmt16.en-de.joined-dict.transformer.tar&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;解压后的文件如下：&lt;/p&gt;
    
    </summary>
    
    
      <category term="DeepLearningApplications" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/"/>
    
      <category term="自然语言处理" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
      <category term="NLP" scheme="https://www.zdaiot.com/tags/NLP/"/>
    
      <category term="fairseq" scheme="https://www.zdaiot.com/tags/fairseq/"/>
    
      <category term="translation" scheme="https://www.zdaiot.com/tags/translation/"/>
    
  </entry>
  
  <entry>
    <title>NLP基本概念</title>
    <link href="https://www.zdaiot.com/DeepLearningApplications/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/NLP%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    <id>https://www.zdaiot.com/DeepLearningApplications/自然语言处理/NLP基本概念/</id>
    <published>2022-04-25T15:29:03.000Z</published>
    <updated>2022-04-25T15:29:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>之前没有接触过NLP，所以不太理解里面的基本名词。所以这里学习一些NLP的基本概念。事先声明，以下大部分内容来源于<a href="https://www.wolai.com/suprit/efbNFtBsMPWL8XZaUVE4Qd#9ETQ482a4QuHmUxZ34ow3Y" target="_blank" rel="noopener">第1章-自然语言处理基础概念</a>和easyai的《非技术也能看懂的NLP入门科普》。不理解的地方我会加上自己的批注。</p><h2 id="自然语言"><a href="#自然语言" class="headerlink" title="自然语言"></a>自然语言</h2><p><strong>自然语言</strong>是指汉语、英语、法语等人们日常使用的语言，是自然而然的随着人类社会发展演变而来的语言，区别于如程序设计的语言的人工语言。</p><p>语音和文字是构成语言的两个基本属性，语音是语言的物质外壳，文字则是记录语言的书写符号系统。</p><h3 id="自然语言与编程语言的对比"><a href="#自然语言与编程语言的对比" class="headerlink" title="自然语言与编程语言的对比"></a>自然语言与编程语言的对比</h3><h4 id="词汇量"><a href="#词汇量" class="headerlink" title="词汇量"></a>词汇量</h4><p><strong>自然语言的词汇量的丰富程度远远超过编程语言</strong> 。例如，C 语言共有 32 个关键字，Java 有 52 个；而中文目前大约有五万多个词条，并且仍在不断增加。</p><h4 id="结构化"><a href="#结构化" class="headerlink" title="结构化"></a>结构化</h4><p>自然语言<strong>是非结构化</strong> 的，而编程语言是<strong>结构化的</strong> 。<strong>结构化指的是信息具有明确的结构关系，可以通过明确的机制来读写</strong> 。例如，Python 用 <code>apple.funder=&#39;乔布斯&#39;</code> 可以明确读取苹果公司的创始人，而中文我们可以说 <code>苹果公司的创世人是乔布斯</code>，可以说 <code>乔布斯是苹果公司的创始人</code>，还可以说 <code>只有乔布斯才可以称得上苹果公司的创始人</code>…</p><p>编程语言通过极少的词汇量 + 极强的结构化实现了各式各样的程序代码。 自然语言通过极多的词汇量 + 极弱的结构化实现了五花八门的表达方式。</p><h4 id="歧义性"><a href="#歧义性" class="headerlink" title="歧义性"></a>歧义性</h4><p><strong>自然语言中可能存在大量的歧义，而这些歧义在不同的语境下可能表现为不同的意思</strong> ，举一个经典的笑话：</p><blockquote><p>他说：“她这个人真有意思(funy)。”她说：“他这个人怪有意思的(funy)。”于是人们以为他们有了意思(wish)，并让他向她意思意思（express）。他火了：“我根本没有那个意思(thought)！”她也生气了：“你们这么说是什么意思（Intention）？”事后有人说：“真有意思(funny)。”也有人说：“真没意思(nonsense)。”</p></blockquote><p>而机器所处理的<strong>编程语言则不能具有任何歧义</strong> ，有一点歧义就会导致代码的运行错误、编译错误。</p><h4 id="容错性"><a href="#容错性" class="headerlink" title="容错性"></a>容错性</h4><p><strong>自然语言在使用中可能会出现很多错误</strong> ，例如拼写错误、语法错误、顺序错误、发音错误等，而我们人类基本都可以理解这些有一些小错误的文本。但计算机对于编程语言的要求则是<strong>绝对正确</strong> 。</p><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426000538301.png" alt="img" style="zoom:50%;"></p><h4 id="易变性"><a href="#易变性" class="headerlink" title="易变性"></a>易变性</h4><p>任何语言都不是一成不变的，例如，汉语每年会产生大量的新词汇，而编程语言 C++ 几乎每隔很多年才会修订一次。</p><h4 id="简略性"><a href="#简略性" class="headerlink" title="简略性"></a>简略性</h4><p><strong>人类语言往往简洁、干练</strong> 。我们经常省略大量背景知识或常识，比如我们会对朋友说“老地方见” ，而不必指出“ 老地方” 在哪里。对于机构名称，我们经常使用简称，比如“工行” “地税局” ，假定对方熟悉该简称。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>首先记住一条原则：<strong>计算机对编程语言要求绝对精准无误，而自然语言非常灵活随意</strong> 。自然语言处理工作重点就是解决这个矛盾。</p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">自然语言</th><th style="text-align:center">编程语言</th></tr></thead><tbody><tr><td style="text-align:center">词汇量</td><td style="text-align:center">极多</td><td style="text-align:center">极少</td></tr><tr><td style="text-align:center">结构化</td><td style="text-align:center">极弱</td><td style="text-align:center">极强</td></tr><tr><td style="text-align:center">歧义性</td><td style="text-align:center">极强</td><td style="text-align:center">极弱</td></tr><tr><td style="text-align:center">容错性</td><td style="text-align:center">极强</td><td style="text-align:center">极弱</td></tr><tr><td style="text-align:center">易变性</td><td style="text-align:center">极强</td><td style="text-align:center">极弱</td></tr><tr><td style="text-align:center">简略性</td><td style="text-align:center">极强</td><td style="text-align:center">极弱</td></tr></tbody></table></div><h2 id="自然语言处理"><a href="#自然语言处理" class="headerlink" title="自然语言处理"></a>自然语言处理</h2><p>自然语言处理（Natural Language Processing : NLP) ，就是利用计算机为工具对人类特有的书面形式和口头形式的自然语言的信息进行各种类型处理和加工的技术。——冯志伟《自然语言的计算机处理》 1996</p><p><strong>自然语言处理（NLP）分为自然语言理解（NLU）和自然语言生成（NLG）。</strong>翻译任务属于NLG。</p><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426191558666.png" alt="image-20220426191558666" style="zoom:80%;"></p><p>自然语言理解（NLU）就是希望机器像人一样，具备正常人的语言理解能力，由于自然语言在理解上有很多难点(下面详细说明)，所以NLU是至今还远不如人类的表现。</p><p>自然语言理解的5个难点：</p><ol><li>语言的多样性</li><li>语言的歧义性</li><li>语言的鲁棒性</li><li>语言的知识依赖</li><li>语言的上下文</li></ol><p>自然语言生成（NLG）是为了跨越人类和机器之间的沟通鸿沟，将非语言格式的数据转换成人类可以理解的语言格式，如文章、报告等。</p><h3 id="自然语言处理任务流程"><a href="#自然语言处理任务流程" class="headerlink" title="自然语言处理任务流程"></a>自然语言处理任务流程</h3><p>按照处理对象的颗粒度，自然语言处理的任务大致可以分为图所示的几个层次：</p><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426000556138.png" alt="img" style="zoom:50%;"></p><h3 id="自然语言处理的数据类型"><a href="#自然语言处理的数据类型" class="headerlink" title="自然语言处理的数据类型"></a>自然语言处理的数据类型</h3><p>自然语言处理系统的输入源一共有 3 个 ，即<strong>语音、图像与文本</strong> 。其中<strong>文本处理是重中之重</strong> ，<strong>其他两种数据最后也一般先要转化为文本才能进行后续的处理任务</strong> ，对应的处理分别为<strong>语音识别（Speech Recognition）和光学字符识别（Optical Character Recognition，OCR）</strong>。</p><h2 id="英文-NLP-语料预处理的6个步骤"><a href="#英文-NLP-语料预处理的6个步骤" class="headerlink" title="英文 NLP 语料预处理的6个步骤"></a>英文 NLP 语料预处理的6个步骤</h2><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426201418534.png" alt="image-20220426201418534" style="zoom:80%;"></p><ol><li>分词-Tokenization </li><li>词干提取-Stemming </li><li>词形还原-Lemmatization </li><li>词性标注-Parts of Speech </li><li>命名实体识别-NER </li><li>分块-Chunking</li></ol><h3 id="分词-Tokenization"><a href="#分词-Tokenization" class="headerlink" title="分词-Tokenization"></a>分词-Tokenization</h3><p>分词是NLP的基础任务，将句子，段落分解为字词单位，方便后续的处理的分析。</p><p>接下来我们将介绍分词的原因，中英文分词的3个区别，中文分词的3大难点，分词的3种典型方法。最后将介绍中文分词和英文分词常用的工具。</p><h4 id="什么是分词"><a href="#什么是分词" class="headerlink" title="什么是分词"></a>什么是分词</h4><p>分词是NLP的重要步骤。分词就是将句子、段落、文章这种长文本，分解为以字词为单位的数据结构，方便后续的处理分析工作。</p><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426202408499.png" alt="image-20220426202408499" style="zoom:80%;"></p><h4 id="为什么要分词"><a href="#为什么要分词" class="headerlink" title="为什么要分词"></a>为什么要分词</h4><ol><li>将复杂问题转化为数学问题：机器学习之所以可以解决很多复杂的问题，是因为它把这些问题都转化为了数学问题。而NLP也是相同的思路，文本都是一些「非结构化数据」，我们需要先将这些数据转化为「结构化数据」，结构化数据就可以转化为数学问题了，而分词就是转化的第一步。</li></ol><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426202600199.png" alt="image-20220426202600199" style="zoom:80%;"></p><ol><li><p>词是一个比较合适的粒度词是表达完整含义的最小单位。</p><p>字的粒度太小，无法表达完整含义，比如”鼠“可以是”老鼠”，也可以是”鼠标”。而句子的粒度太大，承载的信息量多，很难复用。比如”传统方法要分词，一个重要原因是传统方法对远距离依赖的建模能力较弱。</p><p>而在深度学习时代，虽然数据量和算力大幅度增长，但是大部分还是需要分词的。对于不分词的例子可以看文章 《Is Word Segmentation Necessary for Deep Learning of Chinese Representations?》。</p><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426202822779.png" alt="image-20220426202822779" style="zoom:80%;"></p></li></ol><h4 id="中英文分词的3个典型区别"><a href="#中英文分词的3个典型区别" class="headerlink" title="中英文分词的3个典型区别"></a>中英文分词的3个典型区别</h4><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426203105838.png" alt="image-20220426203105838" style="zoom:80%;"></p><p>区别1：分词方式不同，中文更难。英文有天然的空格作为分隔符，但是中文没有。所以如何切分是一个难点，再加上中文里一词多意的情况非常多，导致很容易出现歧义。下文中难点部分会详细说明。</p><p>区别2：英文单词有多种形态。英文单词存在丰富的变形变换。为了应对这些复杂的变换，英文NLP相比中文存在一些独特的处理步骤，我们称为词形还原(Lemmatization)和词干提取(Stemming) 。中文则不需要。</p><ul><li><p>词性还原：does，done，doing，did需要通过词性还原恢复成do。</p></li><li><p>词干提取：cities，children，teeth这些词，需要转换为city，child，tooth这些基本形态。</p></li></ul><p>区别3：中文分词需要考虑粒度问题例如「中国科学技术大学」就有很多种分法：</p><ul><li>中国科学技术大学</li><li>中国、科学技术、大学</li><li>中国、科学、技术、大学</li></ul><p>粒度越大，表达的意思就越准确，但是也会导致召回比较少。所以中文需要不同的场景和要求选择不同的粒度。这个在英文中是没有的。</p><h4 id="中文分词的三大难点"><a href="#中文分词的三大难点" class="headerlink" title="中文分词的三大难点"></a>中文分词的三大难点</h4><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426203605466.png" alt="image-20220426203605466" style="zoom:80%;"></p><p>难点1：没有统一的标准目前中文分词没有统一的标准，也没有公认的规范。不同的公司和组织各有各的方法和规则。</p><p>难点2：歧义词如何切分例如「兵乓球拍卖完了」就有2种分词方式表达了2种不同的含义：</p><ul><li>乒兵球\拍卖\完了</li><li>乒兵\球拍\卖完了</li></ul><p>难点3：新词的识别信息爆炸的时代，三天两头就会冒出来一堆新词。如何快速的识别出这些新词是一大难点。比如当年「蓝瘦香菇」大火，就需要快速识别。</p><h4 id="三种典型的分词方法"><a href="#三种典型的分词方法" class="headerlink" title="三种典型的分词方法"></a>三种典型的分词方法</h4><p>分词的方法大致分为3类:</p><ol><li>基于词典匹配</li><li>基于统计</li><li>基于深度学习</li></ol><p><strong>基于词典匹配的分词方式</strong></p><p>优点：速度快、成本低</p><p>缺点：适应性不强，不同领域效果差异大</p><p>基本思想是基于词典匹配，将待分词的中文文本根据一定规则切分和调整，然后跟词典中的词语进行匹配，匹配成功则按照词典的词分词，匹配失败通过调整或者重新选择，如此反复循环即可。代表方法有基于正向最大匹配和基于逆向最大匹配及双向匹配法。</p><p><strong>基于统计的分词方法</strong></p><p>优点：适应性较强</p><p>缺点：成本较高，速度较慢</p><p>这类目前常用的是算法是HMM、CRF、SVM、深度学习等算法，比如stanford、Hanlp分词工具是基于CRF算法。以CRF为例，基本思路是对汉字进行标注训练，不仅考虑了词语出现的频率，还考虑上下文，具备较好的学习能力，因此其对歧义词和未登录词的识别都具有良好的效果。</p><p><strong>基于深度学习</strong></p><p>优点：准确率高、适应性强</p><p>缺点：成本高，速度慢</p><p>例如有人员尝试使用双向LSTM+CRF实现分词器，其本质上是序列标注，所以有通用性，命名实体识别等都可以使用该模型，据报道其分词器字符准确率可高达97.5%。</p><p><strong>常见的分词器都是使用机器学习算法和词典相结合，一方面能够提高分词准确率，另一方面能够改善领域适应性。</strong></p><h4 id="中文分词工具"><a href="#中文分词工具" class="headerlink" title="中文分词工具"></a>中文分词工具</h4><p>下面排名根据GitHub上的star数排名：</p><ol><li>Hanlp</li><li>Stanford 分词</li><li>ansj 分词器</li><li>哈工大LTP</li><li>KCWS分词器</li><li>jieba</li><li>IK</li><li>清华大学THULAC</li><li>ICTCLAS</li></ol><h4 id="英文分词工具"><a href="#英文分词工具" class="headerlink" title="英文分词工具"></a>英文分词工具</h4><ol><li>Spacy</li><li>Gensim</li><li>NLTK</li><li>Moses</li></ol><p>这里重点介绍一下Moses，因为它在fairseq库的翻译任务中有使用。<a href="https://github.com/moses-smt/mosesdecoder" target="_blank" rel="noopener">Moses</a>它是一个统计机器翻译模型，我们主要使用里面的perl脚本进行数据预处理。所以确保电脑上已经安装配置好了perl（ubuntu自带）。</p><p>Moses可以做很多预处理，比如说Normalize punctuation、Tokenizer、Clean corpus、Truecase，这里只介绍Tokenizer：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对校验集和测试集做同样的操作</span></span><br><span class="line">perl dir_name/mosesdecoder/scripts/tokenizer/tokenizer.perl -a -l en &lt; data/train.norm.en &gt; data/train.norm.tok.en</span><br></pre></td></tr></table></figure><h3 id="词干提取-Stemming-和词形还原-Lemmatization"><a href="#词干提取-Stemming-和词形还原-Lemmatization" class="headerlink" title="词干提取(Stemming) 和词形还原(Lemmatization)"></a>词干提取(Stemming) 和词形还原(Lemmatization)</h3><p>词干提取和词形还原是英文语料预处理中的重要环节。虽然他们的目的一致，但是两者还是存在一些差异。</p><p>接下来将介绍他们的概念、异同、实现算法等。</p><h4 id="词干提取和词形还原在NLP中在什么位置？"><a href="#词干提取和词形还原在NLP中在什么位置？" class="headerlink" title="词干提取和词形还原在NLP中在什么位置？"></a>词干提取和词形还原在NLP中在什么位置？</h4><p>词干提取是英文语料预处理的一个步骤（中文并不需要），而语料预处理是NLP的第一步，下面这张图将让大家知道词干提取和词形还原在这个知识结构中的位置。</p><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426204556829.png" alt="image-20220426204556829" style="zoom:80%;"></p><h4 id="词干提取-Stemming"><a href="#词干提取-Stemming" class="headerlink" title="词干提取-Stemming"></a>词干提取-Stemming</h4><p>词干提取是去除单词的前后缀得到词根的过程大家常见的前后词缀有「名词的复数」、「进行式」、「过去分词」。</p><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426204725930.png" alt="image-20220426204725930" style="zoom:80%;"></p><h4 id="词形还原-Lemmatisation"><a href="#词形还原-Lemmatisation" class="headerlink" title="词形还原-Lemmatisation"></a>词形还原-Lemmatisation</h4><p>词形还原是基于词典，将单词的复杂形态转变成最基础的形态。</p><p>词形还原不是简单地将前后缀去掉，而是会根据词典将单词进行转换。比如「drove」会转换为「drive」。</p><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426204839512.png" alt="image-20220426204839512" style="zoom:80%;"></p><h4 id="为什么要做词干提取和词形还原？"><a href="#为什么要做词干提取和词形还原？" class="headerlink" title="为什么要做词干提取和词形还原？"></a>为什么要做词干提取和词形还原？</h4><p>比如当我搜索「play basketball」时，Bob is playing basketball也符合我的要求，但是play和playing对于计算机来说是2种完全不同的东西，所以我们需要将playing转换成play。</p><p><strong>词干提取和词形还原的目的就是将长相不同、但是含义相同的词统一起来，这样方便后续的处理和分析。</strong></p><h4 id="词干提取和词形还原的4个相似点"><a href="#词干提取和词形还原的4个相似点" class="headerlink" title="词干提取和词形还原的4个相似点"></a>词干提取和词形还原的4个相似点</h4><ol><li>目标一致。词干提取和词形还原的目标均为将词的屈折形态或派生形态简化或归并为词干(stem)或原形的基础形式，都是一种对词的不同形态的统一归并的过程。</li><li>结果部分交叉。词干取和词形还原不是互斥关系，其结果是有部分交叉的。一部分词利用这两类方法都能达到相同的词形转换效果。如”dogs”的词干为“dog”,其原形也为”dog”。</li><li>主流实现方法类似。目前实现词干提取和词形还原的主流实现方法均是利用语言中存在的规则或利用词典映射提取词干或获得词的原形。</li><li>应用领域相似。主要应用于信息检索和文本、自然语言处理等方面，二者均是这些应用的基本步骤。</li></ol><h4 id="词干提取和词形还原的5个不同点"><a href="#词干提取和词形还原的5个不同点" class="headerlink" title="词干提取和词形还原的5个不同点"></a>词干提取和词形还原的5个不同点</h4><ol><li>在原理上，词干提取主要是采用“缩减“的方法，将词转换为词干，如将“cas“处理为”cat”，将”effective”处理为”effect”。而词形还原主要采用“转变“的方法，将词转变为其原形，如将“drove”处理为”drive”，将”driving”处理为”drive“。</li><li>在复杂性上，词干提取方法相对简单，词形还原则需要返回词的原形，需要对词形进行分析，不仅要进行词缀的转化，还要进行词性识别，区分相同词形但原形不同的词的差别。词性标注的准确率也直接影响词形还原的准确率，因此，词形还原更为复杂。</li><li>在实现方法上，虽然词干提取和词形还原实现的主流方法类似，但二者在具体实现上各有侧重。词干提取的实现方法主要利用规则变化进行词缀的去除和缩减，从而达到词的简化效果。词形还原则相对较复杂，有复杂的形态变化，单纯依据规则无法很好地完成。其更依赖于词典，进行词形变化和原形的映射，生成词典中的有效词。</li><li>在结果上，词干提取和词形还原也有部分区别。词干提取的结果可能并不是完整的、具有意义的词，而只是词的一部分，如“reviva”词干提取的结果为”reviv“，“ailiner“词干提取的结果为“airlin”。而经词形还原处理后获得的结果是具有一定意义的、完整的词，一般为词典中的有效词。</li><li>在应用领域上，同样各有侧重。虽然二者均被应用于信息检索和文本处理中，但侧重不同。词干提取更多被应用于信息检索领域，如Solr、Lucene等，用于扩展检索，粒度较粗。词形还原更主要被应用于文本挖掘、自然语言处理，用于更细粒度、更为准确的文本分析和表达。</li></ol><h4 id="3种主流的词干提取算法"><a href="#3种主流的词干提取算法" class="headerlink" title="3种主流的词干提取算法"></a>3种主流的词干提取算法</h4><p>Porter、Snowball（推荐）、lancaster</p><h4 id="词形还原的实践方法"><a href="#词形还原的实践方法" class="headerlink" title="词形还原的实践方法"></a>词形还原的实践方法</h4><p>词形还原是基于词典的，每种语言都需要经过语义分析、词性标注来建立完整的词库，目前英文词库是很完善的。</p><p>Python中的NLTK库包含英语单词的词汇数据库。这些单词基于它们的语义关系链接在一起。链接取决于单词的含义。特别是，我们可以利用WordNet。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer</span><br><span class="line">lemmatizer = WordNetLemmatizer()</span><br><span class="line">print(lemmatizer.lemmatize(<span class="string">"blogs"</span>)) <span class="comment">#Returns blog</span></span><br></pre></td></tr></table></figure><h3 id="词性标注（Part-of-Speech，POS-Tagging）"><a href="#词性标注（Part-of-Speech，POS-Tagging）" class="headerlink" title="词性标注（Part of Speech，POS-Tagging）"></a>词性标注（Part of Speech，POS-Tagging）</h3><h4 id="什么是词性标注"><a href="#什么是词性标注" class="headerlink" title="什么是词性标注"></a>什么是词性标注</h4><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426205906549.png" alt="image-20220426205906549" style="zoom: 67%;"></p><p>维基百科上对词性的定义为: In traditional grammar, a part of speech (abbreviated form: PoS or POS) is a category of words (or, more generally, of lexical items) which have similar grammatical properties.</p><p>词性指以词的特点作为划分词类的根据。词类是一个语言学术语，是一种语言中词的语法分类，是以语法特征(包括句法功能和形态变化)为主要依据、兼顾词汇意义对词进行划分的结果。</p><p>从组合和聚合关系来说，一个词类是指：在一个语言中，众多具有相同句法功能、能在同样的组合位置中出现的词，聚合在一起形成的范畴。词类是最普遍的语法的聚合。词类划分具有层次性。如汉语中，词可以分成实词和虚词，实词中又包括体词、谓词等，体词中又可以分出名词和代词等。</p><p>词性标注就是在给定句子中判定每个词的语法范畴，确定其词性并加以标注的过程，这也是自然语言处理中一项非常重要的基础性工作，所有对于词性标注的研究已经有较长的时间，在研究者长期的研究总结中，发现汉语词性标注中面临了许多棘手的问题。</p><h4 id="中文词性标注的难点"><a href="#中文词性标注的难点" class="headerlink" title="中文词性标注的难点"></a>中文词性标注的难点</h4><p>汉语是一种缺乏词形态变化的语言，词的类别不能像印欧语那样，直接从词的形态变化上来判别。</p><p>常用词兼类现象严重。《现代汉语八百词》收取的常用词中，兼类词所占的比例高达22.5%，而且发现越是常用的词，不同的用法越多。由于兼类使用程度高，兼类现象涉及汉语中大部分词类，因而造成在汉语文本中词类歧义排除的任务量巨大。</p><p>研究者主观原因造成的困难。语言学界在词性划分的目的、标准等问题上还存在分歧。目前还没有一个统的被广泛认可汉语词类划分标准，词类划分的粒度和标记符号都不统一。</p><p>词类划分标准和标记符号集的差异，以及分词规范的含混性，给中文信息处理带来了极大的困难。</p><h4 id="词性标注4种常见方法"><a href="#词性标注4种常见方法" class="headerlink" title="词性标注4种常见方法"></a>词性标注4种常见方法</h4><p>关于词性标注的研究比较多，这里介绍一波常见的几类方法，包括基于规则的词性标注方法、基于统计模型的词性标注方法、基于统计方法与规则方法相结合的词性标注方法、基于深度学习的词性标注方法等。</p><p><strong>基于规则的词性标注方法</strong></p><p>基于规则的词性标注方法是人们提出较早的一种词性标注方法，其基本思想是按兼类词搭配关系和上下文语境建造词类消歧规则。早期的词类标注规则一般由人工构建。</p><p>随着标注语料库规模的增大，可利用的资源也变得越来越多，这时候以人工提取规则的方法显然变得不现实，于是乎，人们提出了基于机器学习的规则自动提出方法。</p><p><strong>基于统计模型的词性标注方法</strong></p><p>统计方法将词性标注看作是一个序列标注问题。其基本思想是：给定带有各自标注的词的序列，我们可以确定下一个词最可能的词性。</p><p>现在已经有隐马尔可夫模型(HMM)、条件随机域(CRF)等统计模型了，这些模型可以使用有标记数据的大型语料库进行训练，而有标记的数据则是指其中每一个词都分配了正确的词性标注的文本。</p><p><strong>基于统计方法与规则方法相结合的词性标注方法</strong></p><p>理性主义方法与经验主义相结合的处理策略一直是自然语言处理领域的专家们不断研究和探索的问题，对于词性标注问题当然也不例外。</p><p>这类方法的主要特点在于对统计标注结果的筛选，只对那些被认为可疑的标注结果，才采用规则方法进行歧义消解，而不是对所有情况都既使用统计方法又使用规则方法。</p><p><strong>基于深度学习的词性标注方法</strong></p><p>可以当作序列标注的任务来做，目前深度学习解决序列标注任务常用方法包括LSTM+CRF、BiLSTM+CRF等。</p><p>值得一提的是，这一类方法近年来文章非常多，想深入了解这一块的朋友们可以看这里：<a href="https://github.com/sebastianruder/NLP-progress/blob/master/english/part-of-speech_tagging.md" target="_blank" rel="noopener">NLP-progress-GitHub</a></p><p>最后再放一个词性标注任务数据集-<a href="https://pan.baidu.com/s/1fW908EQmyMv0XB5i0DhVyQ" target="_blank" rel="noopener">人民日报1998词性标注数据集</a></p><h4 id="词性标注工具推荐"><a href="#词性标注工具推荐" class="headerlink" title="词性标注工具推荐"></a>词性标注工具推荐</h4><p><strong>Jieba</strong></p><p>“结巴“中文分词：做最好的Python中文分词组件，可以进行词性标注。<a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener">Github地址</a></p><p><strong>SnowNLP</strong></p><p>SnowNLP是一个Python写的类库，可以方便的处理中文文本内容。<a href="https://github.com/isnowfy/snownlp" target="_blank" rel="noopener">Github地址</a></p><p><strong>THULAC</strong></p><p>THULAC(THU Lexical Analyzer for Chinese)由清华大学自然语言处理与社会人文计算实验室研制推出的一套中文词法分析工具包，具有中文分词和词性标注功能。<a href="https://github.com/thunlp/THULAC" target="_blank" rel="noopener">Github地址</a></p><p><strong>StanfordCoreNLP</strong></p><p>斯坦福NLP组的开源，支持oython接口。<a href="https://github.com/Lynten/stanford-corenlp" target="_blank" rel="noopener">Github地址</a></p><p><strong>HanLP</strong></p><p>HaLP是一系列模型与算法组成的NLP工具包，由大快搜索主导并完全开源，目标是普及自然语言处理在生产环境中的应用。<a href="https://github.com/hankcs/pyhanlp" target="_blank" rel="noopener">Github地址</a></p><p><strong>NLTK</strong></p><p>NLTK是一个高效的Python构建的平台，用来处理人类自然语言数据。<a href="https://github.com/nltk/nltk" target="_blank" rel="noopener">Github地址</a></p><p><strong>SpaCy</strong></p><p>工业级的自然语言处理工具，遗憾的是不支持中文。<a href="https://github.com/explosion/spaCy" target="_blank" rel="noopener">Github地址</a></p><h4 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h4><p>来源于<a href="https://blog.csdn.net/Sirow/article/details/89306934" target="_blank" rel="noopener">NLP中的 POS Tagging 和Chunking</a></p><p><strong>词性标注</strong>是一种监督学习解决方案，它使用前一个单词，下一个单词，首字母大写等功能。NLTK具有获取词性标注的功能，并且在<strong>断句分词</strong>(<strong>Tokenization</strong>)过程之后开始处理单词词性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">sentence = <span class="string">"My name is Jocelyn"</span> </span><br><span class="line">token = nltk.word_tokenize(sentence) <span class="comment">#分词</span></span><br><span class="line">token</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'My'</span>, <span class="string">'name'</span>, <span class="string">'is'</span>, <span class="string">'Jocelyn'</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">------------------------华丽分割线--------------------</span><br><span class="line">nltk.pos_tag(token)   <span class="comment">#词性标注</span></span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="string">'My'</span>, <span class="string">'PRP$'</span>), (<span class="string">'name'</span>, <span class="string">'NN'</span>), (<span class="string">'is'</span>, <span class="string">'VBZ'</span>), (<span class="string">'Jocelyn'</span>, <span class="string">'NNP'</span>)]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">------------------------华丽分割线--------------------</span><br><span class="line"><span class="comment"># We can get more details about any POS tag using help funciton of NLTK as follows.</span></span><br><span class="line">nltk.help.upenn_tagset(<span class="string">"PRP$"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PRP$: pronoun, possessive</span><br><span class="line">    her his mine my our ours their thy your</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">------------------------华丽分割线--------------------</span><br><span class="line">nltk.help.upenn_tagset(<span class="string">"NN"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NN: noun, common, singular <span class="keyword">or</span> mass</span><br><span class="line">    common-carrier cabbage knuckle-duster Casino afghan shed thermostat</span><br><span class="line">    investment slide humour falloff slick wind hyena override subhumanity</span><br><span class="line">    machinist ...</span><br></pre></td></tr></table></figure><p>最流行的标签集是Penn Treebank标签集。大多数已经训练过的英语标签都是在这个标签上训练的。要查看完整列表，请使用<a href="https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html" target="_blank" rel="noopener">此链接</a>。</p><h3 id="命名实体识别（NER）"><a href="#命名实体识别（NER）" class="headerlink" title="命名实体识别（NER）"></a>命名实体识别（NER）</h3><h4 id="什么是命名实体识别"><a href="#什么是命名实体识别" class="headerlink" title="什么是命名实体识别"></a>什么是命名实体识别</h4><p>命名实体识别(Named Entity Recognition，简称NER)，又称作”专名识别”，是指识别文本中具有特定意义的实体、主要包括人名、地名、机构名、专有名词等。简单的讲，就是识别自然文本中的实体指称的边界和类别。</p><h4 id="命名实体识别的发展历史"><a href="#命名实体识别的发展历史" class="headerlink" title="命名实体识别的发展历史"></a>命名实体识别的发展历史</h4><p>NER一直是NLP领域中的研究热点，从早期基于词典和规则的方法，到传统机器学习的方法，到近年来基于深度学习的方法，NER研究进展的大概趋势大致如下图所示。</p><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426211710080.png" alt="image-20220426211710080" style="zoom: 80%;"></p><h4 id="相关工具推荐"><a href="#相关工具推荐" class="headerlink" title="相关工具推荐"></a>相关工具推荐</h4><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426211826504.png" alt="image-20220426211826504" style="zoom: 67%;"></p><h3 id="分块-组块分析，Chunking"><a href="#分块-组块分析，Chunking" class="headerlink" title="分块(组块分析，Chunking)"></a>分块(组块分析，Chunking)</h3><p>来源于<a href="https://blog.csdn.net/Sirow/article/details/89306934" target="_blank" rel="noopener">NLP中的 POS Tagging 和Chunking</a></p><h4 id="什么是分块"><a href="#什么是分块" class="headerlink" title="什么是分块"></a>什么是分块</h4><p>组块分析是从非结构化文本中提取短语的过程。相对于词性标注POS-Tagging来说，POS-Tagging返回了解析树的最底层，就是一个个单词。但是有时候你需要的是几个单词构成的名词短语，而非个个单词，在这种情况下，您可以使用chunker获取您需要的信息，而不是浪费时间为句子生成完整的解析树。举个例子(中文)：与其要单个字，不如要一个词，例如，将“南非”之类的短语作为一个单独的词，而不是分别拆成“南”和“非”去理解。</p><h4 id="分块与词性标注的关系"><a href="#分块与词性标注的关系" class="headerlink" title="分块与词性标注的关系"></a>分块与词性标注的关系</h4><p>组块分析是可以接着POS-Tagging工作继续完成，它使用词性标注作为输入，并提供分析好的组块做为输出。与词性标注的标签类似，它也有一组标准的组块标签，如名词短语（np）、动词短语（vp）等，当你想从诸如位置，人名等文本中提取信息时，分块是非常重要的。在NLP中，称为命名实体识别，举个例子‘李雷的杯子’是分块分出的一个短语，而抽取’李雷’这个人名，就是命名体识别。所以，组块分析也是命名体识别的基础。</p><h4 id="实战-1"><a href="#实战-1" class="headerlink" title="实战"></a>实战</h4><p>有很多库提供现成的短语，如spacy或textblob。NLTK只是提供了一种使用正则表达式生成块的机制。为了创建NP块(名词模式)，我们将使用一个正则表达式规则来定义分块的语法。通常我们认为，一个名词词组由一个可选的限定词（dt），后跟任意数量的形容词（jj），然后是一个名词（nn），那么它就应该是名词短语NP(Noun Phrase)区块。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Example of a simple regular expression based NP chunker.</span></span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">sentence = <span class="string">"the little yellow dog barked at the cat"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Define your grammar using regular expressions#Define  </span></span><br><span class="line">grammar = (<span class="string">'''</span></span><br><span class="line"><span class="string">    NP: &#123;&lt;DT&gt;?&lt;JJ&gt;*&lt;NN&gt;&#125; # NP</span></span><br><span class="line"><span class="string">    '''</span>)</span><br><span class="line">  </span><br><span class="line">chunkParserchunkPar  = nltk.RegexpParser(grammar)</span><br><span class="line">tagged = nltk.pos_tag(nltk.word_tokenize(sentence))</span><br><span class="line">tagged</span><br></pre></td></tr></table></figure><p>结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="string">'the'</span>, <span class="string">'DT'</span>),</span><br><span class="line"> (<span class="string">'little'</span>, <span class="string">'JJ'</span>),</span><br><span class="line"> (<span class="string">'yellow'</span>, <span class="string">'JJ'</span>),</span><br><span class="line"> (<span class="string">'dog'</span>, <span class="string">'NN'</span>),</span><br><span class="line"> (<span class="string">'barked'</span>, <span class="string">'VBD'</span>),</span><br><span class="line"> (<span class="string">'at'</span>, <span class="string">'IN'</span>),</span><br><span class="line"> (<span class="string">'the'</span>, <span class="string">'DT'</span>),</span><br><span class="line"> (<span class="string">'cat'</span>, <span class="string">'NN'</span>)]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">------------------------华丽分割线--------------------</span><br><span class="line">tree = chunkParser.parse(tagged)</span><br><span class="line"><span class="keyword">for</span> subtree <span class="keyword">in</span> tree.subtrees():</span><br><span class="line">    print(subtree)</span><br></pre></td></tr></table></figure><p>结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(S</span><br><span class="line">  (NP the/DT little/JJ yellow/JJ dog/NN)</span><br><span class="line">  barked/VBD</span><br><span class="line">  at/IN</span><br><span class="line">  (NP the/DT cat/NN))</span><br><span class="line">(NP the/DT little/JJ yellow/JJ dog/NN)</span><br><span class="line">(NP the/DT cat/NN)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">------------------------华丽分割线--------------------</span><br><span class="line">tree.draw()</span><br></pre></td></tr></table></figure><p>结果</p><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/20190415101658900.png" alt="在这里插入代码片"></p><h2 id="中文-NLP-语料预处理的4个步骤"><a href="#中文-NLP-语料预处理的4个步骤" class="headerlink" title="中文 NLP 语料预处理的4个步骤"></a>中文 NLP 语料预处理的4个步骤</h2><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426202024909.png" alt="image-20220426202024909" style="zoom:80%;"></p><ol><li>中文分词- Chinese Word Segmentation </li><li>词性标注- Part of Speech</li><li>命名实体识别-NER</li><li>去除停用词</li></ol><h3 id="词法分析（中文分词、词性标注和命名实体识别）"><a href="#词法分析（中文分词、词性标注和命名实体识别）" class="headerlink" title="词法分析（中文分词、词性标注和命名实体识别）"></a>词法分析（中文分词、词性标注和命名实体识别）</h3><p><strong>中文分词、词性标注和命名实体识别都是围绕词语进行分析，统称词法分析</strong> 。词法分析的主要任务是<strong>将文本分隔为有意义的词语</strong> (中文分词) ，<strong>确定每个词语的类别和浅层的歧义消除</strong>（词性标注），并且<strong>识别出一些较长的专有名词</strong> ( 命名实体识别) 。</p><p>对中文而言，词法分析常常是后续高级任务的基础。在流水线式的系统中，如果词法分析出错，则会波及后续任务。</p><p>词法分析可以说是自然语言处理的基础任务，目前中文词法分析已经非常成熟。</p><h3 id="去掉停用词"><a href="#去掉停用词" class="headerlink" title="去掉停用词"></a>去掉停用词</h3><p>来源于<a href="https://blog.csdn.net/lztttao/article/details/104723228" target="_blank" rel="noopener">Python-中文分词并去除停用词仅保留汉字</a></p><p>对于一个由中文句子组成的列表，现在需要去除一切标点符号、空格、及数字等，仅保留中文并将句子输出为列表。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentence</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">0             巴林新增3例新冠肺炎确诊病例 累计确诊50例</span><br><span class="line">1                        稳外资外贸 中国这样做</span><br><span class="line">2             工信部：每天保障湖北地区防护服数量达25万件</span><br><span class="line">3          广东建口岸联防联控机制 疫情严重地区入境者均需隔离</span><br><span class="line">4                广州警方将全面压缩港澳商务签注办理时限</span><br><span class="line">5               他们，身处脱贫攻坚一线，又是疫情防控先锋</span><br><span class="line">6                南非卫生部：尚未考虑任何旅行或贸易禁令</span><br><span class="line">7    工信部：为湖北提供约6.5万台（套）医疗设备 基本满足防疫需要</span><br><span class="line">8              【抗疫在基层】战疫日记：防疫战中的武汉味道</span><br><span class="line">9         中国经济战“疫”录：疫情下共享经济的“危”与“机” </span><br><span class="line">Name: 标题, dtype: object</span><br></pre></td></tr></table></figure><p>首先加载re和jieba包。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> jieba</span><br></pre></td></tr></table></figure><p>接下来使用以下代码构造分词去停用词函数，其中chineseStopWords.txt为停用词库。这里的处理逻辑是：先导入停用词库形成列表，接下来对一个单独句子处理，先通过re.findall提取出句子中的每一个单独汉字，再用join函数把汉字连接成没有空格和符号的句子，再用jieba.lcut将句子分词形成列表，这里使用的是精准切割（cut_all = False），最后通过for循环，倒序检查列表的每一个元素，如果这个元素出现在停用词列表中，者将其删除，最后返回这个列表。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">stopwords = [i.strip() <span class="keyword">for</span> i <span class="keyword">in</span> open(<span class="string">'chineseStopWords.txt'</span>).readlines()]</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pretty_cut</span><span class="params">(sentence)</span>:</span></span><br><span class="line">    cut_list = jieba.lcut(<span class="string">''</span>.join(re.findall(<span class="string">'[\u4e00-\u9fa5]'</span>, sentence)), cut_all = <span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(cut_list)<span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">        <span class="keyword">if</span> cut_list[i] <span class="keyword">in</span> stopwords:</span><br><span class="line">            <span class="keyword">del</span> cut_list[i]</span><br><span class="line">    <span class="keyword">return</span> cut_list</span><br></pre></td></tr></table></figure><p>接下来通过apply函数对列表批量分词。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list(map(<span class="keyword">lambda</span> x: pretty_cut(x), sentence))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="string">'巴林'</span>, <span class="string">'新增'</span>, <span class="string">'例新冠'</span>, <span class="string">'肺炎'</span>, <span class="string">'确诊'</span>, <span class="string">'病例'</span>, <span class="string">'累计'</span>, <span class="string">'确诊'</span>, <span class="string">'例'</span>],</span><br><span class="line"> [<span class="string">'稳'</span>, <span class="string">'外资'</span>, <span class="string">'外贸'</span>, <span class="string">'中国'</span>],</span><br><span class="line"> [<span class="string">'工信部'</span>, <span class="string">'保障'</span>, <span class="string">'湖北'</span>, <span class="string">'地区'</span>, <span class="string">'防护服'</span>, <span class="string">'数量'</span>, <span class="string">'达'</span>, <span class="string">'万件'</span>],</span><br><span class="line"> [<span class="string">'广东'</span>, <span class="string">'建'</span>, <span class="string">'口岸'</span>, <span class="string">'联防'</span>, <span class="string">'联控'</span>, <span class="string">'机制'</span>, <span class="string">'疫情'</span>, <span class="string">'地区'</span>, <span class="string">'入境者'</span>, <span class="string">'均'</span>, <span class="string">'需'</span>, <span class="string">'隔离'</span>],</span><br><span class="line"> [<span class="string">'广州'</span>, <span class="string">'警方'</span>, <span class="string">'压缩'</span>, <span class="string">'港澳'</span>, <span class="string">'商务'</span>, <span class="string">'签注'</span>, <span class="string">'办理'</span>, <span class="string">'时限'</span>],</span><br><span class="line"> [<span class="string">'身处'</span>, <span class="string">'脱贫'</span>, <span class="string">'攻坚'</span>, <span class="string">'一线'</span>, <span class="string">'疫情'</span>, <span class="string">'防控'</span>, <span class="string">'先锋'</span>],</span><br><span class="line"> [<span class="string">'南非'</span>, <span class="string">'卫生部'</span>, <span class="string">'尚未'</span>, <span class="string">'旅行'</span>, <span class="string">'贸易'</span>, <span class="string">'禁令'</span>],</span><br><span class="line"> [<span class="string">'工信部'</span>, <span class="string">'湖北'</span>, <span class="string">'提供'</span>, <span class="string">'约'</span>, <span class="string">'万台'</span>, <span class="string">'套'</span>, <span class="string">'医疗'</span>, <span class="string">'设备'</span>, <span class="string">'防疫'</span>],</span><br><span class="line"> [<span class="string">'抗疫'</span>, <span class="string">'基层'</span>, <span class="string">'战疫'</span>, <span class="string">'日记'</span>, <span class="string">'防疫'</span>, <span class="string">'战中'</span>, <span class="string">'武汉'</span>, <span class="string">'味道'</span>],</span><br><span class="line"> [<span class="string">'中国'</span>, <span class="string">'经济'</span>, <span class="string">'战疫录'</span>, <span class="string">'疫情'</span>, <span class="string">'共享'</span>, <span class="string">'经济'</span>, <span class="string">'危与机'</span>]]</span><br></pre></td></tr></table></figure><h2 id="信息抽取"><a href="#信息抽取" class="headerlink" title="信息抽取"></a>信息抽取</h2><p><strong>词法分析之后，文本已经呈现出部分结构化的趋势</strong> 。至少，计算机看到的不再是一个超长的字符串，而是有意义的单词列表（分词结果），并且每个单词还附有自己的词性（词性标注结果）以及一些标签（命名实体识别）。</p><p>根据这些分词后的单词与标签，通过信息抽取我们可以抽取出一部分有用的信息。例如通过高频词抽取出关键词；根据词语之间的统计学信息抽取出关键短语乃至句子。</p><h2 id="文本分类与文本聚类"><a href="#文本分类与文本聚类" class="headerlink" title="文本分类与文本聚类"></a>文本分类与文本聚类</h2><p>将文本拆分为一系列词语之后，我们还可以在文章级别做一系列分析。</p><p>把许多文档分类进行整理称作文本分类，例如判断一段话是褒义还是贬义的，判断一封邮件是否是垃圾邮件。</p><p>把相似的文本归档到一起，或者排除重复的文档，而不关心具体类别，此时进行的任务称作文本聚类。</p><h2 id="句法分析"><a href="#句法分析" class="headerlink" title="句法分析"></a>句法分析</h2><p>词法分析只能得到零散的词汇信息，<strong>通过句法分析可以得到句子之间的语法关系</strong> 。</p><p>例如，在一些问答系统中，比如我们问智能语音助手“查询刘医生主治的内科病人”，用户真正想要查询的不是“刘医生” ，也不是“内科” ，而是“病人” 。但这三个词语都是名词，只有通过句法分析清楚他们之间的语法关系才能理清。</p><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426000616386.png" alt="img" style="zoom:50%;"></p><h2 id="语义分析"><a href="#语义分析" class="headerlink" title="语义分析"></a>语义分析</h2><p>相较于句法分析，语义分析侧重语义而非语法 。 它包括词义消歧（确定一个词在语境中的含义，而不是简单的词性）、 语义角色标注（标注句子中的谓语与其他成分的关系） 乃至语义依存分析（分析句子中词语之间的语义关系 ）。</p><h2 id="篇章分析"><a href="#篇章分析" class="headerlink" title="篇章分析"></a>篇章分析</h2><p>篇章分析可以自动分析自然语言语篇或者话语的组成结构、句际关系、语句衔接、语义连贯以及交际功能并得到相应内部表示的过程、技术和方法。</p><p>简单来说就是从更为广的视角—篇章角度进行分析，自然最为复杂也最为困难，目前很不成熟。</p><h2 id="指代消解"><a href="#指代消解" class="headerlink" title="指代消解"></a>指代消解</h2><p>指代消解指在文本中确定代词指向哪个名词短语的问题，举个例子：</p><blockquote><p>今天晚上 10 点有<strong>国足</strong> 的比赛，<strong>他们</strong> 的对手是<strong>泰国队</strong> 。在过去几年跟<strong>泰国队</strong> 的较量中<strong>他们</strong> 处于领先，只有一场惨败 1-5。</p></blockquote><p>指代消解要做的就是分辨文本中的 <code>他们</code> 指的到底是 <code>国足</code> 还是 <code>泰国队</code>。</p><h2 id="其他-NLP-任务"><a href="#其他-NLP-任务" class="headerlink" title="其他 NLP 任务"></a>其他 NLP 任务</h2><p>上述的这些任务是 NLP 中最为基础也最为重要的基本任务，除此之外还有一些更加偏向应用、与终端产品联系更为紧密的任务：</p><ul><li>自动问答，例如 Siri。</li><li>自动摘要，为一篇长文档生成简短的摘要。</li><li>自动翻译，例如中文自动翻译英文。</li><li>⚠️ 信息检索，一般认为信息检索（Information Retrieve, IR）是区别于自然语言处理的独立学科。虽然两者具有密切的联系，但 IR 的目标是查询信息，而 NLP 的目标是理解语言。</li></ul><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426000638461.png" alt="img" style="zoom:50%;"></p><h2 id="语料库"><a href="#语料库" class="headerlink" title="语料库"></a>语料库</h2><p><strong>语料库</strong>（Corpus，复数为Corpora或Corpuses）定义为：为语言研究和应用而收集的，在计算机中存储的语言材料，由自然出现的书面语或口语的样本汇集而成，用来代表特定的语言或语言变体。</p><p>语料库具有以下三个基本特征：样本代表性；规模有限性；机读形式化。‘</p><h3 id="中文分词语料库"><a href="#中文分词语料库" class="headerlink" title="中文分词语料库"></a>中文分词语料库</h3><p>中文分词语料库指的是<strong>由人工正确切分后的句子集合</strong> 。最为著名的语料库如《人民日报》语料库。</p><h3 id="词性标注语料库"><a href="#词性标注语料库" class="headerlink" title="词性标注语料库"></a>词性标注语料库</h3><p>指的是<strong>切分并为每个词语指定一个词性的语料</strong> ，每个单词后面用斜杠隔开的就是词性标签。例如：</p><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426000703581.png" alt="img"></p><h3 id="命名实体识别语料库"><a href="#命名实体识别语料库" class="headerlink" title="命名实体识别语料库"></a>命名实体识别语料库</h3><p>这种语料库人工标注了一些实体名词以及实体类别。比如《 人民日报》语料库中一共含有人名、 地名和机构名 3 种命名实体：</p><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426000721175.png" alt="img"></p><h3 id="句法分析语料库"><a href="#句法分析语料库" class="headerlink" title="句法分析语料库"></a>句法分析语料库</h3><p>这种语料库每个句子都经过了<strong>分词、 词性标注和句法标注</strong> ，即标注了单词之间的联系和关系。 例如一个句子可视化后如图所示。</p><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image-20220426000746650.png" alt="img" style="zoom:50%;"></p><h3 id="文本分类语料库"><a href="#文本分类语料库" class="headerlink" title="文本分类语料库"></a>文本分类语料库</h3><p>指的是人工标注了所属分类的文章构成的语料库，这种语料库标注最为简单，数据量也非常大。</p><h3 id="NLP-开源工具"><a href="#NLP-开源工具" class="headerlink" title="NLP 开源工具"></a>NLP 开源工具</h3><p>针对前面提到的NLP 的任务的各个流程，网上已经有了很多的开源工具可以直接使用，下边介绍最为主流的几种</p><p><img src="/DeepLearningApplications/自然语言处理/NLP基本概念/image.png" alt="img" style="zoom:50%;"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/apr15/article/details/108029160" target="_blank" rel="noopener">自然语言处理的21个基本概念</a><br><a href="https://www.cnblogs.com/sybil-hxl/p/12881509.html" target="_blank" rel="noopener">NLP（一）基本概念和基础知识 </a><br><a href="https://www.wolai.com/suprit/efbNFtBsMPWL8XZaUVE4Qd#9ETQ482a4QuHmUxZ34ow3Y" target="_blank" rel="noopener">第1章-自然语言处理基础概念</a><br><a href="https://blog.csdn.net/Sirow/article/details/89306934" target="_blank" rel="noopener">NLP中的 POS Tagging 和Chunking</a><br><a href="https://blog.csdn.net/lztttao/article/details/104723228" target="_blank" rel="noopener">Python-中文分词并去除停用词仅保留汉字</a><br><a href="https://blog.csdn.net/Elenore1997/article/details/89483681" target="_blank" rel="noopener">使用Moses脚本进行数据预处理</a><br><a href="https://blog.csdn.net/weixin_38937984/article/details/103995209" target="_blank" rel="noopener">moses(mosesdecoder)数据预处理&amp;BPE分词&amp;moses用法总结</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前没有接触过NLP，所以不太理解里面的基本名词。所以这里学习一些NLP的基本概念。事先声明，以下大部分内容来源于&lt;a href=&quot;https://www.wolai.com/suprit/efbNFtBsMPWL8XZaUVE4Qd#9ETQ482a4QuHmUxZ34ow3Y&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;第1章-自然语言处理基础概念&lt;/a&gt;和easyai的《非技术也能看懂的NLP入门科普》。不理解的地方我会加上自己的批注。&lt;/p&gt;
&lt;h2 id=&quot;自然语言&quot;&gt;&lt;a href=&quot;#自然语言&quot; class=&quot;headerlink&quot; title=&quot;自然语言&quot;&gt;&lt;/a&gt;自然语言&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;自然语言&lt;/strong&gt;是指汉语、英语、法语等人们日常使用的语言，是自然而然的随着人类社会发展演变而来的语言，区别于如程序设计的语言的人工语言。&lt;/p&gt;
&lt;p&gt;语音和文字是构成语言的两个基本属性，语音是语言的物质外壳，文字则是记录语言的书写符号系统。&lt;/p&gt;
&lt;h3 id=&quot;自然语言与编程语言的对比&quot;&gt;&lt;a href=&quot;#自然语言与编程语言的对比&quot; class=&quot;headerlink&quot; title=&quot;自然语言与编程语言的对比&quot;&gt;&lt;/a&gt;自然语言与编程语言的对比&lt;/h3&gt;
    
    </summary>
    
    
      <category term="DeepLearningApplications" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/"/>
    
      <category term="自然语言处理" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
      <category term="NLP" scheme="https://www.zdaiot.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Transformer原理</title>
    <link href="https://www.zdaiot.com/DeepLearningApplications/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/Transformer%E5%8E%9F%E7%90%86/"/>
    <id>https://www.zdaiot.com/DeepLearningApplications/自然语言处理/Transformer原理/</id>
    <published>2022-04-24T14:18:03.000Z</published>
    <updated>2022-04-24T14:18:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>Transformer由论文<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">《Attention is All You Need》</a>提出。学（烤）习（贝）一下。实现声明，本文大部分内容来源于<a href="https://zhuanlan.zhihu.com/p/338817680" target="_blank" rel="noopener">Transformer模型详解（图解最完整版）</a>，对于不理解的地方，我会加上个人注解。</p><h2 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h2><p>首先介绍 Transformer 的整体结构，下图是 Transformer 用于中英文翻译的整体结构：</p><p><img src="https://pic4.zhimg.com/v2-4544255f3f24b7af1e520684ae38403f_b.jpg" alt="img" style="zoom: 67%;"></p><p>可以看到 <strong>Transformer 由 Encoder 和 Decoder 两个部分组成</strong>，各包含 6 个 block。它的工作流程大体如下：</p><p><strong>第一步：</strong>获取输入句子的每一个单词的表示向量 <strong>x</strong>，<strong>x</strong>由<strong>单词的 Embedding（从原始数据提取出来的Feature） 和单词位置的 Embedding</strong> 相加得到。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-7dd39c44b0ae45d31a3ae7f39d3f883f_b.jpg" alt="img" style="zoom:80%;"></p><p><strong>第二步：</strong>将得到的单词表示向量矩阵 (如上图所示，每一行是一个单词的表示 <strong>x</strong>) 传入 Encoder 中，经过 6 个 Encoder block 后可以得到句子所有单词的编码信息矩阵 <strong>C</strong>，如下图。单词向量矩阵用$X_{n,d}$表示， n 是句子中单词个数，d 是表示向量的维度 (论文中 d=512)。每一个 Encoder block 输出的矩阵维度与输入完全一致。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-45db05405cb96248aff98ee07a565baa_b.jpg" alt="img" style="zoom: 50%;"></p><p><strong>第三步</strong>：将 Encoder 输出的编码信息矩阵 <strong>C</strong> 传递到 Decoder 中，Decoder 依次会根据当前翻译过的单词 1~ i 翻译下一个单词 i+1，如下图所示。在使用的过程中，翻译到单词 i+1 的时候需要通过 <strong>Mask (掩盖)</strong> 操作遮盖住 i+1 之后的单词。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-5367bd47a2319397317562c0da77e455_b.jpg" alt="img"></p><p>上图 Decoder 接收了 Encoder 的编码矩阵 <strong>C</strong>，然后首先输入一个翻译开始符 “<begin>“，预测第一个单词 “I”；然后输入翻译开始符 “<begin>“ 和单词 “I”，预测单词 “have”，以此类推。这是 Transformer 使用时候的大致流程，接下来是里面各个部分的细节。</begin></begin></p><h2 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h2><p>Transformer 中单词的输入表示 <strong>x</strong>由<strong>单词 Embedding</strong> 和<strong>位置 Embedding</strong> （Positional Encoding）相加得到。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-b0a11f97ab22f5d9ebc396bc50fa9c3f_b.jpg" alt="img" style="zoom:80%;"></p><h3 id="单词-Embedding"><a href="#单词-Embedding" class="headerlink" title="单词 Embedding"></a>单词 Embedding</h3><p>单词的 Embedding 有很多种方式可以获取，例如可以采用 <strong>Word2Vec、Glove</strong> 等算法预训练得到，也可以在 Transformer 中训练得到（比如fairseq的翻译模型就利用了<code>torch.nn.Embedding</code>进行Embedding并训练）。</p><h3 id="位置-Embedding"><a href="#位置-Embedding" class="headerlink" title="位置 Embedding"></a>位置 Embedding</h3><p>Transformer 中除了单词的 Embedding，还需要使用位置 Embedding 表示单词出现在句子中的位置。<strong>因为 Transformer 不采用 RNN 的结构，而是使用全局信息，不能利用单词的顺序信息，而这部分信息对于 NLP 来说非常重要。</strong>所以 Transformer 中使用位置 Embedding 保存单词在序列中的相对或绝对位置。</p><p>位置 Embedding 用 <strong>PE</strong>表示，<strong>PE</strong> 的维度与单词 Embedding 是一样的。PE 可以通过训练得到，也可以使用某种公式计算得到。在 Transformer 中采用了后者，计算公式如下：</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-8b442ffd03ea0f103e9acc37a1db910a_b.jpg" alt="img" style="zoom:50%;"></p><p>其中，pos 表示单词在句子中的位置，d 表示 PE的维度 (与词 Embedding 一样)，2i 表示偶数的维度，2i+1 表示奇数维度 (即 2i≤d, 2i+1≤d)。使用这种公式计算 PE 有以下的好处：</p><ul><li>使 PE 能够适应比训练集里面所有句子更长的句子，假设训练集里面最长的句子是有 20 个单词，突然来了一个长度为 21 的句子，则使用公式计算的方法可以计算出第 21 位的 Embedding。</li><li>可以让模型容易地计算出相对位置，对于固定长度的间距 k，<strong>PE(pos+k)</strong> 可以用 <strong>PE(pos)</strong> 计算得到。因为 Sin(A+B) = Sin(A)Cos(B) + Cos(A)Sin(B), Cos(A+B) = Cos(A)Cos(B) - Sin(A)Sin(B)。</li></ul><p>将单词的词 Embedding 和位置 Embedding 相加，就可以得到单词的表示向量 <strong>x</strong>，<strong>x</strong> 就是 Transformer 的输入。</p><h2 id="Self-Attention（自注意力机制）"><a href="#Self-Attention（自注意力机制）" class="headerlink" title="Self-Attention（自注意力机制）"></a>Self-Attention（自注意力机制）</h2><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-f6380627207ff4d1e72addfafeaff0bb_b.jpg" alt="img" style="zoom: 67%;"></p><p>上图是论文中 Transformer 的内部结构图，左侧为 Encoder block，右侧为 Decoder block。红色圈中的部分为 <strong>Multi-Head Attention</strong>，是由多个 <strong>Self-Attention</strong>组成的，可以看到 Encoder block 包含一个 Multi-Head Attention，而 Decoder block 包含两个 Multi-Head Attention (其中有一个用到 Masked)。Multi-Head Attention 上方还包括一个 Add &amp; Norm 层，Add 表示残差连接 (Residual Connection) 用于防止网络退化，Norm 表示 Layer Normalization，用于对每一层的激活值进行归一化。</p><p>因为 <strong>Self-Attention</strong>是 Transformer 的重点，所以我们重点关注 Multi-Head Attention 以及 Self-Attention，首先详细了解一下 Self-Attention 的内部逻辑。</p><h3 id="Self-Attention-结构"><a href="#Self-Attention-结构" class="headerlink" title="Self-Attention 结构"></a>Self-Attention 结构</h3><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-6444601b4c41d99e70569b0ea388c3bd_b.jpg" alt="img" style="zoom: 67%;"></p><p>上图是 Self-Attention 的结构，在计算的时候需要用到矩阵<strong>Q(查询),K(键值),V(值)</strong>。在实际中，Self-Attention 接收的是输入(单词的表示向量<strong>x</strong>组成的矩阵<strong>X</strong>) 或者上一个 Encoder block 的输出。而<strong>Q,K,V</strong>正是通过 Self-Attention 的输入进行线性变换得到的。</p><h3 id="Q-K-V-的计算"><a href="#Q-K-V-的计算" class="headerlink" title="Q, K, V 的计算"></a>Q, K, V 的计算</h3><p>Self-Attention 的输入用矩阵<strong>X</strong>进行表示，则可以使用线性变阵矩阵<strong>WQ,WK,WV</strong>计算得到<strong>Q,K,V</strong>。计算如下图所示，<strong>注意 X, Q, K, V 的每一行都表示一个单词。</strong></p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-4f4958704952dcf2c4b652a1cd38f32e_b.jpg" alt="img" style="zoom:50%;"></p><h3 id="Self-Attention-的输出"><a href="#Self-Attention-的输出" class="headerlink" title="Self-Attention 的输出"></a>Self-Attention 的输出</h3><p>得到矩阵 <strong>Q, K, V</strong> 之后就可以计算出 Self-Attention 的输出了，计算的公式如下（先计算括号内+softmax，然后乘上<strong>V</strong>）：</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-9699a37b96c2b62d22b312b5e1863acd_b.jpg" alt="img" style="zoom:50%;"></p><p>公式中计算矩阵<strong>Q</strong>和<strong>K</strong>每一行向量的内积，为了防止内积过大，因此除以$d_k$的平方根。<strong>Q</strong>乘以<strong>K</strong>的转置后，<strong>得到的矩阵行列数都为 n，n 为句子单词数，这个矩阵可以表示单词之间的 attention 强度。</strong>下图为<strong>Q</strong>乘以$K^T$，1234 表示的是句子中的单词。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-9caab2c9a00f6872854fb89278f13ee1_b.jpg" alt="img" style="zoom:80%;"></p><p>得到 $QK^T$ 之后，使用 Softmax 计算每一个单词对于其他单词的 attention 系数，公式中的 Softmax 是对矩阵的每一行进行 Softmax，即每一行的和都变为 1。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-96a3716cf7f112f7beabafb59e84f418_b.jpg" alt="img" style="zoom:80%;"></p><p>得到 Softmax 矩阵之后可以和<strong>V</strong>相乘，得到最终的输出<strong>Z</strong>。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-7ac99bce83713d568d04e6ecfb31463b_b.jpg" alt="img" style="zoom:80%;"></p><p>上图中 Softmax 矩阵的第 1 行表示单词 1 与其他所有单词的 attention 系数，<strong>最终单词 1 的输出$Z_1$等于所有单词 $i$ 的值 $V_i$ 根据 attention 系数的比例加在一起得到</strong>，如下图所示：</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-27822b2292cd6c38357803093bea5d0e_bc.jpg" alt="img"></p><h3 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h3><p>在上一步，我们已经知道怎么通过 Self-Attention 计算得到输出矩阵 <strong>Z</strong>，而 Multi-Head Attention 是由多个 Self-Attention 组合形成的，下图是论文中 Multi-Head Attention 的结构图。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-b0ea8f5b639786f98330f70405e94a75_b.jpg" alt="img" style="zoom:50%;"></p><p>从上图可以看到 Multi-Head Attention 包含多个 Self-Attention 层，首先将输入<strong>X</strong>分别传递到 h 个不同的 Self-Attention 中（也就是说会有8个不同的<strong>V、K、Q</strong>），计算得到 h 个输出矩阵<strong>Z</strong>。下图是 h=8 时候的情况，此时会得到 8 个输出矩阵<strong>Z</strong>。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-6bdaf739fd6b827b2087b4e151c560f4_b.jpg" alt="img" style="zoom:50%;"></p><p>得到 8 个输出矩阵 <strong>Z1</strong> 到 <strong>Z8</strong> 之后，Multi-Head Attention 将它们拼接在一起 <strong>(Concat)</strong>，然后传入一个<strong>Linear</strong>层，得到 Multi-Head Attention 最终的输出<strong>Z</strong>。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-35d78d9aa9150ae4babd0ea6aa68d113_b.jpg" alt="img" style="zoom:90%;"></p><p>可以看到 Multi-Head Attention 输出的矩阵<strong>Z</strong>与其输入的矩阵<strong>X</strong>的维度是一样的。</p><h2 id="Encoder-结构"><a href="#Encoder-结构" class="headerlink" title="Encoder 结构"></a>Encoder 结构</h2><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-0203e83066913b53ec6f5482be092aa1_b.jpg" alt="img" style="zoom:60%;"></p><p>上图红色部分是 Transformer 的 Encoder block 结构，可以看到是由 Multi-Head Attention, <strong>Add &amp; Norm, Feed Forward, Add &amp; Norm</strong> 组成的。刚刚已经了解了 Multi-Head Attention 的计算过程，现在了解一下 Add &amp; Norm 和 Feed Forward 部分。</p><h3 id="Add-amp-Norm"><a href="#Add-amp-Norm" class="headerlink" title="Add &amp; Norm"></a>Add &amp; Norm</h3><p>Add &amp; Norm 层由 Add 和 Norm 两部分组成，其计算公式如下（以下分别表示上图红色部分第一个和第二个Add &amp; Norm 层）：</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-a4b35db50f882522ee52f61ddd411a5a_b.jpg" alt="img" style="zoom:50%;"></p><p>其中 <strong>X</strong> 表示 Multi-Head Attention 或者 Feed Forward 的输入，MultiHeadAttention(<strong>X</strong>) 和 FeedForward(<strong>X</strong>) 表示输出 (输出与输入 <strong>X</strong> 维度是一样的，所以可以相加)。</p><p><strong>Add</strong>指 <strong>X</strong>+MultiHeadAttention(<strong>X</strong>)或者<strong>X</strong>+FeedForward(<strong>X</strong>)，是一种残差连接，通常用于<strong>解决多层网络训练的问题，可以让网络只关注当前差异的部分</strong>，在 ResNet 中经常用到：</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-4b3dde965124bd00f9893b05ebcaad0f_b.jpg" alt="img" style="zoom:67%;"></p><p><strong>Norm</strong>指 Layer Normalization，通常用于 RNN 结构，Layer Normalization 会将每一层神经元的输入都转成均值方差都一样的，这样可以<strong>加快收敛</strong>。</p><h3 id="Feed-Forward"><a href="#Feed-Forward" class="headerlink" title="Feed Forward"></a>Feed Forward</h3><p>Feed Forward 层比较简单，是一个两层的全连接层，第一层的激活函数为 Relu，第二层不使用激活函数，对应的公式如下。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-47b39ca4cc3cd0be157d6803c8c8e0a1_b.jpg" alt="img" style="zoom:50%;"></p><p><strong>X</strong>是输入，Feed Forward 最终得到的输出矩阵的维度与<strong>X</strong>一致。</p><h3 id="组成-Encoder"><a href="#组成-Encoder" class="headerlink" title="组成 Encoder"></a>组成 Encoder</h3><p>通过上面描述的 Multi-Head Attention, Feed Forward, Add &amp; Norm 就可以构造出一个 Encoder block，Encoder block 接收输入矩阵 $X_{(n\times d)}$，并输出一个矩阵 $O_{(n\times d)}$。通过<strong>多个 Encoder block 叠加就可以组成 Encoder。</strong></p><p>第一个 Encoder block 的输入为句子单词的表示向量矩阵，后续 Encoder block 的输入是前一个 Encoder block 的输出，最后一个 Encoder block 输出的矩阵就是<strong>编码信息矩阵 C</strong>，这一矩阵后续会用到 Decoder 中。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-45db05405cb96248aff98ee07a565baa_b-20220424232200361.jpg" alt="img" style="zoom:50%;"></p><h2 id="Decoder-结构"><a href="#Decoder-结构" class="headerlink" title="Decoder 结构"></a>Decoder 结构</h2><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-f5049e8711c3abe8f8938ced9e7fc3da_b.jpg" alt="img" style="zoom:60%;"></p><p>上图红色部分为 Transformer 的 Decoder block 结构，与 Encoder block 相似，但是存在一些区别：</p><ul><li>包含两个 Multi-Head Attention 层。</li><li>第一个 Multi-Head Attention 层采用了 Masked 操作。</li><li>第二个 Multi-Head Attention 层的<strong>K, V</strong>矩阵使用 Encoder 的<strong>编码信息矩阵C</strong>进行计算，而<strong>Q</strong>使用上一个 Decoder block 的输出计算。</li><li>最后有一个 Softmax 层计算下一个翻译单词的概率。</li></ul><h3 id="第一个-Multi-Head-Attention"><a href="#第一个-Multi-Head-Attention" class="headerlink" title="第一个 Multi-Head Attention"></a>第一个 Multi-Head Attention</h3><p>Decoder block 的第一个 Multi-Head Attention 采用了 Masked 操作，因为在翻译的过程中是顺序翻译的，即翻译完第 i 个单词，才可以翻译第 i+1 个单词。通过 Masked 操作可以防止第 i 个单词知道 i+1 个单词之后的信息。下面以 “我有一只猫” 翻译成 “I have a cat” 为例，了解一下 Masked 操作。</p><p>下面的描述中使用了类似 Teacher Forcing 的概念，在 Decoder 的时候，是需要根据之前的翻译，求解当前最有可能的翻译，如下图所示。首先根据输入 “<begin>“ 预测出第一个单词为 “I”，然后根据输入 “<begin> I” 预测下一个单词 “have”。</begin></begin></p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-4616451fe8aa59b2df2ead30fa31dc98_b.jpg" alt="img"></p><p>Decoder 可以在训练的过程中使用 Teacher Forcing 并且并行化训练，即将正确的单词序列 (<begin> I have a cat) 和对应输出 (I have a cat <end>) 传递到 Decoder。那么在预测第 i 个输出时，就要将<strong>输出序列</strong>第 i+1 之后的单词掩盖住（输入序列不需要遮挡），<strong>注意 Mask 操作是在 Self-Attention 的 Softmax 之前使用的，下面用 0 1 2 3 4 5 分别表示 “<begin> I have a cat <end>“。</end></begin></strong></end></begin></p><p><strong>第一步：</strong>先介绍 Decoder 的输入矩阵和 <strong>Mask</strong> 矩阵，输入矩阵包含 “<begin> I have a cat” (0, 1, 2, 3, 4) 五个单词的表示向量，<strong>Mask</strong> 是一个 5×5 的矩阵。在 <strong>Mask</strong> 可以发现单词 0 只能使用单词 0 的信息，而单词 1 可以使用单词 0, 1 的信息，即只能使用之前的信息（从图中可以看出，Mask操作必须放在Softmax之前，否则还是利用到了之后的信息）。</begin></p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-b26299d383aee0dd42b163e8bda74fc8_b.jpg" alt="img" style="zoom:80%;"></p><p><strong>第二步：</strong>接下来的操作和之前的 Self-Attention 一样，通过输入矩阵<strong>X</strong>计算得到<strong>Q,K,V</strong>矩阵。然后计算<strong>Q</strong>和 $K^T$ 的乘积 $QK^T$ 。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-a63ff9b965595438ed0c0e0547cd3d3b_b.jpg" alt="img" style="zoom:80%;"></p><p><strong>第三步：</strong>在得到 $QK^T$ 之后需要进行 Softmax，计算 attention score，我们在 Softmax 之前需要使用<strong>Mask</strong>矩阵遮挡住每一个单词之后的信息，遮挡操作如下：</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-35d1c8eae955f6f4b6b3605f7ef00ee1_b.jpg" alt="img"></p><blockquote><p>也有可能不是按位相乘，而是让 $QK^T$ 中mask==0的对应位置，是一个极小值，这样这些位置在经过softmax后，值仍然很小。</p></blockquote><p>得到 <strong>Mask</strong> $QK^T$ 之后在 <strong>Mask</strong> $QK^T$上进行 Softmax，每一行的和都为 1。但是<strong>单词 0 在单词 1, 2, 3, 4 上的 attention score 都为 0。</strong></p><p><strong>第四步：</strong>使用 <strong>Mask</strong> $QK^T$与矩阵 <strong>V</strong>相乘，得到输出 <strong>Z</strong>，则单词 1 的输出向量 $Z1$ 是只包含单词 1 信息的。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-58f916c806a6981e296a7a699151af87_b.jpg" alt="img" style="zoom:80%;"></p><p>为什么说这样可以保证单词 1 的输出向量 $Z1$ 是只包含单词 1 信息的，可以看如下这个图理解这个矩阵相乘。</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/aaa.jpg" alt="aaa"></p><p><strong>第五步：</strong>通过上述步骤就可以得到一个 Mask Self-Attention 的输出矩阵 $Z_i$ ，然后和 Encoder 类似，通过 Multi-Head Attention 拼接多个输出$Z_i$ 然后计算得到第一个 Multi-Head Attention 的输出<strong>Z</strong>，<strong>Z</strong>与输入<strong>X</strong>维度一样。</p><h3 id="第二个-Multi-Head-Attention"><a href="#第二个-Multi-Head-Attention" class="headerlink" title="第二个 Multi-Head Attention"></a>第二个 Multi-Head Attention</h3><p>Decoder block 第二个 Multi-Head Attention 变化不大， 主要的区别在于其中 Self-Attention 的 <strong>K, V</strong>矩阵不是使用 上一个 Decoder block 的输出计算的，而是使用 <strong>Encoder 的编码信息矩阵 C</strong> 计算的。</p><p>根据 Encoder 的输出 <strong>C</strong>计算得到 <strong>K, V</strong>，根据上一个 Mask Multi-Head Attention的输出 <strong>Z</strong> 计算 <strong>Q</strong> （因为此时得到的<strong>Z</strong>已经经过了mask，所以无需再次mask了），后续的计算方法与之前描述的一致。</p><p>这样做的好处是在 Decoder 的时候，每一位单词都可以利用到 Encoder 所有单词的信息 (这些信息无需 <strong>Mask</strong>)。</p><h3 id="Softmax-预测输出单词"><a href="#Softmax-预测输出单词" class="headerlink" title="Softmax 预测输出单词"></a>Softmax 预测输出单词</h3><p>Decoder block 最后的部分是利用 Softmax 预测下一个单词，在之前的网络层我们可以得到一个最终的输出 Z，因为 Mask 的存在，使得单词 0 的输出 Z0 只包含单词 0 的信息，如下：</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-335cfa1b345bdd5cf1e212903bb9b185_b.jpg" alt="img" style="zoom:80%;"></p><p>Softmax 根据输出矩阵的每一行预测下一个单词：</p><p><img src="/DeepLearningApplications/自然语言处理/Transformer原理/v2-0938aa45a288b5d6bef6487efe53bd9d_b.jpg" alt="img" style="zoom:80%;"></p><p>这就是 Decoder block 的定义，与 Encoder 一样，Decoder 是由多个 Decoder block 组合而成。</p><h2 id="Transformer-总结"><a href="#Transformer-总结" class="headerlink" title="Transformer 总结"></a>Transformer 总结</h2><ul><li>Transformer 与 RNN 不同，可以比较好地并行训练。</li><li>Transformer 本身是不能利用单词的顺序信息的，因此需要在输入中添加位置 Embedding，否则 Transformer 就是一个词袋模型了。</li><li>Transformer 的重点是 Self-Attention 结构，其中用到的 <strong>Q, K, V</strong>矩阵通过输出进行线性变换得到。</li><li>Transformer 中 Multi-Head Attention 中有多个 Self-Attention，可以捕获单词之间多种维度上的相关系数 attention score。</li></ul><h2 id="疑问解决"><a href="#疑问解决" class="headerlink" title="疑问解决"></a>疑问解决</h2><h3 id="Decoder中是否用了真实标签"><a href="#Decoder中是否用了真实标签" class="headerlink" title="Decoder中是否用了真实标签"></a>Decoder中是否用了真实标签</h3><p>训练时：第i个decoder的输入 = encoder输出 + ground truth embeding</p><p>预测时：第i个decoder的输入 = encoder输出 + 第(i-1)个decoder输出</p><p>训练时因为知道ground truth embeding，相当于知道正确答案，网络可以一次训练完成。</p><p>预测时，首先输入start，输出预测的第一个单词 然后start和新单词组成新的query，再输入decoder来预测下一个单词，循环往复 直至end</p><h3 id="Softmax怎么将输出矩阵的行向量映射到相应的单词？"><a href="#Softmax怎么将输出矩阵的行向量映射到相应的单词？" class="headerlink" title="Softmax怎么将输出矩阵的行向量映射到相应的单词？"></a>Softmax怎么将输出矩阵的行向量映射到相应的单词？</h3><p>行向量代表着单词的类型，输出概率最大的那个位置就是预测的单词。行向量中单词的位置是固定的，只需要找位置信息就能找到相应的单词了。</p><h3 id="Transformer中的mask"><a href="#Transformer中的mask" class="headerlink" title="Transformer中的mask"></a>Transformer中的mask</h3><p>在《<a href="https://github.com/harvardnlp/annotated-transformer" target="_blank" rel="noopener">the annotated transformer</a>》中有多个mask，这里总结一下。</p><p>整个模型中使用到的mask主要就是source mask和target mask，其各自的作用如下所示：</p><ol><li>source mask：</li></ol><ul><li><p>source长短不一而无法形成batch，因此引入了pad。将source mask传入到encoder中，让attention在计算$\mathrm{softmax}(\frac{QK^T}{\sqrt{d_k}})$时，pad位置的值不起作用。</p></li><li><p>同时这个mask还需要传入每个decoderLayer第二个multi-head attention模块中，就是防止来自encoder的key和来自decoder的query在计算多头注意力的时候算了target中的词和source中pad的权重</p></li></ul><ol><li>target mask：需要分training和testing进行讨论</li></ol><ul><li><strong>训练</strong>时，用于防止target的ground truth长短不一引入pad造成的误差，以及<strong>避免在自回归时看到正在预测的字和以后字的ground truth</strong></li><li><strong>测试</strong>时，逻辑上decoder不需要target mask，但出于编程方便的考虑引入mask，假装用于防止看到后面的ground truth，target mask的最后两维的shape和目前生成出来的序列长度相同，但实际上每次都会有一些重复运算在里面，比如目前在预测第10个词时，第1-9个词还需要重新算一遍。核心原因是：模型在写的时候主要考虑的是训练，执行一次attention函数翻译完一个batch的所有句子，而测试时必须是单个或多个句子word by word进行计算</li></ul><h3 id="Teacher-Forcing是什么"><a href="#Teacher-Forcing是什么" class="headerlink" title="Teacher Forcing是什么"></a>Teacher Forcing是什么</h3><blockquote><p>我把这个概念放在了这里，前文没提到这个，现在知识不成体系，不知道放哪合适。</p></blockquote><p>Teacher Forcing 是一种用于序列生成任务的训练技巧，与Autoregressive模式相对应，这里阐述下两者的区别：</p><ul><li>Autoregressive 模式下，在 timesteps $t$ decoder模块的输入是 timesteps $t-1$ 的输出 $y_{t-1}$。这时候我们称  $y_{t-1}$为当前预测步的 context;</li><li>Teacher-Forcing 模式下，在 timestep $t$  decoder模块的输入是 Ground-truth 语句中位置的  $y_{t-1}^<em>$ 单词。这时候我们称 $y_{t-1}^</em>$为当前预测步的 context；</li></ul><p>Teacher-Forcing 技术之所以作为一种有用的训练技巧，主要是因为：</p><ul><li>Teacher-Forcing 能够在训练的时候矫正模型的预测，避免在序列生成的过程中误差进一步放大。</li><li>Teacher-Forcing 能够极大的加快模型的收敛速度，令模型训练过程更加快&amp;平稳。</li><li><strong>Teacher-Forcing 技术是保证 Transformer 模型能够在训练过程中完全并行计算所有token的关键技术。</strong></li></ul><blockquote><p>如果要用比较不太严谨的比喻来说，Teacher-Forcing 技术相当于就是小明学习的时候旁边坐了一位学霸，当发现小明在做序列生成题目的时候， 每一步都把上一步的正确答案给他偷看。那么小明当然只需要顺着上一步的答案的思路，计算出这一步的结果就行了。这种做法，比起自己每一步都瞎猜， 当然能够有效的避免误差进一步放大，同时在学习前期还能通过学霸辅导的这种方式快速学到很多的知识。</p></blockquote><p>Teacher Forcing 最常见的问题就是 Exposure Bias 了。</p><blockquote><p>模型在训练时基于真实的描述句来生成下一个词，但在测试的时候，它只能基于模型自己的生成结果来生成下一个词，模型自己的生成结果有可能是错的，一旦出错，就会让模型处于一个在训练阶段没有见过的情况，从而导致在生成过程中的误差逐渐累积</p></blockquote><p>上面的『比喻』，其实就是不太严谨的 Exposure Bias 现象了。更严谨的表述，由于训练和预测的时候decode行为的不一致， 导致预测单词（predict words）在训练和预测的时候是<strong>从不同的分布中推断出来的</strong>。而这种不一致导致训练模型和预测模型直接的Gap，就叫做 Exposure Bias。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/338817680" target="_blank" rel="noopener">Transformer模型详解（图解最完整版）</a><br><a href="https://zhuanlan.zhihu.com/p/504408727" target="_blank" rel="noopener">the annotated transformer中的关于mask的问题 - lumino的文章 - 知乎</a><br><a href="https://zhuanlan.zhihu.com/p/352176558" target="_blank" rel="noopener">各种各样的语言生成模型训练算法</a><br><a href="https://kexue.fm/archives/7259" target="_blank" rel="noopener">Seq2Seq中Exposure Bias现象的浅析与对策</a><br><a href="https://zhuanlan.zhihu.com/p/93030328" target="_blank" rel="noopener">关于Teacher Forcing 和Exposure Bias的碎碎念</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Transformer由论文&lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;《Attention is All You Need》&lt;/a&gt;提出。学（烤）习（贝）一下。实现声明，本文大部分内容来源于&lt;a href=&quot;https://zhuanlan.zhihu.com/p/338817680&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Transformer模型详解（图解最完整版）&lt;/a&gt;，对于不理解的地方，我会加上个人注解。&lt;/p&gt;
&lt;h2 id=&quot;整体结构&quot;&gt;&lt;a href=&quot;#整体结构&quot; class=&quot;headerlink&quot; title=&quot;整体结构&quot;&gt;&lt;/a&gt;整体结构&lt;/h2&gt;&lt;p&gt;首先介绍 Transformer 的整体结构，下图是 Transformer 用于中英文翻译的整体结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4544255f3f24b7af1e520684ae38403f_b.jpg&quot; alt=&quot;img&quot; style=&quot;zoom: 67%;&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以看到 &lt;strong&gt;Transformer 由 Encoder 和 Decoder 两个部分组成&lt;/strong&gt;，各包含 6 个 block。它的工作流程大体如下：&lt;/p&gt;
    
    </summary>
    
    
      <category term="DeepLearningApplications" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/"/>
    
      <category term="自然语言处理" scheme="https://www.zdaiot.com/categories/DeepLearningApplications/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
      <category term="NLP" scheme="https://www.zdaiot.com/tags/NLP/"/>
    
      <category term="Transformer" scheme="https://www.zdaiot.com/tags/Transformer/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow中的Queue</title>
    <link href="https://www.zdaiot.com/MLFrameworks/TensorFlow/TensorFlow%E4%B8%AD%E7%9A%84Queue/"/>
    <id>https://www.zdaiot.com/MLFrameworks/TensorFlow/TensorFlow中的Queue/</id>
    <published>2022-04-15T12:10:24.000Z</published>
    <updated>2022-04-15T12:10:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>事先声明，本文章大部分内容来源于<a href="https://www.jianshu.com/p/d063804fb272" target="_blank" rel="noopener">理解TensorFlow的Queue</a>，并添加个人理解。</p><p>Queue相关的概念只有三个：</p><ul><li><code>Queue</code>是TF队列和缓存机制的实现</li><li><code>QueueRunner</code>是TF中对操作Queue的线程的封装</li><li><code>Coordinator</code>是TF中用来协调线程运行的工具</li></ul><p>虽然它们经常同时出现，但这三样东西在TensorFlow里面是可以单独使用的，不妨先分开来看待。</p><h2 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h2><p>根据实现的方式不同，分成具体的几种类型，例如：</p><ul><li>tf.FIFOQueue 按入列顺序出列的队列</li><li>tf.RandomShuffleQueue 随机顺序出列的队列</li><li>tf.PaddingFIFOQueue 以固定长度批量出列的队列</li><li>tf.PriorityQueue 带优先级出列的队列</li><li>… …</li></ul><p>这些类型的Queue除了自身的性质不太一样外，创建、使用的方法基本是相同的。</p><p>以FIFOQueue为例，创建函数的参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.FIFOQueue(capacity, dtypes, shapes=<span class="literal">None</span>, names=<span class="literal">None</span> ...)</span><br></pre></td></tr></table></figure><p>Queue主要包含<strong>入列（enqueue）</strong>和<strong>出列（dequeue）</strong>两个操作。enqueue（入队）操作返回计算图中的一个Operation节点，dequeue操作返回一个Tensor值。Tensor在创建时同样只是一个定义（或称为“声明”），需要放在Session中运行才能获得真正的数值。下面是一个单独使用Queue的例子：</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.InteractiveSession()</span><br><span class="line"></span><br><span class="line">q = tf.FIFOQueue(<span class="number">2</span>, <span class="string">"float"</span>)</span><br><span class="line">init = q.enqueue_many(([<span class="number">0</span>,<span class="number">0</span>],))  <span class="comment"># 入列多个元素</span></span><br><span class="line"></span><br><span class="line">x = q.dequeue()</span><br><span class="line">y = x+<span class="number">1</span></span><br><span class="line">q_inc = q.enqueue([y])</span><br><span class="line"></span><br><span class="line">init.run()</span><br><span class="line">q_inc.run()</span><br><span class="line">q_inc.run()</span><br><span class="line">q_inc.run()</span><br><span class="line">x.<span class="keyword">eval</span>()  <span class="comment"># 返回1</span></span><br><span class="line">x.<span class="keyword">eval</span>()  <span class="comment"># 返回2</span></span><br><span class="line">x.<span class="keyword">eval</span>()  <span class="comment"># 卡住</span></span><br></pre></td></tr></table></figure><p>注意，如果一次性入列超过Queue Size的数据，enqueue操作会卡住，直到有数据（被其他线程）从队列取出。对一个已经取空的队列使用dequeue操作也会卡住，直到有新的数据（从其他线程）写入。</p><h2 id="QueueRunner"><a href="#QueueRunner" class="headerlink" title="QueueRunner"></a>QueueRunner</h2><p>Tensorflow的计算主要在使用CPU/GPU和内存，而数据读取涉及磁盘操作，速度远低于前者操作。因此通常会<strong>使用多个线程读取数据，然后使用一个线程消费数据。QueueRunner就是来管理这些读写队列的线程的。</strong></p><p>QueueRunner需要与Queue一起使用（这名字已经注定了它和Queue脱不开干系），但并不一定必须使用Coordinator。看下面这个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf  </span><br><span class="line"><span class="keyword">import</span> sys  </span><br><span class="line">q = tf.FIFOQueue(<span class="number">10</span>, <span class="string">"float"</span>)  </span><br><span class="line">counter = tf.Variable(<span class="number">0.0</span>)  <span class="comment">#计数器</span></span><br><span class="line"><span class="comment"># 给计数器加一</span></span><br><span class="line">increment_op = tf.assign_add(counter, <span class="number">1.0</span>)</span><br><span class="line"><span class="comment"># 将计数器加入队列</span></span><br><span class="line">enqueue_op = q.enqueue(counter)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建QueueRunner</span></span><br><span class="line"><span class="comment"># 用多个线程向队列添加数据</span></span><br><span class="line"><span class="comment"># 这里实际创建了4个线程，两个增加计数，两个执行入队</span></span><br><span class="line">qr = tf.train.QueueRunner(q, enqueue_ops=[increment_op, enqueue_op] * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主线程</span></span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line">tf.global_variables_initializer().run()</span><br><span class="line"><span class="comment"># 启动入队线程</span></span><br><span class="line">qr.create_threads(sess, start=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    <span class="keyword">print</span> (sess.run(q.dequeue()))</span><br></pre></td></tr></table></figure><p>增加计数的进程会不停的后台运行，执行入队的进程会先执行10次（因为队列长度只有10），然后主线程开始消费数据，当一部分数据消费被后，入队的进程又会开始执行。最终主线程消费完20个数据后停止，但其他线程继续运行，程序不会结束。</p><h2 id="Coordinator"><a href="#Coordinator" class="headerlink" title="Coordinator"></a>Coordinator</h2><p>Coordinator是个用来保存线程组运行状态的协调器对象，它和TensorFlow的Queue没有必然关系，是可以单独和Python线程使用的。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> threading, time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 子线程函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loop</span><span class="params">(coord, id)</span>:</span></span><br><span class="line">    t = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> coord.should_stop():</span><br><span class="line">        print(id)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        t += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 只有1号线程调用request_stop方法</span></span><br><span class="line">        <span class="keyword">if</span> (t &gt;= <span class="number">2</span> <span class="keyword">and</span> id == <span class="number">1</span>):</span><br><span class="line">            coord.request_stop()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主线程</span></span><br><span class="line">coord = tf.train.Coordinator()</span><br><span class="line"><span class="comment"># 使用Python API创建10个线程</span></span><br><span class="line">threads = [threading.Thread(target=loop, args=(coord, i)) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动所有线程，并等待线程结束</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> threads: t.start()</span><br><span class="line">coord.join(threads)</span><br></pre></td></tr></table></figure><p>将这个程序运行起来，会发现所有的子线程执行完两个周期后都会停止，主线程会等待所有子线程都停止后结束，从而使整个程序结束。由此可见，只要有任何一个线程调用了Coordinator的<code>request_stop</code>方法，所有的线程都可以通过<code>should_stop</code>方法感知并停止当前线程。</p><p>将QueueRunner和Coordinator一起使用，实际上就是封装了这个判断操作，从而使任何一个现成出现异常时，能够正常结束整个程序，同时主线程也可以直接调用<code>request_stop</code>方法来停止所有子线程的执行。</p><h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><p>在TensorFlow中用Queue的经典模式有两种，都是配合了QueueRunner和Coordinator一起使用的。</p><p>第一种，显式的创建QueueRunner，然后调用它的<code>create_threads</code>方法启动线程。例如下面这段代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1000个4维输入向量，每个数取值为1-10之间的随机数</span></span><br><span class="line">data = <span class="number">10</span> * np.random.randn(<span class="number">1000</span>, <span class="number">4</span>) + <span class="number">1</span></span><br><span class="line"><span class="comment"># 1000个随机的目标值，值为0或1</span></span><br><span class="line">target = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, size=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建Queue，队列中每一项包含一个输入数据和相应的目标值</span></span><br><span class="line">queue = tf.FIFOQueue(capacity=<span class="number">50</span>, dtypes=[tf.float32, tf.int32], shapes=[[<span class="number">4</span>], []])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量入列数据（这是一个Operation）</span></span><br><span class="line">enqueue_op = queue.enqueue_many([data, target])</span><br><span class="line"><span class="comment"># 出列数据（这是一个Tensor定义）</span></span><br><span class="line">data_sample, label_sample = queue.dequeue()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建包含4个线程的QueueRunner</span></span><br><span class="line">qr = tf.train.QueueRunner(queue, [enqueue_op] * <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 创建Coordinator</span></span><br><span class="line">    coord = tf.train.Coordinator()</span><br><span class="line">    <span class="comment"># 启动QueueRunner管理的线程</span></span><br><span class="line">    enqueue_threads = qr.create_threads(sess, coord=coord, start=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 主线程，消费100个数据</span></span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        <span class="keyword">if</span> coord.should_stop():</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        data_batch, label_batch = sess.run([data_sample, label_sample])</span><br><span class="line">    <span class="comment"># 主线程计算完成，停止所有采集数据的进程</span></span><br><span class="line">    coord.request_stop()</span><br><span class="line">    coord.join(enqueue_threads)</span><br></pre></td></tr></table></figure><p>第二种，使用全局的<code>start_queue_runners</code>方法启动线程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 同时打开多个文件，显示创建Queue，同时隐含了QueueRunner的创建</span></span><br><span class="line">filename_queue = tf.train.string_input_producer([<span class="string">"data1.csv"</span>,<span class="string">"data2.csv"</span>])</span><br><span class="line">reader = tf.TextLineReader(skip_header_lines=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># Tensorflow的Reader对象可以直接接受一个Queue作为输入</span></span><br><span class="line">key, value = reader.read(filename_queue)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    coord = tf.train.Coordinator()</span><br><span class="line">    <span class="comment"># 启动计算图中所有的队列线程</span></span><br><span class="line">    threads = tf.train.start_queue_runners(coord=coord)</span><br><span class="line">    <span class="comment"># 主线程，消费100个数据</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        features, labels = sess.run([data_batch, label_batch])</span><br><span class="line">    <span class="comment"># 主线程计算完成，停止所有采集数据的进程</span></span><br><span class="line">    coord.request_stop()</span><br><span class="line">    coord.join(threads)</span><br></pre></td></tr></table></figure><p>在这个例子中，<code>tf.train.string_input_produecer</code>会将一个隐含的QueueRunner添加到全局图中（类似的操作还有<code>tf.train.shuffle_batch</code>、<code>tf.train.slice_input_producer</code>等）。</p><p>由于没有显式地返回QueueRunner来用create_threads启动线程，这里使用了<code>tf.train.start_queue_runners</code>方法直接启动<code>tf.GraphKeys.QUEUE_RUNNERS</code>集合中的所有队列线程。</p><p>这两种方式在效果上是等效的。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.jianshu.com/p/d063804fb272" target="_blank" rel="noopener">理解TensorFlow的Queue</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;事先声明，本文章大部分内容来源于&lt;a href=&quot;https://www.jianshu.com/p/d063804fb272&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;理解TensorFlow的Queue&lt;/a&gt;，并添加个人理解。&lt;/p&gt;
&lt;p&gt;Queue相关的概念只有三个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Queue&lt;/code&gt;是TF队列和缓存机制的实现&lt;/li&gt;
&lt;li&gt;&lt;code&gt;QueueRunner&lt;/code&gt;是TF中对操作Queue的线程的封装&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Coordinator&lt;/code&gt;是TF中用来协调线程运行的工具&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虽然它们经常同时出现，但这三样东西在TensorFlow里面是可以单独使用的，不妨先分开来看待。&lt;/p&gt;
&lt;h2 id=&quot;Queue&quot;&gt;&lt;a href=&quot;#Queue&quot; class=&quot;headerlink&quot; title=&quot;Queue&quot;&gt;&lt;/a&gt;Queue&lt;/h2&gt;
    
    </summary>
    
    
      <category term="MLFrameworks" scheme="https://www.zdaiot.com/categories/MLFrameworks/"/>
    
      <category term="TensorFlow" scheme="https://www.zdaiot.com/categories/MLFrameworks/TensorFlow/"/>
    
    
      <category term="TensorFlow" scheme="https://www.zdaiot.com/tags/TensorFlow/"/>
    
      <category term="Queue" scheme="https://www.zdaiot.com/tags/Queue/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow模型保存总结</title>
    <link href="https://www.zdaiot.com/MLFrameworks/TensorFlow/TensorFlow%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E6%80%BB%E7%BB%93/"/>
    <id>https://www.zdaiot.com/MLFrameworks/TensorFlow/TensorFlow模型保存总结/</id>
    <published>2022-04-09T06:32:24.000Z</published>
    <updated>2022-04-09T06:32:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>事先声明，以下大部分内容来源于<a href="https://zhuanlan.zhihu.com/p/113734249" target="_blank" rel="noopener">tensorflow 模型导出总结</a>，并加上个人见解。</p><p>tensorflow 1.0 以及2.0 提供了多种不同的模型导出格式，例如说有checkpoint，SavedModel，Frozen GraphDef，Keras model（HDF5） 以及用于移动端，嵌入式的TFLite。 </p><p>模型导出主要包含了：参数以及网络结构的导出，不同的导出格式可能是分别导出，或者是整合成一个独立的文件。</p><ul><li>参数和网络结构分开保存：checkpoint， SavedModel</li><li>只保存权重：HDF5（可选）</li><li>参数和网络结构保存在一个文件：Frozen GraphDef，HDF5（可选）</li></ul><p>在tensorflow 1.0中，可以见下图，主要有三种主要的API：Keras、Estimator以及Legacy即最初的session模型，其中tf.Keras主要保存为HDF5，Estimator保存为SavedModel，而Lagacy主要保存的是Checkpoint，并且可以通过freeze_graph，将模型变量冻结，得到Frozen GradhDef的文件。这三种格式的模型，都可以通过TFLite Converter导出为 <code>.tflite</code> 的模型文件，用于安卓/ios/嵌入式设备的serving。</p><p><img src="/MLFrameworks/TensorFlow/TensorFlow模型保存总结/v2-b71487837e3a0527aaa15fe6b35fcef6_b.jpg" alt="img"></p><p>在tensorflow 2.0中，推荐使用SavedModel进行模型的保存，所以keras默认导出格式是SavedModel，也可以通过显性使用 <code>.h5</code> 后缀，使得保存的模型格式为HDF5 。 此外其他low level API，都支持导出为SavedModel格式，以及Concrete Functions。Concrete Function是一个签名函数，有固定格式的输入和输出。 最终转化成Flatbuffer，服务端运行结束。</p><h2 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h2><p>checkpint（CKPT）的导出是网络结构和参数权重分开保存的。其组成：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">checkpoint <span class="comment"># 列出该目录下，保存的所有的checkpoint列表，下面有具体的例子</span></span><br><span class="line">├── events.out.tfevents<span class="number">.1583930869</span>.prod-cloudserver-gpu169 <span class="comment"># tensorboad可视化所需文件，可以直观看出模型的结构</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    model.ckpt-13000表示前缀，代表第13000 global steps时的保存结果，我们在指定checkpoint加载时，也只需要说明前缀即可。</span></span><br><span class="line"><span class="string">    你可以只用 .ckpt-meta 和 .ckpt-data 恢复一个模型 </span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">├── model.ckpt<span class="number">-13000.</span>index <span class="comment"># 可能是内部需要的某种索引来正确映射前两个文件，它通常不是必需的</span></span><br><span class="line">├── model.ckpt<span class="number">-13000.</span>data<span class="number">-00000</span>-of<span class="number">-00001</span> <span class="comment"># 包含所有变量的值，没有结构</span></span><br><span class="line">├── model.ckpt<span class="number">-13000.</span>meta <span class="comment"># 包含元图，即计算图的结构，不一定含有变量，就算有变量也没有变量的值（基本上你可以在tensorboard/graph中看到）。</span></span><br></pre></td></tr></table></figure><p>所以一个checkpoint 组成是由两个部分，三个文件组成，其中网络结构部分（meta文件），以及参数部分（参数名：index，参数值：data）</p><p>其中<code>checkpoint</code>文件中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model_checkpoint_path: &quot;model.ckpt-16329&quot;</span><br><span class="line">all_model_checkpoint_paths: &quot;model.ckpt-13000&quot;</span><br><span class="line">all_model_checkpoint_paths: &quot;model.ckpt-14000&quot;</span><br><span class="line">all_model_checkpoint_paths: &quot;model.ckpt-15000&quot;</span><br><span class="line">all_model_checkpoint_paths: &quot;model.ckpt-16000&quot;</span><br><span class="line">all_model_checkpoint_paths: &quot;model.ckpt-16329&quot;</span><br></pre></td></tr></table></figure><p>使用<code>tensorboard --logdir PATH_TO_CHECKPOINT --host=127.0.0.1</code>: tensorboard 会调用最新的events.out.tfevents.*文件，并生成tensorboard，例如下图：</p><p><img src="/MLFrameworks/TensorFlow/TensorFlow模型保存总结/v2-4d9cb38d90d32706892fde8d9de4b07c_b.jpg" alt="img"></p><h3 id="导出成CKPT"><a href="#导出成CKPT" class="headerlink" title="导出成CKPT"></a>导出成CKPT</h3><ul><li>tensorflow 1.0</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># in tensorflow 1.0</span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line">saver.save(sess=session, save_path=args.save_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 若不想保存meta文件</span></span><br><span class="line">saver2save(sess=session, save_path=args.save_path, write_meta_graph=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ul><li>estimator</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># estimator</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">通过 RunConfig 配置多少时间或者多少个steps 保存一次模型，默认600s 保存一次。</span></span><br><span class="line"><span class="string">具体参考 https://zhuanlan.zhihu.com/p/112062303</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">run_config = tf.estimator.RunConfig(</span><br><span class="line">    model_dir=FLAGS.output_dir, <span class="comment"># 模型保存路径</span></span><br><span class="line">    session_config=config,</span><br><span class="line">    save_checkpoints_steps=FLAGS.save_checkpoints_steps, <span class="comment"># 多少steps保存一次ckpt</span></span><br><span class="line">    keep_checkpoint_max=<span class="number">1</span>)</span><br><span class="line">estimator = tf.estimator.Estimator(</span><br><span class="line">  model_fn=model_fn,</span><br><span class="line">  config=run_config,</span><br><span class="line">  params=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><blockquote><p>关于estimator的介绍可以参考：<a href="https://zhuanlan.zhihu.com/p/112062303" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/112062303</a></p></blockquote><h3 id="加载CKPT"><a href="#加载CKPT" class="headerlink" title="加载CKPT"></a>加载CKPT</h3><ul><li>tf1.0<br>ckpt加载的脚本如下，加载完后，session就会是保存的ckpt了。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tf1.0</span></span><br><span class="line">session = tf.Session()</span><br><span class="line">session.run(tf.global_variables_initializer())</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line">saver.restore(sess=session, save_path=args.save_path)  <span class="comment"># 读取保存的模型</span></span><br></pre></td></tr></table></figure><ul><li>对于estimator 会自动load output_dir 中的最新的ckpt。</li><li>我们常用的<code>model_file = tf.train.latest_checkpoint(FLAGS.output_dir)</code> 获取最新的ckpt</li></ul><h3 id="Meta文件分析"><a href="#Meta文件分析" class="headerlink" title="Meta文件分析"></a>Meta文件分析</h3><p>TensorFlow的Meta文件不一定含有变量，也就是使用<code>tf.global_variables()</code>或者<code>tf.trainable_variables()</code>均返回的是空list。</p><p>被这个问题困扰了很久，但是一直查不到结果，我就从TensorFlow的源码入手分析一下。我调试了<code>saver.restore</code>的函数，最终定位到了<a href="https://github.com/tensorflow/tensorflow/blob/v1.15.5/tensorflow/python/framework/meta_graph.py#L824" target="_blank" rel="noopener">meta_graph.py#L824</a>。</p><p>相关代码如下：</p><p><img src="/MLFrameworks/TensorFlow/TensorFlow模型保存总结/image-20220410162903108.png" alt="image-20220410162903108" style="zoom: 80%;"></p><p>代码中有一个函数为<code>meta_graph_def.collection_def</code>，若这里面有<code>trainable_variables</code>才可以，但是我遇到了一个meta文件，<code>meta_graph_def.collection_def</code>为空，也就没有了变量。但是这个文件咋来的，还不是很清楚。需要进一步探索。</p><h2 id="SavedModel"><a href="#SavedModel" class="headerlink" title="SavedModel"></a>SavedModel</h2><p>SavedModel 格式是tensorflow 2.0 推荐的格式，他很好地支持了tf-serving等部署，并且可以简单被python，java等调用。</p><p>一个 SavedModel 包含了一个完整的 TensorFlow program, 包含了 weights 以及 计算图 computation. 它不需要原本的模型代码就可以加载所以很容易在 TFLite, TensorFlow.js, TensorFlow Serving, or TensorFlow Hub 上部署。</p><p>通常SavedModel由以下几个部分组成</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">├── assets/ # 所需的外部文件，例如说初始化的词汇表文件，一般无</span><br><span class="line">├── assets.extra/ # TensorFlow graph 不需要的文件, 例如说给用户知晓的如何使用SavedModel的信息. Tensorflow 不使用这个目录下的文件。</span><br><span class="line">├── saved_model.pb # 保存的是MetaGraph的网络结构, 或者说是saved_model.pbtxt</span><br><span class="line">├── variables # 参数权重，包含了所有模型的变量(tf.Variable objects)参数</span><br><span class="line">    ├── variables.data-00000-of-00001</span><br><span class="line">    └── variables.index</span><br></pre></td></tr></table></figure><p>补充pb格式说明：GraphDef(*.pb)格式文件包含 protobuf 对象序列化后的数据，包含了计算图，可以从中得到所有运算符（operators）的细节，也包含张量（tensors）和 Variables 定义，但不包含 Variable 的值，因此只能从中恢复计算图，但一些训练的权值仍需要从 checkpoint 中恢复。</p><p>TensorFlow 一些例程中用到 *.pb 文件作为预训练模型，这和上面 GraphDef 格式稍有不同，属于冻结（Frozen）后的 GraphDef 文件，简称 FrozenGraphDef 格式。这种文件格式不包含 Variables 节点。将 GraphDef 中所有 Variable 节点转换为常量（其值从 checkpoint 获取），就变为 FrozenGraphDef 格式。代码可以参考 <code>tensorflow/python/tools/freeze_graph.py</code>。</p><p><code>*.pb</code> 为二进制文件，实际上 protobuf 也支持文本格式（<code>*.pbtxt</code>），但包含权值时文本格式会占用大量磁盘空间，一般不用。</p><h3 id="导出为SavedModel"><a href="#导出为SavedModel" class="headerlink" title="导出为SavedModel"></a>导出为SavedModel</h3><ul><li>tf 1.0 方式</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""tf1.0"""</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>], name=<span class="string">"myInput"</span>)</span><br><span class="line">y = tf.nn.softmax(tf.matmul(x, W) + b, name=<span class="string">"myOutput"</span>)</span><br><span class="line">tf.saved_model.simple_save(</span><br><span class="line">                sess,</span><br><span class="line">                export_dir,</span><br><span class="line">                inputs=&#123;<span class="string">"myInput"</span>: x&#125;,</span><br><span class="line">                outputs=&#123;<span class="string">"myOutput"</span>: y&#125;)</span><br></pre></td></tr></table></figure><p><code>simple_save</code> 是对于普通的tf 模型导出的最简单的方式，只需要补充简单的必要参数，有很多参数被省略，其中被省略的最重要的参数是<code>tag</code>（在下面<code>saved_model.builder.SavedModelBuilder</code>会介绍）：<code>tag</code> 是用来区别不同的 <code>MetaGraphDef</code>，这是在加载模型所需要的参数。其默认值是tag_constants.SERVING (“serve”)。对于某些节点，如果没有办法直接加name，那么可以采用 <code>tf.identity</code>， 为节点加名字，例如说CRF的输出，以及使dataset后，无法直接加input的name，都可以采用这个方式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addNameToTensor</span><span class="params">(someTensor, theName)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.identity(someTensor, name=theName)</span><br></pre></td></tr></table></figure><ul><li>estimator 方式</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""estimator"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">serving_input_fn</span><span class="params">()</span>:</span></span><br><span class="line">    label_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>], name=<span class="string">'label_ids'</span>)</span><br><span class="line">    input_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'input_ids'</span>)</span><br><span class="line">    input_mask = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'input_mask'</span>)</span><br><span class="line">    segment_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'segment_ids'</span>)</span><br><span class="line">    input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(&#123;</span><br><span class="line">        <span class="string">'label_ids'</span>: label_ids,</span><br><span class="line">        <span class="string">'input_ids'</span>: input_ids,</span><br><span class="line">        <span class="string">'input_mask'</span>: input_mask,</span><br><span class="line">        <span class="string">'segment_ids'</span>: segment_ids,</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="keyword">return</span> input_fn</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> do_export:</span><br><span class="line">   estimator._export_to_tpu = <span class="literal">False</span></span><br><span class="line">   estimator.export_saved_model(Flags.export_dir, serving_input_fn)</span><br></pre></td></tr></table></figure><ul><li>保存多个 <code>MetaGraphDef&#39;s</code>，使用到了tag</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow.python.saved_model</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.saved_model <span class="keyword">import</span> tag_constants</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.saved_model.signature_def_utils_impl <span class="keyword">import</span> predict_signature_def</span><br><span class="line">builder = saved_model.builder.SavedModelBuilder(export_path)</span><br><span class="line"></span><br><span class="line">signature = predict_signature_def(inputs=&#123;<span class="string">'myInput'</span>: x&#125;,</span><br><span class="line">                                  outputs=&#123;<span class="string">'myOutput'</span>: y&#125;)</span><br><span class="line"><span class="string">""" using custom tag instead of: tags=[tag_constants.SERVING] """</span></span><br><span class="line">builder.add_meta_graph_and_variables(sess=sess,</span><br><span class="line">                                     tags=[<span class="string">"myTag"</span>],</span><br><span class="line">                                     signature_def_map=&#123;<span class="string">'predict'</span>: signature&#125;)</span><br><span class="line">builder.save()</span><br></pre></td></tr></table></figure><ul><li>ckpt转SavedModel</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_saved_model</span><span class="params">(bert_config, num_labels, use_one_hot_embeddings)</span>:</span></span><br><span class="line">  tf_config = tf.compat.v1.ConfigProto()</span><br><span class="line">  tf_config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line"> </span><br><span class="line">  model_file = tf.train.latest_checkpoint(FLAGS.output_dir)</span><br><span class="line">  <span class="keyword">with</span> tf.Graph().as_default(), tf.Session(config=tf_config) <span class="keyword">as</span> tf_sess:</span><br><span class="line">    label_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>], name=<span class="string">'label_ids'</span>)</span><br><span class="line">    input_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'input_ids'</span>)</span><br><span class="line">    input_mask = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'input_mask'</span>)</span><br><span class="line">    segment_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'segment_ids'</span>)</span><br><span class="line"> </span><br><span class="line">    loss, per_example_loss, probabilities, predictions = \</span><br><span class="line">          create_model(bert_config, <span class="literal">False</span>, input_ids, input_mask, segment_ids, label_ids,</span><br><span class="line">              num_labels, use_one_hot_embeddings)</span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    print(<span class="string">"restore;&#123;&#125;"</span>.format(model_file))</span><br><span class="line">    saver.restore(tf_sess, model_file)</span><br><span class="line">    tf.saved_model.simple_save(tf_sess,</span><br><span class="line">            FLAGS.output_dir,</span><br><span class="line">            inputs=&#123;</span><br><span class="line">              <span class="string">'label_ids'</span>: label_ids,</span><br><span class="line">              <span class="string">'input_ids'</span>: input_ids,</span><br><span class="line">              <span class="string">'input_mask'</span>: input_mask,</span><br><span class="line">              <span class="string">'segment_ids'</span>: segment_ids,</span><br><span class="line">            &#125;,</span><br><span class="line">            outputs=&#123;<span class="string">"probabilities"</span>: probabilities&#125;)</span><br></pre></td></tr></table></figure><ul><li>frozen graph to savedModel。注意这个方法我失败了，variables文件夹下面没有东西。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.saved_model <span class="keyword">import</span> signature_constants</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.saved_model <span class="keyword">import</span> tag_constants</span><br><span class="line"></span><br><span class="line">export_dir = <span class="string">'inference/pb2saved'</span></span><br><span class="line">graph_pb = <span class="string">'inference/robert_tiny_clue/frozen_model.pb'</span></span><br><span class="line"></span><br><span class="line">builder = tf.saved_model.builder.SavedModelBuilder(export_dir)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.gfile.GFile(graph_pb, <span class="string">"rb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">    graph_def = tf.GraphDef()</span><br><span class="line">    graph_def.ParseFromString(f.read())</span><br><span class="line"></span><br><span class="line">sigs = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=tf.Graph()) <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># name="" is important to ensure we don't get spurious prefixing</span></span><br><span class="line">    tf.import_graph_def(graph_def, name=<span class="string">""</span>)</span><br><span class="line">    g = tf.get_default_graph()</span><br><span class="line">    input_ids = sess.graph.get_tensor_by_name(</span><br><span class="line">    <span class="string">"input_ids:0"</span>)</span><br><span class="line">    input_mask = sess.graph.get_tensor_by_name(</span><br><span class="line">    <span class="string">"input_mask:0"</span>)</span><br><span class="line">    segment_ids = sess.graph.get_tensor_by_name(</span><br><span class="line">    <span class="string">"segment_ids:0"</span>)</span><br><span class="line">    probabilities = g.get_tensor_by_name(<span class="string">"loss/pred_prob:0"</span>)</span><br><span class="line"></span><br><span class="line">    sigs[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY] = \</span><br><span class="line">        tf.saved_model.signature_def_utils.predict_signature_def(</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"input_ids"</span>: input_ids,</span><br><span class="line">                <span class="string">"input_mask"</span>: input_mask,</span><br><span class="line">                <span class="string">"segment_ids"</span>: segment_ids</span><br><span class="line">            &#125;, &#123;</span><br><span class="line">                <span class="string">"probabilities"</span>: probabilities</span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">    builder.add_meta_graph_and_variables(sess,</span><br><span class="line">                                         [tag_constants.SERVING],</span><br><span class="line">                                         signature_def_map=sigs)</span><br><span class="line"></span><br><span class="line">builder.save()</span><br></pre></td></tr></table></figure><ul><li>tf.keras 2.0</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.save(<span class="string">'saved_model/my_model'</span>)  </span><br><span class="line"><span class="string">""</span><span class="string">"saved as SavedModel by default"</span><span class="string">""</span></span><br></pre></td></tr></table></figure><h3 id="加载SavedModel"><a href="#加载SavedModel" class="headerlink" title="加载SavedModel"></a>加载SavedModel</h3><p>对于在java中加载SavedModel，我们首先需要知道我们模型输入和输出，可以通过以下的脚本在terminal中运行 <code>saved_model_cli show --dir SavedModel路径 --tag_set serve --signature_def serving_default</code> 得到类似以下的结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">MetaGraphDef <span class="keyword">with</span> tag-set: <span class="string">'serve'</span> contains the following SignatureDefs:</span><br><span class="line"></span><br><span class="line">signature_def[<span class="string">'serving_default'</span>]:</span><br><span class="line">  The given SavedModel SignatureDef contains the following input(s):</span><br><span class="line">    inputs[<span class="string">'input_ids'</span>] tensor_info:</span><br><span class="line">        dtype: DT_INT32</span><br><span class="line">        shape: (<span class="number">-1</span>, <span class="number">128</span>)</span><br><span class="line">        name: input_ids:<span class="number">0</span></span><br><span class="line">    inputs[<span class="string">'input_mask'</span>] tensor_info:</span><br><span class="line">        dtype: DT_INT32</span><br><span class="line">        shape: (<span class="number">-1</span>, <span class="number">128</span>)</span><br><span class="line">        name: input_mask:<span class="number">0</span></span><br><span class="line">    inputs[<span class="string">'label_ids'</span>] tensor_info:</span><br><span class="line">        dtype: DT_INT32</span><br><span class="line">        shape: (<span class="number">-1</span>)</span><br><span class="line">        name: label_ids:<span class="number">0</span></span><br><span class="line">    inputs[<span class="string">'segment_ids'</span>] tensor_info:</span><br><span class="line">        dtype: DT_INT32</span><br><span class="line">        shape: (<span class="number">-1</span>, <span class="number">128</span>)</span><br><span class="line">        name: segment_ids:<span class="number">0</span></span><br><span class="line">  The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">    outputs[<span class="string">'probabilities'</span>] tensor_info:</span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (<span class="number">-1</span>, <span class="number">7</span>)</span><br><span class="line">        name: loss/pred_prob:<span class="number">0</span></span><br><span class="line">  Method name <span class="keyword">is</span>: tensorflow/serving/predict</span><br></pre></td></tr></table></figure><p>首先我们可以看到有inputs，以及outputs，分别是一个key为string，value为tensor的字典，每个tensor都有各自的名字。</p><p>当然我们可以通过<code>saved_model_cli show --dir SavedModel路径 --all</code>得到所有的结果，包含了<code>Concrete Functions</code>。</p><h4 id="Python-加载"><a href="#Python-加载" class="headerlink" title="Python 加载"></a>Python 加载</h4><p>我们有常见两种方式可以加载savedModel，一种是采用 <code>tf.contrib.predictor.from_saved_model</code> 传入predictor模型的inputs dict，然后得到 outputs dict。 一种是直接类似tf1.0的方式，采用 <code>tf.saved_model.loader.load</code>， feed tensor然后fetch tensor。</p><ul><li><p>采用predictor</p><p>采用predictor时， 需要传入的字典名字用的是 inputs的key，而不是tensor的names</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">predict_fn = tf.contrib.predictor.from_saved_model(args_in_use.model)</span><br><span class="line"><span class="comment"># 其中feature.xxxxxx 应该是需要feed_dict的数据</span></span><br><span class="line">prediction = predict_fn(&#123;</span><br><span class="line">                <span class="string">"input_ids"</span>: [feature.input_ids],</span><br><span class="line">                <span class="string">"input_mask"</span>: [feature.input_mask],</span><br><span class="line">                <span class="string">"segment_ids"</span>: [feature.segment_ids],</span><br><span class="line">            &#125;)</span><br><span class="line">probabilities = prediction[<span class="string">"probabilities"</span>]</span><br></pre></td></tr></table></figure><ul><li><p>tf 1.0 采用 loader</p><p>采用loader的方式是采用 session 的feed_dict 方式，该方式feed的是tenor的names，fetch的同样也是tensor 的names。其中feed_dict的key 可以直接是tensor的name，或者是采用 <code>sess.graph.get_tensor_by_name(TENSOR_NAME)</code> 得到的tensor。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session(graph=tf.Graph()) <span class="keyword">as</span> sess:</span><br><span class="line">    tf.saved_model.loader.load(sess, [<span class="string">"serve"</span>], export_path)</span><br><span class="line">    graph = tf.get_default_graph()</span><br><span class="line">    feed_dict = &#123;<span class="string">"input_ids_1:0"</span>: [feature.input_ids],</span><br><span class="line">                <span class="string">"input_mask_1:0"</span>: [feature.input_mask],</span><br><span class="line">                <span class="string">"segment_ids_1:0"</span>: [feature.segment_ids]&#125;</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    # alternative way</span></span><br><span class="line"><span class="string">    feed_dict = &#123;sess.graph.get_tensor_by_name("input_ids_1:0"): </span></span><br><span class="line"><span class="string">                          [feature.input_ids],</span></span><br><span class="line"><span class="string">                sess.graph.get_tensor_by_name("input_mask_1:0"):</span></span><br><span class="line"><span class="string">                          [feature.input_mask],</span></span><br><span class="line"><span class="string">                sess.graph.get_tensor_by_name("segment_ids_1:0"):</span></span><br><span class="line"><span class="string">                          [feature.segment_ids]&#125;</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    sess.run(<span class="string">'loss/pred_prob:0'</span>,</span><br><span class="line">               feed_dict=feed_dict)</span><br></pre></td></tr></table></figure><ul><li>tf.keras 2.0</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new_model = tf.keras.models.load_model(<span class="string">'saved_model/my_model'</span>)</span><br></pre></td></tr></table></figure><h4 id="JAVA-加载"><a href="#JAVA-加载" class="headerlink" title="JAVA 加载"></a>JAVA 加载</h4><p>注意 java加载的时候，如果遇到Op not defined 的错误，是需要匹配模型训练python的tensorflow版本以及java的tensorflow版本的。</p><p>所以我们知道我们在tag-set 为serve的tag下，有4个inputs tensors，name分别为<code>input_ids:0</code>, <code>input_mask:0</code>, <code>label_ids:0</code>, <code>segment_ids:0</code>, 输出为1个，name是 <code>loss/pred_prob:0</code>。并且我们知道这些tensor的类型。</p><p>所以我们可以通过下面的java代码，进行加载，获得结果。注意我们需要传入的name中不需要传入<code>:0</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.tensorflow.*</span><br><span class="line">SavedModelBundle savedModelBundle = SavedModelBundle.load(<span class="string">"./export_path"</span>, <span class="string">"serve"</span>);</span><br><span class="line">Graph graph = savedModelBundle.graph();</span><br><span class="line"></span><br><span class="line">Tensor tensor = <span class="keyword">this</span>.savedModelBundle.session().runner()</span><br><span class="line">                .feed(<span class="string">"input_ids"</span>, inputIdTensor)</span><br><span class="line">                .feed(<span class="string">"input_mask"</span>, inputMaskTensor)</span><br><span class="line">                .feed(<span class="string">"segment_ids"</span>, inputSegmentTensor)</span><br><span class="line">                .fetch(<span class="string">"loss/pred_prob"</span>)</span><br><span class="line">                .run().get(<span class="number">0</span>);</span><br></pre></td></tr></table></figure><h4 id="CLI-加载"><a href="#CLI-加载" class="headerlink" title="CLI 加载"></a>CLI 加载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ saved_model_cli show --dir <span class="built_in">export</span>/1524906774 \</span><br><span class="line">  --tag_set serve --signature_def serving_default</span><br><span class="line">The given SavedModel SignatureDef contains the following input(s):</span><br><span class="line">  inputs[<span class="string">'inputs'</span>] tensor_info:</span><br><span class="line">      dtype: DT_STRING</span><br><span class="line">      shape: (-1)</span><br><span class="line">The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">  outputs[<span class="string">'classes'</span>] tensor_info:</span><br><span class="line">      dtype: DT_STRING</span><br><span class="line">      shape: (-1, 3)</span><br><span class="line">  outputs[<span class="string">'scores'</span>] tensor_info:</span><br><span class="line">      dtype: DT_FLOAT</span><br><span class="line">      shape: (-1, 3)</span><br><span class="line">Method name is: tensorflow/serving/classify</span><br><span class="line"></span><br><span class="line">$ saved_model_cli run --dir <span class="built_in">export</span>/1524906774 \</span><br><span class="line">  --tag_set serve --signature_def serving_default \</span><br><span class="line">  --input_examples <span class="string">'inputs=[&#123;"SepalLength":[5.1],"SepalWidth":[3.3],"PetalLength":[1.7],"PetalWidth":[0.5]&#125;]'</span></span><br><span class="line">Result <span class="keyword">for</span> output key classes:</span><br><span class="line">[[b<span class="string">'0'</span> b<span class="string">'1'</span> b<span class="string">'2'</span>]]</span><br><span class="line">Result <span class="keyword">for</span> output key scores:</span><br><span class="line">[[9.9919027e-01 8.0969761e-04 1.2872645e-09]]</span><br></pre></td></tr></table></figure><h2 id="Frozen-Graph"><a href="#Frozen-Graph" class="headerlink" title="Frozen Graph"></a>Frozen Graph</h2><p>frozen Graphdef 将tensorflow导出的模型的权重都freeze住，使得其都变为常量。并且模型参数和网络结构保存在同一个文件中，可以在python以及java中自由调用。</p><h3 id="导出为pb"><a href="#导出为pb" class="headerlink" title="导出为pb"></a>导出为pb</h3><h4 id="python"><a href="#python" class="headerlink" title="python"></a>python</h4><ul><li>采用session方式保存frozen graph</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""tf1.0"""</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.python.framework.graph_util <span class="keyword">import</span> convert_variables_to_constants</span><br><span class="line"></span><br><span class="line">output_graph_def = convert_variables_to_constants(</span><br><span class="line">                    session,</span><br><span class="line">                    session.graph_def,</span><br><span class="line">                    output_node_names=[<span class="string">'loss/pred_prob'</span>])</span><br><span class="line">tf.train.write_graph(output_graph_def, args.export_dir, args.model_name, as_text=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ul><li>采用ckpt 转换成frozen graph<br>以下采用bert tensorflow模型做演示</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">NB：首先我们要在create_model() 函数中，为我们需要的输出节点取个名字，</span></span><br><span class="line"><span class="string">  比如说我们要： probabilities = tf.nn.softmax(logits, axis=-1, name='pred_prob')</span></span><br><span class="line"><span class="string">"""</span> </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_frozen_model</span><span class="params">(bert_config, num_labels, use_one_hot_embeddings)</span>:</span></span><br><span class="line">  tf_config = tf.compat.v1.ConfigProto()</span><br><span class="line">  tf_config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line">  output_node_names = [<span class="string">'loss/pred_prob'</span>]</span><br><span class="line">  </span><br><span class="line">  model_file = tf.train.latest_checkpoint(FLAGS.output_dir)</span><br><span class="line">  <span class="keyword">with</span> tf.Graph().as_default(), tf.Session(config=tf_config) <span class="keyword">as</span> tf_sess: </span><br><span class="line">    label_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>], name=<span class="string">'label_ids'</span>)</span><br><span class="line">    input_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'input_ids'</span>)</span><br><span class="line">    input_mask = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'input_mask'</span>)</span><br><span class="line">    segment_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'segment_ids'</span>)</span><br><span class="line"></span><br><span class="line">    create_model(bert_config, <span class="literal">False</span>, input_ids, input_mask, segment_ids, label_ids,</span><br><span class="line">            num_labels, use_one_hot_embeddings)</span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    print(<span class="string">"restore;&#123;&#125;"</span>.format(model_file))</span><br><span class="line">    saver.restore(tf_sess, model_file)</span><br><span class="line">    tmp_g = tf_sess.graph.as_graph_def()</span><br><span class="line">    <span class="keyword">if</span> FLAGS.use_opt:</span><br><span class="line">      input_tensors = [input_ids, input_mask, segment_ids]</span><br><span class="line">      dtypes = [n.dtype <span class="keyword">for</span> n <span class="keyword">in</span> input_tensors]</span><br><span class="line">      print(<span class="string">'optimize...'</span>)</span><br><span class="line">      tmp_g = optimize_for_inference(tmp_g,</span><br><span class="line">                                    [n.name[:<span class="number">-2</span>] <span class="keyword">for</span> n <span class="keyword">in</span> input_tensors],</span><br><span class="line">                                     output_node_names,</span><br><span class="line">                                     [dtype.as_datatype_enum <span class="keyword">for</span> dtype <span class="keyword">in</span> dtypes],</span><br><span class="line">                                     <span class="literal">False</span>)</span><br><span class="line">    print(<span class="string">'freeze...'</span>)</span><br><span class="line">    frozen_graph = tf.graph_util.convert_variables_to_constants(tf_sess, </span><br><span class="line">            tmp_g, output_node_names)</span><br><span class="line">    out_graph_path = os.path.join(FLAGS.output_dir, <span class="string">"frozen_model.pb"</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.io.gfile.GFile(out_graph_path, <span class="string">"wb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">      f.write(frozen_graph.SerializeToString())      </span><br><span class="line">    print(<span class="string">f'pb file saved in <span class="subst">&#123;out_graph_path&#125;</span>'</span>)</span><br></pre></td></tr></table></figure><ul><li>采用savedModel 转换成 frozen graph</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.tools <span class="keyword">import</span> freeze_graph</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.saved_model <span class="keyword">import</span> tag_constants</span><br><span class="line"></span><br><span class="line">input_saved_model_dir = <span class="string">"./1583934987/"</span></span><br><span class="line">output_node_names = <span class="string">"loss/pred_prob"</span></span><br><span class="line">input_binary = <span class="literal">False</span></span><br><span class="line">input_saver_def_path = <span class="literal">False</span></span><br><span class="line">restore_op_name = <span class="literal">None</span></span><br><span class="line">filename_tensor_name = <span class="literal">None</span></span><br><span class="line">clear_devices = <span class="literal">False</span></span><br><span class="line">input_meta_graph = <span class="literal">False</span></span><br><span class="line">checkpoint_path = <span class="literal">None</span></span><br><span class="line">input_graph_filename = <span class="literal">None</span></span><br><span class="line">saved_model_tags = tag_constants.SERVING</span><br><span class="line">output_graph_filename=<span class="string">'frozen_graph.pb'</span></span><br><span class="line"></span><br><span class="line">freeze_graph.freeze_graph(input_graph_filename,</span><br><span class="line">  input_saver_def_path,</span><br><span class="line">  input_binary,</span><br><span class="line">  checkpoint_path,</span><br><span class="line">  output_node_names,</span><br><span class="line">  restore_op_name,</span><br><span class="line">  filename_tensor_name,</span><br><span class="line">  output_graph_filename,</span><br><span class="line">  clear_devices,</span><br><span class="line">  <span class="string">""</span>, <span class="string">""</span>, <span class="string">""</span>,</span><br><span class="line">  input_meta_graph,</span><br><span class="line">  input_saved_model_dir,</span><br><span class="line">  saved_model_tags)</span><br></pre></td></tr></table></figure><ul><li>HDF5 to pb</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">freeze_session</span><span class="params">(session, keep_var_names=None, output_names=None, clear_devices=True)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Freezes the state of a session into a pruned computation graph.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Creates a new computation graph where variable nodes are replaced by</span></span><br><span class="line"><span class="string">    constants taking their current value in the session. The new graph will be</span></span><br><span class="line"><span class="string">    pruned so subgraphs that are not necessary to compute the requested</span></span><br><span class="line"><span class="string">    outputs are removed.</span></span><br><span class="line"><span class="string">    @param session The TensorFlow session to be frozen.</span></span><br><span class="line"><span class="string">    @param keep_var_names A list of variable names that should not be frozen,</span></span><br><span class="line"><span class="string">                          or None to freeze all the variables in the graph.</span></span><br><span class="line"><span class="string">    @param output_names Names of the relevant graph outputs.</span></span><br><span class="line"><span class="string">    @param clear_devices Remove the device directives from the graph for better portability.</span></span><br><span class="line"><span class="string">    @return The frozen graph definition.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    graph = session.graph</span><br><span class="line">    <span class="keyword">with</span> graph.as_default():</span><br><span class="line">        freeze_var_names = list(set(v.op.name <span class="keyword">for</span> v <span class="keyword">in</span> tf.global_variables()).difference(keep_var_names <span class="keyword">or</span> []))</span><br><span class="line">        output_names = output_names <span class="keyword">or</span> []</span><br><span class="line">        output_names += [v.op.name <span class="keyword">for</span> v <span class="keyword">in</span> tf.global_variables()]</span><br><span class="line">        input_graph_def = graph.as_graph_def()</span><br><span class="line">        <span class="keyword">if</span> clear_devices:</span><br><span class="line">            <span class="keyword">for</span> node <span class="keyword">in</span> input_graph_def.node:</span><br><span class="line">                node.device = <span class="string">""</span></span><br><span class="line">        frozen_graph = tf.graph_util.convert_variables_to_constants(</span><br><span class="line">            session, input_graph_def, output_names, freeze_var_names)</span><br><span class="line">        <span class="keyword">return</span> frozen_graph</span><br><span class="line">        </span><br><span class="line">frozen_graph = freeze_session(K.get_session(),</span><br><span class="line">                              output_names=[out.op.name <span class="keyword">for</span> out <span class="keyword">in</span> model.outputs])</span><br><span class="line"></span><br><span class="line">tf.train.write_graph(frozen_graph, <span class="string">"some_directory"</span>, <span class="string">"my_model.pb"</span>, as_text=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h4 id="CLI转换工具"><a href="#CLI转换工具" class="headerlink" title="CLI转换工具"></a>CLI转换工具</h4><p>以下的工具可以快速进行ckpt到pb的转换，但是不能再原本的基础上增加tensor 的名字。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">freeze_graph --input_checkpoint model.ckpt-16329 \</span><br><span class="line">             --output_graph 0316_roberta.pb \</span><br><span class="line">             --output_node_names loss/pred_prob \</span><br><span class="line">             --checkpoint_version 1 \</span><br><span class="line">             --input_meta_graph model.ckpt-16329.meta \</span><br><span class="line">             --input_binary true</span><br></pre></td></tr></table></figure><h3 id="模型加载"><a href="#模型加载" class="headerlink" title="模型加载"></a>模型加载</h3><p>获取frozen graph 中节点名字的脚本如下，但是一般来说，我们的inputs都是我们定义好的placeholders。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printTensors</span><span class="params">(pb_file)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""read pb into graph_def"""</span></span><br><span class="line">    <span class="keyword">with</span> tf.gfile.GFile(pb_file, <span class="string">"rb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        graph_def = tf.GraphDef()</span><br><span class="line">        graph_def.ParseFromString(f.read())</span><br><span class="line"></span><br><span class="line">    <span class="string">"""import graph_def"""</span></span><br><span class="line">    <span class="keyword">with</span> tf.Graph().as_default() <span class="keyword">as</span> graph:</span><br><span class="line">        tf.import_graph_def(graph_def)</span><br><span class="line"></span><br><span class="line">    <span class="string">"""print operations"""</span></span><br><span class="line">    <span class="keyword">for</span> op <span class="keyword">in</span> graph.get_operations():</span><br><span class="line">        print(op.name)</span><br><span class="line"></span><br><span class="line">printTensors(<span class="string">"path-to-my-pbfile.pb"</span>)</span><br></pre></td></tr></table></figure><p>得到类似如下的结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import/input_ids:0</span><br><span class="line">import/input_mask:0</span><br><span class="line">import/segment_ids:0</span><br><span class="line">...</span><br><span class="line">import/loss/pred_prob:0</span><br></pre></td></tr></table></figure><p>当我们知道我们要feed以及fetch的节点名称之后，我们就可以通过python/java加载了。<br>跟savedModel一样，对于某些节点，如果没有办法直接加name，那么可以采用 <code>tf.identity</code>， 为节点加名字，例如说CRF的输出，以及使用dataset后，无法直接加input的name，都可以采用这个方式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addNameToTensor</span><span class="params">(someTensor, theName)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.identity(someTensor, name=theName)</span><br></pre></td></tr></table></figure><h4 id="Python-加载-1"><a href="#Python-加载-1" class="headerlink" title="Python 加载"></a>Python 加载</h4><p>我们保存完frozen graph 模型后，假设我们的模型包含以下的tensors：</p><p>那么我们通过python加载的代码如下, 采用的是session feed和fetch的方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    output_graph_def = tf.GraphDef()</span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">   load pb model</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">with</span> open(args_in_use.model, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        output_graph_def.ParseFromString(f.read())</span><br><span class="line">        tf.import_graph_def(output_graph_def, name=<span class="string">''</span>) <span class="comment">#name是必须的</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    enter a text and predict</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        tf.global_variables_initializer().run()</span><br><span class="line">        input_ids = sess.graph.get_tensor_by_name(</span><br><span class="line">            <span class="string">"input_ids:0"</span>)</span><br><span class="line">        input_mask = sess.graph.get_tensor_by_name(</span><br><span class="line">            <span class="string">"input_mask:0"</span>)</span><br><span class="line">        segment_ids = sess.graph.get_tensor_by_name(</span><br><span class="line">            <span class="string">"segment_ids:0"</span>)</span><br><span class="line">        output = <span class="string">"loss/pred_prob:0"</span></span><br><span class="line">        </span><br><span class="line">        feed_dict = &#123;</span><br><span class="line">            input_ids: [feature.input_ids],</span><br><span class="line">            input_mask: [feature.input_mask],</span><br><span class="line">            segment_ids: [feature.segment_ids],</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># 也可以直接使用</span></span><br><span class="line">        <span class="comment"># feed_dict = &#123;</span></span><br><span class="line">        <span class="comment">#     "input_ids:0": [feature.input_ids],</span></span><br><span class="line">        <span class="comment">#     "input_mask:0": [feature.input_mask],</span></span><br><span class="line">        <span class="comment">#     "segment_ids:0": [feature.segment_ids],</span></span><br><span class="line">        <span class="comment"># &#125;</span></span><br><span class="line">        y_pred_cls = sess.run(output, feed_dict=feed_dict)</span><br></pre></td></tr></table></figure><h4 id="Java-加载"><a href="#Java-加载" class="headerlink" title="Java 加载"></a>Java 加载</h4><p>对于frozen graph，我们加载的方式和savedModel很类似，首先我们需要先启动一个session，然后在启动一个<code>runner()</code>，然后再feed模型的输入，以及fetch模型的输出。</p><p>注意 java加载的时候，如果遇到Op not defined 的错误，是需要匹配模型训练python的tensorflow版本以及java的tensorflow版本的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TensorUtil.class</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Session <span class="title">generateSession</span><span class="params">(String modelPath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Preconditions.checkNotNull(modelPath);</span><br><span class="line">    <span class="keyword">byte</span>[] graphDef = ByteStreams.toByteArray(TensorUtil.class.getResourceAsStream(modelPath));</span><br><span class="line">    LOGGER.info(<span class="string">"Graph Def Length: &#123;&#125;"</span>, graphDef.length);</span><br><span class="line">    Graph graph = <span class="keyword">new</span> Graph();</span><br><span class="line">    graph.importGraphDef(graphDef);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Session(graph);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// model.class</span></span><br><span class="line"><span class="keyword">this</span>.session = TensorUtil.generateSession(modelPath);</span><br><span class="line"></span><br><span class="line">Tensor tensor = <span class="keyword">this</span>.session.runner()</span><br><span class="line">                    .feed(<span class="string">"input_ids"</span>, inputIdTensor)</span><br><span class="line">                    .feed(<span class="string">"input_mask"</span>, inputMaskTensor)</span><br><span class="line">                    .feed(<span class="string">"segment_ids"</span>, inputSegmentTensor)</span><br><span class="line">                    .fetch(<span class="string">"loss/pred_prob"</span>)</span><br><span class="line">                    .run().get(<span class="number">0</span>);</span><br></pre></td></tr></table></figure><h2 id="HDF5"><a href="#HDF5" class="headerlink" title="HDF5"></a>HDF5</h2><p>HDF5 是keras or tf.keras 特有的存储格式。</p><h3 id="HDF5导出"><a href="#HDF5导出" class="headerlink" title="HDF5导出"></a>HDF5导出</h3><ul><li>导出整个模型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""默认1.0 是HDF5，但是2.0中，是SavedModel，所以需要显性地指定`.h5`后缀"""</span></span><br><span class="line">model.save(<span class="string">'my_model.h5'</span>)</span><br></pre></td></tr></table></figure><ul><li>导出模型weights</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""keras 1.0"""</span></span><br><span class="line">model.save_weights(<span class="string">'my_model_weights.h5'</span>)</span><br></pre></td></tr></table></figure><h3 id="HDF5加载"><a href="#HDF5加载" class="headerlink" title="HDF5加载"></a>HDF5加载</h3><ul><li><p>加载整个模型（无自定义部分）</p></li><li><ul><li>keras1.0</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""keras 1.0"""</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line">model = load_model(model_path)</span><br></pre></td></tr></table></figure><ul><li><ul><li>keras2.0</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""keras 2.0"""</span></span><br><span class="line">new_model = tf.keras.models.load_model(<span class="string">'my_model.h5'</span>)</span><br></pre></td></tr></table></figure><ul><li><p>加载整个模型（含自定义部分）<br>对于有自定义layers的或者实现的模型加载，需要增加dependencies 的映射字典，例如下面的例子：</p></li><li><ul><li>keras1.0</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dependencies = &#123;<span class="string">'MyLayer'</span>: MyLayer(), <span class="string">'auc'</span>: auc, <span class="string">'log_loss'</span>: log_loss&#125;</span><br><span class="line">model = load_model(model_path, custom_objects=dependencies, compile=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ul><li><ul><li>keras 2.0</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">To save custom objects to HDF5, you must do the following:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1. Define a get_config method in your object, and optionally a from_config classmethod.</span></span><br><span class="line"><span class="string">get_config(self) returns a JSON-serializable dictionary of parameters needed to recreate the object.</span></span><br><span class="line"><span class="string">from_config(cls, config) uses the returned config from get_config to create a new object. By default, this function will use the config as initialization kwargs (return cls(**config)).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">2. Pass the object to the custom_objects argument when loading the model. The argument must be a dictionary mapping the string class name to the Python class. E.g. tf.keras.models.load_model(path, custom_objects=&#123;'CustomLayer': CustomLayer&#125;)</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>加载模型权重<br>假设你有了相同的模型构建了，那么直接运行下面的代码，加载模型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_weights(<span class="string">'my_model_weights.h5'</span>)</span><br></pre></td></tr></table></figure><p>如果你想要做transfer learning，即从其他的已保存的模型中加载部分的模型参数权重，自己目前的模型结构与保存的模型不同，可以通过参数的名字进行加载，加上 <code>by_name=True</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_weights(<span class="string">'my_model_weights.h5'</span>, by_name=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h2 id="tfLite"><a href="#tfLite" class="headerlink" title="tfLite"></a>tfLite</h2><h3 id="TFlite转换"><a href="#TFlite转换" class="headerlink" title="TFlite转换"></a>TFlite转换</h3><ul><li>savedModel to TFLite</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">--saved_model_dir:  Type: string. Specifies the full path to the directory containing the SavedModel generated in 1.X or 2.X.</span></span><br><span class="line"><span class="string">--output_file: Type: string. Specifies the full path of the output file.</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">tflite_convert \</span><br><span class="line">    --saved_model_dir=1583934987 \</span><br><span class="line">    --output_file=rbt.tflite</span><br></pre></td></tr></table></figure><ul><li>frozen graph to TFLite</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tflite_convert --graph_def_file albert_tiny_zh.pb \</span><br><span class="line">               --input_arrays <span class="string">'input_ids,input_masks,segment_ids'</span> \</span><br><span class="line">               --output_arrays <span class="string">'finetune_mrc/add, finetune_mrc/add_1'</span>\</span><br><span class="line">               --input_shapes 1,512:1,512:1,512 \</span><br><span class="line">               --output_file saved_model.tflite \</span><br><span class="line">               --enable_v1_converter \</span><br><span class="line">               --experimental_new_converter</span><br></pre></td></tr></table></figure><ul><li>HDF5 to TFLite</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#--keras_model_file. Type: string. Specifies the full path of the HDF5 file containing the tf.keras model generated in 1.X or 2.X.   </span></span><br><span class="line"><span class="comment">#--output_file: Type: string. Specifies the full path of the output file.</span></span><br><span class="line">tflite_convert \</span><br><span class="line">    --keras_model_file=h5_dir/ \</span><br><span class="line">    --output_file=rbt.tflite</span><br></pre></td></tr></table></figure><p>另外，补充一个TFlite转frozen graph：</p><p>tensorflow在早期提供了转换工具（1.9版本后的tensorflow没有再提到这个功能了），具体操作可以看<a href="https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md" target="_blank" rel="noopener">这里</a>。</p><p>有的模型TOCO工具可能会转换失败，可以参考<a href="https://gist.github.com/tworuler/bd7bd4c6cd9a8fbbeb060e7b64cfa008" target="_blank" rel="noopener">这个链接</a>。</p><h3 id="TFLite-加载"><a href="#TFLite-加载" class="headerlink" title="TFLite 加载"></a>TFLite 加载</h3><p>参考 <a href="https://link.zhihu.com/?target=https%3A//www.tensorflow.org/lite/guide/inference" target="_blank" rel="noopener">https://www.tensorflow.org/lite/guide/inference</a><br>参考 <a href="https://link.zhihu.com/?target=https%3A//github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/r1/convert/index.md" target="_blank" rel="noopener">https://github.com/tensorflow/t</a></p><p>这里介绍一个Python的加载。</p><ul><li>当从SavedModel转换得到，并且含有SignatureDef时：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestModel</span><span class="params">(tf.Module)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    super(TestModel, self).__init__()</span><br><span class="line"></span><br><span class="line"><span class="meta">  @tf.function(input_signature=[tf.TensorSpec(shape=[1, 10], dtype=tf.float32)])</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(self, x)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Simple method that accepts single input 'x' and returns 'x' + 4.</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># Name the output 'result' for convenience.</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'result'</span> : x + <span class="number">4</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">SAVED_MODEL_PATH = <span class="string">'content/saved_models/test_variable'</span></span><br><span class="line">TFLITE_FILE_PATH = <span class="string">'content/test_variable.tflite'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the model</span></span><br><span class="line">module = TestModel()</span><br><span class="line"><span class="comment"># You can omit the signatures argument and a default signature name will be</span></span><br><span class="line"><span class="comment"># created with name 'serving_default'.</span></span><br><span class="line">tf.saved_model.save(</span><br><span class="line">    module, SAVED_MODEL_PATH,</span><br><span class="line">    signatures=&#123;<span class="string">'my_signature'</span>:module.add.get_concrete_function()&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert the model using TFLiteConverter</span></span><br><span class="line">converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_PATH)</span><br><span class="line">tflite_model = converter.convert()</span><br><span class="line"><span class="keyword">with</span> open(TFLITE_FILE_PATH, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">  f.write(tflite_model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the TFLite model in TFLite Interpreter</span></span><br><span class="line">interpreter = tf.lite.Interpreter(TFLITE_FILE_PATH)</span><br><span class="line"><span class="comment"># There is only 1 signature defined in the model,</span></span><br><span class="line"><span class="comment"># so it will return it by default.</span></span><br><span class="line"><span class="comment"># If there are multiple signatures then we can pass the name.</span></span><br><span class="line">my_signature = interpreter.get_signature_runner()</span><br><span class="line"></span><br><span class="line"><span class="comment"># my_signature is callable with input as arguments.</span></span><br><span class="line">output = my_signature(x=tf.constant([<span class="number">1.0</span>], shape=(<span class="number">1</span>,<span class="number">10</span>), dtype=tf.float32))</span><br><span class="line"><span class="comment"># 'output' is dictionary with all outputs from the inference.</span></span><br><span class="line"><span class="comment"># In this case we have single output 'result'.</span></span><br><span class="line">print(output[<span class="string">'result'</span>])</span><br></pre></td></tr></table></figure><ul><li>当没有SignatureDef时</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the TFLite model and allocate tensors.</span></span><br><span class="line">interpreter = tf.lite.Interpreter(model_path=<span class="string">"converted_model.tflite"</span>)</span><br><span class="line">interpreter.allocate_tensors()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get input and output tensors.</span></span><br><span class="line">input_details = interpreter.get_input_details()</span><br><span class="line">output_details = interpreter.get_output_details()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test the model on random input data.</span></span><br><span class="line">input_shape = input_details[<span class="number">0</span>][<span class="string">'shape'</span>]</span><br><span class="line">input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)</span><br><span class="line">interpreter.set_tensor(input_details[<span class="number">0</span>][<span class="string">'index'</span>], input_data)</span><br><span class="line"></span><br><span class="line">interpreter.invoke()</span><br><span class="line"></span><br><span class="line"><span class="comment"># The function `get_tensor()` returns a copy of the tensor data.</span></span><br><span class="line"><span class="comment"># Use `tensor()` in order to get a pointer to the tensor.</span></span><br><span class="line">output_data = interpreter.get_tensor(output_details[<span class="number">0</span>][<span class="string">'index'</span>])</span><br><span class="line">print(output_data)</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/nanhuaibeian/article/details/101751439" target="_blank" rel="noopener">TensorFlow：.ckpt文件与.ckpt.meta和.ckpt.index以及.pb文件之间的关系是什么？</a><br><a href="https://sulingling123.github.io/2019/08/15/TF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD%E6%96%B9%E5%BC%8F/" target="_blank" rel="noopener">TF的三种模型的保存与加载方式</a><br><a href="https://cloud.tencent.com/developer/article/1009979" target="_blank" rel="noopener">TensorFlow 到底有几种模型格式？</a><br><a href="https://zhuanlan.zhihu.com/p/113734249" target="_blank" rel="noopener">tensorflow 模型导出总结</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;事先声明，以下大部分内容来源于&lt;a href=&quot;https://zhuanlan.zhihu.com/p/113734249&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;tensorflow 模型导出总结&lt;/a&gt;，并加上个人见解。&lt;/p&gt;
&lt;p&gt;tensorflow 1.0 以及2.0 提供了多种不同的模型导出格式，例如说有checkpoint，SavedModel，Frozen GraphDef，Keras model（HDF5） 以及用于移动端，嵌入式的TFLite。 &lt;/p&gt;
&lt;p&gt;模型导出主要包含了：参数以及网络结构的导出，不同的导出格式可能是分别导出，或者是整合成一个独立的文件。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;参数和网络结构分开保存：checkpoint， SavedModel&lt;/li&gt;
&lt;li&gt;只保存权重：HDF5（可选）&lt;/li&gt;
&lt;li&gt;参数和网络结构保存在一个文件：Frozen GraphDef，HDF5（可选）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在tensorflow 1.0中，可以见下图，主要有三种主要的API：Keras、Estimator以及Legacy即最初的session模型，其中tf.Keras主要保存为HDF5，Estimator保存为SavedModel，而Lagacy主要保存的是Checkpoint，并且可以通过freeze_graph，将模型变量冻结，得到Frozen GradhDef的文件。这三种格式的模型，都可以通过TFLite Converter导出为 &lt;code&gt;.tflite&lt;/code&gt; 的模型文件，用于安卓/ios/嵌入式设备的serving。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MLFrameworks" scheme="https://www.zdaiot.com/categories/MLFrameworks/"/>
    
      <category term="TensorFlow" scheme="https://www.zdaiot.com/categories/MLFrameworks/TensorFlow/"/>
    
    
      <category term="TensorFlow" scheme="https://www.zdaiot.com/tags/TensorFlow/"/>
    
      <category term="save" scheme="https://www.zdaiot.com/tags/save/"/>
    
  </entry>
  
  <entry>
    <title>数字编码</title>
    <link href="https://www.zdaiot.com/Tools/Computer/%E6%95%B0%E5%AD%97%E7%BC%96%E7%A0%81/"/>
    <id>https://www.zdaiot.com/Tools/Computer/数字编码/</id>
    <published>2022-03-31T07:08:55.000Z</published>
    <updated>2022-03-31T07:08:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近，学完字符编码之后，准备一鼓作气，看一下数字编码。</p><h2 id="整数编码"><a href="#整数编码" class="headerlink" title="整数编码"></a>整数编码</h2><p>在C语音中，整数编码可以分为有符号整数和无符号整数。当用关键字 char short long等指定，默认的是前面有signed，如果声明为有符号类型，需要在关键字前加unsigned，如unsigned short ，unsigned long等等。</p><p>那么这些数据是如何存储的呢？</p><h3 id="无符号整数"><a href="#无符号整数" class="headerlink" title="无符号整数"></a>无符号整数</h3><p>首先我们来看最简单的无符号整数。假设该二进制数有$w$位，那么它能表示的数据范围为$[0,2^w−1]$。</p><p>以int8为例（也就是用8个bit来表示数字），那么取值范围为<code>0000 0000</code>到<code>1111 1111</code>，也就是<code>0</code>到<code>255</code>。这本身没有什么好讲的。</p><p>下面是在C\C++中无符号基本数据类型的最小值跟最大值(64位机器)：</p><div class="table-container"><table><thead><tr><th>数据类型</th><th>最小值</th><th>最大值</th></tr></thead><tbody><tr><td>unsigned char</td><td>0</td><td>255</td></tr><tr><td>unsigned short</td><td>0</td><td>65 535</td></tr><tr><td>unsigned int</td><td>0</td><td>4 294 967 295</td></tr><tr><td>unsigned long</td><td>0</td><td>18 446 744 073 709 551 615</td></tr></tbody></table></div><h3 id="有符号整数"><a href="#有符号整数" class="headerlink" title="有符号整数"></a>有符号整数</h3><p>无符号整数看起来很简单，但是无法处理负数。这时候有符号整数就派上用上了。</p><h4 id="原码、反码、补码"><a href="#原码、反码、补码" class="headerlink" title="原码、反码、补码"></a>原码、反码、补码</h4><p>我们首先介绍几个关键概念。</p><p><strong>原码：</strong>原码表示是最简单的，第一位为符号位，其余位为相应的数值。</p><p>例如short a = 6，a 的原码就是0000 0000 0000 0110。更改 a 的值a = -18，此时 a 的原码就是1000 0000 0001 0010。</p><p><strong>反码：</strong>正数的反码与其原码相同；负数的反码是将原码中除符号位以外的所有位取反。</p><p>例如short a = 6，a 的原码和反码都是0000 0000 0000 0110。更改 a 的值a = -6，此时 a 的反码是1111 1111 1111 1001。</p><p><strong>补码：</strong>对于正数，它的补码就是其原码（原码、反码、补码都相同）；对于负数，补码等于反码加1。例如short a = 6，a 的原码、反码、补码都是0000 0000 0000 0110。更改 a 的值a = -6;，此时 a 的补码是1111 1111 1111 1010。</p><p>用公式表示该过程如下：</p><script type="math/tex; mode=display">D_{signed}(\vec{x})=-x_{w-1}2^{w-1}+\sum_{i=0}^{w-2}x_i2^i</script><p>其中$\vec{x}$为二进制为$w$位的向量形式，其中的分量只能是0和1。上式可以看到最高位$x_{w-1}$为符号位，最高位$x_{w-1}$为1则为负数，为0则代表正数，此时只剩下了$\sum_{i=0}^{w-2}x_i2^i$。</p><script type="math/tex; mode=display">D_{signed}([0 0 0 1])=-0*2^3+0*2^2+0*2^1+1*2^0=0+0+0+1=1\\D_{signed}([0 1 0 1])=-0*2^3+1*2^2+0*2^1+1*2^0=0+4+0+1=5\\D_{signed}([1 0 1 1])=-1*2^3+0*2^2+1*2^1+1*2^0=-8+0+2+1=-5\\D_{signed}([1 1 1 1])=-1*2^3+1*2^2+1*2^1+1*2^0=-8+4+2+1=-1</script><p>下面我们来考虑$w$位补码所能表示的范围，上面的式子所能表示的最小值是最高位为 1，其他位均为零的时候即$D_{min}=-2^{w-1}$。而最大值是最高位（符号位）为 0，其他位均为 1 时，即$D_{max}=\sum_{i=0}^{w-2}2^i=2^{w-1}-1$。所以一个$w$位的二进制数可以表示的有符号数值范围是$[-2^{w-1},2^{w-1}-1]$。</p><p>下面是在C\C++中无符号基本数据类型的最小值跟最大值(64位机器)。</p><div class="table-container"><table><thead><tr><th>数据类型</th><th>最小值</th><th>最大值</th></tr></thead><tbody><tr><td>char</td><td>-128</td><td>127</td></tr><tr><td>short</td><td>-32 768</td><td>32 767</td></tr><tr><td>int</td><td>-2 147 483 648</td><td>2 147 483 647</td></tr><tr><td>long</td><td>-9 223 372 036 854 775 808</td><td>9 223 372 036 854 775 807</td></tr></tbody></table></div><p>那么为什么补码表示的表示范围是不对称的，正数比负数要少一个？是因为有一半的位要表示负数（符号位为 1），另一半的位要表示正数（符号位为 0）。以int8为例，那么<code>1000 0000</code>和<code>0000 0000</code>分别表示正负0，但是我们并不需要负0，所以把<code>1000 0000</code>编码为了负数。</p><h4 id="产生原因"><a href="#产生原因" class="headerlink" title="产生原因"></a>产生原因</h4><p>那么有了原码，计算机为什么还要用补码呢？这就需要看它们的运算情况。</p><p>假设字长为 8 位 ，那么原码的运算方式为：1 - 1 = 1 + ( -1 ) =(00000001) + (10000001) = (10000010) = -2，这显然不正确。出现的原因是这种形式下，符号位无法参与运算。当两个正数相加时是没有问题的，但是负数无法参与运算。</p><p>我们接下来看一下反码的运算：1 - 1 = 1 + ( -1 )= (00000001) + (11111110) = (11111111) = ( -0 ) 有问题。1 – 2 = 1 + ( -2 ) = (00000001) + (11111101) = (11111110) = ( -1 ) 正确。反码的问题出 现在(+0)和(-0)上，因为在人们的计算概念中零是没有正负之分的。</p><p> 再来看补码的加减运算 如下：1 - 1 = 1 + （-1） = (00000001) + (11111111) = (00000000) = 0 正确。1 – 2 = 1 + （-2）= (00000001) + (11111110) = (11111111) = ( -1 ) 正确。</p><h2 id="浮点数编码"><a href="#浮点数编码" class="headerlink" title="浮点数编码"></a>浮点数编码</h2><p>根据国际标准IEEE 754，任意一个二进制浮点数V可以表示成下面的形式：</p><p><img src="/Tools/Computer/数字编码/times 2^E&chs=45.png" alt="img" style="zoom: 67%;"></p><p>1、(-1)^s表示<strong>符号标志位</strong>，当s=0，V为正数；当s=1，V为负数。</p><p>2、M表示有效数字，大于等于1，小于2。<strong>称作尾数(significand)。</strong></p><p>3、2为<strong>基数</strong>。</p><p>4、E则是指数部分称作<strong>阶码(exponent)</strong>。</p><p>举例来说，十进制的5.0，写成二进制是101.0，相当于1.01×2^2。那么，按照上面V的格式，可以得出s=0，M=1.01，E=2。</p><p>十进制的-5.0，写成二进制是-101.0，相当于-1.01×2^2。那么，s=1，M=1.01，E=2。</p><p>IEEE 754规定，对于32位的浮点数，最高的1位是符号位s，接着的8位是指数E，剩下的23位为有效数字M。</p><p><img src="/Tools/Computer/数字编码/bg2010060601.png" alt="img"></p><p>对于64位的浮点数，最高的1位是符号位S，接着的11位是指数E，剩下的52位为有效数字M。</p><p><img src="/Tools/Computer/数字编码/bg2010060602.png" alt="img"></p><p>IEEE 754对有效数字M和指数E，还有一些特别规定。</p><p>前面说过，1≤M&lt;2，也就是说，M可以写成1.xxxxxx的形式，其中xxxxxx表示小数部分。<strong>IEEE 754规定，在计算机内部保存M时，默认这个数的第一位总是1，因此可以被舍去，只保存后面的xxxxxx部分。</strong>比如保存1.01的时候，只保存01，等到读取的时候，再把第一位的1加上去。这样做的目的，是节省1位有效数字。以32位浮点数为例，留给M只有23位，将第一位的1舍去以后，等于可以保存24位有效数字。</p><p>至于指数E，情况就比较复杂。</p><p>首先，E为一个无符号整数（unsigned int）。这意味着，如果E为8位，它的取值范围为<code>0~255</code>；如果E为11位，它的取值范围为<code>0~2047</code>。但是，我们知道，科学计数法中的E是可以出现负数的，<strong>所以IEEE 754规定，E的值必须再减去一个中间数，得到真实值，这个中间数称为偏置量Bias。</strong>它的数值跟存储阶码的位长有关，当阶码位长为k的时候偏置量的值为<code>2 ^ k - 1</code>。对于8位的E，这个中间数是127；对于11位的E，这个中间数是1023。</p><p>比如，2^10的E是10，所以保存成32位浮点数时，必须加上中间数，保存成10+127=137，即10001001。</p><h3 id="规格化浮点数"><a href="#规格化浮点数" class="headerlink" title="规格化浮点数"></a>规格化浮点数</h3><p><strong>E不全为0或不全为1。</strong>这时，浮点数就采用上面的规则表示，即指数E的计算值减去127（或1023），得到真实值，再将有效数字M前加上第一位的1。</p><p>可以推断出它所能够表示的无符号数取值范围是<code>1~254</code>。因此，阶码值的取值范围是<code>-126 ～ 127</code>。</p><h3 id="非规格化浮点数"><a href="#非规格化浮点数" class="headerlink" title="非规格化浮点数"></a>非规格化浮点数</h3><p>非规格化浮点数的特点就是<strong>用于存储阶码的所有位全为0E全为0，存储尾数的位可以随意定制</strong>。非规格化浮点数主要用于表示那些<em>非常接近于0的数</em>。这时，浮点数的指数E等于1-127（或者1-1023），有效数字M不再加上第一位的1，而是还原为0.xxxxxx的小数。这样做是为了表示±0，以及接近于0的很小的数字。</p><p>为啥这个地方是1-127呢？这是为了平滑过度。具体可看<a href="https://www.beansmile.com/blog/posts/details-of-ieee-float" target="_blank" rel="noopener">详谈IEEE浮点数编码机制</a>。</p><h3 id="特殊值"><a href="#特殊值" class="headerlink" title="特殊值"></a>特殊值</h3><p><strong>E全为1。</strong>这时如果有效数字M全为0，表示±无穷大（正负取决于符号位s）；如果有效数字M不全为0，表示这个数不是一个数（NaN）。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/q932104843/article/details/69808550" target="_blank" rel="noopener">计算机整数编码系统</a><br><a href="https://zhuanlan.zhihu.com/p/54990992" target="_blank" rel="noopener">整数的编码与存储</a><br><a href="https://www.cnblogs.com/sv00/p/9865124.html" target="_blank" rel="noopener">了解浮点数的编码形式</a><br><a href="https://www.ruanyifeng.com/blog/2010/06/ieee_floating-point_representation.html" target="_blank" rel="noopener">浮点数的二进制表示</a><br><a href="https://www.beansmile.com/blog/posts/details-of-ieee-float" target="_blank" rel="noopener">详谈IEEE浮点数编码机制</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近，学完字符编码之后，准备一鼓作气，看一下数字编码。&lt;/p&gt;
&lt;h2 id=&quot;整数编码&quot;&gt;&lt;a href=&quot;#整数编码&quot; class=&quot;headerlink&quot; title=&quot;整数编码&quot;&gt;&lt;/a&gt;整数编码&lt;/h2&gt;&lt;p&gt;在C语音中，整数编码可以分为有符号整数和无符号整数。当用关键字 char short long等指定，默认的是前面有signed，如果声明为有符号类型，需要在关键字前加unsigned，如unsigned short ，unsigned long等等。&lt;/p&gt;
&lt;p&gt;那么这些数据是如何存储的呢？&lt;/p&gt;
&lt;h3 id=&quot;无符号整数&quot;&gt;&lt;a href=&quot;#无符号整数&quot; class=&quot;headerlink&quot; title=&quot;无符号整数&quot;&gt;&lt;/a&gt;无符号整数&lt;/h3&gt;
    
    </summary>
    
    
      <category term="Tools" scheme="https://www.zdaiot.com/categories/Tools/"/>
    
      <category term="Computer" scheme="https://www.zdaiot.com/categories/Tools/Computer/"/>
    
    
      <category term="编码" scheme="https://www.zdaiot.com/tags/%E7%BC%96%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>字符编码</title>
    <link href="https://www.zdaiot.com/Tools/Computer/%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/"/>
    <id>https://www.zdaiot.com/Tools/Computer/字符编码/</id>
    <published>2022-03-30T12:26:55.000Z</published>
    <updated>2022-03-30T12:26:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近在搞二进制分析的东西，对于字符编码特别糊涂，所以学习了一下，本来觉得<a href="https://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html" target="_blank" rel="noopener">阮一峰的笔记</a>挺好的，但是感觉又有点问题，所以我这里在自己总结一下，以下大部分内容还是来源于<a href="https://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html" target="_blank" rel="noopener">阮一峰的笔记</a>。当然我自己总结的可能也不太对（知识有限呀），之后可以再修改。</p><h2 id="ASCII-码"><a href="#ASCII-码" class="headerlink" title="ASCII 码"></a>ASCII 码</h2><p>计算机中，每一个二进制位（bit）有<code>0</code>和<code>1</code>两种状态，因此八个二进制位就可以组合出256种状态，这被称为一个字节（byte）。也就是说，一个字节一共可以用来表示256种不同的状态，每一个状态对应一个符号，就是256个符号，从<code>00000000</code>到<code>11111111</code>。</p><p>上个世纪60年代，美国制定了一套字符编码，对英语字符与二进制位之间的关系，做了统一规定。这被称为 ASCII 码，一直沿用至今。</p><p>ASCII 码一共规定了128个字符的编码，比如空格<code>SPACE</code>是32（二进制<code>00100000</code>），大写的字母<code>A</code>是65（二进制<code>01000001</code>）。这128个符号（包括32个不能打印出来的控制符号），<strong>只占用了一个字节的后面7位，最前面的一位统一规定为<code>0</code></strong>。</p><h2 id="ANSI"><a href="#ANSI" class="headerlink" title="ANSI"></a>ANSI</h2><p>ASCII 码只能表示128个字符，对于英文是足够的，但是对于中文、日文、法语等是不够的。比如，在法语中，字母上方有注音符号，它就无法用 ASCII 码表示。于是，一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的<code>é</code>的编码为130（二进制<code>10000010</code>）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。</p><p>至于亚洲国家的文字，使用的符号就更多了，汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如，简体中文常见的编码方式是 GB2312，使用两个字节表示一个汉字，所以理论上最多可以表示 256 x 256 = 65536 个符号。</p><p>但是，这里又出现了新的问题。不同的国家有不同的字母，因此，哪怕它们都使用256个符号的编码方式，代表的字母却不一样。比如，130在法语编码中代表了<code>é</code>，在希伯来语编码中却代表了字母<code>Gimel</code> (<code>ג</code>)，在俄语编码中又会代表另一个符号。但是不管怎样，所有这些编码方式中，0—127表示的符号是一样的，不一样的只是128—255的这一段。</p><p>好了，终于可以开始扯Windows的记事本了。</p><p>在早期并没有Unicode（下文介绍）的时候，可以看到编码是十分混乱的，Windows想了个办法，就是允许一个默认语言编码，就是当遇到一个字符串，不是Unicode的时候，就用<strong>默认语言编码解释（在区域和语言选项里可以改默认语言）</strong>。这个默认语言，在不同Windows语言版本里是不同的，在简体中文版里，是GBK，在繁体中文版里，是BIG5，在日文版里是JIS。</p><p>而Windows的<code>notepad.exe</code>（记事本）中的ANSI编码（如下图所示）就是这种默认编码。所以，一个中文文本，用ANSI编码保存，在简体中文版Windows就会使用GBK模式保存，拿到繁体中文Windows读取，就会使用BIG5模式读取，那么就全乱套了（文件二进制数不变，但是解码查表规则不同）。</p><p><img src="/Tools/Computer/字符编码/image-20220330203356707.png" alt="image-20220330203356707" style="zoom: 80%;"></p><h2 id="Unicode字符集"><a href="#Unicode字符集" class="headerlink" title="Unicode字符集"></a>Unicode字符集</h2><p>正如上一节所说，世界上存在着多种编码方式，同一个二进制数字可以被解释成不同的符号。因此，要想打开一个文本文件，就必须知道它的编码方式，否则用错误的编码方式解读，就会出现乱码。为什么电子邮件常常出现乱码？就是因为发信人和收信人使用的编码方式不一样。</p><p>可以想象，如果有一种字符集，将世界上所有的符号都纳入其中。每一个符号都给予一个独一无二的编码，那么乱码问题就会消失。这就是 Unicode，就像它的名字都表示的，这是一种统一的字符集标准。</p><p>Unicode 当然是一个很大的集合，现在的规模可以容纳100多万个符号。每个符号的编码都不一样，比如，<code>U+0639</code>表示阿拉伯字母<code>Ain</code>，<code>U+0041</code>表示英语的大写字母<code>A</code>，<code>U+4E25</code>表示汉字<code>严</code>。具体的符号对应表，可以查询<a href="https://www.unicode.org/" target="_blank" rel="noopener">unicode.org</a>，或者专门的<a href="http://www.chi2ko.com/tool/CJK.htm" target="_blank" rel="noopener">汉字对应表</a>。</p><h2 id="Unicode的问题"><a href="#Unicode的问题" class="headerlink" title="Unicode的问题"></a>Unicode的问题</h2><p>需要注意的是，Unicode 只是一个字符集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何编码。</p><p>比如，汉字<code>严</code>的 Unicode 是十六进制数<code>4E25</code>，转换成二进制数足足有15位（<code>100111000100101</code>），也就是说，这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。</p><p>这里就有两个严重的问题，第一个问题是，如何才能区别 Unicode 和 ASCII ？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果 Unicode 统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是<code>0</code>，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。</p><p>它们造成的结果是：</p><p>1）出现了 Unicode 的多种编码方式，也就是说有许多种不同的二进制格式，可以用来表示 Unicode。</p><p>2）Unicode 在很长一段时间内无法推广，直到互联网的出现。</p><h2 id="UTF-8编码"><a href="#UTF-8编码" class="headerlink" title="UTF-8编码"></a>UTF-8编码</h2><p>互联网的普及，强烈要求出现一种统一的编码方式。UTF-8 就是在互联网上使用最广的一种 Unicode 的编码方式。其他编码方式还包括 UTF-16（字符用两个字节或四个字节表示）和 UTF-32（字符用四个字节表示），不过在互联网上基本不用。<strong>重复一遍，这里的关系是，UTF-8 是 Unicode字符集 的编码方式之一。</strong></p><p>UTF-8 最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。</p><p>UTF-8 的编码规则很简单，只有二条：</p><p>1）对于单字节的符号，字节的第一位设为<code>0</code>，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的。</p><p>2）对于<code>n</code>字节的符号（<code>n &gt; 1</code>），第一个字节的前<code>n</code>位都设为<code>1</code>，第<code>n + 1</code>位设为<code>0</code>，后面字节的前两位一律设为<code>10</code>。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。</p><p>下表总结了编码规则，字母<code>x</code>表示可用编码的位。</p><blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; Unicode符号范围     |        UTF-8编码方式</span><br><span class="line">&gt; (十六进制)        |              （二进制）</span><br><span class="line">&gt; ----------------------+---------------------------------------------</span><br><span class="line">&gt; 0000 0000-0000 007F | 0xxxxxxx</span><br><span class="line">&gt; 0000 0080-0000 07FF | 110xxxxx 10xxxxxx</span><br><span class="line">&gt; 0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx</span><br><span class="line">&gt; 0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>跟据上表，解读 UTF-8 编码非常简单。如果一个字节的第一位是<code>0</code>，则这个字节单独就是一个字符；如果第一位是<code>1</code>，则连续有多少个<code>1</code>，就表示当前字符占用多少个字节。</p><p>下面，还是以汉字<code>严</code>为例，演示如何实现 UTF-8 编码。</p><p><code>严</code>的 Unicode 是<code>4E25</code>（<code>100111000100101</code>），根据上表，可以发现<code>4E25</code>处在第三行的范围内（<code>0000 0800 - 0000 FFFF</code>），因此<code>严</code>的 UTF-8 编码需要三个字节，即格式是<code>1110xxxx 10xxxxxx 10xxxxxx</code>。然后，从<code>严</code>的最后一个二进制位开始，依次从后向前填入格式中的<code>x</code>，多出的位补<code>0</code>。这样就得到了，<code>严</code>的 UTF-8 编码是<code>11100100 10111000 10100101</code>，转换成十六进制就是<code>E4B8A5</code>。</p><h2 id="编码之间的转换"><a href="#编码之间的转换" class="headerlink" title="编码之间的转换"></a>编码之间的转换</h2><p>通过上一节的例子，可以看到<code>严</code>的 Unicode码 是<code>4E25</code>，UTF-8 编码是<code>E4B8A5</code>，两者是不一样的。它们之间的转换可以通过程序实现。比如用Windows平台<code>notepad.exe</code>（记事本），打开文件后，点击<code>文件</code>菜单中的<code>另存为</code>命令，会跳出一个对话框，在最底部有一个<code>编码</code>的下拉条。选择完”编码方式”后，点击”保存”按钮，文件的编码方式就立刻转换好了。</p><p><img src="/Tools/Computer/字符编码/image-20220330203356707.png" alt="image-20220330203356707" style="zoom: 80%;"></p><h2 id="Little-endian-和-Big-endian"><a href="#Little-endian-和-Big-endian" class="headerlink" title="Little endian 和 Big endian"></a>Little endian 和 Big endian</h2><p>以汉字<code>严</code>为例，Unicode 码是<code>4E25</code>，需要用两个字节存储，一个字节是<code>4E</code>，另一个字节是<code>25</code>。存储的时候，<code>4E</code>在前，<code>25</code>在后，这就是 Big endian 方式；<code>25</code>在前，<code>4E</code>在后，这是 Little endian 方式。</p><p>那么很自然的，就会出现一个问题：计算机怎么知道某一个文件到底采用哪一种方式编码？</p><p>Unicode 规范定义，每一个文件的最前面分别加入一个表示编码顺序的字符，这个字符的名字叫做”零宽度非换行空格”（zero width no-break space），用<code>FEFF</code>表示。这正好是两个字节，而且<code>FF</code>比<code>FE</code>大<code>1</code>。</p><p>如果一个文本文件的头两个字节是<code>FE FF</code>，就表示该文件采用大头方式；如果头两个字节是<code>FF FE</code>，就表示该文件采用小头方式。</p><h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><p>我们使用Winhex软件打开一个Pytorch模型文件（含网络结构），查看其二进制、ASCII编码、UTF-8编码，其中部分内容如下。</p><p><img src="/Tools/Computer/字符编码/image-20220330231545195.png" alt="image-20220330231545195" style="zoom:50%;"></p><p>注意到其中有一个<code>E7 AC AC</code>字符，对应的二进制位<code>11100111 10101100 10101100</code>，正好符合UTF-8编码，解码之后二进制为<code>0111 101100 101100</code>，再换算成16进制为<code>7B2C</code>，查找<a href="https://www.unicode.org/charts/PDF/U4E00.pdf" target="_blank" rel="noopener">Unicode字符集</a>，正好是<code>第</code>这个字。</p><p><img src="/Tools/Computer/字符编码/image-20220330233301713.png" alt="image-20220330233301713" style="zoom:50%;"></p><h2 id="实战2"><a href="#实战2" class="headerlink" title="实战2"></a>实战2</h2><p>打开”记事本”程序<code>notepad.exe</code>，新建一个文本文件，内容就是一个<code>严</code>字，依次采用<code>ANSI</code>，<code>Unicode</code>，<code>Unicode big endian</code>，<code>UTF-8-BOM</code>和<code>UTF-8</code>，编码方式保存。</p><p>然后，用文本编辑软件<a href="https://www.google.cn/search?aq=t&amp;oq=UltraEdit&amp;complete=1&amp;hl=zh-CN&amp;newwindow=1&amp;rlz=1B3GGGL_zh-CNCN216CN216&amp;q=ultraedit+下载&amp;btnG=Google+搜索&amp;meta=" target="_blank" rel="noopener">UltraEdit 中</a>的”十六进制功能”，观察该文件的内部编码方式。</p><p>1）ANSI：文件的编码就是两个字节<code>D1 CF</code>，这正是<code>严</code>的 GB2312 编码，这也暗示 GB2312 是采用大头方式存储的。</p><p>2）Unicode：编码是四个字节<code>FF FE 25 4E</code>，其中<code>FF FE</code>表明是小头方式存储，真正的编码是<code>4E25</code>。</p><p>3）Unicode big endian：编码是四个字节<code>FE FF 4E 25</code>，其中<code>FE FF</code>表明是大头方式存储。</p><p>4）UTF-8-BOM：编码是六个字节<code>EF BB BF E4 B8 A5</code>，前三个字节<code>EF BB BF</code>表示这是UTF-8编码，后三个<code>E4B8A5</code>就是<code>严</code>的具体编码，它的存储顺序与编码顺序是一致的。</p><p>5）UTF-8：编码是三个字节<code>E4 B8 A5</code>，<code>E4B8A5</code>就是<code>严</code>的具体编码，它的存储顺序与编码顺序是一致的。值得注意的是，UTF-8其实是不需要BOM，根据编码规则就可以知道这个是UTF-8了。</p><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>补充一个知识点：二进制与十六进制的转换。</p><p>方法：取四合一法，即从二进制的小数点为分界点，向左（向右）每四位取成一位，接着将这四位二进制按权相加，得到的数就是一位十六位二进制数，然后，按顺序进行排列，小数点的位置不变，得到的数字就是我们所求的十六进制数。如果向左（向右）取四位后，取到最高（最低）位时候，如果无法凑足四位，可以在小数点最左边（最右边），即整数的最高位（最低位）添0，凑足四位。</p><p>1、例：将二进制11101001.1011转换为十六进制</p><p>得到结果：将二进制11101001.1011转换为十六进制为E9.B</p><p>2、例：将101011.101转换为十六进制</p><p>因此得到结果：将二进制101011.101转换为十六进制为2B.A</p><p>3、例：将二进制1110 1010 0101转换为十六进制</p><p>结果：EA5。</p><p>验证：二进制<code>2**11+2**10+2**9+2^7+2**5+2**2+2**0=3749</code>，可以化简为<code>(2**3+2**2+2**1)*(2**8)+(2**3+2**1)*(2**4)+2**2+2**0=3749</code>。<code>1110 1010 0101</code>分别对应于<code>E A 5</code>，换算成十进制为<code>14*(16**2)+10*16+5=3749</code>。所以取四合一法是正确的。</p><h2 id="x字符串转码"><a href="#x字符串转码" class="headerlink" title="\x字符串转码"></a>\x字符串转码</h2><p>在使用Python的时候，经常遇到类似于<code>\xe4\xbd\xa0\xe5\xa5\xbd\xe4\xb8\x96\xe7\x95\x8c</code>的编码，其实它是utf-8编码，但数据类型是字符串类型，而不是bytes类型的utf-8编码。如果我们需要将\x开头的字符串编码转换中文。</p><p>先将字符串编码指定为unicode_escape，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">'\xe4\xbd\xa0\xe5\xa5\xbd\xe4\xb8\x96\xe7\x95\x8c'</span></span><br><span class="line">s = s.encode(<span class="string">'unicode_escape'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 得到bytes类型数据（单斜杠变成双斜杠）</span></span><br><span class="line"><span class="string">b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\\xe4\\xb8\\x96\\xe7\\x95\\x8c'</span></span><br></pre></td></tr></table></figure><p>接着再对bytes类型进行utf-8解码，得到字符串，将字符串中的 “ \x “ 替换为 “ % “，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ss = s.decode(<span class="string">'utf-8'</span>).replace(<span class="string">'\\x'</span>, <span class="string">'%'</span>)</span><br><span class="line"><span class="comment"># 替换作用就是将字符串改为url的utf-8编码格式</span></span><br><span class="line">%e4%bd%a0%e5%a5%bd%e4%b8%<span class="number">96</span>%e7%<span class="number">95</span>%<span class="number">8</span>c</span><br></pre></td></tr></table></figure><p>最后利用urllib中的unquote方法将url编码解码，得到中文</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line">un = urllib.parse.unquote(ss)</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">你好世界</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html" target="_blank" rel="noopener">字符编码笔记：ASCII，Unicode 和 UTF-8</a><br><a href="https://www.zhihu.com/question/20650946/answer/15751688" target="_blank" rel="noopener">Windows 记事本的 ANSI、Unicode、UTF-8 这三种编码模式有什么区别？ - 时国怀的回答 - 知乎</a><br><a href="https://www.zhihu.com/question/20650946/answer/15745831" target="_blank" rel="noopener">Windows 记事本的 ANSI、Unicode、UTF-8 这三种编码模式有什么区别？ - 梁海的回答 - 知乎 </a><br><a href="https://blog.csdn.net/YungGuo/article/details/110197818" target="_blank" rel="noopener">关于\x开头的字符串编码转换中文解决方法</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在搞二进制分析的东西，对于字符编码特别糊涂，所以学习了一下，本来觉得&lt;a href=&quot;https://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;阮一峰的笔记&lt;/a&gt;挺好的，但是感觉又有点问题，所以我这里在自己总结一下，以下大部分内容还是来源于&lt;a href=&quot;https://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;阮一峰的笔记&lt;/a&gt;。当然我自己总结的可能也不太对（知识有限呀），之后可以再修改。&lt;/p&gt;
&lt;h2 id=&quot;ASCII-码&quot;&gt;&lt;a href=&quot;#ASCII-码&quot; class=&quot;headerlink&quot; title=&quot;ASCII 码&quot;&gt;&lt;/a&gt;ASCII 码&lt;/h2&gt;&lt;p&gt;计算机中，每一个二进制位（bit）有&lt;code&gt;0&lt;/code&gt;和&lt;code&gt;1&lt;/code&gt;两种状态，因此八个二进制位就可以组合出256种状态，这被称为一个字节（byte）。也就是说，一个字节一共可以用来表示256种不同的状态，每一个状态对应一个符号，就是256个符号，从&lt;code&gt;00000000&lt;/code&gt;到&lt;code&gt;11111111&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;上个世纪60年代，美国制定了一套字符编码，对英语字符与二进制位之间的关系，做了统一规定。这被称为 ASCII 码，一直沿用至今。&lt;/p&gt;
&lt;p&gt;ASCII 码一共规定了128个字符的编码，比如空格&lt;code&gt;SPACE&lt;/code&gt;是32（二进制&lt;code&gt;00100000&lt;/code&gt;），大写的字母&lt;code&gt;A&lt;/code&gt;是65（二进制&lt;code&gt;01000001&lt;/code&gt;）。这128个符号（包括32个不能打印出来的控制符号），&lt;strong&gt;只占用了一个字节的后面7位，最前面的一位统一规定为&lt;code&gt;0&lt;/code&gt;&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Tools" scheme="https://www.zdaiot.com/categories/Tools/"/>
    
      <category term="Computer" scheme="https://www.zdaiot.com/categories/Tools/Computer/"/>
    
    
      <category term="编码" scheme="https://www.zdaiot.com/tags/%E7%BC%96%E7%A0%81/"/>
    
  </entry>
  
</feed>
