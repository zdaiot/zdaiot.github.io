<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 3.9.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"www.zdaiot.com",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="Pytorch的两种保存模型方式众所周知，Pytorch存储模型主要有两种方式。 方式一：Save/Load state_dict (Recommended) 只保存权重： 1torch.save(model.state_dict(), PATH)"><meta name="keywords" content="Pytorch"><meta property="og:type" content="article"><meta property="og:title" content="Pytorch模型存储研究"><meta property="og:url" content="https://www.zdaiot.com/MLFrameworks/Pytorch/Pytorch模型存储研究/index.html"><meta property="og:site_name" content="zdaiot"><meta property="og:description" content="Pytorch的两种保存模型方式众所周知，Pytorch存储模型主要有两种方式。 方式一：Save/Load state_dict (Recommended) 只保存权重： 1torch.save(model.state_dict(), PATH)"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://www.zdaiot.com/MLFrameworks/Pytorch/Pytorch模型存储研究/image-20220323203426343.png"><meta property="og:image" content="https://www.zdaiot.com/MLFrameworks/Pytorch/Pytorch模型存储研究/image-20220323223740287.png"><meta property="og:image" content="https://www.zdaiot.com/MLFrameworks/Pytorch/Pytorch模型存储研究/截屏2022-03-23%2023.13.29.png"><meta property="og:image" content="https://www.zdaiot.com/MLFrameworks/Pytorch/Pytorch模型存储研究/截屏2022-03-23%2023.27.02.png"><meta property="og:image" content="https://www.zdaiot.com/MLFrameworks/Pytorch/Pytorch模型存储研究/截屏2022-03-23%2023.24.34.png"><meta property="og:updated_time" content="2022-03-23T11:23:38.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Pytorch模型存储研究"><meta name="twitter:description" content="Pytorch的两种保存模型方式众所周知，Pytorch存储模型主要有两种方式。 方式一：Save/Load state_dict (Recommended) 只保存权重： 1torch.save(model.state_dict(), PATH)"><meta name="twitter:image" content="https://www.zdaiot.com/MLFrameworks/Pytorch/Pytorch模型存储研究/image-20220323203426343.png"><link rel="canonical" href="https://www.zdaiot.com/MLFrameworks/Pytorch/Pytorch模型存储研究/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>Pytorch模型存储研究 | zdaiot</title><script data-pjax>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?0b0b58037319da4959d5a3c014160ccd";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">zdaiot</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">404NotFound</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.zdaiot.com/MLFrameworks/Pytorch/Pytorch模型存储研究/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/uploads/avatar.png"><meta itemprop="name" content="zdaiot"><meta itemprop="description" content="404NotFound"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="zdaiot"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> Pytorch模型存储研究<a href="https://github.com/zdaiot/zdaiot.github.io/tree/hexo/source/_posts/MLFrameworks/Pytorch/Pytorch模型存储研究.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pencil-alt"></i></a></h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-03-23 19:23:38" itemprop="dateCreated datePublished" datetime="2022-03-23T19:23:38+08:00">2022-03-23</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MLFrameworks/" itemprop="url" rel="index"><span itemprop="name">MLFrameworks</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MLFrameworks/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>9.7k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>9 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="Pytorch的两种保存模型方式"><a href="#Pytorch的两种保存模型方式" class="headerlink" title="Pytorch的两种保存模型方式"></a>Pytorch的两种保存模型方式</h2><p>众所周知，Pytorch存储模型主要有<a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html" target="_blank" rel="noopener">两种方式</a>。</p><p><strong>方式一：Save/Load <code>state_dict</code> (Recommended)</strong></p><p>只保存权重：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model.state_dict(), PATH)</span><br></pre></td></tr></table></figure><p>加载模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = TheModelClass(*args, **kwargs)</span><br><span class="line">model.load_state_dict(torch.load(PATH))</span><br><span class="line">model.eval()</span><br></pre></td></tr></table></figure><p><strong>方式二：Save/Load Entire Model</strong></p><p>保存模型和权重：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model, PATH)</span><br></pre></td></tr></table></figure><p>加载模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Model class must be defined somewhere</span></span><br><span class="line">model = torch.load(PATH)</span><br><span class="line">model.eval()</span><br></pre></td></tr></table></figure><p>注意到方式二在加载模型的时候，官方有一个提醒：<code># Model class must be defined somewhere</code>，也就是从<code>PATH</code>中读取时需要定义出来<code>TheModelClass</code>，否则的话会直接报错。可能你看到这个地方不是很明白，我们可以做一个实验。</p><h2 id="Save-Load-Entire-Model：缺陷"><a href="#Save-Load-Entire-Model：缺陷" class="headerlink" title="Save/Load Entire Model：缺陷"></a>Save/Load Entire Model：缺陷</h2><p>我们首先定义模型结构，并进行保存，假设下面代码存储在文件<code>E:\Working\torch_save\save_learn.py</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myConv</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_channel, output_chanel)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(input_channel, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(output_chanel, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)  <span class="comment"># flatten all dimensions except batch</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_conv</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> myConv(input_channel=<span class="number">3</span>, output_chanel=<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define Model</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TheModelClass</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv = get_conv()</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = torch.sigmoid(self.fc3(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">   </span><br><span class="line">model = TheModelClass()</span><br><span class="line">output = model(torch.ones(<span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">print(output)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里_use_new_zipfile_serialization=False是使用非压缩存储方式，这个之后再进行解释。</span></span><br><span class="line">torch.save(model, <span class="string">'./model_file.pth'</span>, _use_new_zipfile_serialization=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>执行该文件，可以保存模型到<code>./model_file.pth</code>，并且得到输出如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Out[<span class="number">1</span>]: tensor([[<span class="number">0.5042</span>]], grad_fn=&lt;SigmoidBackward0&gt;)</span><br></pre></td></tr></table></figure><p>此时，新建一个文件<code>E:\Working\torch_save\load_learn.py</code>，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">model = torch.load(<span class="string">'model_file.pth'</span>)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure><p>执行该文件，会报错如下，也就是在该文件中，找不到<code>TheModelClass</code>类的定义：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"E:/Working/torch_save/load_learn.py"</span>, line <span class="number">4</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    model = torch.load(<span class="string">'model_file.pth'</span>)</span><br><span class="line">  File <span class="string">"C:\Users\zhaodali\Anaconda3\lib\site-packages\torch\serialization.py"</span>, line <span class="number">713</span>, <span class="keyword">in</span> load</span><br><span class="line">    <span class="keyword">return</span> _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)</span><br><span class="line">  File <span class="string">"C:\Users\zhaodali\Anaconda3\lib\site-packages\torch\serialization.py"</span>, line <span class="number">930</span>, <span class="keyword">in</span> _legacy_load</span><br><span class="line">    result = unpickler.load()</span><br><span class="line">  File <span class="string">"C:\Users\zhaodali\Anaconda3\lib\site-packages\torch\serialization.py"</span>, line <span class="number">746</span>, <span class="keyword">in</span> find_class</span><br><span class="line">    <span class="keyword">return</span> super().find_class(mod_name, name)</span><br><span class="line">AttributeError: Can<span class="string">'t get attribute '</span>TheModelClass<span class="string">' on &lt;module '</span>__main__<span class="string">' from '</span>E:/Working/torch_save/load_learn.py<span class="string">'&gt;</span></span><br></pre></td></tr></table></figure><p>那么，既然<code>./model_file.pth</code>文件已经保存了模型结构，怎么可以在不知道源代码的情况下，加载进来呢？围绕这个问题，我进行了一系列的探索。</p><h2 id="pickle库"><a href="#pickle库" class="headerlink" title="pickle库"></a>pickle库</h2><p>再看一遍Pytorch的<a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html" target="_blank" rel="noopener">官方文档</a>，有关于为什么在加载模型时，必须要事先定义类的解释说明：</p><blockquote><p>This save/load process uses the most intuitive syntax and involves the least amount of code. Saving a model in this way will save the entire module using Python’s <a href="https://docs.python.org/3/library/pickle.html" target="_blank" rel="noopener">pickle</a> module. The disadvantage of this approach is that the serialized data is bound to the specific classes and the exact directory structure used when the model is saved. The reason for this is because pickle does not save the model class itself. Rather, it saves a path to the file containing the class, which is used during load time. Because of this, your code can break in various ways when used in other projects or after refactors.</p></blockquote><p>简单来说，Pytorch保存整个module使用的是pickle库，由于这个库在保存类的时候，并不是保存类本身，而是只保存了类名和类定义的位置，在加载的时候，pickle库会找类定义的位置，去加载类的定义。可以看这句话还是很懵逼，我们可以直接去<a href="https://docs.python.org/zh-cn/3/library/pickle.html#what-can-be-pickled-and-unpickled" target="_blank" rel="noopener">pickle官方库</a>看相应的解释。</p><p>以下来自官方文档，为了方便理解，这里将这些内容全部复制过来了。</p><h3 id="可以被序列化-反序列化的对象"><a href="#可以被序列化-反序列化的对象" class="headerlink" title="可以被序列化/反序列化的对象"></a>可以被序列化/反序列化的对象</h3><p>下列类型可以被封存：</p><ul><li><code>None</code>、<code>True</code> 和 <code>False</code></li><li>整数、浮点数、复数</li><li>str、byte、bytearray</li><li>只包含可封存对象的集合，包括 tuple、list、set 和 dict</li><li>定义在模块最外层的函数（使用 <a href="https://docs.python.org/zh-cn/3/reference/compound_stmts.html#def" target="_blank" rel="noopener"><code>def</code></a> 定义，<a href="https://docs.python.org/zh-cn/3/reference/expressions.html#lambda" target="_blank" rel="noopener"><code>lambda</code></a> 函数则不可以）</li><li>定义在模块最外层的内置函数</li><li>定义在模块最外层的类</li><li>某些类实例，这些类的 <a href="https://docs.python.org/zh-cn/3/library/stdtypes.html#object.__dict__" target="_blank" rel="noopener"><code>__dict__</code></a> 属性值或 <code>__getstate__()</code> 函数的返回值可以被封存（详情参阅 <a href="https://docs.python.org/zh-cn/3/library/pickle.html#pickle-inst" target="_blank" rel="noopener">封存类实例</a> 这一段）。</li></ul><p>尝试封存不能被封存的对象会抛出 <a href="https://docs.python.org/zh-cn/3/library/pickle.html#pickle.PicklingError" target="_blank" rel="noopener"><code>PicklingError</code></a> 异常，异常发生时，可能有部分字节已经被写入指定文件中。尝试封存递归层级很深的对象时，可能会超出最大递归层级限制，此时会抛出 <a href="https://docs.python.org/zh-cn/3/library/exceptions.html#RecursionError" target="_blank" rel="noopener"><code>RecursionError</code></a> 异常，可以通过 <a href="https://docs.python.org/zh-cn/3/library/sys.html#sys.setrecursionlimit" target="_blank" rel="noopener"><code>sys.setrecursionlimit()</code></a> 调整递归层级，不过请谨慎使用这个函数，因为可能会导致解释器崩溃。</p><p>注意，<strong>函数（内置函数或用户自定义函数）在被封存时，引用的是函数全名。这意味着只有函数所在的模块名，与函数名会被封存，函数体及其属性不会被封存。因此，在解封的环境中，函数所属的模块必须是可以被导入的，而且模块必须包含这个函数被封存时的名称</strong>，否则会抛出异常。</p><p>同样的，<strong>类也只封存名称，所以在解封环境中也有和函数相同的限制。注意，类体及其数据不会被封存</strong>，所以在下面的例子中类属性 <code>attr</code> 不会存在于解封后的环境中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foo</span>:</span></span><br><span class="line">    attr = <span class="string">'A class attribute'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'file.pickle'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> handle:</span><br><span class="line">    pickle.dump(Foo, handle)</span><br></pre></td></tr></table></figure><p>用Hex Fiend软件（Windows下的WinHex软件）查看<code>file.pickle</code>文件，可以如下所示，可以看到确实只封存了名称。</p><p><img src="/MLFrameworks/Pytorch/Pytorch模型存储研究/image-20220323203426343.png" alt="image-20220323203426343" style="zoom:50%"></p><p>这些限制决定了为什么必须在一个模块的最外层定义可封存的函数和类。</p><p>类似的，在封存类的实例时，其类体和类数据不会跟着实例一起被封存，只有实例数据会被封存。这样设计是有目的的，在将来修复类中的错误、给类增加方法之后，仍然可以载入原来版本类实例的封存数据来还原该实例。如果你准备长期使用一个对象，可能会同时存在较多版本的类体，可以为对象添加版本号，这样就可以通过类的 <code>__setstate__()</code> 方法将老版本转换成新版本。</p><h3 id="封存类实例"><a href="#封存类实例" class="headerlink" title="封存类实例"></a>封存类实例</h3><p>在本节中，我们描述了可用于定义、自定义和控制如何封存和解封类实例的通用流程。</p><p>通常，使一个实例可被封存不需要附加任何代码。Pickle 默认会通过 Python 的内省机制获得实例的类及属性。而当实例解封时，它的 <code>__init__()</code> 方法通常 <em>不会</em> 被调用。其默认动作是：先创建一个未初始化的实例，然后还原其属性，下面的代码展示了这种行为的实现机制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save</span><span class="params">(obj)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (obj.__class__, obj.__dict__)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load</span><span class="params">(cls, attributes)</span>:</span></span><br><span class="line">    obj = cls.__new__(cls)</span><br><span class="line">    obj.__dict__.update(attributes)</span><br><span class="line">    <span class="keyword">return</span> obj</span><br></pre></td></tr></table></figure><p>由此可见，确实是pickle本身的机制导致了Pytorch load的异常。</p><h2 id="Hex-Fiend分析"><a href="#Hex-Fiend分析" class="headerlink" title="Hex Fiend分析"></a>Hex Fiend分析</h2><p>那么，真的没有办法去加载保存在<code>./model_file.pth</code>文件中的结构么？我们又从该文件的二进制流中进行分析。用Hex Fiend软件打开<code>./model_file.pth</code>文件，可以在最前面看到一些模型类的定义和类所处的位置，而这些信息跟我们的真实情况一模一样。</p><p><img src="/MLFrameworks/Pytorch/Pytorch模型存储研究/image-20220323223740287.png" alt="image-20220323223740287" style="zoom:30%"></p><p>那么就可以想到，既然Pytorch在load的时候找不到类的定义和位置，而这些信息在Hex Fiend软件中又可以看到，那我们建立对应的文件，并把类的定义手动复制过来不就行了么？</p><p>观察Hex Fiend软件中的信息，发现我们类的定义都是在<code>E:/Working/torch_save/save_learn.py</code>，因此，我们只需要新建一个文件<code>load_test.py</code>，将类的定义放到该文件夹中，如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TheModelClass</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv = get_conv()</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = torch.sigmoid(self.fc3(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myConv</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_channel, output_chanel)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(input_channel, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(output_chanel, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)  <span class="comment"># flatten all dimensions except batch</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = torch.load(<span class="string">'model_file.pth'</span>)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure><blockquote><p>因为我们这里类的定义都是一个文件中的，所以新建一个文件即可。若类的定义是放在不同的文件中的，则需要建立对应目录的文件，并放对应的类。</p></blockquote><p>运行这个文件，我们发现竟然可以load进来了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">TheModelClass(</span><br><span class="line">  (conv): myConv(</span><br><span class="line">    (conv1): Conv2d(<span class="number">3</span>, <span class="number">6</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (pool): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (conv2): Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  )</span><br><span class="line">  (fc1): Linear(in_features=<span class="number">400</span>, out_features=<span class="number">120</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (fc2): Linear(in_features=<span class="number">120</span>, out_features=<span class="number">84</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (fc3): Linear(in_features=<span class="number">84</span>, out_features=<span class="number">1</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>那么能够进行前向推理呢？我们又添加了如下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">output = model(torch.ones(1, 3, 32, 32))</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure><p>但是发现会报错：<code>NameError: name &#39;F&#39; is not defined</code>。也就是说<code>forward</code>前向推理中<code>F</code>未定义。我们导入相应的库<code>import torch.nn.functional as F</code>，此时再运行文件，发现可以推理了，输出如下，推理结果与真实结果一致，说明我们加载成功了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">0.5042</span>]], grad_fn=&lt;SigmoidBackward&gt;)</span><br></pre></td></tr></table></figure><p>我们由此还可以得出一个结论：<strong>模型在前向推理时会调用<code>forward</code>函数，也就是<code>forward</code>函数必须与真实的<code>forward</code>函数完全一致，否则会报错。</strong></p><p>另外，我们还可以观察一下，我在模型定义时用了<code>get_conv()</code>函数来声明卷积层，而该函数的定义在<code>./model_file.pth</code>文件中并没有，但是我们仍然还原出了模型，那么是不是类的初始化并不重要呢？我们把类的初始化代码都删除，只保留代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TheModelClass</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = torch.sigmoid(self.fc3(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myConv</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)  <span class="comment"># flatten all dimensions except batch</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = torch.load(<span class="string">'model_file.pth'</span>)</span><br><span class="line">print(model)</span><br><span class="line">output = model(torch.ones(<span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure><p>发现仍然可以推理成功，且结果正确。</p><p>最后，我们在运行时还观察到如下warning，也就是TheModelClass的原定义已经被更改了。</p><blockquote><p>/torch/serialization.py:671: SourceChangeWarning: source code of class ‘<strong>main</strong>.TheModelClass’ has changed. you can retrieve the original source code by accessing the object’s source attribute or set <code>torch.nn.Module.dump_patches = True</code> and use the patch tool to revert the changes.<br> warnings.warn(msg, SourceChangeWarning)</p></blockquote><p>我们点开该warning提醒的位置，可以发现Pytorch会将保存在<code>./model_file.pth</code>文件中的源码与当前的源码进行对比。值得注意的是，下面有一行代码<code>if container_type.dump_patches:</code>，这个是<code>nn.Module</code>才有的属性，所以在还原类的时候，必须让类继承<code>nn.Module</code>，否则还原的时候会保存。</p><p><img src="/MLFrameworks/Pytorch/Pytorch模型存储研究/截屏2022-03-23 23.13.29.png" alt="截屏2022-03-23 23.13.29" style="zoom:50%"></p><p>那么我们就可以得出另一个结论：<strong>类的具体初始化可以没有或者不正确，但是类的位置和名字必须正确，且类必须继承<code>nn.Module</code>。</strong></p><h2 id="压缩存储方式"><a href="#压缩存储方式" class="headerlink" title="压缩存储方式"></a>压缩存储方式</h2><p>在本文的开头，我们在保存模型的时候，使用了参数<code>_use_new_zipfile_serialization=False</code>，这会使用非压缩存储方式。若不使用该参数，存储模型的时候，会采用压缩存储方式。这种存储方式并不会保存像类的定义和位置这些信息，而且会进行压缩（因为我们可以用zip解压模型文件）。</p><p>至于为什么说这种存储方式并不会保存类的定义和位置呢？这不仅仅可以通过Hex Fiend分析得到，而且还可以直接看torch save的源代码，其文件位于<code>torch\serialization.py</code>中。</p><p>如下是非压缩存储方式，在持久化存储时使用的代码（关于持久化存储可以看<a href="https://docs.python.org/zh-cn/3/library/pickle.html#persistence-of-external-objects" target="_blank" rel="noopener">官方的代码</a>）。</p><p><img src="/MLFrameworks/Pytorch/Pytorch模型存储研究/截屏2022-03-23 23.27.02.png" alt="截屏2022-03-23 23.27.02" style="zoom:50%"></p><p>如下是压缩存储方式，在持久化存储时使用的代码。</p><p><img src="/MLFrameworks/Pytorch/Pytorch模型存储研究/截屏2022-03-23 23.24.34.png" alt="截屏2022-03-23 23.24.34" style="zoom:50%"></p><p>对比一下可以发现，非压缩存储方式查询相应的源码并进行保存，而压缩存储方式不会。</p><blockquote><p>前面介绍说pickle并不会保存类的实现，而Pytorch在非压缩存储方式却保存了相应的源码，这也跟上述的持久化存储函数有关。</p></blockquote><p>因此像前文介绍的，从Hex Fiend中获取类的定义和位置，然后实现模型的load和推理，并不适合压缩存储方式。而对于压缩存储方式，当同时存储了模型和权重，同时又没有源码的情况下，如何load并推理，目前还没有研究出来。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我们最后做一下总结：</p><ol><li>Pytorch存储Entire Model的时候，有非压缩（旧）与压缩（新）两种方式。这两种方式都会借助于pickle库实现保存。</li><li>pickle库本身在封存类的时候，只会封装类名，其类体和类数据不会跟着实例一起被封存。这导致了Pytorch恢复Entire Model时，必须要有类的定义。</li><li>在恢复Entire Model时，Model类的具体初始化可以没有或者不正确，但是类的位置和名字必须正确，且类必须继承<code>nn.Module</code>。模型在前向推理时会调用<code>forward</code>函数，也就是<code>forward</code>函数必须与真实的<code>forward</code>函数完全一致，否则会报错。</li><li>非压缩的的方式，会将所有Model Class源代码保存下来，而压缩的方式并不会保存这些信息。因此前者可以通过手动恢复Model Class定义的方式来加载模型，而后者不可以。</li></ol></div><div><div style="text-align:center;color:#ccc;font-size:14px">------ 本文结束------</div></div><div class="reward-container"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/uploads/wechat.png" alt="zdaiot 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/uploads/aipay.jpg" alt="zdaiot 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> zdaiot</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.zdaiot.com/MLFrameworks/Pytorch/Pytorch模型存储研究/" title="Pytorch模型存储研究">https://www.zdaiot.com/MLFrameworks/Pytorch/Pytorch模型存储研究/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><p>欢迎关注我的其它发布渠道</p><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="/uploads/wechat-qcode.jpg"><span class="icon"><i class="fab fa-weixin"></i></span> <span class="label">WeChat</span></a></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Pytorch/" rel="tag"><i class="fa fa-tag"></i> Pytorch</a></div><div class="post-nav"><div class="post-nav-item"><a href="/Mac/brew使用/" rel="prev" title="brew使用"><i class="fa fa-chevron-left"></i> brew使用</a></div><div class="post-nav-item"> <a href="/MLFrameworks/Pytorch/Pytorch Tensor形状变换/" rel="next" title="Pytorch Tensor形状变换">Pytorch Tensor形状变换<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="gitalk-container"></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Pytorch的两种保存模型方式"><span class="nav-number">1.</span> <span class="nav-text">Pytorch的两种保存模型方式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Save-Load-Entire-Model：缺陷"><span class="nav-number">2.</span> <span class="nav-text">Save/Load Entire Model：缺陷</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pickle库"><span class="nav-number">3.</span> <span class="nav-text">pickle库</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#可以被序列化-反序列化的对象"><span class="nav-number">3.1.</span> <span class="nav-text">可以被序列化/反序列化的对象</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#封存类实例"><span class="nav-number">3.2.</span> <span class="nav-text">封存类实例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hex-Fiend分析"><span class="nav-number">4.</span> <span class="nav-text">Hex Fiend分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#压缩存储方式"><span class="nav-number">5.</span> <span class="nav-text">压缩存储方式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">6.</span> <span class="nav-text">总结</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="zdaiot" src="/uploads/avatar.png"><p class="site-author-name" itemprop="name">zdaiot</p><div class="site-description" itemprop="description">404NotFound</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">327</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">55</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">383</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zdaiot" title="GitHub → https://github.com/zdaiot" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:zdaiot@163.com" title="E-Mail → mailto:zdaiot@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/" title="知乎 → https://www.zhihu.com/people/" rel="noopener" target="_blank"><i class="fa fa-book fa-fw"></i> 知乎</a></span><span class="links-of-author-item"><a href="https://blog.csdn.net/zdaiot" title="CSDN → https://blog.csdn.net/zdaiot" rel="noopener" target="_blank"><i class="fa fa-copyright fa-fw"></i> CSDN</a></span></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="link fa-fw"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://kalacloud.com" title="https://kalacloud.com" rel="noopener" target="_blank">卡拉云低代码工具</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://beian.miit.gov.cn" rel="noopener" target="_blank">京ICP备2021031914号</a></div><div class="copyright"> &copy; <span itemprop="copyrightYear">2023</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">zdaiot</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-chart-area"></i></span> <span title="站点总字数">2.3m</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span title="站点阅读时长">35:21</span></div><div class="addthis_inline_share_toolbox"><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b5e7e498f94b7ad" async="async"></script></div> <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now=new Date;function createtime(){var n=new Date("08/01/2018 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="Run for "+dnum+" Days ",document.getElementById("times").innerHTML=hnum+" Hours "+mnum+" m "+snum+" s"}setInterval("createtime()",250)</script><div class="busuanzi-count"><script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script><script data-pjax>!function(){var o,n,e=document.getElementsByTagName("link");if(0<e.length)for(i=0;i<e.length;i++)"canonical"==e[i].rel.toLowerCase()&&e[i].href&&(o=e[i].href);n=o?o.split(":")[0]:window.location.protocol.split(":")[0],o||(o=window.location.href),function(){var e=o,i=document.referrer;if(!/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(e)){var t="https"===String(n).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";i?(t+="?r="+encodeURIComponent(document.referrer),e&&(t+="&l="+e)):e&&(t+="?l="+e),(new Image).src=t}}(window)}()</script><script src="/js/local-search.js"></script><div id="pjax"><script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '4800250e682fe873198b',
      clientSecret: '80f7f33f5f8ddfd3944f455cabadda4ff3299147',
      repo        : 'zdaiot.github.io',
      owner       : 'zdaiot',
      admin       : ['zdaiot'],
      id          : '293eb72007bba6a46eb4e906ae837931',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/wanko.model.json"},display:{position:"left",width:150,height:300},mobile:{show:!0}})</script></body></html>