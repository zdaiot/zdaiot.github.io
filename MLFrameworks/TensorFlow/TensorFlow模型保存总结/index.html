<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 3.9.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"www.zdaiot.com",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="事先声明，以下大部分内容来源于tensorflow 模型导出总结，并加上个人见解。 tensorflow 1.0 以及2.0 提供了多种不同的模型导出格式，例如说有checkpoint，SavedModel，Frozen GraphDef，Keras model（HDF5） 以及用于移动端，嵌入式的TFLite。  模型导出主要包含了：参数以及网络结构的导出，不同的导出格式可能是分别导出，或者是整"><meta name="keywords" content="TensorFlow,save"><meta property="og:type" content="article"><meta property="og:title" content="TensorFlow模型保存总结"><meta property="og:url" content="https://www.zdaiot.com/MLFrameworks/TensorFlow/TensorFlow模型保存总结/index.html"><meta property="og:site_name" content="zdaiot"><meta property="og:description" content="事先声明，以下大部分内容来源于tensorflow 模型导出总结，并加上个人见解。 tensorflow 1.0 以及2.0 提供了多种不同的模型导出格式，例如说有checkpoint，SavedModel，Frozen GraphDef，Keras model（HDF5） 以及用于移动端，嵌入式的TFLite。  模型导出主要包含了：参数以及网络结构的导出，不同的导出格式可能是分别导出，或者是整"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://www.zdaiot.com/MLFrameworks/TensorFlow/TensorFlow模型保存总结/v2-b71487837e3a0527aaa15fe6b35fcef6_b.jpg"><meta property="og:image" content="https://www.zdaiot.com/MLFrameworks/TensorFlow/TensorFlow模型保存总结/v2-4d9cb38d90d32706892fde8d9de4b07c_b.jpg"><meta property="og:image" content="https://www.zdaiot.com/MLFrameworks/TensorFlow/TensorFlow模型保存总结/image-20220410162903108.png"><meta property="og:updated_time" content="2022-04-09T06:32:24.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="TensorFlow模型保存总结"><meta name="twitter:description" content="事先声明，以下大部分内容来源于tensorflow 模型导出总结，并加上个人见解。 tensorflow 1.0 以及2.0 提供了多种不同的模型导出格式，例如说有checkpoint，SavedModel，Frozen GraphDef，Keras model（HDF5） 以及用于移动端，嵌入式的TFLite。  模型导出主要包含了：参数以及网络结构的导出，不同的导出格式可能是分别导出，或者是整"><meta name="twitter:image" content="https://www.zdaiot.com/MLFrameworks/TensorFlow/TensorFlow模型保存总结/v2-b71487837e3a0527aaa15fe6b35fcef6_b.jpg"><link rel="canonical" href="https://www.zdaiot.com/MLFrameworks/TensorFlow/TensorFlow模型保存总结/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>TensorFlow模型保存总结 | zdaiot</title><script data-pjax>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?0b0b58037319da4959d5a3c014160ccd";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">zdaiot</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">404NotFound</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.zdaiot.com/MLFrameworks/TensorFlow/TensorFlow模型保存总结/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/uploads/avatar.png"><meta itemprop="name" content="zdaiot"><meta itemprop="description" content="404NotFound"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="zdaiot"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> TensorFlow模型保存总结<a href="https://github.com/zdaiot/zdaiot.github.io/tree/hexo/source/_posts/MLFrameworks/TensorFlow/TensorFlow模型保存总结.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pencil-alt"></i></a></h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-04-09 14:32:24" itemprop="dateCreated datePublished" datetime="2022-04-09T14:32:24+08:00">2022-04-09</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MLFrameworks/" itemprop="url" rel="index"><span itemprop="name">MLFrameworks</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MLFrameworks/TensorFlow/" itemprop="url" rel="index"><span itemprop="name">TensorFlow</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>28k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>25 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>事先声明，以下大部分内容来源于<a href="https://zhuanlan.zhihu.com/p/113734249" target="_blank" rel="noopener">tensorflow 模型导出总结</a>，并加上个人见解。</p><p>tensorflow 1.0 以及2.0 提供了多种不同的模型导出格式，例如说有checkpoint，SavedModel，Frozen GraphDef，Keras model（HDF5） 以及用于移动端，嵌入式的TFLite。</p><p>模型导出主要包含了：参数以及网络结构的导出，不同的导出格式可能是分别导出，或者是整合成一个独立的文件。</p><ul><li>参数和网络结构分开保存：checkpoint， SavedModel</li><li>只保存权重：HDF5（可选）</li><li>参数和网络结构保存在一个文件：Frozen GraphDef，HDF5（可选）</li></ul><p>在tensorflow 1.0中，可以见下图，主要有三种主要的API：Keras、Estimator以及Legacy即最初的session模型，其中tf.Keras主要保存为HDF5，Estimator保存为SavedModel，而Lagacy主要保存的是Checkpoint，并且可以通过freeze_graph，将模型变量冻结，得到Frozen GradhDef的文件。这三种格式的模型，都可以通过TFLite Converter导出为 <code>.tflite</code> 的模型文件，用于安卓/ios/嵌入式设备的serving。</p><p><img src="/MLFrameworks/TensorFlow/TensorFlow模型保存总结/v2-b71487837e3a0527aaa15fe6b35fcef6_b.jpg" alt="img"></p><p>在tensorflow 2.0中，推荐使用SavedModel进行模型的保存，所以keras默认导出格式是SavedModel，也可以通过显性使用 <code>.h5</code> 后缀，使得保存的模型格式为HDF5 。 此外其他low level API，都支持导出为SavedModel格式，以及Concrete Functions。Concrete Function是一个签名函数，有固定格式的输入和输出。 最终转化成Flatbuffer，服务端运行结束。</p><h2 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h2><p>checkpint（CKPT）的导出是网络结构和参数权重分开保存的。其组成：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">checkpoint <span class="comment"># 列出该目录下，保存的所有的checkpoint列表，下面有具体的例子</span></span><br><span class="line">├── events.out.tfevents<span class="number">.1583930869</span>.prod-cloudserver-gpu169 <span class="comment"># tensorboad可视化所需文件，可以直观看出模型的结构</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    model.ckpt-13000表示前缀，代表第13000 global steps时的保存结果，我们在指定checkpoint加载时，也只需要说明前缀即可。</span></span><br><span class="line"><span class="string">    你可以只用 .ckpt-meta 和 .ckpt-data 恢复一个模型 </span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">├── model.ckpt<span class="number">-13000.</span>index <span class="comment"># 可能是内部需要的某种索引来正确映射前两个文件，它通常不是必需的</span></span><br><span class="line">├── model.ckpt<span class="number">-13000.</span>data<span class="number">-00000</span>-of<span class="number">-00001</span> <span class="comment"># 包含所有变量的值，没有结构</span></span><br><span class="line">├── model.ckpt<span class="number">-13000.</span>meta <span class="comment"># 包含元图，即计算图的结构，不一定含有变量，就算有变量也没有变量的值（基本上你可以在tensorboard/graph中看到）。</span></span><br></pre></td></tr></table></figure><p>所以一个checkpoint 组成是由两个部分，三个文件组成，其中网络结构部分（meta文件），以及参数部分（参数名：index，参数值：data）</p><p>其中<code>checkpoint</code>文件中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model_checkpoint_path: &quot;model.ckpt-16329&quot;</span><br><span class="line">all_model_checkpoint_paths: &quot;model.ckpt-13000&quot;</span><br><span class="line">all_model_checkpoint_paths: &quot;model.ckpt-14000&quot;</span><br><span class="line">all_model_checkpoint_paths: &quot;model.ckpt-15000&quot;</span><br><span class="line">all_model_checkpoint_paths: &quot;model.ckpt-16000&quot;</span><br><span class="line">all_model_checkpoint_paths: &quot;model.ckpt-16329&quot;</span><br></pre></td></tr></table></figure><p>使用<code>tensorboard --logdir PATH_TO_CHECKPOINT --host=127.0.0.1</code>: tensorboard 会调用最新的events.out.tfevents.*文件，并生成tensorboard，例如下图：</p><p><img src="/MLFrameworks/TensorFlow/TensorFlow模型保存总结/v2-4d9cb38d90d32706892fde8d9de4b07c_b.jpg" alt="img"></p><h3 id="导出成CKPT"><a href="#导出成CKPT" class="headerlink" title="导出成CKPT"></a>导出成CKPT</h3><ul><li>tensorflow 1.0</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># in tensorflow 1.0</span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line">saver.save(sess=session, save_path=args.save_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 若不想保存meta文件</span></span><br><span class="line">saver2save(sess=session, save_path=args.save_path, write_meta_graph=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ul><li>estimator</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># estimator</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">通过 RunConfig 配置多少时间或者多少个steps 保存一次模型，默认600s 保存一次。</span></span><br><span class="line"><span class="string">具体参考 https://zhuanlan.zhihu.com/p/112062303</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">run_config = tf.estimator.RunConfig(</span><br><span class="line">    model_dir=FLAGS.output_dir, <span class="comment"># 模型保存路径</span></span><br><span class="line">    session_config=config,</span><br><span class="line">    save_checkpoints_steps=FLAGS.save_checkpoints_steps, <span class="comment"># 多少steps保存一次ckpt</span></span><br><span class="line">    keep_checkpoint_max=<span class="number">1</span>)</span><br><span class="line">estimator = tf.estimator.Estimator(</span><br><span class="line">  model_fn=model_fn,</span><br><span class="line">  config=run_config,</span><br><span class="line">  params=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><blockquote><p>关于estimator的介绍可以参考：<a href="https://zhuanlan.zhihu.com/p/112062303" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/112062303</a></p></blockquote><h3 id="加载CKPT"><a href="#加载CKPT" class="headerlink" title="加载CKPT"></a>加载CKPT</h3><ul><li>tf1.0<br>ckpt加载的脚本如下，加载完后，session就会是保存的ckpt了。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tf1.0</span></span><br><span class="line">session = tf.Session()</span><br><span class="line">session.run(tf.global_variables_initializer())</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line">saver.restore(sess=session, save_path=args.save_path)  <span class="comment"># 读取保存的模型</span></span><br></pre></td></tr></table></figure><ul><li>对于estimator 会自动load output_dir 中的最新的ckpt。</li><li>我们常用的<code>model_file = tf.train.latest_checkpoint(FLAGS.output_dir)</code> 获取最新的ckpt</li></ul><h3 id="Meta文件分析"><a href="#Meta文件分析" class="headerlink" title="Meta文件分析"></a>Meta文件分析</h3><p>TensorFlow的Meta文件不一定含有变量，也就是使用<code>tf.global_variables()</code>或者<code>tf.trainable_variables()</code>均返回的是空list。</p><p>被这个问题困扰了很久，但是一直查不到结果，我就从TensorFlow的源码入手分析一下。我调试了<code>saver.restore</code>的函数，最终定位到了<a href="https://github.com/tensorflow/tensorflow/blob/v1.15.5/tensorflow/python/framework/meta_graph.py#L824" target="_blank" rel="noopener">meta_graph.py#L824</a>。</p><p>相关代码如下：</p><p><img src="/MLFrameworks/TensorFlow/TensorFlow模型保存总结/image-20220410162903108.png" alt="image-20220410162903108" style="zoom:80%"></p><p>代码中有一个函数为<code>meta_graph_def.collection_def</code>，若这里面有<code>trainable_variables</code>才可以，但是我遇到了一个meta文件，<code>meta_graph_def.collection_def</code>为空，也就没有了变量。但是这个文件咋来的，还不是很清楚。需要进一步探索。</p><h2 id="SavedModel"><a href="#SavedModel" class="headerlink" title="SavedModel"></a>SavedModel</h2><p>SavedModel 格式是tensorflow 2.0 推荐的格式，他很好地支持了tf-serving等部署，并且可以简单被python，java等调用。</p><p>一个 SavedModel 包含了一个完整的 TensorFlow program, 包含了 weights 以及 计算图 computation. 它不需要原本的模型代码就可以加载所以很容易在 TFLite, TensorFlow.js, TensorFlow Serving, or TensorFlow Hub 上部署。</p><p>通常SavedModel由以下几个部分组成</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">├── assets/ # 所需的外部文件，例如说初始化的词汇表文件，一般无</span><br><span class="line">├── assets.extra/ # TensorFlow graph 不需要的文件, 例如说给用户知晓的如何使用SavedModel的信息. Tensorflow 不使用这个目录下的文件。</span><br><span class="line">├── saved_model.pb # 保存的是MetaGraph的网络结构, 或者说是saved_model.pbtxt</span><br><span class="line">├── variables # 参数权重，包含了所有模型的变量(tf.Variable objects)参数</span><br><span class="line">    ├── variables.data-00000-of-00001</span><br><span class="line">    └── variables.index</span><br></pre></td></tr></table></figure><p>补充pb格式说明：GraphDef(*.pb)格式文件包含 protobuf 对象序列化后的数据，包含了计算图，可以从中得到所有运算符（operators）的细节，也包含张量（tensors）和 Variables 定义，但不包含 Variable 的值，因此只能从中恢复计算图，但一些训练的权值仍需要从 checkpoint 中恢复。</p><p>TensorFlow 一些例程中用到 *.pb 文件作为预训练模型，这和上面 GraphDef 格式稍有不同，属于冻结（Frozen）后的 GraphDef 文件，简称 FrozenGraphDef 格式。这种文件格式不包含 Variables 节点。将 GraphDef 中所有 Variable 节点转换为常量（其值从 checkpoint 获取），就变为 FrozenGraphDef 格式。代码可以参考 <code>tensorflow/python/tools/freeze_graph.py</code>。</p><p><code>*.pb</code> 为二进制文件，实际上 protobuf 也支持文本格式（<code>*.pbtxt</code>），但包含权值时文本格式会占用大量磁盘空间，一般不用。</p><h3 id="导出为SavedModel"><a href="#导出为SavedModel" class="headerlink" title="导出为SavedModel"></a>导出为SavedModel</h3><ul><li>tf 1.0 方式</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""tf1.0"""</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>], name=<span class="string">"myInput"</span>)</span><br><span class="line">y = tf.nn.softmax(tf.matmul(x, W) + b, name=<span class="string">"myOutput"</span>)</span><br><span class="line">tf.saved_model.simple_save(</span><br><span class="line">                sess,</span><br><span class="line">                export_dir,</span><br><span class="line">                inputs=&#123;<span class="string">"myInput"</span>: x&#125;,</span><br><span class="line">                outputs=&#123;<span class="string">"myOutput"</span>: y&#125;)</span><br></pre></td></tr></table></figure><p><code>simple_save</code> 是对于普通的tf 模型导出的最简单的方式，只需要补充简单的必要参数，有很多参数被省略，其中被省略的最重要的参数是<code>tag</code>（在下面<code>saved_model.builder.SavedModelBuilder</code>会介绍）：<code>tag</code> 是用来区别不同的 <code>MetaGraphDef</code>，这是在加载模型所需要的参数。其默认值是tag_constants.SERVING (“serve”)。对于某些节点，如果没有办法直接加name，那么可以采用 <code>tf.identity</code>， 为节点加名字，例如说CRF的输出，以及使dataset后，无法直接加input的name，都可以采用这个方式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addNameToTensor</span><span class="params">(someTensor, theName)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.identity(someTensor, name=theName)</span><br></pre></td></tr></table></figure><ul><li>estimator 方式</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""estimator"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">serving_input_fn</span><span class="params">()</span>:</span></span><br><span class="line">    label_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>], name=<span class="string">'label_ids'</span>)</span><br><span class="line">    input_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'input_ids'</span>)</span><br><span class="line">    input_mask = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'input_mask'</span>)</span><br><span class="line">    segment_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'segment_ids'</span>)</span><br><span class="line">    input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(&#123;</span><br><span class="line">        <span class="string">'label_ids'</span>: label_ids,</span><br><span class="line">        <span class="string">'input_ids'</span>: input_ids,</span><br><span class="line">        <span class="string">'input_mask'</span>: input_mask,</span><br><span class="line">        <span class="string">'segment_ids'</span>: segment_ids,</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="keyword">return</span> input_fn</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> do_export:</span><br><span class="line">   estimator._export_to_tpu = <span class="literal">False</span></span><br><span class="line">   estimator.export_saved_model(Flags.export_dir, serving_input_fn)</span><br></pre></td></tr></table></figure><ul><li>保存多个 <code>MetaGraphDef&#39;s</code>，使用到了tag</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow.python.saved_model</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.saved_model <span class="keyword">import</span> tag_constants</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.saved_model.signature_def_utils_impl <span class="keyword">import</span> predict_signature_def</span><br><span class="line">builder = saved_model.builder.SavedModelBuilder(export_path)</span><br><span class="line"></span><br><span class="line">signature = predict_signature_def(inputs=&#123;<span class="string">'myInput'</span>: x&#125;,</span><br><span class="line">                                  outputs=&#123;<span class="string">'myOutput'</span>: y&#125;)</span><br><span class="line"><span class="string">""" using custom tag instead of: tags=[tag_constants.SERVING] """</span></span><br><span class="line">builder.add_meta_graph_and_variables(sess=sess,</span><br><span class="line">                                     tags=[<span class="string">"myTag"</span>],</span><br><span class="line">                                     signature_def_map=&#123;<span class="string">'predict'</span>: signature&#125;)</span><br><span class="line">builder.save()</span><br></pre></td></tr></table></figure><ul><li>ckpt转SavedModel</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_saved_model</span><span class="params">(bert_config, num_labels, use_one_hot_embeddings)</span>:</span></span><br><span class="line">  tf_config = tf.compat.v1.ConfigProto()</span><br><span class="line">  tf_config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line"> </span><br><span class="line">  model_file = tf.train.latest_checkpoint(FLAGS.output_dir)</span><br><span class="line">  <span class="keyword">with</span> tf.Graph().as_default(), tf.Session(config=tf_config) <span class="keyword">as</span> tf_sess:</span><br><span class="line">    label_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>], name=<span class="string">'label_ids'</span>)</span><br><span class="line">    input_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'input_ids'</span>)</span><br><span class="line">    input_mask = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'input_mask'</span>)</span><br><span class="line">    segment_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'segment_ids'</span>)</span><br><span class="line"> </span><br><span class="line">    loss, per_example_loss, probabilities, predictions = \</span><br><span class="line">          create_model(bert_config, <span class="literal">False</span>, input_ids, input_mask, segment_ids, label_ids,</span><br><span class="line">              num_labels, use_one_hot_embeddings)</span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    print(<span class="string">"restore;&#123;&#125;"</span>.format(model_file))</span><br><span class="line">    saver.restore(tf_sess, model_file)</span><br><span class="line">    tf.saved_model.simple_save(tf_sess,</span><br><span class="line">            FLAGS.output_dir,</span><br><span class="line">            inputs=&#123;</span><br><span class="line">              <span class="string">'label_ids'</span>: label_ids,</span><br><span class="line">              <span class="string">'input_ids'</span>: input_ids,</span><br><span class="line">              <span class="string">'input_mask'</span>: input_mask,</span><br><span class="line">              <span class="string">'segment_ids'</span>: segment_ids,</span><br><span class="line">            &#125;,</span><br><span class="line">            outputs=&#123;<span class="string">"probabilities"</span>: probabilities&#125;)</span><br></pre></td></tr></table></figure><ul><li>frozen graph to savedModel。注意这个方法我失败了，variables文件夹下面没有东西。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.saved_model <span class="keyword">import</span> signature_constants</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.saved_model <span class="keyword">import</span> tag_constants</span><br><span class="line"></span><br><span class="line">export_dir = <span class="string">'inference/pb2saved'</span></span><br><span class="line">graph_pb = <span class="string">'inference/robert_tiny_clue/frozen_model.pb'</span></span><br><span class="line"></span><br><span class="line">builder = tf.saved_model.builder.SavedModelBuilder(export_dir)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.gfile.GFile(graph_pb, <span class="string">"rb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">    graph_def = tf.GraphDef()</span><br><span class="line">    graph_def.ParseFromString(f.read())</span><br><span class="line"></span><br><span class="line">sigs = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=tf.Graph()) <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># name="" is important to ensure we don't get spurious prefixing</span></span><br><span class="line">    tf.import_graph_def(graph_def, name=<span class="string">""</span>)</span><br><span class="line">    g = tf.get_default_graph()</span><br><span class="line">    input_ids = sess.graph.get_tensor_by_name(</span><br><span class="line">    <span class="string">"input_ids:0"</span>)</span><br><span class="line">    input_mask = sess.graph.get_tensor_by_name(</span><br><span class="line">    <span class="string">"input_mask:0"</span>)</span><br><span class="line">    segment_ids = sess.graph.get_tensor_by_name(</span><br><span class="line">    <span class="string">"segment_ids:0"</span>)</span><br><span class="line">    probabilities = g.get_tensor_by_name(<span class="string">"loss/pred_prob:0"</span>)</span><br><span class="line"></span><br><span class="line">    sigs[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY] = \</span><br><span class="line">        tf.saved_model.signature_def_utils.predict_signature_def(</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"input_ids"</span>: input_ids,</span><br><span class="line">                <span class="string">"input_mask"</span>: input_mask,</span><br><span class="line">                <span class="string">"segment_ids"</span>: segment_ids</span><br><span class="line">            &#125;, &#123;</span><br><span class="line">                <span class="string">"probabilities"</span>: probabilities</span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">    builder.add_meta_graph_and_variables(sess,</span><br><span class="line">                                         [tag_constants.SERVING],</span><br><span class="line">                                         signature_def_map=sigs)</span><br><span class="line"></span><br><span class="line">builder.save()</span><br></pre></td></tr></table></figure><ul><li>tf.keras 2.0</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.save(<span class="string">'saved_model/my_model'</span>)  </span><br><span class="line"><span class="string">""</span><span class="string">"saved as SavedModel by default"</span><span class="string">""</span></span><br></pre></td></tr></table></figure><h3 id="加载SavedModel"><a href="#加载SavedModel" class="headerlink" title="加载SavedModel"></a>加载SavedModel</h3><p>对于在java中加载SavedModel，我们首先需要知道我们模型输入和输出，可以通过以下的脚本在terminal中运行 <code>saved_model_cli show --dir SavedModel路径 --tag_set serve --signature_def serving_default</code> 得到类似以下的结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">MetaGraphDef <span class="keyword">with</span> tag-set: <span class="string">'serve'</span> contains the following SignatureDefs:</span><br><span class="line"></span><br><span class="line">signature_def[<span class="string">'serving_default'</span>]:</span><br><span class="line">  The given SavedModel SignatureDef contains the following input(s):</span><br><span class="line">    inputs[<span class="string">'input_ids'</span>] tensor_info:</span><br><span class="line">        dtype: DT_INT32</span><br><span class="line">        shape: (<span class="number">-1</span>, <span class="number">128</span>)</span><br><span class="line">        name: input_ids:<span class="number">0</span></span><br><span class="line">    inputs[<span class="string">'input_mask'</span>] tensor_info:</span><br><span class="line">        dtype: DT_INT32</span><br><span class="line">        shape: (<span class="number">-1</span>, <span class="number">128</span>)</span><br><span class="line">        name: input_mask:<span class="number">0</span></span><br><span class="line">    inputs[<span class="string">'label_ids'</span>] tensor_info:</span><br><span class="line">        dtype: DT_INT32</span><br><span class="line">        shape: (<span class="number">-1</span>)</span><br><span class="line">        name: label_ids:<span class="number">0</span></span><br><span class="line">    inputs[<span class="string">'segment_ids'</span>] tensor_info:</span><br><span class="line">        dtype: DT_INT32</span><br><span class="line">        shape: (<span class="number">-1</span>, <span class="number">128</span>)</span><br><span class="line">        name: segment_ids:<span class="number">0</span></span><br><span class="line">  The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">    outputs[<span class="string">'probabilities'</span>] tensor_info:</span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (<span class="number">-1</span>, <span class="number">7</span>)</span><br><span class="line">        name: loss/pred_prob:<span class="number">0</span></span><br><span class="line">  Method name <span class="keyword">is</span>: tensorflow/serving/predict</span><br></pre></td></tr></table></figure><p>首先我们可以看到有inputs，以及outputs，分别是一个key为string，value为tensor的字典，每个tensor都有各自的名字。</p><p>当然我们可以通过<code>saved_model_cli show --dir SavedModel路径 --all</code>得到所有的结果，包含了<code>Concrete Functions</code>。</p><h4 id="Python-加载"><a href="#Python-加载" class="headerlink" title="Python 加载"></a>Python 加载</h4><p>我们有常见两种方式可以加载savedModel，一种是采用 <code>tf.contrib.predictor.from_saved_model</code> 传入predictor模型的inputs dict，然后得到 outputs dict。 一种是直接类似tf1.0的方式，采用 <code>tf.saved_model.loader.load</code>， feed tensor然后fetch tensor。</p><ul><li><p>采用predictor</p><p>采用predictor时， 需要传入的字典名字用的是 inputs的key，而不是tensor的names</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">predict_fn = tf.contrib.predictor.from_saved_model(args_in_use.model)</span><br><span class="line"><span class="comment"># 其中feature.xxxxxx 应该是需要feed_dict的数据</span></span><br><span class="line">prediction = predict_fn(&#123;</span><br><span class="line">                <span class="string">"input_ids"</span>: [feature.input_ids],</span><br><span class="line">                <span class="string">"input_mask"</span>: [feature.input_mask],</span><br><span class="line">                <span class="string">"segment_ids"</span>: [feature.segment_ids],</span><br><span class="line">            &#125;)</span><br><span class="line">probabilities = prediction[<span class="string">"probabilities"</span>]</span><br></pre></td></tr></table></figure><ul><li><p>tf 1.0 采用 loader</p><p>采用loader的方式是采用 session 的feed_dict 方式，该方式feed的是tenor的names，fetch的同样也是tensor 的names。其中feed_dict的key 可以直接是tensor的name，或者是采用 <code>sess.graph.get_tensor_by_name(TENSOR_NAME)</code> 得到的tensor。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session(graph=tf.Graph()) <span class="keyword">as</span> sess:</span><br><span class="line">    tf.saved_model.loader.load(sess, [<span class="string">"serve"</span>], export_path)</span><br><span class="line">    graph = tf.get_default_graph()</span><br><span class="line">    feed_dict = &#123;<span class="string">"input_ids_1:0"</span>: [feature.input_ids],</span><br><span class="line">                <span class="string">"input_mask_1:0"</span>: [feature.input_mask],</span><br><span class="line">                <span class="string">"segment_ids_1:0"</span>: [feature.segment_ids]&#125;</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    # alternative way</span></span><br><span class="line"><span class="string">    feed_dict = &#123;sess.graph.get_tensor_by_name("input_ids_1:0"): </span></span><br><span class="line"><span class="string">                          [feature.input_ids],</span></span><br><span class="line"><span class="string">                sess.graph.get_tensor_by_name("input_mask_1:0"):</span></span><br><span class="line"><span class="string">                          [feature.input_mask],</span></span><br><span class="line"><span class="string">                sess.graph.get_tensor_by_name("segment_ids_1:0"):</span></span><br><span class="line"><span class="string">                          [feature.segment_ids]&#125;</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    sess.run(<span class="string">'loss/pred_prob:0'</span>,</span><br><span class="line">               feed_dict=feed_dict)</span><br></pre></td></tr></table></figure><ul><li>tf.keras 2.0</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new_model = tf.keras.models.load_model(<span class="string">'saved_model/my_model'</span>)</span><br></pre></td></tr></table></figure><h4 id="JAVA-加载"><a href="#JAVA-加载" class="headerlink" title="JAVA 加载"></a>JAVA 加载</h4><p>注意 java加载的时候，如果遇到Op not defined 的错误，是需要匹配模型训练python的tensorflow版本以及java的tensorflow版本的。</p><p>所以我们知道我们在tag-set 为serve的tag下，有4个inputs tensors，name分别为<code>input_ids:0</code>, <code>input_mask:0</code>, <code>label_ids:0</code>, <code>segment_ids:0</code>, 输出为1个，name是 <code>loss/pred_prob:0</code>。并且我们知道这些tensor的类型。</p><p>所以我们可以通过下面的java代码，进行加载，获得结果。注意我们需要传入的name中不需要传入<code>:0</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.tensorflow.*</span><br><span class="line">SavedModelBundle savedModelBundle = SavedModelBundle.load(<span class="string">"./export_path"</span>, <span class="string">"serve"</span>);</span><br><span class="line">Graph graph = savedModelBundle.graph();</span><br><span class="line"></span><br><span class="line">Tensor tensor = <span class="keyword">this</span>.savedModelBundle.session().runner()</span><br><span class="line">                .feed(<span class="string">"input_ids"</span>, inputIdTensor)</span><br><span class="line">                .feed(<span class="string">"input_mask"</span>, inputMaskTensor)</span><br><span class="line">                .feed(<span class="string">"segment_ids"</span>, inputSegmentTensor)</span><br><span class="line">                .fetch(<span class="string">"loss/pred_prob"</span>)</span><br><span class="line">                .run().get(<span class="number">0</span>);</span><br></pre></td></tr></table></figure><h4 id="CLI-加载"><a href="#CLI-加载" class="headerlink" title="CLI 加载"></a>CLI 加载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ saved_model_cli show --dir <span class="built_in">export</span>/1524906774 \</span><br><span class="line">  --tag_set serve --signature_def serving_default</span><br><span class="line">The given SavedModel SignatureDef contains the following input(s):</span><br><span class="line">  inputs[<span class="string">'inputs'</span>] tensor_info:</span><br><span class="line">      dtype: DT_STRING</span><br><span class="line">      shape: (-1)</span><br><span class="line">The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">  outputs[<span class="string">'classes'</span>] tensor_info:</span><br><span class="line">      dtype: DT_STRING</span><br><span class="line">      shape: (-1, 3)</span><br><span class="line">  outputs[<span class="string">'scores'</span>] tensor_info:</span><br><span class="line">      dtype: DT_FLOAT</span><br><span class="line">      shape: (-1, 3)</span><br><span class="line">Method name is: tensorflow/serving/classify</span><br><span class="line"></span><br><span class="line">$ saved_model_cli run --dir <span class="built_in">export</span>/1524906774 \</span><br><span class="line">  --tag_set serve --signature_def serving_default \</span><br><span class="line">  --input_examples <span class="string">'inputs=[&#123;"SepalLength":[5.1],"SepalWidth":[3.3],"PetalLength":[1.7],"PetalWidth":[0.5]&#125;]'</span></span><br><span class="line">Result <span class="keyword">for</span> output key classes:</span><br><span class="line">[[b<span class="string">'0'</span> b<span class="string">'1'</span> b<span class="string">'2'</span>]]</span><br><span class="line">Result <span class="keyword">for</span> output key scores:</span><br><span class="line">[[9.9919027e-01 8.0969761e-04 1.2872645e-09]]</span><br></pre></td></tr></table></figure><h2 id="Frozen-Graph"><a href="#Frozen-Graph" class="headerlink" title="Frozen Graph"></a>Frozen Graph</h2><p>frozen Graphdef 将tensorflow导出的模型的权重都freeze住，使得其都变为常量。并且模型参数和网络结构保存在同一个文件中，可以在python以及java中自由调用。</p><h3 id="导出为pb"><a href="#导出为pb" class="headerlink" title="导出为pb"></a>导出为pb</h3><h4 id="python"><a href="#python" class="headerlink" title="python"></a>python</h4><ul><li>采用session方式保存frozen graph</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""tf1.0"""</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.python.framework.graph_util <span class="keyword">import</span> convert_variables_to_constants</span><br><span class="line"></span><br><span class="line">output_graph_def = convert_variables_to_constants(</span><br><span class="line">                    session,</span><br><span class="line">                    session.graph_def,</span><br><span class="line">                    output_node_names=[<span class="string">'loss/pred_prob'</span>])</span><br><span class="line">tf.train.write_graph(output_graph_def, args.export_dir, args.model_name, as_text=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ul><li>采用ckpt 转换成frozen graph<br>以下采用bert tensorflow模型做演示</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">NB：首先我们要在create_model() 函数中，为我们需要的输出节点取个名字，</span></span><br><span class="line"><span class="string">  比如说我们要： probabilities = tf.nn.softmax(logits, axis=-1, name='pred_prob')</span></span><br><span class="line"><span class="string">"""</span> </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_frozen_model</span><span class="params">(bert_config, num_labels, use_one_hot_embeddings)</span>:</span></span><br><span class="line">  tf_config = tf.compat.v1.ConfigProto()</span><br><span class="line">  tf_config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line">  output_node_names = [<span class="string">'loss/pred_prob'</span>]</span><br><span class="line">  </span><br><span class="line">  model_file = tf.train.latest_checkpoint(FLAGS.output_dir)</span><br><span class="line">  <span class="keyword">with</span> tf.Graph().as_default(), tf.Session(config=tf_config) <span class="keyword">as</span> tf_sess: </span><br><span class="line">    label_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>], name=<span class="string">'label_ids'</span>)</span><br><span class="line">    input_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'input_ids'</span>)</span><br><span class="line">    input_mask = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'input_mask'</span>)</span><br><span class="line">    segment_ids = tf.placeholder(tf.int32, [<span class="literal">None</span>, FLAGS.max_seq_length], name=<span class="string">'segment_ids'</span>)</span><br><span class="line"></span><br><span class="line">    create_model(bert_config, <span class="literal">False</span>, input_ids, input_mask, segment_ids, label_ids,</span><br><span class="line">            num_labels, use_one_hot_embeddings)</span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    print(<span class="string">"restore;&#123;&#125;"</span>.format(model_file))</span><br><span class="line">    saver.restore(tf_sess, model_file)</span><br><span class="line">    tmp_g = tf_sess.graph.as_graph_def()</span><br><span class="line">    <span class="keyword">if</span> FLAGS.use_opt:</span><br><span class="line">      input_tensors = [input_ids, input_mask, segment_ids]</span><br><span class="line">      dtypes = [n.dtype <span class="keyword">for</span> n <span class="keyword">in</span> input_tensors]</span><br><span class="line">      print(<span class="string">'optimize...'</span>)</span><br><span class="line">      tmp_g = optimize_for_inference(tmp_g,</span><br><span class="line">                                    [n.name[:<span class="number">-2</span>] <span class="keyword">for</span> n <span class="keyword">in</span> input_tensors],</span><br><span class="line">                                     output_node_names,</span><br><span class="line">                                     [dtype.as_datatype_enum <span class="keyword">for</span> dtype <span class="keyword">in</span> dtypes],</span><br><span class="line">                                     <span class="literal">False</span>)</span><br><span class="line">    print(<span class="string">'freeze...'</span>)</span><br><span class="line">    frozen_graph = tf.graph_util.convert_variables_to_constants(tf_sess, </span><br><span class="line">            tmp_g, output_node_names)</span><br><span class="line">    out_graph_path = os.path.join(FLAGS.output_dir, <span class="string">"frozen_model.pb"</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.io.gfile.GFile(out_graph_path, <span class="string">"wb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">      f.write(frozen_graph.SerializeToString())      </span><br><span class="line">    print(<span class="string">f'pb file saved in <span class="subst">&#123;out_graph_path&#125;</span>'</span>)</span><br></pre></td></tr></table></figure><ul><li>采用savedModel 转换成 frozen graph</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.tools <span class="keyword">import</span> freeze_graph</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.saved_model <span class="keyword">import</span> tag_constants</span><br><span class="line"></span><br><span class="line">input_saved_model_dir = <span class="string">"./1583934987/"</span></span><br><span class="line">output_node_names = <span class="string">"loss/pred_prob"</span></span><br><span class="line">input_binary = <span class="literal">False</span></span><br><span class="line">input_saver_def_path = <span class="literal">False</span></span><br><span class="line">restore_op_name = <span class="literal">None</span></span><br><span class="line">filename_tensor_name = <span class="literal">None</span></span><br><span class="line">clear_devices = <span class="literal">False</span></span><br><span class="line">input_meta_graph = <span class="literal">False</span></span><br><span class="line">checkpoint_path = <span class="literal">None</span></span><br><span class="line">input_graph_filename = <span class="literal">None</span></span><br><span class="line">saved_model_tags = tag_constants.SERVING</span><br><span class="line">output_graph_filename=<span class="string">'frozen_graph.pb'</span></span><br><span class="line"></span><br><span class="line">freeze_graph.freeze_graph(input_graph_filename,</span><br><span class="line">  input_saver_def_path,</span><br><span class="line">  input_binary,</span><br><span class="line">  checkpoint_path,</span><br><span class="line">  output_node_names,</span><br><span class="line">  restore_op_name,</span><br><span class="line">  filename_tensor_name,</span><br><span class="line">  output_graph_filename,</span><br><span class="line">  clear_devices,</span><br><span class="line">  <span class="string">""</span>, <span class="string">""</span>, <span class="string">""</span>,</span><br><span class="line">  input_meta_graph,</span><br><span class="line">  input_saved_model_dir,</span><br><span class="line">  saved_model_tags)</span><br></pre></td></tr></table></figure><ul><li>HDF5 to pb</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">freeze_session</span><span class="params">(session, keep_var_names=None, output_names=None, clear_devices=True)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Freezes the state of a session into a pruned computation graph.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Creates a new computation graph where variable nodes are replaced by</span></span><br><span class="line"><span class="string">    constants taking their current value in the session. The new graph will be</span></span><br><span class="line"><span class="string">    pruned so subgraphs that are not necessary to compute the requested</span></span><br><span class="line"><span class="string">    outputs are removed.</span></span><br><span class="line"><span class="string">    @param session The TensorFlow session to be frozen.</span></span><br><span class="line"><span class="string">    @param keep_var_names A list of variable names that should not be frozen,</span></span><br><span class="line"><span class="string">                          or None to freeze all the variables in the graph.</span></span><br><span class="line"><span class="string">    @param output_names Names of the relevant graph outputs.</span></span><br><span class="line"><span class="string">    @param clear_devices Remove the device directives from the graph for better portability.</span></span><br><span class="line"><span class="string">    @return The frozen graph definition.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    graph = session.graph</span><br><span class="line">    <span class="keyword">with</span> graph.as_default():</span><br><span class="line">        freeze_var_names = list(set(v.op.name <span class="keyword">for</span> v <span class="keyword">in</span> tf.global_variables()).difference(keep_var_names <span class="keyword">or</span> []))</span><br><span class="line">        output_names = output_names <span class="keyword">or</span> []</span><br><span class="line">        output_names += [v.op.name <span class="keyword">for</span> v <span class="keyword">in</span> tf.global_variables()]</span><br><span class="line">        input_graph_def = graph.as_graph_def()</span><br><span class="line">        <span class="keyword">if</span> clear_devices:</span><br><span class="line">            <span class="keyword">for</span> node <span class="keyword">in</span> input_graph_def.node:</span><br><span class="line">                node.device = <span class="string">""</span></span><br><span class="line">        frozen_graph = tf.graph_util.convert_variables_to_constants(</span><br><span class="line">            session, input_graph_def, output_names, freeze_var_names)</span><br><span class="line">        <span class="keyword">return</span> frozen_graph</span><br><span class="line">        </span><br><span class="line">frozen_graph = freeze_session(K.get_session(),</span><br><span class="line">                              output_names=[out.op.name <span class="keyword">for</span> out <span class="keyword">in</span> model.outputs])</span><br><span class="line"></span><br><span class="line">tf.train.write_graph(frozen_graph, <span class="string">"some_directory"</span>, <span class="string">"my_model.pb"</span>, as_text=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h4 id="CLI转换工具"><a href="#CLI转换工具" class="headerlink" title="CLI转换工具"></a>CLI转换工具</h4><p>以下的工具可以快速进行ckpt到pb的转换，但是不能再原本的基础上增加tensor 的名字。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">freeze_graph --input_checkpoint model.ckpt-16329 \</span><br><span class="line">             --output_graph 0316_roberta.pb \</span><br><span class="line">             --output_node_names loss/pred_prob \</span><br><span class="line">             --checkpoint_version 1 \</span><br><span class="line">             --input_meta_graph model.ckpt-16329.meta \</span><br><span class="line">             --input_binary true</span><br></pre></td></tr></table></figure><h3 id="模型加载"><a href="#模型加载" class="headerlink" title="模型加载"></a>模型加载</h3><p>获取frozen graph 中节点名字的脚本如下，但是一般来说，我们的inputs都是我们定义好的placeholders。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printTensors</span><span class="params">(pb_file)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""read pb into graph_def"""</span></span><br><span class="line">    <span class="keyword">with</span> tf.gfile.GFile(pb_file, <span class="string">"rb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        graph_def = tf.GraphDef()</span><br><span class="line">        graph_def.ParseFromString(f.read())</span><br><span class="line"></span><br><span class="line">    <span class="string">"""import graph_def"""</span></span><br><span class="line">    <span class="keyword">with</span> tf.Graph().as_default() <span class="keyword">as</span> graph:</span><br><span class="line">        tf.import_graph_def(graph_def)</span><br><span class="line"></span><br><span class="line">    <span class="string">"""print operations"""</span></span><br><span class="line">    <span class="keyword">for</span> op <span class="keyword">in</span> graph.get_operations():</span><br><span class="line">        print(op.name)</span><br><span class="line"></span><br><span class="line">printTensors(<span class="string">"path-to-my-pbfile.pb"</span>)</span><br></pre></td></tr></table></figure><p>得到类似如下的结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import/input_ids:0</span><br><span class="line">import/input_mask:0</span><br><span class="line">import/segment_ids:0</span><br><span class="line">...</span><br><span class="line">import/loss/pred_prob:0</span><br></pre></td></tr></table></figure><p>当我们知道我们要feed以及fetch的节点名称之后，我们就可以通过python/java加载了。<br>跟savedModel一样，对于某些节点，如果没有办法直接加name，那么可以采用 <code>tf.identity</code>， 为节点加名字，例如说CRF的输出，以及使用dataset后，无法直接加input的name，都可以采用这个方式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addNameToTensor</span><span class="params">(someTensor, theName)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.identity(someTensor, name=theName)</span><br></pre></td></tr></table></figure><h4 id="Python-加载-1"><a href="#Python-加载-1" class="headerlink" title="Python 加载"></a>Python 加载</h4><p>我们保存完frozen graph 模型后，假设我们的模型包含以下的tensors：</p><p>那么我们通过python加载的代码如下, 采用的是session feed和fetch的方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    output_graph_def = tf.GraphDef()</span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">   load pb model</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">with</span> open(args_in_use.model, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        output_graph_def.ParseFromString(f.read())</span><br><span class="line">        tf.import_graph_def(output_graph_def, name=<span class="string">''</span>) <span class="comment">#name是必须的</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    enter a text and predict</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        tf.global_variables_initializer().run()</span><br><span class="line">        input_ids = sess.graph.get_tensor_by_name(</span><br><span class="line">            <span class="string">"input_ids:0"</span>)</span><br><span class="line">        input_mask = sess.graph.get_tensor_by_name(</span><br><span class="line">            <span class="string">"input_mask:0"</span>)</span><br><span class="line">        segment_ids = sess.graph.get_tensor_by_name(</span><br><span class="line">            <span class="string">"segment_ids:0"</span>)</span><br><span class="line">        output = <span class="string">"loss/pred_prob:0"</span></span><br><span class="line">        </span><br><span class="line">        feed_dict = &#123;</span><br><span class="line">            input_ids: [feature.input_ids],</span><br><span class="line">            input_mask: [feature.input_mask],</span><br><span class="line">            segment_ids: [feature.segment_ids],</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># 也可以直接使用</span></span><br><span class="line">        <span class="comment"># feed_dict = &#123;</span></span><br><span class="line">        <span class="comment">#     "input_ids:0": [feature.input_ids],</span></span><br><span class="line">        <span class="comment">#     "input_mask:0": [feature.input_mask],</span></span><br><span class="line">        <span class="comment">#     "segment_ids:0": [feature.segment_ids],</span></span><br><span class="line">        <span class="comment"># &#125;</span></span><br><span class="line">        y_pred_cls = sess.run(output, feed_dict=feed_dict)</span><br></pre></td></tr></table></figure><h4 id="Java-加载"><a href="#Java-加载" class="headerlink" title="Java 加载"></a>Java 加载</h4><p>对于frozen graph，我们加载的方式和savedModel很类似，首先我们需要先启动一个session，然后在启动一个<code>runner()</code>，然后再feed模型的输入，以及fetch模型的输出。</p><p>注意 java加载的时候，如果遇到Op not defined 的错误，是需要匹配模型训练python的tensorflow版本以及java的tensorflow版本的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TensorUtil.class</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Session <span class="title">generateSession</span><span class="params">(String modelPath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Preconditions.checkNotNull(modelPath);</span><br><span class="line">    <span class="keyword">byte</span>[] graphDef = ByteStreams.toByteArray(TensorUtil.class.getResourceAsStream(modelPath));</span><br><span class="line">    LOGGER.info(<span class="string">"Graph Def Length: &#123;&#125;"</span>, graphDef.length);</span><br><span class="line">    Graph graph = <span class="keyword">new</span> Graph();</span><br><span class="line">    graph.importGraphDef(graphDef);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Session(graph);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// model.class</span></span><br><span class="line"><span class="keyword">this</span>.session = TensorUtil.generateSession(modelPath);</span><br><span class="line"></span><br><span class="line">Tensor tensor = <span class="keyword">this</span>.session.runner()</span><br><span class="line">                    .feed(<span class="string">"input_ids"</span>, inputIdTensor)</span><br><span class="line">                    .feed(<span class="string">"input_mask"</span>, inputMaskTensor)</span><br><span class="line">                    .feed(<span class="string">"segment_ids"</span>, inputSegmentTensor)</span><br><span class="line">                    .fetch(<span class="string">"loss/pred_prob"</span>)</span><br><span class="line">                    .run().get(<span class="number">0</span>);</span><br></pre></td></tr></table></figure><h2 id="HDF5"><a href="#HDF5" class="headerlink" title="HDF5"></a>HDF5</h2><p>HDF5 是keras or tf.keras 特有的存储格式。</p><h3 id="HDF5导出"><a href="#HDF5导出" class="headerlink" title="HDF5导出"></a>HDF5导出</h3><ul><li>导出整个模型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""默认1.0 是HDF5，但是2.0中，是SavedModel，所以需要显性地指定`.h5`后缀"""</span></span><br><span class="line">model.save(<span class="string">'my_model.h5'</span>)</span><br></pre></td></tr></table></figure><ul><li>导出模型weights</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""keras 1.0"""</span></span><br><span class="line">model.save_weights(<span class="string">'my_model_weights.h5'</span>)</span><br></pre></td></tr></table></figure><h3 id="HDF5加载"><a href="#HDF5加载" class="headerlink" title="HDF5加载"></a>HDF5加载</h3><ul><li><p>加载整个模型（无自定义部分）</p></li><li><ul><li>keras1.0</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""keras 1.0"""</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line">model = load_model(model_path)</span><br></pre></td></tr></table></figure><ul><li><ul><li>keras2.0</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""keras 2.0"""</span></span><br><span class="line">new_model = tf.keras.models.load_model(<span class="string">'my_model.h5'</span>)</span><br></pre></td></tr></table></figure><ul><li><p>加载整个模型（含自定义部分）<br>对于有自定义layers的或者实现的模型加载，需要增加dependencies 的映射字典，例如下面的例子：</p></li><li><ul><li>keras1.0</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dependencies = &#123;<span class="string">'MyLayer'</span>: MyLayer(), <span class="string">'auc'</span>: auc, <span class="string">'log_loss'</span>: log_loss&#125;</span><br><span class="line">model = load_model(model_path, custom_objects=dependencies, compile=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ul><li><ul><li>keras 2.0</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">To save custom objects to HDF5, you must do the following:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1. Define a get_config method in your object, and optionally a from_config classmethod.</span></span><br><span class="line"><span class="string">get_config(self) returns a JSON-serializable dictionary of parameters needed to recreate the object.</span></span><br><span class="line"><span class="string">from_config(cls, config) uses the returned config from get_config to create a new object. By default, this function will use the config as initialization kwargs (return cls(**config)).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">2. Pass the object to the custom_objects argument when loading the model. The argument must be a dictionary mapping the string class name to the Python class. E.g. tf.keras.models.load_model(path, custom_objects=&#123;'CustomLayer': CustomLayer&#125;)</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>加载模型权重<br>假设你有了相同的模型构建了，那么直接运行下面的代码，加载模型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_weights(<span class="string">'my_model_weights.h5'</span>)</span><br></pre></td></tr></table></figure><p>如果你想要做transfer learning，即从其他的已保存的模型中加载部分的模型参数权重，自己目前的模型结构与保存的模型不同，可以通过参数的名字进行加载，加上 <code>by_name=True</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_weights(<span class="string">'my_model_weights.h5'</span>, by_name=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h2 id="tfLite"><a href="#tfLite" class="headerlink" title="tfLite"></a>tfLite</h2><h3 id="TFlite转换"><a href="#TFlite转换" class="headerlink" title="TFlite转换"></a>TFlite转换</h3><ul><li>savedModel to TFLite</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">--saved_model_dir:  Type: string. Specifies the full path to the directory containing the SavedModel generated in 1.X or 2.X.</span></span><br><span class="line"><span class="string">--output_file: Type: string. Specifies the full path of the output file.</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">tflite_convert \</span><br><span class="line">    --saved_model_dir=1583934987 \</span><br><span class="line">    --output_file=rbt.tflite</span><br></pre></td></tr></table></figure><ul><li>frozen graph to TFLite</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tflite_convert --graph_def_file albert_tiny_zh.pb \</span><br><span class="line">               --input_arrays <span class="string">'input_ids,input_masks,segment_ids'</span> \</span><br><span class="line">               --output_arrays <span class="string">'finetune_mrc/add, finetune_mrc/add_1'</span>\</span><br><span class="line">               --input_shapes 1,512:1,512:1,512 \</span><br><span class="line">               --output_file saved_model.tflite \</span><br><span class="line">               --enable_v1_converter \</span><br><span class="line">               --experimental_new_converter</span><br></pre></td></tr></table></figure><ul><li>HDF5 to TFLite</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#--keras_model_file. Type: string. Specifies the full path of the HDF5 file containing the tf.keras model generated in 1.X or 2.X.   </span></span><br><span class="line"><span class="comment">#--output_file: Type: string. Specifies the full path of the output file.</span></span><br><span class="line">tflite_convert \</span><br><span class="line">    --keras_model_file=h5_dir/ \</span><br><span class="line">    --output_file=rbt.tflite</span><br></pre></td></tr></table></figure><p>另外，补充一个TFlite转frozen graph：</p><p>tensorflow在早期提供了转换工具（1.9版本后的tensorflow没有再提到这个功能了），具体操作可以看<a href="https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md" target="_blank" rel="noopener">这里</a>。</p><p>有的模型TOCO工具可能会转换失败，可以参考<a href="https://gist.github.com/tworuler/bd7bd4c6cd9a8fbbeb060e7b64cfa008" target="_blank" rel="noopener">这个链接</a>。</p><h3 id="TFLite-加载"><a href="#TFLite-加载" class="headerlink" title="TFLite 加载"></a>TFLite 加载</h3><p>参考 <a href="https://link.zhihu.com/?target=https%3A//www.tensorflow.org/lite/guide/inference" target="_blank" rel="noopener">https://www.tensorflow.org/lite/guide/inference</a><br>参考 <a href="https://link.zhihu.com/?target=https%3A//github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/r1/convert/index.md" target="_blank" rel="noopener">https://github.com/tensorflow/t</a></p><p>这里介绍一个Python的加载。</p><ul><li>当从SavedModel转换得到，并且含有SignatureDef时：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestModel</span><span class="params">(tf.Module)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    super(TestModel, self).__init__()</span><br><span class="line"></span><br><span class="line"><span class="meta">  @tf.function(input_signature=[tf.TensorSpec(shape=[1, 10], dtype=tf.float32)])</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(self, x)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Simple method that accepts single input 'x' and returns 'x' + 4.</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># Name the output 'result' for convenience.</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'result'</span> : x + <span class="number">4</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">SAVED_MODEL_PATH = <span class="string">'content/saved_models/test_variable'</span></span><br><span class="line">TFLITE_FILE_PATH = <span class="string">'content/test_variable.tflite'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the model</span></span><br><span class="line">module = TestModel()</span><br><span class="line"><span class="comment"># You can omit the signatures argument and a default signature name will be</span></span><br><span class="line"><span class="comment"># created with name 'serving_default'.</span></span><br><span class="line">tf.saved_model.save(</span><br><span class="line">    module, SAVED_MODEL_PATH,</span><br><span class="line">    signatures=&#123;<span class="string">'my_signature'</span>:module.add.get_concrete_function()&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert the model using TFLiteConverter</span></span><br><span class="line">converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_PATH)</span><br><span class="line">tflite_model = converter.convert()</span><br><span class="line"><span class="keyword">with</span> open(TFLITE_FILE_PATH, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">  f.write(tflite_model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the TFLite model in TFLite Interpreter</span></span><br><span class="line">interpreter = tf.lite.Interpreter(TFLITE_FILE_PATH)</span><br><span class="line"><span class="comment"># There is only 1 signature defined in the model,</span></span><br><span class="line"><span class="comment"># so it will return it by default.</span></span><br><span class="line"><span class="comment"># If there are multiple signatures then we can pass the name.</span></span><br><span class="line">my_signature = interpreter.get_signature_runner()</span><br><span class="line"></span><br><span class="line"><span class="comment"># my_signature is callable with input as arguments.</span></span><br><span class="line">output = my_signature(x=tf.constant([<span class="number">1.0</span>], shape=(<span class="number">1</span>,<span class="number">10</span>), dtype=tf.float32))</span><br><span class="line"><span class="comment"># 'output' is dictionary with all outputs from the inference.</span></span><br><span class="line"><span class="comment"># In this case we have single output 'result'.</span></span><br><span class="line">print(output[<span class="string">'result'</span>])</span><br></pre></td></tr></table></figure><ul><li>当没有SignatureDef时</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the TFLite model and allocate tensors.</span></span><br><span class="line">interpreter = tf.lite.Interpreter(model_path=<span class="string">"converted_model.tflite"</span>)</span><br><span class="line">interpreter.allocate_tensors()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get input and output tensors.</span></span><br><span class="line">input_details = interpreter.get_input_details()</span><br><span class="line">output_details = interpreter.get_output_details()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test the model on random input data.</span></span><br><span class="line">input_shape = input_details[<span class="number">0</span>][<span class="string">'shape'</span>]</span><br><span class="line">input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)</span><br><span class="line">interpreter.set_tensor(input_details[<span class="number">0</span>][<span class="string">'index'</span>], input_data)</span><br><span class="line"></span><br><span class="line">interpreter.invoke()</span><br><span class="line"></span><br><span class="line"><span class="comment"># The function `get_tensor()` returns a copy of the tensor data.</span></span><br><span class="line"><span class="comment"># Use `tensor()` in order to get a pointer to the tensor.</span></span><br><span class="line">output_data = interpreter.get_tensor(output_details[<span class="number">0</span>][<span class="string">'index'</span>])</span><br><span class="line">print(output_data)</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/nanhuaibeian/article/details/101751439" target="_blank" rel="noopener">TensorFlow：.ckpt文件与.ckpt.meta和.ckpt.index以及.pb文件之间的关系是什么？</a><br><a href="https://sulingling123.github.io/2019/08/15/TF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD%E6%96%B9%E5%BC%8F/" target="_blank" rel="noopener">TF的三种模型的保存与加载方式</a><br><a href="https://cloud.tencent.com/developer/article/1009979" target="_blank" rel="noopener">TensorFlow 到底有几种模型格式？</a><br><a href="https://zhuanlan.zhihu.com/p/113734249" target="_blank" rel="noopener">tensorflow 模型导出总结</a></p></div><div><div style="text-align:center;color:#ccc;font-size:14px">------ 本文结束------</div></div><div class="reward-container"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/uploads/wechat.png" alt="zdaiot 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/uploads/aipay.jpg" alt="zdaiot 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> zdaiot</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.zdaiot.com/MLFrameworks/TensorFlow/TensorFlow模型保存总结/" title="TensorFlow模型保存总结">https://www.zdaiot.com/MLFrameworks/TensorFlow/TensorFlow模型保存总结/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><p>欢迎关注我的其它发布渠道</p><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="/uploads/wechat-qcode.jpg"><span class="icon"><i class="fab fa-weixin"></i></span> <span class="label">WeChat</span></a></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/TensorFlow/" rel="tag"><i class="fa fa-tag"></i> TensorFlow</a><a href="/tags/save/" rel="tag"><i class="fa fa-tag"></i> save</a></div><div class="post-nav"><div class="post-nav-item"><a href="/Tools/Computer/数字编码/" rel="prev" title="数字编码"><i class="fa fa-chevron-left"></i> 数字编码</a></div><div class="post-nav-item"> <a href="/MLFrameworks/TensorFlow/TensorFlow中的Queue/" rel="next" title="TensorFlow中的Queue">TensorFlow中的Queue<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="gitalk-container"></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#checkpoint"><span class="nav-number">1.</span> <span class="nav-text">checkpoint</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#导出成CKPT"><span class="nav-number">1.1.</span> <span class="nav-text">导出成CKPT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#加载CKPT"><span class="nav-number">1.2.</span> <span class="nav-text">加载CKPT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Meta文件分析"><span class="nav-number">1.3.</span> <span class="nav-text">Meta文件分析</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SavedModel"><span class="nav-number">2.</span> <span class="nav-text">SavedModel</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#导出为SavedModel"><span class="nav-number">2.1.</span> <span class="nav-text">导出为SavedModel</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#加载SavedModel"><span class="nav-number">2.2.</span> <span class="nav-text">加载SavedModel</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Python-加载"><span class="nav-number">2.2.1.</span> <span class="nav-text">Python 加载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#JAVA-加载"><span class="nav-number">2.2.2.</span> <span class="nav-text">JAVA 加载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CLI-加载"><span class="nav-number">2.2.3.</span> <span class="nav-text">CLI 加载</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Frozen-Graph"><span class="nav-number">3.</span> <span class="nav-text">Frozen Graph</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#导出为pb"><span class="nav-number">3.1.</span> <span class="nav-text">导出为pb</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#python"><span class="nav-number">3.1.1.</span> <span class="nav-text">python</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CLI转换工具"><span class="nav-number">3.1.2.</span> <span class="nav-text">CLI转换工具</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模型加载"><span class="nav-number">3.2.</span> <span class="nav-text">模型加载</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Python-加载-1"><span class="nav-number">3.2.1.</span> <span class="nav-text">Python 加载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Java-加载"><span class="nav-number">3.2.2.</span> <span class="nav-text">Java 加载</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDF5"><span class="nav-number">4.</span> <span class="nav-text">HDF5</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HDF5导出"><span class="nav-number">4.1.</span> <span class="nav-text">HDF5导出</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDF5加载"><span class="nav-number">4.2.</span> <span class="nav-text">HDF5加载</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tfLite"><span class="nav-number">5.</span> <span class="nav-text">tfLite</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#TFlite转换"><span class="nav-number">5.1.</span> <span class="nav-text">TFlite转换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TFLite-加载"><span class="nav-number">5.2.</span> <span class="nav-text">TFLite 加载</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考"><span class="nav-number">6.</span> <span class="nav-text">参考</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="zdaiot" src="/uploads/avatar.png"><p class="site-author-name" itemprop="name">zdaiot</p><div class="site-description" itemprop="description">404NotFound</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">320</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">54</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">377</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zdaiot" title="GitHub → https://github.com/zdaiot" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:zdaiot@163.com" title="E-Mail → mailto:zdaiot@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/" title="知乎 → https://www.zhihu.com/people/" rel="noopener" target="_blank"><i class="fa fa-book fa-fw"></i> 知乎</a></span><span class="links-of-author-item"><a href="https://blog.csdn.net/zdaiot" title="CSDN → https://blog.csdn.net/zdaiot" rel="noopener" target="_blank"><i class="fa fa-copyright fa-fw"></i> CSDN</a></span></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="link fa-fw"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://kalacloud.com" title="https://kalacloud.com" rel="noopener" target="_blank">卡拉云低代码工具</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://beian.miit.gov.cn" rel="noopener" target="_blank">京ICP备2021031914号</a></div><div class="copyright"> &copy; <span itemprop="copyrightYear">2023</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">zdaiot</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-chart-area"></i></span> <span title="站点总字数">2.5m</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span title="站点阅读时长">37:18</span></div><div class="addthis_inline_share_toolbox"><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b5e7e498f94b7ad" async="async"></script></div> <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now=new Date;function createtime(){var n=new Date("08/01/2018 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="Run for "+dnum+" Days ",document.getElementById("times").innerHTML=hnum+" Hours "+mnum+" m "+snum+" s"}setInterval("createtime()",250)</script><div class="busuanzi-count"><script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script><script data-pjax>!function(){var o,n,e=document.getElementsByTagName("link");if(0<e.length)for(i=0;i<e.length;i++)"canonical"==e[i].rel.toLowerCase()&&e[i].href&&(o=e[i].href);n=o?o.split(":")[0]:window.location.protocol.split(":")[0],o||(o=window.location.href),function(){var e=o,i=document.referrer;if(!/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(e)){var t="https"===String(n).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";i?(t+="?r="+encodeURIComponent(document.referrer),e&&(t+="&l="+e)):e&&(t+="?l="+e),(new Image).src=t}}(window)}()</script><script src="/js/local-search.js"></script><div id="pjax"><script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '4800250e682fe873198b',
      clientSecret: '80f7f33f5f8ddfd3944f455cabadda4ff3299147',
      repo        : 'zdaiot.github.io',
      owner       : 'zdaiot',
      admin       : ['zdaiot'],
      id          : '80ad9a0b32e3c10581346f546c80a8d6',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/wanko.model.json"},display:{position:"left",width:150,height:300},mobile:{show:!0}})</script></body></html>