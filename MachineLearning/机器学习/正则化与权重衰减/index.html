<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 3.9.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"www.zdaiot.com",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="Why &amp;amp; What 正则化我们总会在各种地方遇到正则化这个看起来很难理解的名词，其实它并没有那么高冷，是很好理解的 首先，从使用正则化解决了一个什么问题的角度来看：正则化是为了防止过拟合， 进而增强泛化能力。用白话文转义，泛化误差（generalization error）= 测试误差（test error），其实就是使用训练数据训练的模型在测试集上的表现（或说性能 performanc"><meta name="keywords" content="正则化,范数,权重衰减"><meta property="og:type" content="article"><meta property="og:title" content="正则化与权重衰减"><meta property="og:url" content="https://www.zdaiot.com/MachineLearning/机器学习/正则化与权重衰减/index.html"><meta property="og:site_name" content="zdaiot"><meta property="og:description" content="Why &amp;amp; What 正则化我们总会在各种地方遇到正则化这个看起来很难理解的名词，其实它并没有那么高冷，是很好理解的 首先，从使用正则化解决了一个什么问题的角度来看：正则化是为了防止过拟合， 进而增强泛化能力。用白话文转义，泛化误差（generalization error）= 测试误差（test error），其实就是使用训练数据训练的模型在测试集上的表现（或说性能 performanc"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/正则化与权重衰减/Overfitting1568430716530.png"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/正则化与权重衰减/1cc0b7ef-bffa-4c8b-a600-9da9e139ccc3.jpg"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/正则化与权重衰减/bc1c1059-6e07-46b9-80c7-45d0715cdc8f.jpg"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/正则化与权重衰减/5a27633b-afba-4093-8a72-a3440ed9cdf8.jpg"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/正则化与权重衰减/L1l2regularization5.png"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/正则化与权重衰减/L1l2regularization6.png"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/正则化与权重衰减/15e0011f-fb50-43c4-b245-1598bbb520c7.jpg"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/正则化与权重衰减/3b25eae6-8486-4a2f-bbeb-14d3f940d8bd.jpg"><meta property="og:updated_time" content="2019-09-15T03:21:26.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="正则化与权重衰减"><meta name="twitter:description" content="Why &amp;amp; What 正则化我们总会在各种地方遇到正则化这个看起来很难理解的名词，其实它并没有那么高冷，是很好理解的 首先，从使用正则化解决了一个什么问题的角度来看：正则化是为了防止过拟合， 进而增强泛化能力。用白话文转义，泛化误差（generalization error）= 测试误差（test error），其实就是使用训练数据训练的模型在测试集上的表现（或说性能 performanc"><meta name="twitter:image" content="https://www.zdaiot.com/MachineLearning/机器学习/正则化与权重衰减/Overfitting1568430716530.png"><link rel="canonical" href="https://www.zdaiot.com/MachineLearning/机器学习/正则化与权重衰减/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>正则化与权重衰减 | zdaiot</title><script data-pjax>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?0b0b58037319da4959d5a3c014160ccd";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">zdaiot</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">404NotFound</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.zdaiot.com/MachineLearning/机器学习/正则化与权重衰减/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/uploads/avatar.png"><meta itemprop="name" content="zdaiot"><meta itemprop="description" content="404NotFound"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="zdaiot"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> 正则化与权重衰减<a href="https://github.com/zdaiot/zdaiot.github.io/tree/hexo/source/_posts/MachineLearning/机器学习/正则化与权重衰减.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pencil-alt"></i></a></h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-04-17 10:27:56" itemprop="dateCreated datePublished" datetime="2019-04-17T10:27:56+08:00">2019-04-17</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2019-09-15 11:21:26" itemprop="dateModified" datetime="2019-09-15T11:21:26+08:00">2019-09-15</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MachineLearning/" itemprop="url" rel="index"><span itemprop="name">MachineLearning</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MachineLearning/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>6k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>5 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="Why-amp-What-正则化"><a href="#Why-amp-What-正则化" class="headerlink" title="Why &amp; What 正则化"></a>Why &amp; What 正则化</h2><p>我们总会在各种地方遇到<strong>正则化</strong>这个看起来很难理解的名词，其实它并没有那么高冷，是很好理解的</p><p>首先，从<strong>使用正则化解决了一个什么问题</strong>的角度来看：<strong>正则化是为了防止过拟合， 进而增强泛化能力</strong>。用白话文转义，<strong>泛化误差</strong>（generalization error）= 测试误差（test error），其实就是使用训练数据训练的模型在测试集上的表现（或说性能 performance）好不好</p><p><img src="/MachineLearning/机器学习/正则化与权重衰减/Overfitting1568430716530.png" alt></p><p>如上图，红色这条“想象力”过于丰富上下横跳的曲线就是过拟合情形。结合上图和正则化的英文 Regularizaiton-Regular-Regularize，<strong>直译应该是：规则化</strong>（加个“化”字变动词，自豪一下中文还是强）。什么是规则？你妈喊你6点前回家吃饭，这就是规则，一个<strong>限制</strong>。同理，在这里，<strong>规则化就是说给需要训练的目标函数加上一些规则（限制），让他们不要自我膨胀</strong>。正则化，看起来，挺不好理解的，追其根源，还是“正则”这两字在中文中实在没有一个直观的对应，如果能翻译成<strong>规则化</strong>，更好理解。但我们一定要明白，搞<strong>学术，概念名词的准确是十分重要</strong>，对于一个<strong>重要唯一确定的概念</strong>，为它安上一个不会产生歧义的名词是必须的，正则化的名称没毛病，只是从如何理解的角度，要灵活和类比。</p><p>我的思考模式的中心有一个理念：<strong>每一个概念</strong>，<strong>被定义</strong>就是为了去<strong>解决一个实际问题（问Why&amp;What），接着寻找解决问题的方法（问How）</strong>，这个“方法”在计算机领域被称为“算法”（非常多的人在研究）。我们无法真正衡量到底是提出问题重要，还是解决问题重要，但我们可以从不同的<strong>解决问题的角度</strong>来思考问题。一方面，<strong>重复</strong>以加深印象。另一方面，具有<strong>多角度的视野</strong>，能让我们获得更多的灵感，真正做到<strong>链接并健壮自己的知识图谱</strong></p><h2 id="How-线性模型角度"><a href="#How-线性模型角度" class="headerlink" title="How 线性模型角度"></a>How 线性模型角度</h2><p><strong>对于线性模型来说，无论是Logistic Regression、SVM或是简单的线性模型，都有一个基函数 $\phi()$，其中有很多 $\mathbf w$ （参数）需要通过对损失函数 $E()$ 求极小值（或最大似然估计）来确定，求的过程，也就是使用训练集的训练过程：梯度下降到最小值点。最终，找到最合适的 $\mathbf w$ 确定模型。</strong>从这个角度来看，正则化是怎么做的呢？</p><h3 id="二次正则项"><a href="#二次正则项" class="headerlink" title="二次正则项"></a>二次正则项</h3><p>我们看一个线性的<strong>损失函数（真实值和预测值的误差）</strong></p><script type="math/tex;mode=display">
E(\mathbf w) =\frac{1}{2} \sum_{n=1}^{N}\{t_n-\mathbf w^T \phi (\mathbf x_n)\}^2 \tag{1}</script><blockquote><p>$E(\mathbf w)$ 是<strong>损失函数（又称误差函数）</strong>，<code>E</code>即Evaluate，有时候写成<code>L</code>即Loss<br>$t_n$ 是测试集的真实输出，又称目标变量【对应第一幅图中的蓝色点】<br>$\mathbf w$ 是权重（需要训练的部分，未知数）<br>$\phi()$ 是<strong>基函数</strong>，例如多项式函数，核函数<br>测试样本有<code>n</code>个数据<br>整个函数直观解释就是<strong>误差方差和</strong>，$\frac{1}{2}$ 只是为了<strong>求导后消去方便计算</strong></p></blockquote><p>加<strong>正则化项</strong>，得到最终的<strong>误差函数（Error function）</strong></p><script type="math/tex;mode=display">
\frac{1}{2} \sum_{n=1}^{N}\{t_n-\mathbf w^T \phi (\mathbf x_n)\}^2 + \frac{\lambda}{2} \mathbf w^T \mathbf w \tag{2}</script><p>在机器学习中，我们将式子$({1})$称为经验风险，而式子$({2})$称为结构风险。所以加上正则化后的最小化又称为结构风险最小化。</p><blockquote><p>(2)式被称为目标函数（评价函数）= 误差函数（损失函数） + 正则化项<br>$\lambda$ 被称为正则化系数，<strong>越大，这个限制越强</strong></p></blockquote><p>2式对 $\mathbf w$ 求导，并令为0（<strong>使误差最小</strong>），可以解得</p><script type="math/tex;mode=display">
\mathbf w = (\lambda \mathbf I + \Phi^T \Phi)^{-1}\Phi^T\mathbf t</script><p>这是<strong>最小二乘法的解形式</strong>，所以在题目中写的是从“最小二乘角度”。至于为何正则化项是 $\frac{\lambda}{2} \mathbf w^T \mathbf w$ 在之后马上解释</p><h3 id="一般正则项"><a href="#一般正则项" class="headerlink" title="一般正则项"></a>一般正则项</h3><p>直观的详解为什么要选择二次正则项。首先，需要从一般推特例，然后分析特例情况的互相优劣条件，可洞若观火。<strong>一般正则项</strong>是以下公式的形式</p><script type="math/tex;mode=display">
\frac{1}{2} \sum_{n=1}^{N}\{t_n-\mathbf w^T \phi (\mathbf x_n)\}^2 + \frac{\lambda}{2} \sum_{j=1}^{M} {\vert w_j \vert}^q \tag{3}</script><blockquote><p><code>M</code>是模型的阶次（表现形式是数据的维度），比如<code>M=2</code>，就是一个平面（二维）内的点</p></blockquote><p>若<code>q=2</code>就是二次正则项。高维度没有图像表征非常难以理解，那就使用二维作为特例来理解。这里令<code>M=2</code>，即$\mathbf x =\{x_1,x_2\} \;\mathbf w=\{w_1,w_2\}$ ，令<code>q=0.5</code> <code>q=1</code> <code>q=2</code> <code>q=4</code> 有</p><p><img src="/MachineLearning/机器学习/正则化与权重衰减/1cc0b7ef-bffa-4c8b-a600-9da9e139ccc3.jpg" alt></p><blockquote><p>横坐标是$w_1$<br>纵坐标是$w_2$<br>绿线是<strong>等高线的其中一条</strong>，换言之是一个<strong>俯视图</strong>，而<strong>z轴代表</strong>的是$ \frac{\lambda}{2} \sum_{j=1}^{M} {\vert w_j \vert}^q$ 的值</p></blockquote><p>空间想象力不足无法理解的读者希望下方的三维图像能给你一个直观的领悟（与绿线图一一对应）</p><p><img src="/MachineLearning/机器学习/正则化与权重衰减/bc1c1059-6e07-46b9-80c7-45d0715cdc8f.jpg" alt></p><p><code>q=2</code>是一个圆非常好理解，考虑 $z = w_1^2 + w_2^2 $ 就是抛物面，俯视图是一个圆。其他几项同理（必须强调<strong>俯视图和等高线的概念</strong>，z轴表示的是正则项项的值）</p><p><img src="/MachineLearning/机器学习/正则化与权重衰减/5a27633b-afba-4093-8a72-a3440ed9cdf8.jpg" width="50%" height="50%"></p><blockquote><p>蓝色的圆圈表示没有经过限制的<strong>损失函数在寻找最小值过程</strong>中，$\mathbf w$的不断迭代（随最小二乘法，最终目的还是使损失函数最小）变化情况，蓝色的圆圈最中心为不加正则项的最优解。<strong>表示的方法是等高线，z轴的值就是</strong> $E(\mathbf w)$<br>$w^*$ 最小值取到的点</p></blockquote><p>或者这个图，更加形象一点</p><p><img src="/MachineLearning/机器学习/正则化与权重衰减/L1l2regularization5.png" alt></p><p>可以直观的理解为（帮助理解正则化），我们的目标函数（误差函数）就是<strong>求蓝圈+红圈的和的最小值</strong>（回想等高线的概念并参照3式），而这个值通在很多情况下是<strong>两个曲面首次相交的地方</strong></p><p>可以看到<strong>二次正则项</strong>的优势，处处可导，方便计算，<strong>限制模型的复杂度，即 $\mathbf w$ 中<code>M</code>的大小，<code>M</code>是模型的阶次</strong>，<code>M</code>越大意味着需要决定的权重越多，所以模型越复杂。在多项式模型多，直观理解是每一个不同幂次的 $x$ 前的系数，0（或很小的值）越多，模型越简单。这就<strong>从数学角度解释了，为什么正则化（规则化）可以限制模型的复杂度，进而避免过拟合</strong></p><p>不知道有没有人发现<strong>一次正则项</strong>的优势，$w^*$ 的位置恰好是 $w_1=0$ 的位置，意味着从另一种角度来说，使用一次正则项可以<strong>降低维度（降低模型复杂度，防止过拟合）二次正则项也做到了这一点，但是一次正则项做的更加彻底</strong>，更稀疏。不幸的是，<strong>一次正则项有拐点</strong>，不是处处可微，给计算带来了难度，很多厉害的论文都是巧妙的使用了一次正则项写出来的，效果十分强大。很多人也用 l1 正则化来挑选对结果贡献最大的重要特征. 但是 l1 的结并不是稳定的. 比如用批数据训练, 每次批数据都会有稍稍不同的误差曲线：</p><p><img src="/MachineLearning/机器学习/正则化与权重衰减/L1l2regularization6.png" alt></p><h2 id="How-神经网络模型角度"><a href="#How-神经网络模型角度" class="headerlink" title="How 神经网络模型角度"></a>How 神经网络模型角度</h2><p>我们已经知道，最简单的单层神经网，可以实现简单的线性模型。而多隐含层的神经网络模型如何来<strong>实现正则化</strong>？（毕竟神经网络模型没有目标函数）</p><p><img src="/MachineLearning/机器学习/正则化与权重衰减/15e0011f-fb50-43c4-b245-1598bbb520c7.jpg" alt></p><blockquote><p><code>M</code>表示单层神经网中隐含层中的神经元的数量</p></blockquote><p>上图展示了神经网络模型过拟合的直观表示</p><p>我们可以通过一系列的推导得知，未来保持神经网络的一致性（即输出的值不能被尺缩变换，或平移变换），在线性模型中的<strong>加入正则项</strong>无法奏效</p><p><strong>所以我们只能通过建立验证集（Validation Set），拉网搜索来确定<code>M</code>的取值（迭代停止的时间），又称为【提前停止】</strong></p><p>这里有一个尾巴，即<strong>神经网络的不变量（invariance）</strong>，我们并不希望加入正则项后出现不在掌控范围内的变化（即所谓图像还是那个图像，不能乱变）。而<strong>机器学习的其中一个核心目的也是去寻找不同事物（对象）的中包含信息的这个不变量（特征）</strong>。卷积神经网络从结构上恰恰实现了这种<strong>不变性</strong>，这也是它强大的一个原因</p><h2 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h2><p>我并不是数学专业的学生，但是我发现在讲完线性模型角度后，有几个概念可以很轻松的解答，就在这里献丑把它们串联起来，并做一些总结以供查阅和对照。</p><p>我们知道，<strong>范数（norm）</strong>的概念来源于<strong>泛函分析与测度理论</strong>，wiki中的定义相当简单明了：<strong>范数是具有“长度”概念的函数</strong>，用于衡量一个<strong>矢量的大小</strong>（测量矢量的测度）</p><p>我们常说测度测度，测量长度，也就是为了表征这个长度。而如何表达“长度”这个概念也是不同的，也就对应了不同的<strong>范数</strong>，本质上说，还是<strong>观察问题的方式和角度不同</strong>，比如那个经典问题，<strong>为什么矩形的面积是长乘以宽？</strong>这背后的关键是欧式空间的<strong>平移不变性</strong>，换句话说，就是面积和长成正比，所以才有这个</p><p>没有<strong>测度论就没有（现代）概率论</strong>。而概率论也是整个机器学习学科的基石之一。测度<strong>就像尺子</strong>，由于测量对象不同，我们需要直尺量布匹、皮尺量身披、卷尺量房间、游标卡尺量工件等等。<strong>注意，“尺子”与刻度（寸、米等）是两回事，不能混淆。</strong></p><p>范数分为<strong>向量范数</strong>（二维坐标系）和<strong>矩阵范数</strong>（多维空间，一般化表达），如果不希望太数学化的解释，那么可以直观的理解为：<strong>0-范数：向量中非零元素的数量；1-范数：向量的元素的绝对值；2-范数：是通常意义上的模（距离）</strong></p><h3 id="向量范数"><a href="#向量范数" class="headerlink" title="向量范数"></a>向量范数</h3><p>关于向量范数，先再把这个图放着，让大家体会到构建知识图谱并串联知识间的本质（根）联系的好处</p><p><img src="/MachineLearning/机器学习/正则化与权重衰减/3b25eae6-8486-4a2f-bbeb-14d3f940d8bd.jpg" alt></p><h4 id="p-范数"><a href="#p-范数" class="headerlink" title="p-范数"></a>p-范数</h4><script type="math/tex;mode=display">
\Vert\mathbf x \Vert_p =(\sum\limits_{i=1}^{N}\vert x_i \vert^p)^{\frac{1}{p}}</script><p>向量元素绝对值的p次方和的 $\frac{1}{p}$ 次幂。可以敏捷的发现，这个<code>p</code>和之前的<code>q</code>从是一个东西，<strong>随着<code>p</code>越大，等高线图越接近正方形（正无穷范数）；越小，曲线弯曲越接近原点（负无穷范数）</strong></p><p>而之前已经说明，<code>q</code>的含义是<strong>一般化正则项的幂指数</strong>，也就是我们常说的2范数，两者在形式上是完全等同的。结合范数的定义，我们可以解释<strong>一般化正则项为一种对待求参数 $\mathbf w$ 的测度</strong>，可以用来限制模型不至于过于复杂</p><h4 id="infty-范数"><a href="#infty-范数" class="headerlink" title="$-\infty$-范数"></a>$-\infty$-范数</h4><script type="math/tex;mode=display">
\Vert \mathbf x \Vert_{-\infty} = arg \operatorname*{min}_{i}{\vert x_i \vert}</script><p>所有<strong>向量元素中绝对值的最小值</strong></p><h4 id="1-范数"><a href="#1-范数" class="headerlink" title="1-范数"></a>1-范数</h4><script type="math/tex;mode=display">
\Vert \mathbf x \Vert_1 = \sum\limits_{i=1}^{N}\vert x_i \vert</script><p>向量元素<strong>绝对值之和</strong>，也称街区距离（city-block）</p><script type="math/tex;mode=display">
\begin{matrix}
4 & 3 & 2 & 3 & 4 \\
3 & 2 & 1 & 2 &  3\\
2 & 1 & 0 & 1 & 2 \\
3 & 2 & 1 & 2 &3  \\
4&3 & 2 &3 &4  \\
\end{matrix}</script><h4 id="2-范数"><a href="#2-范数" class="headerlink" title="2-范数"></a>2-范数</h4><p>$\Vert\mathbf x \Vert_2 = \sqrt{\sum\limits_{i=1}^{N} x_i^2}$ ：向量元素的<strong>平方和再开方</strong>。<strong>Euclid范数</strong>，也称<strong>欧几里得范数，欧氏距离</strong></p><script type="math/tex;mode=display">
\begin{matrix}
2.8&2.2&2&2.2&2.8 \\
2.2&1.4&1&1.4&2.2 \\
2&1&0&1&2 \\
2.2&1.4&1&1.4&2.2 \\
2.8&2.2&2&2.2&2.8 \\
\end{matrix}</script><h4 id="infty-范数-1"><a href="#infty-范数-1" class="headerlink" title="$\infty$-范数"></a>$\infty$-范数</h4><p>$\Vert \mathbf x \Vert_{\infty} = arg \operatorname<em>{max}_{i}{\vert x_i \vert}$ ：所有<strong>向量元素中绝对值的最大值</strong>，也称<em>*棋盘距离（chessboard），切比雪夫距离</em></em></p><script type="math/tex;mode=display">
\begin{matrix}
2 & 3 & 2 & 2 & 2 \\
2 & 1 & 1 & 1 &  2\\
2 & 1 & 0 & 1 & 2 \\
2 & 1 & 1 & 1 &2  \\
2&2 & 2 &2 &2 \\
\end{matrix}</script><h3 id="矩阵范数"><a href="#矩阵范数" class="headerlink" title="矩阵范数"></a>矩阵范数</h3><h4 id="1-范数-1"><a href="#1-范数-1" class="headerlink" title="1-范数"></a>1-范数</h4><script type="math/tex;mode=display">
\Vert \mathbf A \Vert_{1} = arg \operatorname*{max}_{1 \leqslant j \leqslant n}\sum\limits_{i=1}^m{\vert a_{i,j} \vert}</script><p><strong>列和范数</strong>，即所有<strong>矩阵列向量</strong>绝对值之和的最大值</p><h4 id="infty-范数-2"><a href="#infty-范数-2" class="headerlink" title="$\infty$-范数"></a>$\infty$-范数</h4><script type="math/tex;mode=display">
\Vert \mathbf A \Vert_{\infty} = arg \operatorname*{max}_{1 \leqslant i \leqslant n}\sum\limits_{j=1}^m{\vert a_{i,j} \vert}</script><p><strong>行和范数</strong>，即所有<strong>矩阵行向量</strong>绝对值之和的最大值</p><h4 id="2-范数-1"><a href="#2-范数-1" class="headerlink" title="2-范数"></a>2-范数</h4><p>$\Vert \mathbf A \Vert_{2} = \sqrt{\lambda_{max}(\mathbf A^* \mathbf A) }$</p><p><code>p=2</code><strong>且<code>m=n</code>方阵</strong>时，称为谱范数。矩阵 $\mathbf A$ 的<strong>谱范数</strong>是 $\mathbf A$ 最大的<strong>奇异值</strong>或半正定矩阵 $\mathbf A^T \mathbf A$ 的<strong>最大特征值的平方根</strong></p><blockquote><p>$\mathbf A^*$ 为 $\mathbf A$ 的共轭转置，实数域等同于 $\mathbf A^T$</p></blockquote><h4 id="F-范数"><a href="#F-范数" class="headerlink" title="F-范数"></a>F-范数</h4><p>$\Vert \mathbf A \Vert_{F} = \sqrt{ \sum\limits_{i=1}^m \sum\limits_{j=1}^n \vert a_{i,j}\vert^2 }$</p><p>Frobenius范数（希尔伯特-施密特范数，这个称呼只在希尔伯特空间），即<strong>矩阵元素绝对值的平方和再开平方</strong></p><h4 id="核范数"><a href="#核范数" class="headerlink" title="核范数"></a>核范数</h4><p>$\Vert \mathbf A \Vert_{<em>} = \sum\limits_{i=1}^n \lambda_i$ ：$\lambda_i$ 若 $\mathbf A$ <strong>矩阵是方阵，称为本征值</strong>。若<strong>不是方阵，称为奇异值</strong>，即<em>*奇异值/本征值之和</em></em></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>相信每个人在学习过程中都有过看书时，遇到0-范数正则化，或者1-范数正则化，2-范数正则化的表达时很迷惑。写到这里，希望大家能对这些看起来无法理解的晦涩名词有一个融会贯通的理解和感知！</p><p>Learning with intuitive and get Insight</p><p>以上！鞠躬！</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://charlesliuyx.github.io/2017/10/03/%E3%80%90%E7%9B%B4%E8%A7%82%E8%AF%A6%E8%A7%A3%E3%80%91%E4%BB%80%E4%B9%88%E6%98%AF%E6%AD%A3%E5%88%99%E5%8C%96/#How-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E8%A7%92%E5%BA%A6" target="_blank" rel="noopener">【直观详解】什么是正则化</a><br><a href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-09-l1l2regularization/" target="_blank" rel="noopener">L1 / L2 正规化 (Regularization)</a></p></div><div><div style="text-align:center;color:#ccc;font-size:14px">------ 本文结束------</div></div><div class="reward-container"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/uploads/wechat.png" alt="zdaiot 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/uploads/aipay.jpg" alt="zdaiot 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> zdaiot</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.zdaiot.com/MachineLearning/机器学习/正则化与权重衰减/" title="正则化与权重衰减">https://www.zdaiot.com/MachineLearning/机器学习/正则化与权重衰减/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><p>欢迎关注我的其它发布渠道</p><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="/uploads/wechat-qcode.jpg"><span class="icon"><i class="fab fa-weixin"></i></span> <span class="label">WeChat</span></a></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/正则化/" rel="tag"><i class="fa fa-tag"></i> 正则化</a><a href="/tags/范数/" rel="tag"><i class="fa fa-tag"></i> 范数</a><a href="/tags/权重衰减/" rel="tag"><i class="fa fa-tag"></i> 权重衰减</a></div><div class="post-nav"><div class="post-nav-item"><a href="/Python/实战/Numpy矩阵操作总结/" rel="prev" title="Numpy矩阵操作总结"><i class="fa fa-chevron-left"></i> Numpy矩阵操作总结</a></div><div class="post-nav-item"> <a href="/MachineLearning/神经网络/深度学习过拟合问题/" rel="next" title="深度学习过拟合问题">深度学习过拟合问题<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="gitalk-container"></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Why-amp-What-正则化"><span class="nav-number">1.</span> <span class="nav-text">Why &amp; What 正则化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#How-线性模型角度"><span class="nav-number">2.</span> <span class="nav-text">How 线性模型角度</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#二次正则项"><span class="nav-number">2.1.</span> <span class="nav-text">二次正则项</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#一般正则项"><span class="nav-number">2.2.</span> <span class="nav-text">一般正则项</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#How-神经网络模型角度"><span class="nav-number">3.</span> <span class="nav-text">How 神经网络模型角度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#范数"><span class="nav-number">4.</span> <span class="nav-text">范数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#向量范数"><span class="nav-number">4.1.</span> <span class="nav-text">向量范数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#p-范数"><span class="nav-number">4.1.1.</span> <span class="nav-text">p-范数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#infty-范数"><span class="nav-number">4.1.2.</span> <span class="nav-text">$-\infty$-范数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-范数"><span class="nav-number">4.1.3.</span> <span class="nav-text">1-范数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-范数"><span class="nav-number">4.1.4.</span> <span class="nav-text">2-范数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#infty-范数-1"><span class="nav-number">4.1.5.</span> <span class="nav-text">$\infty$-范数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#矩阵范数"><span class="nav-number">4.2.</span> <span class="nav-text">矩阵范数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-范数-1"><span class="nav-number">4.2.1.</span> <span class="nav-text">1-范数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#infty-范数-2"><span class="nav-number">4.2.2.</span> <span class="nav-text">$\infty$-范数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-范数-1"><span class="nav-number">4.2.3.</span> <span class="nav-text">2-范数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#F-范数"><span class="nav-number">4.2.4.</span> <span class="nav-text">F-范数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#核范数"><span class="nav-number">4.2.5.</span> <span class="nav-text">核范数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">5.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考"><span class="nav-number">6.</span> <span class="nav-text">参考</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="zdaiot" src="/uploads/avatar.png"><p class="site-author-name" itemprop="name">zdaiot</p><div class="site-description" itemprop="description">404NotFound</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">308</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">53</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">366</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zdaiot" title="GitHub → https://github.com/zdaiot" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:zdaiot@163.com" title="E-Mail → mailto:zdaiot@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/" title="知乎 → https://www.zhihu.com/people/" rel="noopener" target="_blank"><i class="fa fa-book fa-fw"></i> 知乎</a></span><span class="links-of-author-item"><a href="https://blog.csdn.net/zdaiot" title="CSDN → https://blog.csdn.net/zdaiot" rel="noopener" target="_blank"><i class="fa fa-copyright fa-fw"></i> CSDN</a></span></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="link fa-fw"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://kalacloud.com" title="https://kalacloud.com" rel="noopener" target="_blank">卡拉云低代码工具</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://beian.miit.gov.cn" rel="noopener" target="_blank">京ICP备2021031914号</a></div><div class="copyright"> &copy; <span itemprop="copyrightYear">2022</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">zdaiot</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-chart-area"></i></span> <span title="站点总字数">2m</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span title="站点阅读时长">30:19</span></div><div class="addthis_inline_share_toolbox"><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b5e7e498f94b7ad" async="async"></script></div> <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now=new Date;function createtime(){var n=new Date("08/01/2018 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="Run for "+dnum+" Days ",document.getElementById("times").innerHTML=hnum+" Hours "+mnum+" m "+snum+" s"}setInterval("createtime()",250)</script><div class="busuanzi-count"><script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script><script data-pjax>!function(){var o,n,e=document.getElementsByTagName("link");if(0<e.length)for(i=0;i<e.length;i++)"canonical"==e[i].rel.toLowerCase()&&e[i].href&&(o=e[i].href);n=o?o.split(":")[0]:window.location.protocol.split(":")[0],o||(o=window.location.href),function(){var e=o,i=document.referrer;if(!/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(e)){var t="https"===String(n).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";i?(t+="?r="+encodeURIComponent(document.referrer),e&&(t+="&l="+e)):e&&(t+="?l="+e),(new Image).src=t}}(window)}()</script><script src="/js/local-search.js"></script><div id="pjax"><script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '4800250e682fe873198b',
      clientSecret: '80f7f33f5f8ddfd3944f455cabadda4ff3299147',
      repo        : 'zdaiot.github.io',
      owner       : 'zdaiot',
      admin       : ['zdaiot'],
      id          : '5403f0f9c0c64d1255085b17301ba862',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/wanko.model.json"},display:{position:"left",width:150,height:300},mobile:{show:!0}})</script></body></html>