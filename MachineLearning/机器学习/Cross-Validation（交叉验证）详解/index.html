<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 3.9.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"www.zdaiot.com",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="在机器学习里，通常来说我们不能将全部用于数据训练模型，否则我们将没有数据集对该模型进行验证，从而评估我们的模型的预测效果，也就无法从某些候选模型中选择最适合某个学习问题的模型。以多元回归模型为例：$h_\theta(x)=g(\theta_0+\theta_1x+\theta_2x^2+…++\theta_kx^k)$。应该如何确定k的大小，使得该模型对解决相应的分类问题最为有效？如何在偏倚（bi"><meta name="keywords" content="交叉验证,验证集"><meta property="og:type" content="article"><meta property="og:title" content="Cross-Validation（交叉验证）详解"><meta property="og:url" content="https://www.zdaiot.com/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/index.html"><meta property="og:site_name" content="zdaiot"><meta property="og:description" content="在机器学习里，通常来说我们不能将全部用于数据训练模型，否则我们将没有数据集对该模型进行验证，从而评估我们的模型的预测效果，也就无法从某些候选模型中选择最适合某个学习问题的模型。以多元回归模型为例：$h_\theta(x)=g(\theta_0+\theta_1x+\theta_2x^2+…++\theta_kx^k)$。应该如何确定k的大小，使得该模型对解决相应的分类问题最为有效？如何在偏倚（bi"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-dc2ac40390791ca7f0ccf53cee0d4881_hd.png"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-577bb114a1073273452cc1c73045e274_hd.png"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-27f8c5989dd7790ccf6b626e6854e06c_hd.png"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-c6a79e230f946da8aefd793ed57c0454_hd.png"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-ec72b82d605902ddfa060c2fb5777a05_hd.png"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-fcb843dd06c15a515d03a543864bbb77_hd.png"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-daf077823e7faa57c6f4014389fe12b9_hd.png"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-7302b5c15dcfc6746b51830b65debf62_hd.png"><meta property="og:updated_time" content="2019-09-15T03:20:24.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Cross-Validation（交叉验证）详解"><meta name="twitter:description" content="在机器学习里，通常来说我们不能将全部用于数据训练模型，否则我们将没有数据集对该模型进行验证，从而评估我们的模型的预测效果，也就无法从某些候选模型中选择最适合某个学习问题的模型。以多元回归模型为例：$h_\theta(x)=g(\theta_0+\theta_1x+\theta_2x^2+…++\theta_kx^k)$。应该如何确定k的大小，使得该模型对解决相应的分类问题最为有效？如何在偏倚（bi"><meta name="twitter:image" content="https://www.zdaiot.com/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-dc2ac40390791ca7f0ccf53cee0d4881_hd.png"><link rel="canonical" href="https://www.zdaiot.com/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>Cross-Validation（交叉验证）详解 | zdaiot</title><script data-pjax>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?0b0b58037319da4959d5a3c014160ccd";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">zdaiot</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">404NotFound</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.zdaiot.com/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/uploads/avatar.png"><meta itemprop="name" content="zdaiot"><meta itemprop="description" content="404NotFound"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="zdaiot"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> Cross-Validation（交叉验证）详解<a href="https://github.com/zdaiot/zdaiot.github.io/tree/hexo/source/_posts/MachineLearning/机器学习/Cross-Validation（交叉验证）详解.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pencil-alt"></i></a></h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-04-02 21:50:50" itemprop="dateCreated datePublished" datetime="2019-04-02T21:50:50+08:00">2019-04-02</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2019-09-15 11:20:24" itemprop="dateModified" datetime="2019-09-15T11:20:24+08:00">2019-09-15</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MachineLearning/" itemprop="url" rel="index"><span itemprop="name">MachineLearning</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MachineLearning/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>4.1k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>4 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>在机器学习里，通常来说我们不能将全部用于数据训练模型，否则我们将没有数据集对该模型进行验证，从而评估我们的模型的预测效果，也就无法从某些候选模型中选择最适合某个学习问题的模型。以多元回归模型为例：$h_\theta(x)=g(\theta_0+\theta_1x+\theta_2x^2+…++\theta_kx^k)$。应该如何确定k的大小，使得该模型对解决相应的分类问题最为有效？如何在偏倚（bias）和方差（variance）之间寻求最佳的平衡点？更进一步，我们同样需要知道如何在加权回归模型中选择适当的波长参数$\Gamma$，或者在基于范式$l_1$的SVM模型中选择适当的参数C？</p><p>我们假设模型集合为有限集$\mathcal M=\{M_1,…,M_d\}$我们的目的就是从这d个模型中，选择最有效的模型。</p><p>假设样本集为S，根据经验风险最小化原则（ERM），可能会使用这样的算法：</p><ol><li>在S上训练每个模型$M_i$，得到相应的假设函数$h_i$；</li><li>选择训练误差最小的假设函数，即为我们需要的函数。</li></ol><p>然而，这样的算法实际上并不有效。以多元回归模型为例，指数越高，对样本集S的拟合就越准确，这样虽然保证了较低的训练误差，但是<strong>这种方法会使泛化误差变得很大，</strong>因此，这并不是一个好的方法。</p><p>为了解决这一问题，有如下常用的方法。</p><blockquote><p>下面介绍的各种交叉验证的方法，可用于模型的选择，但也可以针对单个算法和模型进行评价。</p></blockquote><h2 id="简单交叉验证"><a href="#简单交叉验证" class="headerlink" title="简单交叉验证"></a>简单交叉验证</h2><p>第一种是最简单的，也是很容易就想到的。我们可以把整个数据集分成两部分，一部分用于训练$S_{train}$，一部分用于验证$S_{cv}$，这里称作$S_{cv}$简单交叉验证集。这也就是我们经常提到的训练集（training set）和验证集（Validation set）。</p><p><img src="/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-dc2ac40390791ca7f0ccf53cee0d4881_hd.png" alt></p><p>例如，如上图所示，我们可以将蓝色部分的数据作为训练集（包含7、22、13等数据），将右侧的数据作为测试集（包含91等），这样通过在蓝色的训练集上训练模型，在测试集上观察不同模型不同参数对应的MSE的大小，<strong>就可以合适选择模型和参数</strong>了。详细步骤如下：</p><ol><li>在$S_{train}$上训练每个模型$M_i$，得到相应的假设函数$h_i$；</li><li>将每个假设函数$h_i$通过交叉验证集$S_{cv}$进行验证，选择使得训练误差$\hat{\varepsilon}_{S_{cv}}(h_i)$最小的$h_i$；</li><li>通过简单交叉验证，可以得到每个假设函数$h_i$的真实的泛化误差，从而可以选择泛化误差最小的那个假设函数。</li></ol><p>通常，预留1/4-1/3的样本作为交叉验证集，而剩下的作为训练集使用。</p><p>步骤3也可以替换成这样的操作：选择相应的模型$M_i$，使得训练误差$\hat{\varepsilon}_{S_{cv}}(h_i)$最小，<strong>然后在用对整个样本集S进行训练</strong>得到新的$h_i$。使用这样的方法原因是有的学习算法对于初试的条件非常敏感，因此，他也许在上表现良好，但是在整个样本集中却存在很大的误差，因此需要再次带入整个样本集进行验证。</p><p>不过，这个简单的方法存在两个弊端。</p><h3 id="弊端1"><a href="#弊端1" class="headerlink" title="弊端1"></a>弊端1</h3><p>最终模型与参数的选取将极大程度依赖于你对训练集和测试集的划分方法。什么意思呢？我们再看一张图：</p><p><img src="/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-577bb114a1073273452cc1c73045e274_hd.png" alt></p><p>右边是十种不同的训练集和测试集划分方法得到的test MSE，可以看到，在不同的划分方法下，test MSE的变动是很大的，而且对应的最优degree也不一样。所以如果我们的训练集和测试集的划分方法不够好，很有可能无法选择到最好的模型与参数。</p><h3 id="弊端２"><a href="#弊端２" class="headerlink" title="弊端２"></a>弊端２</h3><p>该方法只用了部分数据进行模型的训练</p><p>我们都知道，当用于模型训练的数据量越大时，训练出来的模型通常效果会越好。所以训练集和测试集的划分意味着我们无法充分利用我们手头已有的数据，所以得到的模型效果也会受到一定的影响。</p><p>基于这样的背景，有人就提出了Cross-Validation方法，也就是交叉验证。</p><h2 id="Cross-Validation"><a href="#Cross-Validation" class="headerlink" title="Cross-Validation"></a>Cross-Validation</h2><h3 id="LOOCV（Leave-one-out-cross-validation）"><a href="#LOOCV（Leave-one-out-cross-validation）" class="headerlink" title="LOOCV（Leave-one-out cross-validation）"></a>LOOCV（Leave-one-out cross-validation）</h3><p>首先，我们先介绍LOOCV方法，即（Leave-one-out cross-validation）。像Test set approach一样，LOOCV方法也包含将数据集分为训练集和测试集这一步骤。但是不同的是，我们现在只用一个数据作为测试集，其他的数据都作为训练集，并将<strong>此步骤重复N次</strong>（N为数据集的数据数量）。</p><p><img src="/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-27f8c5989dd7790ccf6b626e6854e06c_hd.png" alt></p><p>如上图所示，假设我们现在有n个数据组成的数据集，那么LOOCV的方法就是每次取出一个数据作为测试集的唯一元素，而其他n-1个数据都作为<strong>训练集用于训练模型和调参</strong>。结果就是我们<strong>最终训练了n个模型，每次都能得到一个MSE。而计算最终test MSE则就是将这n个MSE取平均</strong>。</p><p><img src="/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-c6a79e230f946da8aefd793ed57c0454_hd.png" alt></p><p>$y_i$比起test set approach，LOOCV有很多优点。首先<strong>它不受测试集合训练集划分方法的影响，因为每一个数据都单独的做过测试集</strong>。同时，其<strong>用了n-1个数据训练模型，也几乎用到了所有的数据，保证了模型的bias更小</strong>。不过LOOCV的缺点也很明显，那就是<strong>计算量过于大</strong>，是test set approach耗时的n-1倍。</p><p>为了解决计算成本太大的弊端，又有人提供了下面的式子，使得LOOCV计算成本和只训练一个模型一样快。</p><p><img src="/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-ec72b82d605902ddfa060c2fb5777a05_hd.png" alt></p><p>其中$\hat{y_i}$表示第$i$个拟合值，而$h_i$则表示leverage。关于$h_i$的计算方法详见线性回归的部分（以后会涉及）。</p><h3 id="K-fold-Cross-Validation"><a href="#K-fold-Cross-Validation" class="headerlink" title="K-fold Cross Validation"></a>K-fold Cross Validation</h3><p>另外一种折中的办法叫做K折交叉验证，和LOOCV的不同在于，我们每次的测试集将不再只包含一个数据，而是多个，具体数目将根据K的选取决定。比如，如果<strong>K=5，那么我们就为五折交叉验证</strong>。k-折交叉验证将样本集随机划分为k份，k-1份作为训练集，1份作为验证集，依次轮换训练集和验证集k次，验证误差最小的模型为所求模型。具体方法如下：</p><ol><li>随机将样本集S划分成k个不相交的子集，每个子集中样本数量为m/k个，这些子集分别记作$S_1,…,S_k$；</li><li>对于每个模型$M_i$，进行如下操作：<br>for j=1 to k<br>将$S_1\cup…\cup S_{j-1}\cup S_{j+1}\cup…\cup S_k$作为训练集，训练模型$M_i$，得到相应的假设函数$h_{ij}$。<br>再将$S_j$作为验证集，计算泛化误差$\hat{\varepsilon}_{S_{j}}(h_{ij})$；</li><li>计算<strong>每个模型的平均泛化误差</strong>，选择泛化误差最小的模型$M_i$。</li></ol><p>整体公式可以表示为：</p><p><img src="/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-fcb843dd06c15a515d03a543864bbb77_hd.png" alt></p><p>K-折交叉验证方法，每次留作验证的为总样本量的1/k(通常取k=10)，因此每次用于训练的样本量相应增加了，然而K-折交叉验证对于每个模型都需要运行k次，他的计算成本还是较高的。</p><p>不难理解，其实LOOCV是一种特殊的K-fold Cross Validation（K=N）。再来看一组图：</p><p><img src="/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-daf077823e7faa57c6f4014389fe12b9_hd.png" alt></p><p>每一幅图种蓝色表示的真实的test MSE，而黑色虚线和橙线则分贝表示的是LOOCV方法和10-fold CV方法得到的test MSE。我们可以看到事实上LOOCV和10-fold CV对test MSE的估计是很相似的，但是相比LOOCV，10-fold CV的计算成本却小了很多，耗时更少。</p><h3 id="Bias-Variance-Trade-Off-for-k-Fold-Cross-Validation"><a href="#Bias-Variance-Trade-Off-for-k-Fold-Cross-Validation" class="headerlink" title="Bias-Variance Trade-Off for k-Fold Cross-Validation"></a>Bias-Variance Trade-Off for k-Fold Cross-Validation</h3><p>最后，我们要说说K的选取。事实上，和开头给出的文章里的部分内容一样，K的选取是一个Bias和Variance的trade-off。</p><p><strong>K越大，每次投入的训练集的数据越多，模型的Bias越小</strong>。但是K越大，又意味着每一次选取的训练集之前的相关性越大（考虑最极端的例子，当k=N，也就是在LOOCV里，每次都训练数据几乎是一样的）。而这种<strong>大相关性会导致最终的test error具有更大的Variance</strong>。</p><p>一般来说，根据经验我们一般选择k=5或10。</p><h3 id="Cross-Validation-on-Classification-Problems"><a href="#Cross-Validation-on-Classification-Problems" class="headerlink" title="Cross-Validation on Classification Problems"></a>Cross-Validation on Classification Problems</h3><p>上面我们讲的都是<strong>回归问题</strong>，所以用MSE来衡量test error。如果是<strong>分类问题</strong>，那么我们可以用以下式子来衡量Cross-Validation的test error：</p><p><img src="/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/v2-7302b5c15dcfc6746b51830b65debf62_hd.png" alt></p><p>其中Erri表示的是第i个模型在第i组测试集上的分类错误的个数。</p><p>图片来源：《An Introduction to Statistical Learning with Applications in R》</p><h2 id="深度学习框架中验证集作用"><a href="#深度学习框架中验证集作用" class="headerlink" title="深度学习框架中验证集作用"></a>深度学习框架中验证集作用</h2><p>对于一个模型来说，其参数可以分为普通参数和超参数。在不引入强化学习的前提下，那么普通参数就是可以被梯度下降所更新的，也就是训练集所更新的参数。另外，还有超参数的概念，比如网络层数、网络节点数、迭代次数、学习率等等，这些参数不在梯度下降的更新范围内。尽管现在已经有一些算法可以用来搜索模型的超参数，但多数情况下<strong>我们还是自己人工根据验证集来调</strong>。</p><p>那也就是说，从狭义来讲，验证集没有参与梯度下降的过程，也就是说是没有经过训练的；但从广义上来看，验证集却参与了一个“人工调参”的过程，我们根据验证集的结果调节了迭代数、调节了学习率等等，使得结果在验证集上最优。因此，我们也可以认为，验证集也参与了训练。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>小结：<strong>交叉验证是一种模型选择或者参数选择方法</strong>，其将样本的一部分用于训练，另一部分用于验证。因此不仅考虑了训练误差，同时也考虑了泛化误差。从这里可以看出机器学习、数据挖掘与传统统计学的一个重要差别：传统统计学更注重理论，追求理论的完整性和模型的精确性，在对样本建立某个特定模型后，用理论去对模型进行各种验证；而机器学习/数据挖掘则注重经验，如交叉验证，就是通过不同模型在同一样本上的误差表现好坏，来选择适合这一样本的模型，而不去纠结理论上是否严谨。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/24825503?refer=rdatamining" target="_blank" rel="noopener">【机器学习】Cross-Validation（交叉验证）详解</a><br><a href="https://blog.csdn.net/linkin1005/article/details/42869331" target="_blank" rel="noopener">斯坦福大学机器学习——交叉验证</a><br><a href="https://blog.csdn.net/GoodShot/article/details/80714516" target="_blank" rel="noopener">深度学习-超参数和交叉验证</a><br><a href="https://blog.csdn.net/LUFANGBO/article/details/79308290" target="_blank" rel="noopener">tensorflow：训练集、测试集、验证集</a></p></div><div><div style="text-align:center;color:#ccc;font-size:14px">------ 本文结束------</div></div><div class="reward-container"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/uploads/wechat.png" alt="zdaiot 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/uploads/aipay.jpg" alt="zdaiot 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> zdaiot</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.zdaiot.com/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/" title="Cross-Validation（交叉验证）详解">https://www.zdaiot.com/MachineLearning/机器学习/Cross-Validation（交叉验证）详解/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><p>欢迎关注我的其它发布渠道</p><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="/uploads/wechat-qcode.jpg"><span class="icon"><i class="fab fa-weixin"></i></span> <span class="label">WeChat</span></a></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/交叉验证/" rel="tag"><i class="fa fa-tag"></i> 交叉验证</a><a href="/tags/验证集/" rel="tag"><i class="fa fa-tag"></i> 验证集</a></div><div class="post-nav"><div class="post-nav-item"><a href="/MLFrameworks/TensorFlow/tensorflow学习率、优化函数、正则化总结/" rel="prev" title="tensorflow学习率、优化函数、正则化总结"><i class="fa fa-chevron-left"></i> tensorflow学习率、优化函数、正则化总结</a></div><div class="post-nav-item"> <a href="/MachineLearning/神经网络/26种神经网络激活函数可视化/" rel="next" title="26种神经网络激活函数可视化">26种神经网络激活函数可视化<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="gitalk-container"></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#简单交叉验证"><span class="nav-number">1.</span> <span class="nav-text">简单交叉验证</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#弊端1"><span class="nav-number">1.1.</span> <span class="nav-text">弊端1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#弊端２"><span class="nav-number">1.2.</span> <span class="nav-text">弊端２</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cross-Validation"><span class="nav-number">2.</span> <span class="nav-text">Cross-Validation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#LOOCV（Leave-one-out-cross-validation）"><span class="nav-number">2.1.</span> <span class="nav-text">LOOCV（Leave-one-out cross-validation）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-fold-Cross-Validation"><span class="nav-number">2.2.</span> <span class="nav-text">K-fold Cross Validation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bias-Variance-Trade-Off-for-k-Fold-Cross-Validation"><span class="nav-number">2.3.</span> <span class="nav-text">Bias-Variance Trade-Off for k-Fold Cross-Validation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cross-Validation-on-Classification-Problems"><span class="nav-number">2.4.</span> <span class="nav-text">Cross-Validation on Classification Problems</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#深度学习框架中验证集作用"><span class="nav-number">3.</span> <span class="nav-text">深度学习框架中验证集作用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">4.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考"><span class="nav-number">5.</span> <span class="nav-text">参考</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="zdaiot" src="/uploads/avatar.png"><p class="site-author-name" itemprop="name">zdaiot</p><div class="site-description" itemprop="description">404NotFound</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">308</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">53</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">366</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zdaiot" title="GitHub → https://github.com/zdaiot" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:zdaiot@163.com" title="E-Mail → mailto:zdaiot@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/" title="知乎 → https://www.zhihu.com/people/" rel="noopener" target="_blank"><i class="fa fa-book fa-fw"></i> 知乎</a></span><span class="links-of-author-item"><a href="https://blog.csdn.net/zdaiot" title="CSDN → https://blog.csdn.net/zdaiot" rel="noopener" target="_blank"><i class="fa fa-copyright fa-fw"></i> CSDN</a></span></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="link fa-fw"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://kalacloud.com" title="https://kalacloud.com" rel="noopener" target="_blank">卡拉云低代码工具</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://beian.miit.gov.cn" rel="noopener" target="_blank">京ICP备2021031914号</a></div><div class="copyright"> &copy; <span itemprop="copyrightYear">2022</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">zdaiot</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-chart-area"></i></span> <span title="站点总字数">2m</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span title="站点阅读时长">30:19</span></div><div class="addthis_inline_share_toolbox"><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b5e7e498f94b7ad" async="async"></script></div> <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now=new Date;function createtime(){var n=new Date("08/01/2018 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="Run for "+dnum+" Days ",document.getElementById("times").innerHTML=hnum+" Hours "+mnum+" m "+snum+" s"}setInterval("createtime()",250)</script><div class="busuanzi-count"><script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script><script data-pjax>!function(){var o,n,e=document.getElementsByTagName("link");if(0<e.length)for(i=0;i<e.length;i++)"canonical"==e[i].rel.toLowerCase()&&e[i].href&&(o=e[i].href);n=o?o.split(":")[0]:window.location.protocol.split(":")[0],o||(o=window.location.href),function(){var e=o,i=document.referrer;if(!/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(e)){var t="https"===String(n).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";i?(t+="?r="+encodeURIComponent(document.referrer),e&&(t+="&l="+e)):e&&(t+="?l="+e),(new Image).src=t}}(window)}()</script><script src="/js/local-search.js"></script><div id="pjax"><script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '4800250e682fe873198b',
      clientSecret: '80f7f33f5f8ddfd3944f455cabadda4ff3299147',
      repo        : 'zdaiot.github.io',
      owner       : 'zdaiot',
      admin       : ['zdaiot'],
      id          : '845f3109bea2d70e9fd9fe859aa4f989',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/wanko.model.json"},display:{position:"left",width:150,height:300},mobile:{show:!0}})</script></body></html>