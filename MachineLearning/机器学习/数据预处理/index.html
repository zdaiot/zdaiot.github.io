<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 3.9.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"www.zdaiot.com",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="归一化方式为什么要进行数据归一化在喂给机器学习模型的数据中，对数据要进行归一化的处理。 为什么要进行归一化处理，下面从寻找最优解这个角度给出自己的看法。 假定为预测房价的例子，自变量为面积，房间数两个，因变量为房价。"><meta name="keywords" content="归一化,数据预处理"><meta property="og:type" content="article"><meta property="og:title" content="数据预处理"><meta property="og:url" content="https://www.zdaiot.com/MachineLearning/机器学习/数据预处理/index.html"><meta property="og:site_name" content="zdaiot"><meta property="og:description" content="归一化方式为什么要进行数据归一化在喂给机器学习模型的数据中，对数据要进行归一化的处理。 为什么要进行归一化处理，下面从寻找最优解这个角度给出自己的看法。 假定为预测房价的例子，自变量为面积，房间数两个，因变量为房价。"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/数据预处理/bb136eb7-385b-4558-822a-60f1751973cd.jpg"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/数据预处理/2afc87a4-795e-4822-9160-77d94c4f825c.jpg"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/数据预处理/f6c2b5bc-f3af-4830-8588-748c4d4af926.jpg"><meta property="og:image" content="https://www.zdaiot.com/MachineLearning/机器学习/数据预处理/3b7b6496-5486-4258-8649-4eb3dc634bfa.jpg"><meta property="og:updated_time" content="2019-10-17T03:22:45.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="数据预处理"><meta name="twitter:description" content="归一化方式为什么要进行数据归一化在喂给机器学习模型的数据中，对数据要进行归一化的处理。 为什么要进行归一化处理，下面从寻找最优解这个角度给出自己的看法。 假定为预测房价的例子，自变量为面积，房间数两个，因变量为房价。"><meta name="twitter:image" content="https://www.zdaiot.com/MachineLearning/机器学习/数据预处理/bb136eb7-385b-4558-822a-60f1751973cd.jpg"><link rel="canonical" href="https://www.zdaiot.com/MachineLearning/机器学习/数据预处理/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>数据预处理 | zdaiot</title><script data-pjax>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?0b0b58037319da4959d5a3c014160ccd";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">zdaiot</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">404NotFound</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.zdaiot.com/MachineLearning/机器学习/数据预处理/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/uploads/avatar.png"><meta itemprop="name" content="zdaiot"><meta itemprop="description" content="404NotFound"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="zdaiot"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> 数据预处理<a href="https://github.com/zdaiot/zdaiot.github.io/tree/hexo/source/_posts/MachineLearning/机器学习/数据预处理.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pencil-alt"></i></a></h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-04-24 17:27:56" itemprop="dateCreated datePublished" datetime="2019-04-24T17:27:56+08:00">2019-04-24</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2019-10-17 11:22:45" itemprop="dateModified" datetime="2019-10-17T11:22:45+08:00">2019-10-17</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MachineLearning/" itemprop="url" rel="index"><span itemprop="name">MachineLearning</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MachineLearning/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>6.8k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>6 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="归一化方式"><a href="#归一化方式" class="headerlink" title="归一化方式"></a>归一化方式</h2><h3 id="为什么要进行数据归一化"><a href="#为什么要进行数据归一化" class="headerlink" title="为什么要进行数据归一化"></a>为什么要进行数据归一化</h3><p>在喂给机器学习模型的数据中，对数据要进行<strong>归一化</strong>的处理。</p><p>为什么要进行归一化处理，下面从<strong>寻找最优解</strong>这个角度给出自己的看法。</p><p>假定为预测房价的例子，<strong>自变量为面积，房间数两个，因变量为房价。</strong></p><p>那么可以得到的公式为：</p><script type="math/tex;mode=display">
y=\theta_{1} x_{1}+\theta_{2} x_{2}</script><ul><li>其中$x_1$代表房间数，$\theta_1$代表变量$x_1$前面的系数。</li><li>其中$x_2$代表房间数，$\theta_2$代表变量$x_2$前面的系数。</li></ul><p>首先我们祭出两张图代表数据是否均一化的最优解寻解过程。</p><p><strong>未归一化：</strong></p><p><img src="/MachineLearning/机器学习/数据预处理/bb136eb7-385b-4558-822a-60f1751973cd.jpg" alt></p><p><strong>归一化之后</strong></p><p><img src="/MachineLearning/机器学习/数据预处理/2afc87a4-795e-4822-9160-77d94c4f825c.jpg" alt></p><p>为什么会出现上述两个图，并且它们分别代表什么意思。</p><p>我们在寻找最优解的过程也就是在使得损失函数值最小的$\theta_1,\theta_2$。</p><p><strong>上述两幅图代码的是损失函数的等高线。</strong></p><p>我们很容易看出，当数据没有归一化的时候，面积数的范围可以从0~1000，房间数的范围一般为0~10，可以看出面积数的取值范围远大于房间数。</p><p><strong>这样造成的影响就是在画损失函数的时候，</strong></p><p>数据没有归一化的表达式，可以为：</p><script type="math/tex;mode=display">
J=\left(3 \theta_{1}+600 \theta_{2}-y_{\text {correct}}\right)^{2}</script><p><strong>造成图像的等高线为类似椭圆形状，最优解的寻优过程就是像下图所示：</strong></p><p><img src="/MachineLearning/机器学习/数据预处理/f6c2b5bc-f3af-4830-8588-748c4d4af926.jpg" alt></p><p>而数据归一化之后，损失函数的表达式可以表示为：</p><script type="math/tex;mode=display">
J=\left(0.5 \theta_{1}+0.55 \theta_{2}-y_{\text { correct }}\right)^{2}</script><p>其中变量的前面系数几乎一样，则图像的等高线为类似圆形形状，最优解的寻优过程像下图所示：</p><p><img src="/MachineLearning/机器学习/数据预处理/3b7b6496-5486-4258-8649-4eb3dc634bfa.jpg" alt></p><p>从上可以看出，数据归一化后<strong>，最优解的寻优过程明显会变得平缓，更容易正确的收敛到最优解。</strong></p><p><strong>这是数据为什么要归一化的一个原因。</strong></p><p>另外一方面，在大型项目的数据分析中，由于数据来源的不同通常会导致数据的量纲、数据的量级产生差异，为了让这些数据具备可比性，需要采用标准化方法来消除这些差异。数据的标准化(normalization)就是指将原始各指标数据按比例缩放，去<strong>除数据的单位限制，将其转化为无量纲的纯数值，便于不同单位或量级的指标能够进行比较和加权</strong>。数据标准化最典型的就是数据的归一化处理，即将数据统一映射到[0,1]区间上。</p><p>目前数据标准化方法有多种，归结起来可以分为直线型方法(如极值法、标准差法)、折线型方法(如三折线法)、曲线型方法(如半正态性分布)。不同的标准化方法，对系统的评价结果会产生不同的影响，然而不幸的是，在数据标准化方法的选择上，还没有通用的法则可以遵循。常见的方法有：min-max标准化（min-max normalization）、log函数转换、atan函数转换、z-score标准化（zero-mena normalization，此方法比较常用）、模糊量化法。</p><p>min-max标准化(min-max normalization)也叫离差标准化，是对原始数据的线性变换，使结果落到[0,1]区间，转换函数如下:其中max为样本数据的最大值，min为样本数据的最小值。这种方法有一个缺陷就是当有新数据加入时，可能导致max和min的变化，需要重新定义。log函数转换是通过以10为底的log函数转换以实现归一下，具体方法如下:$y=log_{10}(x)/log_{10}(max)$，max为样本数据最大值，并且所有的数据都要大于等于1。atan函数转换用反正切函数实现数据的归一化:需要注意的是如果想使用这个方法映射到[0,1]的区间，则数据都应该大于等于0，小于0的数据将被映射到[-1,0]区间上。当然并非所有数据标准化的结果都需要映射到[0,1]区间上，这时就可以使用z-score标准化方法，该方法是SPSS中最为常用的标准化方法:z-score 标准化(zero-mean normalization)也叫标准差标准化，该方法使得经过处理的数据符合标准正态分布，即均值为0，标准差为1，其转化函数为:$y=(x−μ)/σ$，其中$μ$为所有样本数据的均值，$σ$为所有样本数据的标准差。</p><p>下面对三种常见的标准化方式进行介绍。</p><h3 id="线性比例变换法"><a href="#线性比例变换法" class="headerlink" title="线性比例变换法"></a>线性比例变换法</h3><script type="math/tex;mode=display">
y_{i}=\frac{x_{i}}{\max (x)}</script><p>Python代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">arr = np.asarray([<span class="number">-10</span>, <span class="number">0</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">80</span>, <span class="number">100</span>])</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> arr:</span><br><span class="line">    x = float(x)/(np.max(arr))</span><br><span class="line">    print(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="number">-0.1</span></span><br><span class="line"><span class="number">0.0</span></span><br><span class="line"><span class="number">0.1</span></span><br><span class="line"><span class="number">0.5</span></span><br><span class="line"><span class="number">0.8</span></span><br><span class="line"><span class="number">1.0</span></span><br></pre></td></tr></table></figure><p></p><h3 id="极差变换法"><a href="#极差变换法" class="headerlink" title="极差变换法"></a>极差变换法</h3><script type="math/tex;mode=display">
y_{i}=\frac{x_{i}-\min (x)}{\max (x)-\min (x)}</script><ul><li>这种方法有个缺陷就是当有新数据加入时，可能导致max和min的变化，需要重新定义。</li><li>除此之外，通过利用变量取值的最大值和最小值（或者最大值）将原始数据转换为界于某一特定范围的数据，从而消除量纲和数量级影响，改变变量在分析中的权重来解决不同度量的问题。该方法在对变量无量纲化过程中仅仅与该变量的最大值和最小值这两个极端值有关，而与其他取值无关，这使得该方法在改变各变量权重时过分依赖两个极端取值。</li></ul><p>自定义Python代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">arr = np.asarray([<span class="number">-10</span>, <span class="number">0</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">80</span>, <span class="number">100</span>])</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> arr:</span><br><span class="line">    x = float(x - np.min(arr))/(np.max(arr)- np.min(arr))</span><br><span class="line">    print(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="number">0.0</span></span><br><span class="line"><span class="number">0.09090909090909091</span></span><br><span class="line"><span class="number">0.18181818181818182</span></span><br><span class="line"><span class="number">0.5454545454545454</span></span><br><span class="line"><span class="number">0.8181818181818182</span></span><br><span class="line"><span class="number">1.0</span></span><br></pre></td></tr></table></figure><p></p><p>使用<code>sklearn.preprocessing.MinMaxScaler</code>类实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line">X_train = np.array([[ <span class="number">1.</span>, <span class="number">-1.</span>,  <span class="number">2.</span>], </span><br><span class="line">                    [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">                    [ <span class="number">0.</span>,  <span class="number">1.</span>, <span class="number">-1.</span>]])</span><br><span class="line">min_max_scaler = MinMaxScaler()</span><br><span class="line"><span class="keyword">print</span> min_max_scaler</span><br><span class="line"><span class="comment">#MinMaxScaler(copy=True, feature_range=(0, 1))</span></span><br><span class="line">X_train_minmax = min_max_scaler.fit_transform(X_train)</span><br><span class="line"><span class="keyword">print</span> X_train_minmax</span><br><span class="line"><span class="comment">#[[ 0.5         0.          1.        ]</span></span><br><span class="line"><span class="comment"># [ 1.          0.5         0.33333333]</span></span><br><span class="line"><span class="comment"># [ 0.          1.          0.        ]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将相同的缩放应用到测试集数据中</span></span><br><span class="line">X_test = np.array([<span class="number">-3.</span>, <span class="number">-1.</span>, <span class="number">4.</span>])</span><br><span class="line">X_test_minmax = min_max_scaler.transform(X_test)</span><br><span class="line"><span class="keyword">print</span> X_test_minmax</span><br><span class="line"><span class="comment">#[-1.5         0.          1.66666667]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#缩放因子等属性</span></span><br><span class="line"><span class="keyword">print</span> min_max_scaler.scale_</span><br><span class="line"><span class="comment">#[ 0.5         0.5         0.33333333]</span></span><br><span class="line"><span class="keyword">print</span> min_max_scaler.min_</span><br><span class="line"><span class="comment">#[ 0.          0.5         0.33333333]</span></span><br></pre></td></tr></table></figure><h3 id="0均值方法-Z-score方法"><a href="#0均值方法-Z-score方法" class="headerlink" title="0均值方法(Z-score方法)"></a>0均值方法(Z-score方法)</h3><script type="math/tex;mode=display">
y_{i}=\frac{x_{i}-\operatorname{mean}(x)}{var(x)}</script><ul><li>即每一变量值与其平均值之差除以该变量的标准差。虽然该方法在无量纲化过程中利用了所有的数据信息，但是该方法在无量纲化后不仅使得转换后的各变量均值相同，且标准差也相同，即无量纲化的同时还消除了各变量在变异程度上的差异，从而转换后的各变量在聚类分析中的重要性程度是同等看待的。而实际分析中，经常根据各变量在不同单位间取值的差异程度大小来决定其在分析中的重要性程度，差异程度大的其分析权重也相对较大。</li><li>z-score标准化方法适用于最大值和最小值未知的情况，或有超出取值范围的离群数据的情况。</li><li>若假设数据集是正态分布的，那么该方法归一化后会生成标准正太分布的数据集。</li><li>若更改了数据集，通常要重新计算方差和均值。</li><li>需要注意的是，我们只能在训练数据集上计算均值和方差，测试数据集和验证数据集都需要采用这个均值和方差，因为测试数据集对于你来说是一个黑盒子，你不能使用里面的任何先验信息。</li></ul><p>自定义Python代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">arr = np.asarray([<span class="number">-10</span>, <span class="number">0</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">80</span>, <span class="number">100</span>])</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> arr:</span><br><span class="line">    x = float(x - arr.mean())/arr.std()</span><br><span class="line">    print(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="number">-1.1674960392312883</span></span><br><span class="line"><span class="number">-0.9259451345627459</span></span><br><span class="line"><span class="number">-0.6843942298942035</span></span><br><span class="line"><span class="number">0.2818093887799661</span></span><br><span class="line"><span class="number">1.0064621027855933</span></span><br><span class="line"><span class="number">1.489563912122678</span></span><br></pre></td></tr></table></figure><p></p><p>使用<code>sklearn.preprocessing.scale()</code>函数，可以直接将给定数据进行标准化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> scale</span><br><span class="line">X = np.array([[ <span class="number">1.</span>, <span class="number">-1.</span>,  <span class="number">2.</span>], </span><br><span class="line">              [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">              [ <span class="number">0.</span>,  <span class="number">1.</span>, <span class="number">-1.</span>]])</span><br><span class="line">X_scaled = scale(X)</span><br><span class="line"><span class="keyword">print</span> X_scaled</span><br><span class="line"><span class="comment">#[[ 0.         -1.22474487  1.33630621]</span></span><br><span class="line"><span class="comment"># [ 1.22474487  0.         -0.26726124]</span></span><br><span class="line"><span class="comment"># [-1.22474487  1.22474487 -1.06904497]]</span></span><br><span class="line"><span class="keyword">print</span> X_scaled.mean(axis = <span class="number">0</span>)</span><br><span class="line"><span class="comment">#[ 0.  0.  0.]</span></span><br><span class="line"><span class="keyword">print</span> X_scaled.std(axis = <span class="number">0</span>)</span><br><span class="line"><span class="comment">#[ 1.  1.  1.]</span></span><br></pre></td></tr></table></figure><p>使用<code>sklearn.preprocessing.StandardScaler</code>类，使用该类的好处在于可以保存训练集中的参数（均值、方差）直接使用其对象转换测试集数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">X = np.array([[ <span class="number">1.</span>, <span class="number">-1.</span>,  <span class="number">2.</span>], </span><br><span class="line">              [ <span class="number">2.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">              [ <span class="number">0.</span>,  <span class="number">1.</span>, <span class="number">-1.</span>]])</span><br><span class="line">scaler = StandardScaler().fit(X)</span><br><span class="line"><span class="keyword">print</span> scaler</span><br><span class="line"><span class="comment">#StandardScaler(copy=True, with_mean=True, with_std=True)</span></span><br><span class="line"><span class="keyword">print</span> scaler.mean_</span><br><span class="line"><span class="comment">#[ 1.          0.          0.33333333]</span></span><br><span class="line"><span class="keyword">print</span> scaler.std_</span><br><span class="line"><span class="comment">#[ 0.81649658  0.81649658  1.24721913]</span></span><br><span class="line"><span class="keyword">print</span> scaler.transform(X)</span><br><span class="line"><span class="comment">#[[ 0.         -1.22474487  1.33630621]</span></span><br><span class="line"><span class="comment"># [ 1.22474487  0.         -0.26726124]</span></span><br><span class="line"><span class="comment"># [-1.22474487  1.22474487 -1.06904497]]</span></span><br></pre></td></tr></table></figure><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>线性比例变换法和0均值方法(Z-score方法)得到的数据不一定分布在[0, 1]之间，并且分布区间通常不确定，而极差变换法得到的数据一定在[0，1]之间。</p><p>每个维度都是去量纲化的，避免了不同量纲的选取对距离计算产生的巨大影响。在分类、聚类算法中，需要使用距离来度量相似性的时候、或者使用PCA技术进行降维的时候，第三种方法(Z-score standardization)表现更好。在不涉及距离度量、协方差计算、数据不符合正太分布的时候，可以使用第一种方法或其他归一化方法。比如图像处理中，将RGB图像转换为灰度图像后将其值限定在[0 255]的范围。</p><p>那么在机器学习中哪些算法可以不做归一化呢？概率模型不需要归一化，因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率。像svm、线性回归之类的最优化问题就需要归一化。决策树属于前者。归一化也是提升算法应用能力的必备能力之一。</p><h2 id="常用图像预处理方式"><a href="#常用图像预处理方式" class="headerlink" title="常用图像预处理方式"></a>常用图像预处理方式</h2><h3 id="预处理方式一"><a href="#预处理方式一" class="headerlink" title="预处理方式一"></a>预处理方式一</h3><p>输入图片 height, width</p><p>RESIZE_SIDE_MIN = 256</p><p>RESIZE_SIDE_MAX = 512</p><p>R_MEAN = 123.68G_MEAN = 116.78B_MEAN = 103.94</p><h4 id="训练预处理"><a href="#训练预处理" class="headerlink" title="训练预处理"></a>训练预处理</h4><ol><li>scale = width &lt; height ? small_size / width : small_size / height 其中 small_size 为 RESIZE_SIDE_MIN 到 RESIZE_SIDE_MAX 的随机数</li><li>new_width = width <em>scale new_height = height</em> scale</li><li>用二分插值法将 (height, width) 转为 (new_height, new_width)</li><li>将 new_height, new_width 的图片 crop 为 crop_height(224), crop_width(224) 其中必须满足 new_height &gt;= crop_height, new_width &gt;= crop_width</li><li>将图片左右翻转（50% 的概率会翻转）</li><li>RGB 分别减去其平均值，其中依次为 R_MEAN, G_MEAN B_MEAN</li></ol><h4 id="测试预处理"><a href="#测试预处理" class="headerlink" title="测试预处理"></a>测试预处理</h4><ol><li>用二分插值法将 (height, width) 转为 (new_height, new_width) 其中 new_height = new_width = 256</li><li>从 crop 中心的 crop_height, crop_width</li><li>RGB 分别减去其平均值，其中依次为 R_MEAN, G_MEAN B_MEAN</li></ol><p>采用上述预处理方法的模型</p><ul><li>resnet_v1_50</li><li>resnet_v1_101</li><li>resnet_v1_152</li><li>resnet_v1_200</li><li>resnet_v2_50</li><li>resnet_v2_101</li><li>resnet_v2_152</li><li>resnet_v2_200</li><li>vgg</li><li>vgg_a</li><li>vgg_16</li><li>vgg_19</li></ul><h3 id="预处理方式二"><a href="#预处理方式二" class="headerlink" title="预处理方式二"></a>预处理方式二</h3><h4 id="训练预处理-1"><a href="#训练预处理-1" class="headerlink" title="训练预处理"></a>训练预处理</h4><ol><li>对图片进行随机 crop, 使其与 bbox 的重叠部分大于 0.1，长宽比在 (0.75, 1.33) 之间，croped 之后的图片大小为原图的(0.05, 1.0)。</li><li>将 crop 之后的图片大小 resize 为 crop_height(224), crop_width(224)</li><li>将 crop 图片左右翻转（50% 的概率会翻转）</li><li>调整 crop 图片的亮度(32. / 255.)和饱和度(0.5, 1.5)</li><li>每个元素减去 0.5，再乘以 2.0</li></ol><h4 id="测试预处理-1"><a href="#测试预处理-1" class="headerlink" title="测试预处理"></a>测试预处理</h4><ol><li>central crop</li><li>二分法插值，将图片变为 height, width</li><li>每个元素减去 0.5，再乘以 2.0</li></ol><p>采用上述预处理方法的模型</p><ul><li>inception</li><li>inception_v1</li><li>inception_v2</li><li>inception_v3</li><li>inception_v4</li><li>inception_resnet_v2</li><li>mobilenet_v1</li><li>nasnet_mobile</li><li>nasnet_large</li><li>pnasnet_large</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/weixin_36612847/article/details/80900181" target="_blank" rel="noopener">深度学习两种图像数据预处理具体方法</a><br><a href="https://blog.csdn.net/UESTC_C2_403/article/details/75804617" target="_blank" rel="noopener">机器学习中常见的几种归一化方法以及原因</a><br><a href="https://blog.csdn.net/hyman_yx/article/details/51820770" target="_blank" rel="noopener">数据归一化及两种常用归一化方法</a><br><a href="https://blog.csdn.net/jisuanjiguoba/article/details/86439375" target="_blank" rel="noopener">数据标准化的三种最常用方式总结（归一化）</a><br><a href="http://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&amp;mid=2247487786&amp;idx=1&amp;sn=eb1b6939936459399a05fae2f4bf645a&amp;chksm=ebb429fedcc3a0e8e9655f814b2d4c6cdb650d1d3bddcc1805a952ea8f8aae10f56a9f95be48&amp;mpshare=1&amp;scene=1&amp;srcid=0603tBqmMewSTLxGX7HvZ71h#rd" target="_blank" rel="noopener">数据进行归一化为什么这么重要！</a></p></div><div><div style="text-align:center;color:#ccc;font-size:14px">------ 本文结束------</div></div><div class="reward-container"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/uploads/wechat.png" alt="zdaiot 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/uploads/aipay.jpg" alt="zdaiot 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> zdaiot</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.zdaiot.com/MachineLearning/机器学习/数据预处理/" title="数据预处理">https://www.zdaiot.com/MachineLearning/机器学习/数据预处理/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><p>欢迎关注我的其它发布渠道</p><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="/uploads/wechat-qcode.jpg"><span class="icon"><i class="fab fa-weixin"></i></span> <span class="label">WeChat</span></a></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/归一化/" rel="tag"><i class="fa fa-tag"></i> 归一化</a><a href="/tags/数据预处理/" rel="tag"><i class="fa fa-tag"></i> 数据预处理</a></div><div class="post-nav"><div class="post-nav-item"><a href="/MachineLearning/神经网络/深度学习过拟合问题/" rel="prev" title="深度学习过拟合问题"><i class="fa fa-chevron-left"></i> 深度学习过拟合问题</a></div><div class="post-nav-item"> <a href="/MachineLearning/神经网络/图像识别、检测、跟踪、分割区别/" rel="next" title="图像识别、检测、跟踪、分割区别">图像识别、检测、跟踪、分割区别<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="gitalk-container"></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#归一化方式"><span class="nav-number">1.</span> <span class="nav-text">归一化方式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么要进行数据归一化"><span class="nav-number">1.1.</span> <span class="nav-text">为什么要进行数据归一化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线性比例变换法"><span class="nav-number">1.2.</span> <span class="nav-text">线性比例变换法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#极差变换法"><span class="nav-number">1.3.</span> <span class="nav-text">极差变换法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#0均值方法-Z-score方法"><span class="nav-number">1.4.</span> <span class="nav-text">0均值方法(Z-score方法)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分析"><span class="nav-number">1.5.</span> <span class="nav-text">分析</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#常用图像预处理方式"><span class="nav-number">2.</span> <span class="nav-text">常用图像预处理方式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#预处理方式一"><span class="nav-number">2.1.</span> <span class="nav-text">预处理方式一</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#训练预处理"><span class="nav-number">2.1.1.</span> <span class="nav-text">训练预处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#测试预处理"><span class="nav-number">2.1.2.</span> <span class="nav-text">测试预处理</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#预处理方式二"><span class="nav-number">2.2.</span> <span class="nav-text">预处理方式二</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#训练预处理-1"><span class="nav-number">2.2.1.</span> <span class="nav-text">训练预处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#测试预处理-1"><span class="nav-number">2.2.2.</span> <span class="nav-text">测试预处理</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考"><span class="nav-number">3.</span> <span class="nav-text">参考</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="zdaiot" src="/uploads/avatar.png"><p class="site-author-name" itemprop="name">zdaiot</p><div class="site-description" itemprop="description">404NotFound</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">308</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">53</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">366</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zdaiot" title="GitHub → https://github.com/zdaiot" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:zdaiot@163.com" title="E-Mail → mailto:zdaiot@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/" title="知乎 → https://www.zhihu.com/people/" rel="noopener" target="_blank"><i class="fa fa-book fa-fw"></i> 知乎</a></span><span class="links-of-author-item"><a href="https://blog.csdn.net/zdaiot" title="CSDN → https://blog.csdn.net/zdaiot" rel="noopener" target="_blank"><i class="fa fa-copyright fa-fw"></i> CSDN</a></span></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="link fa-fw"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://kalacloud.com" title="https://kalacloud.com" rel="noopener" target="_blank">卡拉云低代码工具</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://beian.miit.gov.cn" rel="noopener" target="_blank">京ICP备2021031914号</a></div><div class="copyright"> &copy; <span itemprop="copyrightYear">2022</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">zdaiot</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-chart-area"></i></span> <span title="站点总字数">2m</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span title="站点阅读时长">30:19</span></div><div class="addthis_inline_share_toolbox"><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b5e7e498f94b7ad" async="async"></script></div> <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now=new Date;function createtime(){var n=new Date("08/01/2018 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="Run for "+dnum+" Days ",document.getElementById("times").innerHTML=hnum+" Hours "+mnum+" m "+snum+" s"}setInterval("createtime()",250)</script><div class="busuanzi-count"><script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script><script data-pjax>!function(){var o,n,e=document.getElementsByTagName("link");if(0<e.length)for(i=0;i<e.length;i++)"canonical"==e[i].rel.toLowerCase()&&e[i].href&&(o=e[i].href);n=o?o.split(":")[0]:window.location.protocol.split(":")[0],o||(o=window.location.href),function(){var e=o,i=document.referrer;if(!/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(e)){var t="https"===String(n).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";i?(t+="?r="+encodeURIComponent(document.referrer),e&&(t+="&l="+e)):e&&(t+="?l="+e),(new Image).src=t}}(window)}()</script><script src="/js/local-search.js"></script><div id="pjax"><script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '4800250e682fe873198b',
      clientSecret: '80f7f33f5f8ddfd3944f455cabadda4ff3299147',
      repo        : 'zdaiot.github.io',
      owner       : 'zdaiot',
      admin       : ['zdaiot'],
      id          : '001cb6839c31d7cecfc4710fd95dd129',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/wanko.model.json"},display:{position:"left",width:150,height:300},mobile:{show:!0}})</script></body></html>