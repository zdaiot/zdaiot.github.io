<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 3.9.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"www.zdaiot.com",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="最近参加kaggle比赛，才发现对于图像分割损失函数有各种形式。同时，关于如何实现这些损失函数，尤其是加权的损失函数，之前并没有研究过。但是在实际应用中，应该还是挺常见的，毕竟样本不均衡问题时有发生。好了，废话不多说了， 进入正题。下面的内容均以二分类问题为例。 cross entropy图像分割任务的本质为对于像素点的分类，通常称为密集预测（dense prediction）。分类问题自然可以使"><meta name="keywords" content="图像分割,损失函数"><meta property="og:type" content="article"><meta property="og:title" content="图像分割损失函数"><meta property="og:url" content="https://www.zdaiot.com/DeepLearningApplications/图像分割/图像分割损失函数/index.html"><meta property="og:site_name" content="zdaiot"><meta property="og:description" content="最近参加kaggle比赛，才发现对于图像分割损失函数有各种形式。同时，关于如何实现这些损失函数，尤其是加权的损失函数，之前并没有研究过。但是在实际应用中，应该还是挺常见的，毕竟样本不均衡问题时有发生。好了，废话不多说了， 进入正题。下面的内容均以二分类问题为例。 cross entropy图像分割任务的本质为对于像素点的分类，通常称为密集预测（dense prediction）。分类问题自然可以使"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2019-09-12T11:15:24.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="图像分割损失函数"><meta name="twitter:description" content="最近参加kaggle比赛，才发现对于图像分割损失函数有各种形式。同时，关于如何实现这些损失函数，尤其是加权的损失函数，之前并没有研究过。但是在实际应用中，应该还是挺常见的，毕竟样本不均衡问题时有发生。好了，废话不多说了， 进入正题。下面的内容均以二分类问题为例。 cross entropy图像分割任务的本质为对于像素点的分类，通常称为密集预测（dense prediction）。分类问题自然可以使"><link rel="canonical" href="https://www.zdaiot.com/DeepLearningApplications/图像分割/图像分割损失函数/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>图像分割损失函数 | zdaiot</title><script data-pjax>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?0b0b58037319da4959d5a3c014160ccd";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">zdaiot</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">404NotFound</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.zdaiot.com/DeepLearningApplications/图像分割/图像分割损失函数/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/uploads/avatar.png"><meta itemprop="name" content="zdaiot"><meta itemprop="description" content="404NotFound"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="zdaiot"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> 图像分割损失函数<a href="https://github.com/zdaiot/zdaiot.github.io/tree/hexo/source/_posts/DeepLearningApplications/图像分割/图像分割损失函数.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pencil-alt"></i></a></h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-08-05 22:36:54" itemprop="dateCreated datePublished" datetime="2019-08-05T22:36:54+08:00">2019-08-05</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2019-09-12 19:15:24" itemprop="dateModified" datetime="2019-09-12T19:15:24+08:00">2019-09-12</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/DeepLearningApplications/" itemprop="url" rel="index"><span itemprop="name">DeepLearningApplications</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/DeepLearningApplications/图像分割/" itemprop="url" rel="index"><span itemprop="name">图像分割</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>11k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>10 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>最近参加kaggle比赛，才发现对于图像分割损失函数有各种形式。同时，关于如何实现这些损失函数，尤其是加权的损失函数，之前并没有研究过。但是在实际应用中，应该还是挺常见的，毕竟样本不均衡问题时有发生。好了，废话不多说了， 进入正题。下面的内容均以二分类问题为例。</p><h2 id="cross-entropy"><a href="#cross-entropy" class="headerlink" title="cross entropy"></a>cross entropy</h2><p>图像分割任务的本质为对于<strong>像素点的分类</strong>，通常称为<strong>密集预测</strong>（dense prediction）。分类问题自然可以使用cross entropy(交叉熵损失函数)。</p><p>设真实情况下$\mathbf{P}(Y = 0) = p$，$\mathbf{P}(Y = 1) = 1 - p$。通过 logistic/sigmoid 函数得到的预测$\mathbf{P}(\hat{Y} = 0) = \frac{1}{1 + e^{-x}} = \hat{p}$，$\mathbf{P}(\hat{Y} = 1) = 1 - \frac{1}{1 + e^{-x}} = 1 - \hat{p}$，则交叉熵损失函数CE为</p><script type="math/tex;mode=display">
\text{CE}\left(p, \hat{p}\right) = - \frac{1} {batch\_size \times image\_size}\sum_{i=0}^{batch\_size} \sum_{j=0}^{image\_size} \left(p_{i,j} \log\left(\hat{p}_{i,j}\right) + (1-p_{i,j}) \log\left(1 - \hat{p}_{i,j}\right)\right)</script><p>在keras中，对应函数为<code>binary_crossentropy(y_true, y_pred)</code>，在TensorFlow中，对应函数为<code>softmax_cross_entropy_with_logits_v2</code>，在Pytorch中，对应的损失函数为<code>torch.nn.BCEWithLogitsLoss()</code>。</p><h2 id="Weighted-cross-entropy"><a href="#Weighted-cross-entropy" class="headerlink" title="Weighted cross entropy"></a>Weighted cross entropy</h2><p>Weighted cross entropy是cross entropy的一种变体，具体体现在所有的正例损失前均有一个系数。主要用于类别不平衡的问题，例如当图像中只有10%的正样本，而有90%的负样本的时候，常规的cross entropy不能正常的work。</p><script type="math/tex;mode=display">
\text{WCE}\left(p, \hat{p}\right) = - \frac{1} {batch\_size \times image\_size}\sum_{i=0}^{batch\_size} \sum_{j=0}^{image\_size} \left(\beta_{i,j} p_{i,j} \log\left(\hat{p}_{i,j}\right) + (1-p_{i,j}) \log\left(1 - \hat{p}_{i,j}\right)\right)</script><p>如果想减少false negatives(漏报)，即增加recall，则设置$\beta&gt;1$；若想减少false positives(误报)，则增加precision，则设置$\beta&lt;1$。这个可以这么理解：</p><ul><li>当$\beta&gt;1$的时候，$p_{i,j} \log\left(\hat{p}_{i,j}\right)$的系数较大，所谓false negatives(漏报)，就是指预测错了，预测为了负样本，实际类别为正样本，此时$p_{i,j}=1$，为了使得损失尽可能的小，会导致$\hat{p}_{i,j}$尽可能大，模型更加倾向于尽可能的减少漏报；</li><li>当$\beta&lt;1$的时候，$(1-p_{i,j}) \log\left(1 - \hat{p}_{i,j}\right)$的系数较大，所谓false positives(误报)，就是指预测错了，预测为了正样本，实际类别为负样本，此时$1-p_{i,j}=1$，为了使得损失尽可能的小，会导致$\hat{p}_{i,j}$尽可能小，模型更加倾向于尽可能的减少误报。</li></ul><p>例如，当数据集中含有100个正例，300个负例的时候，Pytorch中的<code>torch.nn.BCEWithLogitsLoss()</code>函数中的<code>pos_weight</code>参数需要为$\frac{300}{100}=3$。此时的loss相当于有关$100\times3=300$个样本。</p><h2 id="Balanced-cross-entropy"><a href="#Balanced-cross-entropy" class="headerlink" title="Balanced cross entropy"></a>Balanced cross entropy</h2><p>该损失函数和WCE基本一致，不同点在于该损失函数对负样本也进行了加权。</p><script type="math/tex;mode=display">
\text{BCE}\left(p, \hat{p}\right) = - \frac{1} {batch\_size \times image\_size}\sum_{i=0}^{batch\_size} \sum_{j=0}^{image\_size} \left(\beta_{i,j} p_{i,j} \log\left(\hat{p}_{i,j}\right) + (1 - \beta_{i,j})(1-p_{i,j}) \log\left(1 - \hat{p}_{i,j}\right)\right)</script><p>上面的公式均是针对每个样本均有一个权重。对于图像分割任务，相当于对所有样本的所有像素点均有一个权重。且该公式中，不管是正样本还是负样本的损失，均要除以$batch_size \times image_size$来得到均值。</p><p>除此之外，在遇到类别不均衡的时候，当计算正负样本损失的时候，分别所以各自的总数，然后加权。这样做的好处是，防止正样本数目过少导致求和后除以$batch_size \times image_size$值很小。当正样本的权值为0.25，负样本的权值为0.75的时候，具体公式可以描述如下：</p><script type="math/tex;mode=display">
loss =  \sum_{i=0}^{batch\_size} \sum_{j=0}^{image\_size} \frac{0.25 \times p_{i,j} \times loss_{i,j}}{ \sum_{i=0}^{batch\_size} \sum_{j=0}^{image\_size} p_{i,j}} + \sum_{i=0}^{batch\_size} \sum_{j=0}^{image\_size} \frac{0.75 \times n_{i,j} \times loss_{i,j}}{ \sum_{i=0}^{batch\_size} \sum_{j=0}^{image\_size} n_{i,j}}</script><p>其中，$p_{i,j}$为一个batch内所有样本所有像素点是否为正样本，为正样本为1，不为正样本为0；$n_{i,j}$为一个batch内所有样本所有像素点是否为负样本，为正样本为0，不为正样本为1；$loss_{i,j}$为一个batch内所有样本所有像素点的损失值。</p><blockquote><p>正样本和负样本权重分别为0.25和0.75是针对<a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/" target="_blank" rel="noopener">SIIM-ACR Pneumothorax Segmentation</a>比赛的。在该比赛中，有掩模的样本总数和无掩模的样本总数大概为1:3，也就相当于0.25:0.75。若不进行加权，则正样本和负样本的损失值基本相同，这不符合实际的数据分布，会导致最终可能出现没有掩模的也预测出了掩模的情况。PS：实际使用的时候，效果特别差。具体原因未知。</p></blockquote><p>具体代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># reference: https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/101429</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">criterion_pixel</span><span class="params">(logit_pixel, truth_pixel)</span>:</span></span><br><span class="line">    logit = logit_pixel.view(<span class="number">-1</span>)</span><br><span class="line">    truth = truth_pixel.view(<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">assert</span>(logit.shape==truth.shape)</span><br><span class="line"></span><br><span class="line">    loss = F.binary_cross_entropy_with_logits(logit, truth, reduction=<span class="string">'none'</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="number">0</span>:</span><br><span class="line">        loss = loss.mean()</span><br><span class="line">    <span class="keyword">if</span> <span class="number">1</span>:</span><br><span class="line">        pos = (truth&gt;<span class="number">0.5</span>).float()</span><br><span class="line">        neg = (truth&lt;<span class="number">0.5</span>).float()</span><br><span class="line">        pos_weight = pos.sum().item() + <span class="number">1e-12</span></span><br><span class="line">        neg_weight = neg.sum().item() + <span class="number">1e-12</span></span><br><span class="line">        loss = (<span class="number">0.25</span>*pos*loss/pos_weight + <span class="number">0.75</span>*neg*loss/neg_weight).sum()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><p></p><h2 id="DiceLoss"><a href="#DiceLoss" class="headerlink" title="DiceLoss"></a>DiceLoss</h2><p>DICE与IOU很相似，具体两者的区别如下：</p><script type="math/tex;mode=display">
\text{DC} = \frac{2 TP}{2 TP + FP + FN} = \frac{2|X \cap Y|}{|X| + |Y|}</script><script type="math/tex;mode=display">
\text{IoU} = \frac{TP}{TP + FP + FN} = \frac{|X \cap Y|}{|X| + |Y| - |X \cap Y|}</script><p>从中可以看出，$\text{DC} \geq \text{IoU}$（两者相减得到的式子中分子为$|X| + |Y| - 2|X \cap Y|$，显然分子大于0）。</p><p>DICE也可以作为loss使用，具体代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># reference: https://github.com/asanakoy/kaggle_carvana_segmentation</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dice_loss</span><span class="params">(preds, trues, weight=None, is_average=True)</span>:</span></span><br><span class="line">    num = preds.size(<span class="number">0</span>)</span><br><span class="line">    preds = preds.view(num, <span class="number">-1</span>)</span><br><span class="line">    trues = trues.view(num, <span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">if</span> weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        w = torch.autograd.Variable(weight).view(num, <span class="number">-1</span>)</span><br><span class="line">        preds = preds * w</span><br><span class="line">        trues = trues * w</span><br><span class="line">    intersection = (preds * trues).sum(<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 分母加1是为了保证不为0，分子加1是为了保证最大值为1</span></span><br><span class="line">    scores = (<span class="number">2.</span> * intersection + <span class="number">1</span>) / (preds.sum(<span class="number">1</span>) + trues.sum(<span class="number">1</span>) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> is_average:</span><br><span class="line">        score = scores.sum() / num</span><br><span class="line">        <span class="comment"># clamp函数是为了保证值在[0,1]之间，防止下面的DiceLoss出现负值</span></span><br><span class="line">        <span class="keyword">return</span> torch.clamp(score, <span class="number">0.</span>, <span class="number">1.</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> scores</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DiceLoss</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size_average=True)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.size_average = size_average</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input, target, weight=None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> - dice_loss(F.sigmoid(input), target, weight=weight, is_average=self.size_average)</span><br></pre></td></tr></table></figure><p></p><p>这里解释下<code>dice_loss</code>函数内部的加权。<code>preds.size(0)</code>得到<code>batch_size</code>大小，<code>w</code>的大小为<code>batch_size*image_size</code>，则可以得到下式：</p><script type="math/tex;mode=display">
loss = 1 - \frac{1} {batch\_size}  \sum_{i=0}^{batch\_size}  \frac{ 2 \times \sum_{j=0}^{image\_size}w_{i,j}\times \hat{p}_{i,j} \times w_{i,j} \times p_{i,j}}{\sum_{j=0}^{image\_size} w_{i,j} \times(\hat{p}_{i,j}+p_{i,j})}</script><p>其中，$\hat p_{i,j}$为一个batch第$i$个样本第$j$个像素的预测值，而$p_{i,j}$为一个batch第$i$个样本第$j$个像素的真实值。</p><p>所以，这里的加权就相当于对一个batch内的所有样本的loss进行加权，和Pytorch中的<a href="https://pytorch.org/docs/stable/nn.html#bcewithlogitsloss" target="_blank" rel="noopener">BCEWithLogitsLoss</a>中的<code>weight</code>参数含义一致。对于图像分割任务，相当于对一个batch内的所有样本的所有像素点进行加权。</p><p>一方面，这样的加权方式不经常使用，因为我们经常会遇到正样本和负样本比例失衡问题，对于所有样本的所有像素点均要设置一个权值，在实现上不如直接设置正样本和负样本的权值方便，类似于Pytorch中的<a href="https://pytorch.org/docs/stable/nn.html#bcewithlogitsloss" target="_blank" rel="noopener">BCEWithLogitsLoss</a>中的<code>pos_weight</code>参数含义。PS:暂时没有实现，所以还是老老实实没一个样本设置一个权值吧。</p><p>另一方面，值得注意的是，在图像分割任务中，会碰到样本mask中没有正样本的情况。例如在<a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/" target="_blank" rel="noopener">SIIM-ACR Pneumothorax Segmentation</a>比赛中，就会出现大部分图像中并没有目标，mask也就全部为负样本。对于mask全部为负样本的数据，若预测出mask也没正样本，上面的<code>dice_loss</code>函数分子接近0，导致最终的loss很大，然而真实情况应该为此时loss应该很小。因此可以考虑下面的dice函数：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dice for threshold selection</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dice_overall</span><span class="params">(self, preds, targs)</span>:</span></span><br><span class="line">    n = preds.shape[<span class="number">0</span>]  <span class="comment"># batch size为多少</span></span><br><span class="line">    preds = preds.view(n, <span class="number">-1</span>)</span><br><span class="line">    targs = targs.view(n, <span class="number">-1</span>)</span><br><span class="line">    <span class="comment"># preds, targs = preds.to(self.device), targs.to(self.device)</span></span><br><span class="line">    preds, targs = preds.cpu(), targs.cpu()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># tensor之间按位相成，求两个集合的交(只有1×1等于1)后。按照第二个维度求和，得到[batch size]大小的tensor，每一个值代表该输入图片真实类标与预测类标的交集大小</span></span><br><span class="line">    intersect = (preds * targs).sum(<span class="number">-1</span>).float()</span><br><span class="line">    <span class="comment"># tensor之间按位相加，求两个集合的并。然后按照第二个维度求和，得到[batch size]大小的tensor，每一个值代表该输入图片真实类标与预测类标的并集大小</span></span><br><span class="line">    union = (preds + targs).sum(<span class="number">-1</span>).float()</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    输入图片真实类标与预测类标无并集有两种情况：第一种为预测与真实均没有类标，此时并集之和为0；第二种为真实有类标，但是预测完全错误，此时并集之和不为0;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    寻找输入图片真实类标与预测类标并集之和为0的情况，将其交集置为1，并集置为2，最后还有一个2*交集/并集，值为1；</span></span><br><span class="line"><span class="string">    其余情况，直接按照2*交集/并集计算，因为上面的并集并没有减去交集，所以需要拿2*交集，其最大值为1</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    u0 = union == <span class="number">0</span></span><br><span class="line">    intersect[u0] = <span class="number">1</span></span><br><span class="line">    union[u0] = <span class="number">2</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> (<span class="number">2.</span> * intersect / union)</span><br></pre></td></tr></table></figure><p></p><p>那么如何实现对所有样本的所有像素点分配权重呢？这需要引入下面的<code>SoftDICELoss</code>。</p><h2 id="SoftDICELoss"><a href="#SoftDICELoss" class="headerlink" title="SoftDICELoss"></a>SoftDICELoss</h2><p>这个loss是一个kaggle的大神提出来的。该损失函数克服了上面<code>DiceLoss</code>损失函数没有考虑</p><p>DICE还有另外一个形式：</p><script type="math/tex;mode=display">
\text{DL}\left(\mathbf{p}, \mathbf{\hat{p}}\right) = \frac{2 \langle\mathbf{p}, \mathbf{\hat{p}}\rangle}{\left\lVert\mathbf{p}\right\rVert_2^2 + \left\lVert\mathbf{\hat{p}}\right\rVert_2^2}</script><p>其中，$\mathbf{p} \in \{0,1\}^n$，$\mathbf{\hat p} \in [0,1]^n$。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># reference https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/101429#latest-588288</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SoftDiceLoss</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""二分类加权dice损失</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size_average=True, weight=[<span class="number">0.2</span>, <span class="number">0.8</span>])</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        weight: 各类别权重</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        super(SoftDiceLoss, self).__init__()</span><br><span class="line">        self.size_average = size_average</span><br><span class="line">        self.weight = torch.FloatTensor(weight)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, logit_pixel, truth_pixel)</span>:</span></span><br><span class="line">        batch_size = len(logit_pixel)</span><br><span class="line">        logit = logit_pixel.view(batch_size, <span class="number">-1</span>)</span><br><span class="line">        truth = truth_pixel.view(batch_size, <span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">assert</span>(logit.shape == truth.shape)</span><br><span class="line"></span><br><span class="line">        loss = self.soft_dice_criterion(logit, truth)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.size_average:</span><br><span class="line">            loss = loss.mean()</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">soft_dice_criterion</span><span class="params">(self, logit, truth)</span>:</span></span><br><span class="line">        batch_size = len(logit)</span><br><span class="line">        probability = torch.sigmoid(logit)</span><br><span class="line"></span><br><span class="line">        p = probability.view(batch_size, <span class="number">-1</span>)</span><br><span class="line">        t = truth.view(batch_size, <span class="number">-1</span>)</span><br><span class="line">        <span class="comment"># 向各样本所有像素点分配所属类别的权重，此时w只有0或1两个值</span></span><br><span class="line">        w = truth.detach()</span><br><span class="line">        self.weight = self.weight.type_as(logit)</span><br><span class="line">        <span class="comment"># * 和 -1 均为像素点之间的运算，默认此时负样本处w=0.2和正样本处w=0.8</span></span><br><span class="line">        w = w * (self.weight[<span class="number">1</span>] - self.weight[<span class="number">0</span>]) + self.weight[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        p = w * (p*<span class="number">2</span> - <span class="number">1</span>)  <span class="comment">#convert to [0,1] --&gt; [-1, 1]</span></span><br><span class="line">        t = w * (t*<span class="number">2</span> - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        intersection = (p * t).sum(<span class="number">-1</span>)</span><br><span class="line">        union =  (p * p).sum(<span class="number">-1</span>) + (t * t).sum(<span class="number">-1</span>)</span><br><span class="line">        dice  = <span class="number">1</span> - <span class="number">2</span> * intersection/union</span><br><span class="line"></span><br><span class="line">        loss = dice</span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><p>解释下上面代码，因为考虑到数据集中可能存在某些样本的掩模均为负样本，没有正样本的情况，所以需要将类标从[0,1]变为[-1,1]。此时，若真实掩模没有mask，预测出来也全部没有mask，不会因为全部值为0，导致dice的分子为0，loss为1。相反此时全部值为-1，dice的值为1，loss为0，更符合我们的实际需求。</p><p>另外，所谓的使用加权的损失函数解决样本不均衡问题，是指对于每一个正样本和负样本均有对应的加权系数。上面代码可以总结为公式：</p><script type="math/tex;mode=display">
loss = 1- \frac{1} {batch\_size} \sum_{i=0}^{batch\_size} \frac{2 \times \sum_{j=0}^{image\_size} w_{i,j}\times p_{i,j} \times w_{i,j} \times t_{i,j}}{\sum_{j=0}^{image\_size}w_{i,j}\times w_{i,j} \times (p_{i,j}+t_{i,j})}</script><p>其中，$t_{i,j} \in {-1,1}$，而$p_{i,j} \in [-1,1]$。若正样本的系数$w_{i,j}$为0.8，而负样本的系数$w_{i,j}$为0.2，则正样本对dice的影响更大，负样本对dice的影响更小。从而让网络更加关注正样本。</p><h2 id="FocalLoss"><a href="#FocalLoss" class="headerlink" title="FocalLoss"></a>FocalLoss</h2><p>该损失函数降低<code>easy examples</code>的权重，使得模型更加关注<code>hard examples</code>。</p><script type="math/tex;mode=display">
\text{FL}\left(p, \hat{p}\right) = -\left(\alpha (1 - \hat{p})^{\gamma} p \log\left(\hat{p}\right) + (1 - \alpha) \hat{p}^{\gamma} (1-p) \log\left(1 - \hat{p}\right)\right)</script><p>其中$\gamma$为超参数，当$\gamma = 0$的时候，我们得到标准BCE。我们这里关注的为当$\gamma \not= 0$的时候，对于这个公式的理解如下。</p><p>当$\gamma&gt;1$时：</p><ul><li>当样本为正样本时，此时上式右边只有第一项不为0。若$\hat{p}$较大的时候，意味着网络对该数据的分类效果较好，$(1 - \hat{p})^{\gamma}$值较小，意味着该数据的loss更小，网络接下来对于该数据的关注会更小；反之，当$\hat{p}$较小的时候，意味着网络对该数据的分类效果较差，$(1 - \hat{p})^{\gamma}$值较大，意味着该数据的loss更大，网络接下来对于该数据的关注会更大。</li><li>当样本为负样本时，此时上式右边只有第二项不为0。若$\hat{p}$较大的时候，意味着网络对该数据的分类效果较差，$\hat{p}^{\gamma}$值较大，意味着该数据的loss更大，网络接下来对于该数据的关注会更大；反之，当$\hat{p}$较小的时候，意味着网络对该数据的分类效果较好，$\hat{p}^{\gamma}$值较小，意味着该数据的loss更小，网络接下来对于该数据的关注会更小。</li></ul><p>当$\gamma&lt;1$的时候，此时损失函数会越加关注容易分的样本，而越加不关注难分的样本，与该损失函数的设计初衷背道而驰。所以实际使用的时候，$\gamma\geq1$。</p><p>因为我们这里使用的是logistic/sigmoid 函数预测的，所以继续进行推导，可以得到</p><script type="math/tex;mode=display">
\begin{aligned}
  &= \alpha(1 - \hat{p})^{\gamma} p \log\left(1 + e^{-x}\right) - \left(1 - \alpha\right)\hat{p}^{\gamma}(1-p) \log\left(\frac{e^{-x}}{1 + e^{-x}}\right)\\
  &= \alpha(1 - \hat{p})^{\gamma}p \log\left(1 + e^{-x}\right) - \left(1 - \alpha\right)\hat{p}^{\gamma}\left(1-p\right)\left(-x - \log\left(1 + e^{-x}\right)\right)\\
  &= \alpha(1 - \hat{p})^{\gamma}p \log\left(1 + e^{-x}\right) + \left(1 - \alpha\right)\hat{p}^{\gamma}\left(1-p\right)\left(x + \log\left(1 + e^{-x}\right)\right)\\
  &= \log\left(1 + e^{-x}\right)\left(\alpha (1 - \hat{p})^{\gamma} p + (1-\alpha)\hat{p}^{\gamma}(1-p)\right) + x(1 - \alpha)\hat{p}^{\gamma}(1 - p)\\
  &= \log\left(e^{-x}(1 + e^{x})\right)\left(\alpha (1 - \hat{p})^{\gamma} p + (1-\alpha)\hat{p}^{\gamma}(1-p)\right) + x(1 - \alpha)\hat{p}^{\gamma}(1 - p)\\
  &= \left(\log\left(1 + e^{x}\right) - x\right)\left(\alpha (1 - \hat{p})^{\gamma} p + (1-\alpha)\hat{p}^{\gamma}(1-p)\right) + x(1 - \alpha)\hat{p}^{\gamma}(1 - p)\\
  &= \left(\log\left(1 + e^{-|x|}\right) + \max(-x, 0)\right)\left(\alpha (1 - \hat{p})^{\gamma} p + (1-\alpha)\hat{p}^{\gamma}(1-p)\right) + x(1 - \alpha)\hat{p}^{\gamma}(1 - p)\\
\end{aligned}</script><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://lars76.github.io/neural-networks/object-detection/losses-for-segmentation/" target="_blank" rel="noopener">Losses for Image Segmentation</a><br><a href="https://pytorch.org/docs/stable/nn.html#bcewithlogitsloss" target="_blank" rel="noopener">BCEWithLogitsLoss</a><br><a href="https://github.com/asanakoy/kaggle_carvana_segmentation/blob/master/asanakoy/losses.py" target="_blank" rel="noopener">losses.py</a><br><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/101429#latest-588288" target="_blank" rel="noopener">some workable loss function</a><br><a href="https://discuss.pytorch.org/t/how-to-apply-weighted-loss-to-a-binary-segmentation-problem/35317" target="_blank" rel="noopener">How to apply weighted loss to a binary segmentation problem?</a></p></div><div><div style="text-align:center;color:#ccc;font-size:14px">------ 本文结束------</div></div><div class="reward-container"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/uploads/wechat.png" alt="zdaiot 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/uploads/aipay.jpg" alt="zdaiot 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> zdaiot</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.zdaiot.com/DeepLearningApplications/图像分割/图像分割损失函数/" title="图像分割损失函数">https://www.zdaiot.com/DeepLearningApplications/图像分割/图像分割损失函数/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><p>欢迎关注我的其它发布渠道</p><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="/uploads/wechat-qcode.jpg"><span class="icon"><i class="fab fa-weixin"></i></span> <span class="label">WeChat</span></a></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/图像分割/" rel="tag"><i class="fa fa-tag"></i> 图像分割</a><a href="/tags/损失函数/" rel="tag"><i class="fa fa-tag"></i> 损失函数</a></div><div class="post-nav"><div class="post-nav-item"><a href="/Linux/软件/Centos搭建Ngrok实现内网穿透/" rel="prev" title="Centos搭建Ngrok实现内网穿透"><i class="fa fa-chevron-left"></i> Centos搭建Ngrok实现内网穿透</a></div><div class="post-nav-item"> <a href="/Linux/软件/Centos搭建Frp实现内网穿透/" rel="next" title="Centos搭建Frp实现内网穿透">Centos搭建Frp实现内网穿透<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="gitalk-container"></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#cross-entropy"><span class="nav-number">1.</span> <span class="nav-text">cross entropy</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Weighted-cross-entropy"><span class="nav-number">2.</span> <span class="nav-text">Weighted cross entropy</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Balanced-cross-entropy"><span class="nav-number">3.</span> <span class="nav-text">Balanced cross entropy</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DiceLoss"><span class="nav-number">4.</span> <span class="nav-text">DiceLoss</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SoftDICELoss"><span class="nav-number">5.</span> <span class="nav-text">SoftDICELoss</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FocalLoss"><span class="nav-number">6.</span> <span class="nav-text">FocalLoss</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考"><span class="nav-number">7.</span> <span class="nav-text">参考</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="zdaiot" src="/uploads/avatar.png"><p class="site-author-name" itemprop="name">zdaiot</p><div class="site-description" itemprop="description">404NotFound</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">317</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">54</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">372</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zdaiot" title="GitHub → https://github.com/zdaiot" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:zdaiot@163.com" title="E-Mail → mailto:zdaiot@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/" title="知乎 → https://www.zhihu.com/people/" rel="noopener" target="_blank"><i class="fa fa-book fa-fw"></i> 知乎</a></span><span class="links-of-author-item"><a href="https://blog.csdn.net/zdaiot" title="CSDN → https://blog.csdn.net/zdaiot" rel="noopener" target="_blank"><i class="fa fa-copyright fa-fw"></i> CSDN</a></span></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="link fa-fw"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://kalacloud.com" title="https://kalacloud.com" rel="noopener" target="_blank">卡拉云低代码工具</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://beian.miit.gov.cn" rel="noopener" target="_blank">京ICP备2021031914号</a></div><div class="copyright"> &copy; <span itemprop="copyrightYear">2023</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">zdaiot</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-chart-area"></i></span> <span title="站点总字数">2.3m</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span title="站点阅读时长">35:08</span></div><div class="addthis_inline_share_toolbox"><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b5e7e498f94b7ad" async="async"></script></div> <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now=new Date;function createtime(){var n=new Date("08/01/2018 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="Run for "+dnum+" Days ",document.getElementById("times").innerHTML=hnum+" Hours "+mnum+" m "+snum+" s"}setInterval("createtime()",250)</script><div class="busuanzi-count"><script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script><script data-pjax>!function(){var o,n,e=document.getElementsByTagName("link");if(0<e.length)for(i=0;i<e.length;i++)"canonical"==e[i].rel.toLowerCase()&&e[i].href&&(o=e[i].href);n=o?o.split(":")[0]:window.location.protocol.split(":")[0],o||(o=window.location.href),function(){var e=o,i=document.referrer;if(!/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(e)){var t="https"===String(n).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";i?(t+="?r="+encodeURIComponent(document.referrer),e&&(t+="&l="+e)):e&&(t+="?l="+e),(new Image).src=t}}(window)}()</script><script src="/js/local-search.js"></script><div id="pjax"><script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '4800250e682fe873198b',
      clientSecret: '80f7f33f5f8ddfd3944f455cabadda4ff3299147',
      repo        : 'zdaiot.github.io',
      owner       : 'zdaiot',
      admin       : ['zdaiot'],
      id          : 'cdfbc842c8c081c0fb1929015cda3844',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/wanko.model.json"},display:{position:"left",width:150,height:300},mobile:{show:!0}})</script></body></html>