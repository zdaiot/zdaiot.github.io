<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 3.9.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"www.zdaiot.com",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="这篇论文给我感觉是很惊艳，实验表格真的是太充分了，而且不像EfficientNet那种大力出奇迹的感觉，这篇论文手工设计出了比EfficientNet还好的论文，经过我自己的实验。同样的epoch和batch size下，RegNetX-8.0GF只占用9G显存，9个半小时单卡就训练完了。但是efficientnet-b4占用双卡，显存占满，需要训练21个小时。最终两者的精度基本一致，但是推理时间"><meta name="keywords" content="RegNet,图像分类"><meta property="og:type" content="article"><meta property="og:title" content="Designing Network Design Spaces"><meta property="og:url" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing Network Design Spaces/index.html"><meta property="og:site_name" content="zdaiot"><meta property="og:description" content="这篇论文给我感觉是很惊艳，实验表格真的是太充分了，而且不像EfficientNet那种大力出奇迹的感觉，这篇论文手工设计出了比EfficientNet还好的论文，经过我自己的实验。同样的epoch和batch size下，RegNetX-8.0GF只占用9G显存，9个半小时单卡就训练完了。但是efficientnet-b4占用双卡，显存占满，需要训练21个小时。最终两者的精度基本一致，但是推理时间"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200511164813758.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200509211937765.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200509221042378.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200509222131303.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200509222806566.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200509221042378.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200509225014779.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200509230209083.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200509231358924.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200510112501953.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200510131045160.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200510131608488.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200510201943112.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200511141510023.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200511142541822.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200511143520477.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200511145206625.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200511150646382.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200511152942959.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200511153852245.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200511154717954.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200511154737768.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200511155649930.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200511160023661.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200511160739894.png"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200511175015017.png"><meta property="og:updated_time" content="2020-05-09T11:28:41.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Designing Network Design Spaces"><meta name="twitter:description" content="这篇论文给我感觉是很惊艳，实验表格真的是太充分了，而且不像EfficientNet那种大力出奇迹的感觉，这篇论文手工设计出了比EfficientNet还好的论文，经过我自己的实验。同样的epoch和batch size下，RegNetX-8.0GF只占用9G显存，9个半小时单卡就训练完了。但是efficientnet-b4占用双卡，显存占满，需要训练21个小时。最终两者的精度基本一致，但是推理时间"><meta name="twitter:image" content="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing%20Network%20Design%20Spaces/image-20200511164813758.png"><link rel="canonical" href="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing Network Design Spaces/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>Designing Network Design Spaces | zdaiot</title><script data-pjax>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?0b0b58037319da4959d5a3c014160ccd";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">zdaiot</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">404NotFound</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing Network Design Spaces/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/uploads/avatar.png"><meta itemprop="name" content="zdaiot"><meta itemprop="description" content="404NotFound"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="zdaiot"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> Designing Network Design Spaces<a href="https://github.com/zdaiot/zdaiot.github.io/tree/hexo/source/_posts/DeepLearningApplications/图像分类/Designing Network Design Spaces.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pencil-alt"></i></a></h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-05-09 19:28:41" itemprop="dateCreated datePublished" datetime="2020-05-09T19:28:41+08:00">2020-05-09</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/DeepLearningApplications/" itemprop="url" rel="index"><span itemprop="name">DeepLearningApplications</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/DeepLearningApplications/图像分类/" itemprop="url" rel="index"><span itemprop="name">图像分类</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>13k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>12 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>这篇论文给我感觉是很惊艳，实验表格真的是太充分了，而且不像EfficientNet那种大力出奇迹的感觉，这篇论文手工设计出了比EfficientNet还好的论文，经过我自己的实验。同样的epoch和batch size下，<code>RegNetX-8.0GF</code>只占用9G显存，9个半小时单卡就训练完了。但是<code>efficientnet-b4</code>占用双卡，显存占满，需要训练21个小时。最终两者的精度基本一致，但是推理时间<code>RegNetX-8.0GF</code>（15.65）只有<code>efficientnet-b4</code>（29.17）的一半。下面对该论文进行详细介绍。</p><h2 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h2><ol><li>提出了一个新的网络设计范例。以统计学的角度提高了对网络设计的理解，并探讨不同设置下的通用网络设计原则。作者不是专注于设计某个具体的网络，而是design network design spaces。整个过程类似于经典的手工网络设计，但是提升到了设计空间的层次。</li><li>使用所提方法，得到了包含一系列简单、常规网络模型的低阶空间——RegNet。在这个空间中，表现优异的网络的宽度和深度能够被一个线性函数量化。并且发现了一些和现有设计思想相悖的结论。</li><li>在不同的FLOPs约束下，都可以从RegNet设计空间中得到简单且轻量的模型。在相同的FLOPs和训练参数下，RegNet模型比EfficientNet的性能更好且在GPUs最多提速5倍。</li></ol><h2 id="创新点来源"><a href="#创新点来源" class="headerlink" title="创新点来源"></a>创新点来源</h2><p>传统NAS方法这种基于个体估计（individual network instance）的方式（每次评估的时候采样一个网络）存在以下缺陷：</p><ul><li>非常不灵活（包含各种各样的可调参数）</li><li>泛化能力差（搜索出的网络可能跟特定设置有关，例如硬件平台）</li><li>可解释性差，不能发现网络设计原则，从而泛化到新的设置中</li></ul><p>面对这个问题，作者提出了可以对网络设计空间进行整体估计（population estimation，意思就是所有的深度宽度之类的最佳设计空间关系给它估计出来）。直观地，如果能得到深度(depth)，宽度(width)等一系列网络设计要素关于网络设计目标的函数关系，那么就很轻松地知道大概多深、多宽的网络是最佳选择。 那么也就可以解决上面所提的问题了，并且这个方式实际上能反应出更优的网络设计准则，从而达到作者Designing Network Design Spaces的目的。</p><h2 id="Design-Space-Design"><a href="#Design-Space-Design" class="headerlink" title="Design Space Design"></a>Design Space Design</h2><p>Design space（设计空间）是包含是一大群（可能是无限的）模型的空间。不同于search space（搜索空间），作者并不是在一个空间内搜索出一个具体的网络实例，而是设计空间本身。作者从一个初始的、不受约束的设计空间出发，通过发现的网络设计准则逐渐的简化该空间，称这个过程为design space design，如图1所示。可以看到这个过程类似于设计一个具体的模型，但是作者把它上升到了整体水平。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200511164813758.png" alt="image-20200511164813758" style="zoom:80%"></p><h3 id="Tools-for-Design-Space-Design"><a href="#Tools-for-Design-Space-Design" class="headerlink" title="Tools for Design Space Design"></a>Tools for Design Space Design</h3><p>那么如何评价一个设计空间的好坏呢？根据前人的研究，可以从设计空间中采样出一系列的模型，然后画出这一系列模型的误差分布图，以这个错误分布图来表征整个设计空间的好坏，直观上比在设计空间中搜索出最优模型然后比较这样的方式更加鲁邦且信息量更加充足。</p><p>具体而言，作者从一个设计空间中采样$n$个模型，然后对这$n$个模型进行一个low-compute、low-epoch的训练，即使用400M FLOPs（$10^6 $FLOPs，记作MF）的模型，且只在ImageNet上训练10个epoch。这样的实验很快速，训练100个400MF的模型10个Epoch和训练单个4GF（$10^9$ FLOPs，记作GF）的ResNet-50模型100个Epoch计算量大致相同。</p><p>作者主要靠the error empirical distribution function (EDF) 来评估一个设计空间的质量。第$i$个模型的误差记作$e_i$，则这$n$个模型的EDF计算公式为：</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200509211937765.png" alt="image-20200509211937765" style="zoom:80%"></p><p>$F(e)$给出了误差小于$e$的模型占比。某个设计空间的EDF如图2(左)所示，可以看到通过这种方式能够将一个复杂的、高维设计空间的表现投影到一个二维空间，从而帮助我们更好的理解设计空间。在这些图中，作者使用了empirical bootstrap来评估最优模型的可能范围，如图2(中、右)所示。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200509221042378.png" alt="image-20200509221042378" style="zoom:80%"></p><p><strong>补充：</strong>给定$n$对$(x_i,e_i)$，其中$x_i$表示<strong>模型的一个属性</strong>如depth，$e_i$表示对应的模型误差。通过如下步骤完成empirical bootstrap。</p><ol><li>从这$n$对中随机采样25%，得到一组sample</li><li>选择这一组sample中误差最小的一对</li><li>重复这个步骤$10^4$次</li><li>计算这$10^4$对样本<strong>属性$x$的95%置信区间</strong>，并以中位数给出了最优可能的值。</li></ol><blockquote><p>置信区间理解：以相同的抽样方式，获得N组抽样样本，每一组抽样样本点数为M，对于每一组抽样样本，按某一置信度，比如说95%，计算出置信区间，那么将会有0.95*N组所计算出来的置信区间中包含有总体待估计参数值。</p><p>不同的样本集具有不同的置信区间，<strong>置信区间是随机变量</strong>。那么，求某一个样本集的置信区间究竟有什么意义呢？在实际应用中，当我们需要研究总体的某些特征时，以总体的均值为例，由于无法获得全体数据，我们通过采样来获得一组样本，这组样本均值作为总体均值的一个点估计，而这组样本的置信区间作为总体均值的一个区间估计。这里以95%置信度为例，那么由这组样本计算出来的95%置信区间能够说明什么呢？通过实验，采样1000个样本集，则可以计算出来的1000个置信区间，其中有大约950个置信区间包含有真实值，换句话说，假设置信区间为[a,b]，<strong>选置信区间的目的是为了让“a和b之间包含总体平均值”这一结果具有特定的概率，这个概率就是置信水平，并不是说总体待估计参数（比如说均值）以一定的概率落在置信区间内。</strong>。所以利用置信区间可以一定程度上对于真实值的取值范围有所了解。</p></blockquote><p>总结来说：</p><ol><li>作者从一个设计空间中采样并训练$n$个模型</li><li>计算并画出决策空间的EDFs来表征设计空间的质量</li><li>使用empirical bootstrap来对一个设计空间的不同属性进行可视化</li><li>根据可视化结果来调整设计空间</li></ol><h3 id="The-AnyNet-Design-Space"><a href="#The-AnyNet-Design-Space" class="headerlink" title="The AnyNet Design Space"></a>The AnyNet Design Space</h3><p>在本文中，一个网络中的元素包含如下几个部分：</p><ol><li>blocks的数量（即网络深度）</li><li>block的宽度（即channels的数量）</li><li>其它的block参数，例如bottleneck ratios or group widths</li></ol><p>初始的AnyNet设计空间很直观，给定一张图片，一个网络由一个simple stem，紧跟着一个执行大量计算的boby部分，最后是预测输出类别的head网络。如图3a所示。作者让stem和head部分尽可能的简单，并且保持固定。然后主要聚焦在网络的boby部分。</p><p>boby部分由4个stage组成（在3.4节探讨了stage的变化），逐渐降低特征图尺寸，如图3b所示。每一个stage都包含相同的blocks，如图3c所示。对于stage $i$，自由维度包含blocks的数量$d_i$，block的宽度$w_i$，以及其他的block参数。虽然整体结构比较简单，但是AnyNet中可能网络的总体数量是巨大的。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200509222131303.png" alt="image-20200509222131303" style="zoom:80%"></p><p>作者大部分实验都是在有分组卷积的标准residual bottlenecks block上进行的，如图4所示。作者将这种block称为x block，基于该block的设计空间为<strong>AnyNetX</strong>（作者在3.4节探索了别的blocks）。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200509222806566.png" alt="image-20200509222806566" style="zoom:80%"></p><p>AnyNetX有<strong>16个自由维度</strong>——4个stage，每个stage都有blocks的数量$d_i$、block的宽度$w_i$，bottleneck ratio $b_i$, and group width $g_i$。作者固定了输入分辨率$r=224$。为了更好的采样，规定$d_i\leq 16,g_i \in \{1,2,\cdots 32 \}$，$b_i \in \{1,2,4\}$，$w_i \leq 1024$且能被8整除。重复采样直到采样到500个满足FLOPs落在300MF到400MF的模型，然后训练10个Epoch，根据作者的经验，10个Epoch已经足够能给出具有鲁棒性的设计空间统计。AnyNetX的基本统计在图2中给出。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200509221042378.png" alt="image-20200509221042378" style="zoom:80%"></p><p>若使用NAS的方法，会在这$(16\cdot 128 \cdot 3 \cdot 6)^4=10^{18}$个模型中搜索出一个最优模型。但是作者借助上面的设计空间评价工具探索一般的设计原则，从而更好的理解和调整设计空间。在这个过程中，目标是：</p><ol><li>简化设计空间</li><li>提高设计空间的可解释性</li><li>提高或者保持设计空间的质量</li><li>保持设计空间的多样性</li></ol><p>主要的步骤如下：</p><p><strong>AnyNet$X_A$：</strong>为了下面表述清晰，作者将上面的AnyNetX空间表示为AnyNet$X_A$。</p><p><strong>AnyNet$X_B$：</strong>对于AnyNet$X_A$设计空间中的所有的stage $i$都采用同一个bottleneck ratio $b_i=b$，得到新的设计空间为AnyNet$X_B$。AnyNet$X_A$和AnyNet$X_B$的EDFs曲线如图5左所示，可以看到两者曲线基本保持一致，也就是说当所有的stage $i$都采用同一个bottleneck ratio时，网络精度并没有损失。这样处理除了<strong>简化了设计空间</strong>之外，AnyNet$X_B$更容易分析，如图5右所示，$b$的95%置信区间为$b\leq2$，但是AnyNet$X_A$并没有这样的趋势（并没有给出图）。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200509225014779.png" alt="image-20200509225014779" style="zoom:80%"></p><p><strong>AnyNet$X_C$：</strong>在AnyNet$X_B$基础上，在进一步保持各个stage $i$都采用同一个group width $g_i=g$，得到新的设计空间为AnyNet$X_C$。如图5中所示，当所有的stage $i$都采用同一个group width时，网络精度并没有损失。这样就可以<strong>进一步简化设计空间</strong>，AnyNet$X_C$比AnyNet$X_A$减少了6个自由度。另外，作者发现当$g &gt; 1$时是最优的（实验没有展示出来），这部分在第4节进行详细介绍。</p><p><strong>AnyNet$X_D$：</strong>接着作者对AnyNet$X_C$中的最好的结构（图6上）和最差的结构（图6下）进行了分析。图中，横坐标表示每个block $j$下标索引，而纵坐标表示每个block $j$对应的网络宽度$w_j$，$d_i$表示第$i$个stage有多少个block，而$w_i$表示第$i$个stage的网络宽度（每个stage内部网络结构相同）。例如下面第一幅图就表示，第一个stage有一个block，宽度为48；第二个stage有2个block，宽度为80；以此类推。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200509230209083.png" alt="image-20200509230209083"></p><p>然后可以发现好的网络都有一个共同的属性，网络的宽度逐渐增加，也就是说$w_{i+1} \geq w_i$，有该约束的设计空间称为AnyNet$X_D$。画出该空间的EDF曲线，如图7(左)所示，发现通过该原则，能够极大的提高EDF。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200509231358924.png" alt="image-20200509231358924"></p><p><strong>AnyNet$X_E$：</strong>通过观察更多的模型（并没展示出来），作者发现对于比较好的模型，每一个stage的宽度$d_i$也有逐渐增加的趋势，但是最后一个stage并不需要。虽然如此，作者约束$d_{i+1} \geq d_i$得到新的设计空间AnyNet$X_E$，然后画出该空间的EDF曲线，如图7(右)所示，发现通过该原则，也能提高EDF。</p><p>靠着一步步的优化，缩小设计空间，作者最终得到了大量包含优质模型且设计空间较小的AnyNet$X_E$。</p><h3 id="The-RegNet-Design-Space"><a href="#The-RegNet-Design-Space" class="headerlink" title="The RegNet Design Space"></a>The RegNet Design Space</h3><p>为了更好的理解模型结构，从AnyNet$X_E$中选出最好的20个模型，然后画出来每个block $j$的网络宽度$w_j$和每个stage $i$的网络深度$d_i$，如图8左上所示。</p><p>虽然每个模型之间的差异巨大，但是整体上表现出来了一种趋势，即当$0\leq j \leq20$时，有$w_j=48 \cdot (j+1)$，也就是图8左上图中的黑线，值得注意的是，纵坐标是取log后的。但是这种量化方式，对于每一个block $j$都指定了一个特定的宽度$w_j$，但是实际上不同模型的$w_j$是不同的，另外若采用这种量化方式，也没有办法保持设计空间的多样性。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200510112501953.png" alt="image-20200510112501953" style="zoom:80%"></p><p>为了解决这个问题，作者采用了下面的改进思路：</p><p>为每一个block的宽度引入一个<strong>线性参数化</strong>的方程：</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200510131045160.png" alt="image-20200510131045160" style="zoom:80%"></p><p>该方程有三个参数：深度$d$，初始宽度$w_0&gt;0$，斜率$w_a&gt;0$。通过该方程为每一个block $j<d $ 产生一个不同的宽度$u_j$。为了量化$u_j$，引入了两组公式和一个新的参数$w_m>0$，用于计算量化因子$s_j$。量化过程如下：</d></p><blockquote><p>简单地说就是算出来的宽度可能是126.123之类的奇葩数字，得给它四舍五入到128这种科学的数字，同时每个stage $i$有很多block，得把宽度统一到某个数字。这就需要<strong>拿一个分段函数去近似上面的线性函数</strong>。于是就有了下面的步骤。</p><p>$w_0、w_a、w_m$都是有自己取值范围的，实际使用时会采用网格搜索的方法，因此在理解这些方程时可以将其看做是常数。</p></blockquote><p>首先给定一个方程(2)中的$u_j$，计算出每一个block $j$的$s_j$：</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200510131608488.png" alt="image-20200510131608488" style="zoom:80%"></p><p>然后，对$s_j$取整用$\lfloor s_j \rceil$表示，然后将量化后的$s_j$带入式子(3)即完成对$u_j$量化，得到每一个block的实际宽度$w_j$，用下式子表示：</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200510201943112.png" alt="image-20200510201943112" style="zoom:80%"></p><p>接着将每个block的宽度转换为stage的形式，也就是说。每一个stage $i$的block宽度为$w_i=w_0 \cdot w_m^i$，block的数量为$d_i = \sum_j \mathbf{1} \left[ \lfloor s_j \rceil = i\right]$（因为量化因子$s_j$控制了block的宽度，同一个stage中block的宽度相同，因此也就有了这两个公式）。</p><p>在AnyNetX空间验证这种参数化的方法。也就是说，给定一个模型，设置网络的深度为$d$，网格搜索得到一组参数$w_0,w_a,w_m$，使得使用该组参数预测出的模型和实际给定的模型每一个block宽度之间的差异最小。该差异用$e_{fit}$表示。AnyNet$X_E$中的两个最好的模型如图8(上中右)所示。可以看到量化后的函数(虚线)和这些模型(实线)拟合的很好。</p><p>接下来，我们画出拟合误差$e_{fit}$关于AnyNet$X_c$到AnyNet$X_E$中模型的曲线如图8(下)所示。</p><ul><li>首先，观察到设计空间中最好的模型都有很好的拟合度。通过empirical bootstrap方法发现，$e_{fit}$值接近零的一个窄带，可能包含每个设计空间中的最佳模型。</li><li>然后，可以发现从AnyNet$X_c$到AnyNet$X_E$，$e_{fit}$越来越小。</li></ul><p>为了进一步测试这种线性参数化的方法，基于AnyNet$X_E$限制$d&lt;64$，$w_0,w_a&lt;256$，$1.5\leq w_m \leq3$，$b$和$g$与之前介绍的方式相同，在这个范围内采样，利用公式(2)-(4)得到具体的网络结构。称有这种限制的空间为RegNet，它只包含简单的、常规的网络。</p><p>RegNetX的EDF如图9(左)所示，可以看到RegNetX中的模型的平均误差比AnyNetX小，说明RegNetX中的模型都是比较优秀的模型。</p><p>从图9(中)作者进一步的对参数进行了限制，具体而言：</p><ol><li>使用$w_m=2$（也就是stage之间的block宽度翻倍）轻微的提高了EDF，但是$w_m \geq 2$表现更好（后面展示）。</li><li>测试了$w_0=w_a$，进一步简化线性参数化方程为$u_j = w_a \cdot (j+1)$。这样效果也变得更好了。</li></ol><p>但是为了维持模型的重要性，作者并没有采样这两种限制。图9(右)展示了随机搜索的效率，发现RegNetX搜索大约32个模型就有可能产生好的模型。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200511141510023.png" alt="image-20200511141510023"></p><p>表1展示了决策空间尺寸的摘要。从原始的AnyNetX设计空间到RegNetX设计空间，作者将自由维度从16缩小到了6，空间缩小了约10个数量级。然而RegNet仍然包含了设计空间的多样性。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200511142541822.png" alt="image-20200511142541822"></p><h3 id="Design-Space-Generalization"><a href="#Design-Space-Generalization" class="headerlink" title="Design Space Generalization"></a>Design Space Generalization</h3><p>我们设计的RegNet设计空间是在low-compute, low-epoch的训练模式下进行的，只有一种block 类型。然而，我们的目标不是为单一设置设计一个设计空间，而是发现可以推广到新设置的网络设计的一般原则。</p><p>在图10中，我们在higher flops, higher epochs, 5个stage, 不同种类的block类型下比较了AnyNet$X_A$、AnyNet$X_E$和RegNetX设计空间。在各种模型下，都有RegNetX&gt;AnyNet$X_E$&gt;AnyNet$X_A$。换句话说，我们的规则并没有在特定的设置上过拟合，具有一定的泛化能力。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200511143520477.png" alt="image-20200511143520477"></p><h2 id="Analyzing-the-RegNetX-Design-Space"><a href="#Analyzing-the-RegNetX-Design-Space" class="headerlink" title="Analyzing the RegNetX Design Space"></a>Analyzing the RegNetX Design Space</h2><p>接下来进一步分析RegNetX设计空间，重新探讨深度网络设计的一些通用规则。RegNetX设计空间有大量的优秀模型，接下来的实验我们改为采样更少的模型（100）个，训练的epoch增多一点（25个）。这样就能观察到更加精细化的趋势。</p><p><strong>RegNet trends.</strong> 图11中展示了RegNetX在不同FLOPs下各种参数的趋势。值得注意的是，通过图11(上左)，发现在不同FLOPs下最优模型（黑色的线，使用empirical bootstrap得到）的depth都很稳定，大概为20个blocks（60层）。这与实际实践中，通常使用更深的模型以得到更高的FLOPs形成了鲜明的对比。通过图11(上中)，发现最优模型的bottleneck ratio $b=1.0$。通过图11(上右)，观察到优秀模型的乘子$w_m$是2.5。这与实际经常采用的stage之间宽度翻倍的方式有点相似但是不完全相同。剩余的参数（$g、w_a、w_0$）随着复杂度的增高而增加。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200511145206625.png" alt="image-20200511145206625"></p><p><strong>Complexity analysis.</strong> 除了FLOPs和参数，作者分析了所有卷积层的输出tensor的尺寸，将其定义为network activations，用于度量网络的复杂度，在图12的左上角列出了常见卷积算子的复杂性度量。虽然activations不是衡量网络复杂性的通用标准，但<strong>activations可能会严重影响内存受限硬件加速器(例如GPU、TPU)上的运行时间</strong>，在图12(上)可以看到，activations跟推理时间的正相关性比FLOPs更强。在图12(下)中，观察到对于总体中最好的模型，activations随FLOPs的平方根增加，参数量随FLOPs线性增加，并且推理时间最好使用FLOPs的线性和平方根项联合建模（即图12(下右)中的式子$24 \sqrt f + 6.0 \cdot f$），因为它同时依赖于FLOPs和activations。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200511150646382.png" alt="image-20200511150646382"></p><p><strong>RegNetX constrained.</strong> 使用上述这些发现，我们可以对RegNetX设计空间进一步微调，首先基于图11(上)，设置$b=1,d\leq40,w_m\geq2$。然后基于图12(下)，对参数量和activations进行约束。这样就能产生快速的、低参数量的、low-memory且不影响精度的模型。在图13中，我们对比了RegNetX有这些约束和没有这些约束下的表现，可以发现在所有FLOPs下，有约束的性能比没有约束的更好。因此在下面的实验结果小节都使用有约束的版本，然后更进一步的限制网络深度$12\leq d \leq 28$（在附录D中有解释）。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200511152942959.png" alt="image-20200511152942959"></p><p><strong>Alternate design choices.</strong> mobile network经常采用the inverted bottleneck (b &lt; 1) 和depthwise conv。在图14(左)，观察到相对于$b=1, g\geq 1$，inverted bottleneck轻微的降低了EDF，depthwise conv（group width $g_i=1$）表现更加差劲。接下来，作者测试了在不同输入图像分辨率对网络的影响，如图14(中)所示，与一般的结论相反，即使在更高的FLOPs，将RegNetX的分辨率固定为$224 \times 224$表现更好。</p><p><strong>SE.</strong> 最后，作者将block X和SE模块进行结合，得到了新的设计空间RegNetY。在图14(右)，发现RegNetY性能提升比较明显。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200511153852245.png" alt="image-20200511153852245"></p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>作者将RegNetX和RegNetY中的最优模型和目前State-of-the-art模型在各种FLOPs下进行对比。对于每一个FLOPs，作者从设计空间中选取最优模型，然后重新训练100个Epoch。在不同FLOPs下，RegNetX和RegNetY中的最优模型结构在图15和16中给出。除了在上面第4章分析出的结论外，作者还发现了如下结论：</p><ol><li>更高FLOPs的模型在stage 3中有更多的blocks，但是在stage4有更少的blocks，这和标准的ReNet网络设计相似。</li><li>group width随着$g$的模型复杂度的提高而增加，但是depth $d$会饱和。</li></ol><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200511154717954.png" alt="image-20200511154717954"></p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200511154737768.png" alt="image-20200511154737768"></p><p>为了公平的比较模型结构带来的差异，作者在训练网络的时候关掉了所有的增强方式。</p><h3 id="State-of-the-Art-Comparison-Mobile-Regime"><a href="#State-of-the-Art-Comparison-Mobile-Regime" class="headerlink" title="State-of-the-Art Comparison: Mobile Regime"></a>State-of-the-Art Comparison: Mobile Regime</h3><p>对于移动端，更加关注在600MF下模型的表现，作者比较了600MF RegNet模型和现有的mobile网络。发现不管是人工设计的网络还是NAS搜索出的网络，都没有从RegNet选出的模型精度高。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200511155649930.png" alt="image-20200511155649930"></p><h3 id="Standard-Baselines-Comparison-ResNe-X-t"><a href="#Standard-Baselines-Comparison-ResNe-X-t" class="headerlink" title="Standard Baselines Comparison: ResNe(X)t"></a>Standard Baselines Comparison: ResNe(X)t</h3><p>作者将RegNet网络和标准的ResNet、ResNext网络进行对比。对比结果在图17和表3中给出，可以发现只通过优化网络结构，RegNet可以取得巨大的提升。表3(a)比较这些方法时采用的是根据activations进行分组，在给定固定推理时间或训练时间下，RegNetx模型都非常有效。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200511160023661.png" alt="image-20200511160023661"></p><h3 id="State-of-the-Art-Comparison-Full-Regime"><a href="#State-of-the-Art-Comparison-Full-Regime" class="headerlink" title="State-of-the-Art Comparison: Full Regime"></a>State-of-the-Art Comparison: Full Regime</h3><p>作者将EfficientNet和RegNetX、RegNetY进行比较，并控制两者在训练过程中参数一致。结果在图18和表4中给出，可以发现，在较低FLOPs下，EfficientNet表现比较好，但是在中等FLOPs下，RegNetY表现比EfficientNet好，在较高FLOPs下，RegNetX和RegNetY表现都比EfficientNet好。</p><p>还可以观察到，受到同时对分辨率和深度进行scale的影响，EfficientNet的activations随着FLOPs线性增长，而RegNet的activations随FLOPs的平方根增长。这导致了EfficientNet的GPU训练速度和推理速度较慢，例如RegNetX-8000比EfficientNet的推理时间快了5倍，同时错误率更低。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200511160739894.png" alt="image-20200511160739894"></p><h3 id="Additional-Ablations"><a href="#Additional-Ablations" class="headerlink" title="Additional Ablations"></a>Additional Ablations</h3><p>最近的很多工作使用了swish激活函数，在图20中，作者对比了RegNetY在Swish and ReLU不同激励函数下的性能，发现swish激励函数在低FLOPs下表现更好，而ReLU激励函数在高FLOPs下表现更好。如果$g$被约束到$g=1$（depthwise conv），那么swish函数比relu函数表现更好，也就是说swish函数和depthwise conv更加搭配。</p><p><img src="/DeepLearningApplications/图像分类/Designing Network Design Spaces/image-20200511175015017.png" alt="image-20200511175015017"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>使用NAS虽然可以产生优秀的网络，但是有着固有的缺点：</p><ol><li>搜索空间大，特别消耗GPU资源</li><li>换一种空间或者设定，又要重新开始搜，不具有通用性</li><li>不具有通用解释性</li></ol><p>而手动设计的网络性能通常没有NAS搜索出来的好，但是可解释强，有通用的网络设计规则。</p><p>面对这些问题，作者将NAS和手动设计网络相结合，从统计学的角度出发，对网络设计空间进行整体估计。从整体估计中，一步步发现网络设计的规则，对设计空间进行优化和限制，提高了模型搜索的速度和效果。然后，作者将该规则应用到higher flops, higher epoch, 5个stage, 不同的block类型的设计空间上，验证了这些网络设计规则具有泛化能力，并不是针对某个设置而言的。最后说明了，在相同的FLOPs和训练参数下，RegNet模型比EfficientNet的性能更好且在GPUs最多提速5倍。</p><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>以下内容来源于<a href="https://zhuanlan.zhihu.com/p/122943688" target="_blank" rel="noopener">FLOPs与模型推理速度</a>。</p><p>大家都知道EfficientNet论文以大幅度降低FLOPs为卖点，但是其推理速度却很慢。比如B3版本的FLOPs不到ResNet50的一半，推理速度却是ResNet50的两倍。那么FLOPs与模型推理速度之间有什么关系么？</p><p><strong>大部分时候，对于GPU，算力瓶颈在于访存带宽。而同种计算量，访存数据量差异巨大。</strong></p><p>而EfficientNet就是使用了大量的低FLOPs、高数据读写量的操作，更具体来说，就是<strong>depthwise卷积操作</strong>。这些具有<strong>高数据读写量</strong>的操作，加上GPU的访存带宽限制，使得模型把大量的时间浪费在了从显存中读写数据上，GPU的算力没有得到“充分利用”。上面其实这个activations大小，就可以看作模型进行推理时，需要从显存中读取的feature blob的大小，近似可以认为是访存数据量的大小。那么我们不妨从activation这个角度看看EfficientNet，看看depthwise卷积与普通卷积的区别。二者在同等FLOPs下，activation有什么不同？这种不同为什么又会导致推理速度的不同？</p><blockquote><p>说depthwise的高数据读写量不是指从CPU往GPU拷贝数据的过程。GPU本身有储存单元和计算单元。这里的数据读写，是指GPU把显存里的数据，从储存单元读取，写入到计算单元（GPU Cores）计算的过程。一块P40，24G显存，可不是这24个G都是计算单元。</p></blockquote><p>为简化处理，以下内容只计算乘法，不计算加法。</p><p>假设一个大小为<strong>56*56*100</strong>的feature（$H<em>W</em>C$），经过一个kernel size为3x3的普通卷积layer，卷积layer的输出channel也是100，输出特征图大小也是$56 <em>56</em> 100 $。其FLOPs计算过程如下：</p><p>一个卷积kernel的大小为：$3<em>3</em>100$，与feature上一个同等大小的blob进行卷积，这是一个逐元素点乘操作，总共有$3<em>3</em>100$次乘法。然后卷积layer输出channel是100，说明有100个这样的卷积kernel，同时在feature的空间位置上，每个像素点都要重复一次卷积操作，共$56<em>56$次，所以总的FLOPs为：**3\</em>3*100*100*56*56<strong>。卷积核参数总量为：</strong>3*3*100*100**。</p><p>然后为了达到同样的FLOPs，我们假设另一个大小为<strong>56*56*10000</strong>的feature，经过一个kernel size为3x3的depthwise卷积layer，卷积layer的输出channel是10000，输出特征图大小也是$56 <em>56</em> 10000 $。其FLOPs计算过程如下：</p><p>一个卷积kernel的大小为：$3<em>3</em>1$，与feature上一个同等大小的blob进行卷积，总共有$3<em>3$次乘法。然后10000个channel通道，每个通道互相独立，对应着10000个不同的卷积kernel，所以重复这一卷积过程10000次。同时在feature的空间位置上逐元素重复，总的FLOPs为：**3\</em>3*10000*56*56<strong>。卷积核参数总量为：</strong>3*3*1*10000**。</p><p>可以看到，两个layer的FLOPs和参数量完全相同。但是推理速度方面，depthwise卷积要远远慢于普通卷积。其原因就是访存数据量的不同：</p><p>由于卷积计算本身已经是flatten的，不需要考虑重复读取问题，那么<strong>总共读取的数据量就是feature的大小加上卷积核weight的大小</strong>，对于普通卷积来说，总读取数据量为：$100<em>56</em>56 + 3<em>3</em>100<em>100 = 4.0e+05$。类似的，depthwise卷积读取的数据总量为：$56</em>56<em>10000 + 3</em>3*10000 = 1e+07$</p><p>可以看到，<strong>在同等FLOPs的情况下，depthwise卷积对应的feature size比普通卷积大的多，受制于GPU访存带宽，过高的数据读取与写入量就成为了限制推理速度的瓶颈。</strong></p><p>我们再回头看EfficientNet，不难看出其中的“取巧”成分。数据访存量与feature size（RegNet中的activation）有关，而feature size又与空间尺寸以及channel通道数（或者换句话说，网络的宽度width）有关。EfficientNet的一个核心就是增大空间尺寸或者网络宽度width以提升模型精度。</p><p>由于depthwise卷积的存在，增大feature的空间尺寸，或者channel通道数（width）都不会显著地增加FLOPs。因此EfficientNet可以声称自己是低FLOPs，但不得不说，这是一种“FLOPs假象”。因为feature size的增大会增加数据访存量，进而增加模型推理时间，这是单纯的FLOPs反映不出来的。</p><p>另外，轻量型的网络中大多都使用了depthwise卷积是出于怎样的考虑，是不是因为在计算受限制的硬件上，普通卷积的网络和depthwise卷积的网络都能达到硬件计算瓶颈的情况下，访存量就没这么重要，模型的FLOPS主要决定了推断时间的多少？</p><p>答：首先，直观上也倾向于计算瓶颈更占主导地位；</p><p>其次，现实应用中，“真正”用于移动终端的轻量级网络使用depthwise的逻辑是这样的，它们的<strong>网络一般和标准ResNet“差不多宽”，或者更小。在这种情况下，depthwise的FLOPs和数据访存量（因为depthwise至少参数量小）都会比普通卷积小，这种情况下自然是很快的。</strong></p><p>最后，FLOPs“诡计”特指那些在ImageNet上用V100刷榜的文章，为了保持FLOPs低，采用了depthwise这样的结构，然后为了刷榜，不得不把输入变大、把网络加宽，然后使用各种很耗时的attention，比如$x=x*sigmoid(x)$。用“FLOPs低”这样的装饰说辞，说自己Efficient。这背后的逻辑应该是，同等宽度下（注意不是FLOPs，可以近似理解为同等数据访存），对于复杂/困难任务，depthwise卷积的快，一定是带来了性能的损失，因为丧失了“更多的可能性”，depthwise毕竟是普通卷积的一个子集。精度损失在移动端可以接受，在ImageNet刷榜就不能接受了，才要另辟蹊径。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/122557226" target="_blank" rel="noopener">《Designing Network Design Spaces》的整体解读（一篇更比六篇强）</a><br><a href="https://www.zhihu.com/question/26419030/answer/237698756" target="_blank" rel="noopener">如何理解 95% 置信区间？ - frank的回答 - 知乎</a><br><a href="https://www.zhihu.com/question/24801731/answer/251576717" target="_blank" rel="noopener">如何通俗地解释「置信区间」和「置信水平」？ - 猴子的回答 - 知乎</a><br><a href="http://www.hahnyuan.com/algorithm/design-network-design-spaces.html" target="_blank" rel="noopener">论文笔记： Designing Network Design Spaces</a><br><a href="https://blog.csdn.net/qq_41185868/article/details/105278487" target="_blank" rel="noopener">Paper：2020年3月30日何恺明团队最新算法RegNet—来自Facebook AI研究院《Designing Network Design Spaces》的翻译与解读</a><br><a href="https://www.zhihu.com/question/384255803" target="_blank" rel="noopener">如何评价FAIR团队最新推出的RegNet？</a><br><a href="https://zhuanlan.zhihu.com/p/122943688" target="_blank" rel="noopener">FLOPs与模型推理速度</a></p></div><div><div style="text-align:center;color:#ccc;font-size:14px">------ 本文结束------</div></div><div class="reward-container"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/uploads/wechat.png" alt="zdaiot 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/uploads/aipay.jpg" alt="zdaiot 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> zdaiot</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing Network Design Spaces/" title="Designing Network Design Spaces">https://www.zdaiot.com/DeepLearningApplications/图像分类/Designing Network Design Spaces/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><p>欢迎关注我的其它发布渠道</p><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="/uploads/wechat-qcode.jpg"><span class="icon"><i class="fab fa-weixin"></i></span> <span class="label">WeChat</span></a></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/RegNet/" rel="tag"><i class="fa fa-tag"></i> RegNet</a><a href="/tags/图像分类/" rel="tag"><i class="fa fa-tag"></i> 图像分类</a></div><div class="post-nav"><div class="post-nav-item"><a href="/DeepLearningApplications/目标检测/EfficientDet：Scalable and Efficient Object Detection/" rel="prev" title="EfficientDet：Scalable and Efficient Object Detection"><i class="fa fa-chevron-left"></i> EfficientDet：Scalable and Efficient Object Detection</a></div><div class="post-nav-item"> <a href="/DeepLearningApplications/图像分类/ResNeSt：Split-Attention Networks/" rel="next" title="ResNeSt：Split-Attention Networks">ResNeSt：Split-Attention Networks<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="gitalk-container"></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#创新点"><span class="nav-number">1.</span> <span class="nav-text">创新点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#创新点来源"><span class="nav-number">2.</span> <span class="nav-text">创新点来源</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Design-Space-Design"><span class="nav-number">3.</span> <span class="nav-text">Design Space Design</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Tools-for-Design-Space-Design"><span class="nav-number">3.1.</span> <span class="nav-text">Tools for Design Space Design</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#The-AnyNet-Design-Space"><span class="nav-number">3.2.</span> <span class="nav-text">The AnyNet Design Space</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#The-RegNet-Design-Space"><span class="nav-number">3.3.</span> <span class="nav-text">The RegNet Design Space</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Design-Space-Generalization"><span class="nav-number">3.4.</span> <span class="nav-text">Design Space Generalization</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Analyzing-the-RegNetX-Design-Space"><span class="nav-number">4.</span> <span class="nav-text">Analyzing the RegNetX Design Space</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实验结果"><span class="nav-number">5.</span> <span class="nav-text">实验结果</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#State-of-the-Art-Comparison-Mobile-Regime"><span class="nav-number">5.1.</span> <span class="nav-text">State-of-the-Art Comparison: Mobile Regime</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Standard-Baselines-Comparison-ResNe-X-t"><span class="nav-number">5.2.</span> <span class="nav-text">Standard Baselines Comparison: ResNe(X)t</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#State-of-the-Art-Comparison-Full-Regime"><span class="nav-number">5.3.</span> <span class="nav-text">State-of-the-Art Comparison: Full Regime</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Additional-Ablations"><span class="nav-number">5.4.</span> <span class="nav-text">Additional Ablations</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">6.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#补充"><span class="nav-number">7.</span> <span class="nav-text">补充</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考"><span class="nav-number">8.</span> <span class="nav-text">参考</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="zdaiot" src="/uploads/avatar.png"><p class="site-author-name" itemprop="name">zdaiot</p><div class="site-description" itemprop="description">404NotFound</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">327</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">55</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">382</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zdaiot" title="GitHub → https://github.com/zdaiot" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:zdaiot@163.com" title="E-Mail → mailto:zdaiot@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/" title="知乎 → https://www.zhihu.com/people/" rel="noopener" target="_blank"><i class="fa fa-book fa-fw"></i> 知乎</a></span><span class="links-of-author-item"><a href="https://blog.csdn.net/zdaiot" title="CSDN → https://blog.csdn.net/zdaiot" rel="noopener" target="_blank"><i class="fa fa-copyright fa-fw"></i> CSDN</a></span></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="link fa-fw"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://kalacloud.com" title="https://kalacloud.com" rel="noopener" target="_blank">卡拉云低代码工具</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://beian.miit.gov.cn" rel="noopener" target="_blank">京ICP备2021031914号</a></div><div class="copyright"> &copy; <span itemprop="copyrightYear">2023</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">zdaiot</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-chart-area"></i></span> <span title="站点总字数">2.3m</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span title="站点阅读时长">35:09</span></div><div class="addthis_inline_share_toolbox"><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b5e7e498f94b7ad" async="async"></script></div> <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now=new Date;function createtime(){var n=new Date("08/01/2018 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="Run for "+dnum+" Days ",document.getElementById("times").innerHTML=hnum+" Hours "+mnum+" m "+snum+" s"}setInterval("createtime()",250)</script><div class="busuanzi-count"><script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script><script data-pjax>!function(){var o,n,e=document.getElementsByTagName("link");if(0<e.length)for(i=0;i<e.length;i++)"canonical"==e[i].rel.toLowerCase()&&e[i].href&&(o=e[i].href);n=o?o.split(":")[0]:window.location.protocol.split(":")[0],o||(o=window.location.href),function(){var e=o,i=document.referrer;if(!/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(e)){var t="https"===String(n).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";i?(t+="?r="+encodeURIComponent(document.referrer),e&&(t+="&l="+e)):e&&(t+="?l="+e),(new Image).src=t}}(window)}()</script><script src="/js/local-search.js"></script><div id="pjax"><script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '4800250e682fe873198b',
      clientSecret: '80f7f33f5f8ddfd3944f455cabadda4ff3299147',
      repo        : 'zdaiot.github.io',
      owner       : 'zdaiot',
      admin       : ['zdaiot'],
      id          : '26246ca8764a0dc555146e1ee17477d1',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/wanko.model.json"},display:{position:"left",width:150,height:300},mobile:{show:!0}})</script></body></html>