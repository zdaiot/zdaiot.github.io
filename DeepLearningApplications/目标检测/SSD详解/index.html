<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 3.9.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"www.zdaiot.com",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="本文主要参考了SSD原理与实现。 前言目标检测近年来已经取得了很重要的进展，主流的算法主要分为两个类型（参考RefineDet）： （1）two-stage方法，如R-CNN系算法，其主要思路是先通过启发式方法（selective search）或者CNN网络（RPN)产生一系列稀疏的候选框，然后对这些候选框进行分类与回归，two-stage方法的优势是准确度高； （2）one-stage方法，如"><meta name="keywords" content="目标检测,SSD"><meta property="og:type" content="article"><meta property="og:title" content="SSD详解"><meta property="og:url" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/index.html"><meta property="og:site_name" content="zdaiot"><meta property="og:description" content="本文主要参考了SSD原理与实现。 前言目标检测近年来已经取得了很重要的进展，主流的算法主要分为两个类型（参考RefineDet）： （1）two-stage方法，如R-CNN系算法，其主要思路是先通过启发式方法（selective search）或者CNN网络（RPN)产生一系列稀疏的候选框，然后对这些候选框进行分类与回归，two-stage方法的优势是准确度高； （2）one-stage方法，如"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/v2-f143b28b7a7a1f912caa9a99c1511849_720w.jpg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/v2-4c1d4d1b857a88b347549e54e15f322e_720w.jpg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/v2-bfaaa064fb1f0c1c7a11a4ce79962e84_720w.jpg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/v2-4e827b166ba5cbaa5ac8b428a32b885d_720w.jpg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/v2-f6563d6d5a6cf6caf037e6d5c60b7910_720w.jpg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/equation.svg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/equation-1585832227319.svg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/equation-1585832255627.svg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/equation-1585832259635.svg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/equation-1585832314100.svg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/equation-1585832317520.svg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/v2-a43295a3e146008b2131b160eec09cd4_720w.jpg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/v2-e3201dedee06e7793affbed4504add17_720w.jpg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/equation-1585832843676.svg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/equation-1585833183025.svg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/equation-1585833189538.svg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/equation-1585833225073.svg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/equation-1585833458893.svg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/v2-2d20292e51ef0ce4008ef8a1cf860030_720w.jpg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/v2-174bec5acd695bacbdaa051b730f998a_720w.jpg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/equation-1585876434317.svg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/v2-a56019049a04217560ac498b626ad916_720w.jpg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/equation-1585876699702.svg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/equation-1585876704028.svg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/v2-d28ded21949483b0fbb64b3612b0d543_720w.jpg"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/v2-616b035d839ec419ad604409d4abf6b0_720w.jpg"><meta property="og:updated_time" content="2020-04-02T10:33:08.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="SSD详解"><meta name="twitter:description" content="本文主要参考了SSD原理与实现。 前言目标检测近年来已经取得了很重要的进展，主流的算法主要分为两个类型（参考RefineDet）： （1）two-stage方法，如R-CNN系算法，其主要思路是先通过启发式方法（selective search）或者CNN网络（RPN)产生一系列稀疏的候选框，然后对这些候选框进行分类与回归，two-stage方法的优势是准确度高； （2）one-stage方法，如"><meta name="twitter:image" content="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/v2-f143b28b7a7a1f912caa9a99c1511849_720w.jpg"><link rel="canonical" href="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>SSD详解 | zdaiot</title><script data-pjax>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?0b0b58037319da4959d5a3c014160ccd";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">zdaiot</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">404NotFound</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/uploads/avatar.png"><meta itemprop="name" content="zdaiot"><meta itemprop="description" content="404NotFound"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="zdaiot"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> SSD详解<a href="https://github.com/zdaiot/zdaiot.github.io/tree/hexo/source/_posts/DeepLearningApplications/目标检测/SSD详解.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pencil-alt"></i></a></h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-04-02 18:33:08" itemprop="dateCreated datePublished" datetime="2020-04-02T18:33:08+08:00">2020-04-02</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/DeepLearningApplications/" itemprop="url" rel="index"><span itemprop="name">DeepLearningApplications</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/DeepLearningApplications/目标检测/" itemprop="url" rel="index"><span itemprop="name">目标检测</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>7.5k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>7 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>本文主要参考了<a href="https://zhuanlan.zhihu.com/p/33544892" target="_blank" rel="noopener">SSD原理与实现</a>。</p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>目标检测近年来已经取得了很重要的进展，主流的算法主要分为两个类型（参考<a href="https://arxiv.org/pdf/1711.06897.pdf" target="_blank" rel="noopener">RefineDet</a>）：</p><p>（1）<strong>two-stage方法</strong>，如R-CNN系算法，其主要思路是先通过启发式方法（selective search）或者CNN网络（RPN)产生一系列稀疏的候选框，然后对这些候选框进行分类与回归，two-stage方法的优势是准确度高；</p><p>（2）<strong>one-stage方法</strong>，如Yolo和SSD，其主要思路是均匀地在图片的不同位置进行密集抽样，抽样时可以采用不同尺度和长宽比，然后利用CNN提取特征后直接进行分类与回归，整个过程只需要一步，所以其优势是速度快，但是均匀的密集采样的一个重要缺点是训练比较困难，这主要是因为正样本与负样本（背景）极其不均衡（参见<a href="https://arxiv.org/abs/1708.02002" target="_blank" rel="noopener">Focal Loss</a>），导致模型准确度稍低。</p><p>不同算法的性能如下图所示，可以看到两类方法在准确度和速度上的差异。</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/v2-f143b28b7a7a1f912caa9a99c1511849_720w.jpg" alt="img" style="zoom:80%"></p><p>SSD算法，其英文全名是Single Shot MultiBox Detector，Single shot指明了SSD算法属于one-stage方法，MultiBox指明了SSD是多框预测。从上图也可以看到，SSD算法在准确度和速度（除了SSD512）上都比Yolo要好很多。下图给出了不同算法的基本框架图，对于Faster R-CNN，其先通过CNN得到候选框，然后再进行分类与回归，而Yolo与SSD可以一步到位完成检测。相比Yolo，SSD有如下几个不同点：</p><ol><li>采用CNN来直接进行检测，而不是像Yolo那样在全连接层之后做检测</li><li>SSD提取了不同尺度的特征图来做检测，大尺度特征图（较靠前的特征图）可以用来检测小物体，而小尺度特征图（较靠后的特征图）用来检测大物体</li><li>SSD采用了不同尺度和长宽比的先验框（Prior boxes, Default boxes，在Faster R-CNN中叫做锚，Anchors）。</li></ol><p><strong>Yolo算法缺点是难以检测小目标，而且定位不准</strong>，但是这几点重要改进使得SSD在一定程度上克服这些缺点。下面我们详细讲解SDD算法的原理。</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/v2-4c1d4d1b857a88b347549e54e15f322e_720w.jpg" alt="img"></p><h2 id="设计理念"><a href="#设计理念" class="headerlink" title="设计理念"></a>设计理念</h2><p>SSD和Yolo一样都是采用一个CNN网络来进行检测，但是却采用了多尺度的特征图，其基本架构如下所示：</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/v2-bfaaa064fb1f0c1c7a11a4ce79962e84_720w.jpg" alt="img"></p><p>SSD核心设计理念可以总结为如下几点：</p><h3 id="采用多尺度特征图用于检测"><a href="#采用多尺度特征图用于检测" class="headerlink" title="采用多尺度特征图用于检测"></a>采用多尺度特征图用于检测</h3><p>所谓多尺度采用大小不同的特征图，CNN网络一般前面的特征图比较大，后面会逐渐采用stride=2的卷积或者pool来降低特征图大小，这正如上图所示，一个比较大的特征图和一个比较小的特征图，它们都用来做检测。这样做的好处是小的特征图卷积核感受视野比较大，且每一个单元格对应在原图中的尺寸比较大，所以可以设定<strong>比较大的特征图来用来检测相对较小的目标，而小的特征图负责检测大目标</strong>，如下图所示，8x8的特征图可以划分更多的单元，但是其每个单元的先验框尺度比较小。</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/v2-4e827b166ba5cbaa5ac8b428a32b885d_720w.jpg" alt="img"></p><h3 id="采用卷积进行检测"><a href="#采用卷积进行检测" class="headerlink" title="采用卷积进行检测"></a>采用卷积进行检测</h3><p>与Yolo最后采用全连接层不同，SSD直接采用卷积对不同的特征图来进行提取检测结果。对于形状为$m \times n \times p$的特征图，只需要采用$3 \times 3 \times p$这样比较小的卷积核得到检测值。</p><h3 id="设置先验框"><a href="#设置先验框" class="headerlink" title="设置先验框"></a>设置先验框</h3><p>在Yolo中，每个单元预测多个边界框，但是其都是相对这个单元本身（正方块），但是真实目标的形状是多变的，Yolo需要在训练过程中自适应目标的形状。而SSD借鉴了Faster R-CNN中anchor的理念，每个单元设置尺度或者长宽比不同的先验框，预测的边界框（bounding boxes）是以这些先验框为基准的，在一定程度上减少训练难度。一般情况下，每个单元会设置多个先验框，其尺度和长宽比存在差异，如下图所示，可以看到每个单元使用了4个不同的先验框，图片中猫和狗分别采用最适合它们形状的先验框来进行训练，后面会详细讲解训练过程中的先验框匹配原则。</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/v2-f6563d6d5a6cf6caf037e6d5c60b7910_720w.jpg" alt="img"></p><p>SSD的检测值也与Yolo不太一样。对于每个单元的每个先验框，其都输出一套独立的检测值，对应一个边界框，主要分为两个部分。第一部分是各个类别的置信度或者评分，值得注意的是SSD将背景也当做了一个特殊的类别，如果检测目标共有$c$个类别，SSD其实需要预测$c+1$个置信度值，其中第一个置信度指的是不含目标或者属于背景的评分。为了表述方便，后面我们说$c$个类别置信度值时，请记住里面包含背景那个特殊的类别，即真实的检测类别只有$c-1$个。在预测过程中，置信度最高的那个类别就是边界框所属的类别，特别地，当第一个置信度值最高时，表示边界框中并不包含目标。第二部分就是边界框的location，包含4个值$(cx,cy,w,h)$，分别表示边界框的中心坐标以及宽高。但是真实预测值其实只是边界框相对于先验框的转换值(paper里面说是offset，但是觉得transformation更合适，参见<a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="noopener">R-CNN</a>)。先验框用$d=(d^{cx},d^{cy},d^{w},d^{h})$表示，其对应边界框用$d=(b^{cx},b^{cy},b^{w},b^{h})$表示，那么边界框的预测值$l$其实是$b$相对于$d$的转换值：</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/equation.svg" alt="[公式]"></p><p><img src="/DeepLearningApplications/目标检测/SSD详解/equation-1585832227319.svg" alt="[公式]"></p><p>习惯上，我们称上面这个过程为边界框的编码（encode），预测时，你需要反向这个过程，即进行解码（decode），从预测值$l$中得到边界框的真实位置$b$：</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/equation-1585832255627.svg" alt="[公式]"></p><p><img src="/DeepLearningApplications/目标检测/SSD详解/equation-1585832259635.svg" alt="[公式]"></p><p>然而，在SSD的<a href="https://github.com/weiliu89/caffe/tree/ssd" target="_blank" rel="noopener">Caffe源码</a>实现中还有trick，那就是设置variance超参数来调整检测值，通过bool参数variance_encoded_in_target来控制两种模式，当其为True时，表示variance被包含在预测值中，就是上面那种情况。但是如果是False（大部分采用这种方式，训练更容易？），就需要手动设置超参数variance，用来对$l$的4个值进行放缩，此时边界框需要这样解码：</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/equation-1585832314100.svg" alt="[公式]"></p><p><img src="/DeepLearningApplications/目标检测/SSD详解/equation-1585832317520.svg" alt="[公式]"></p><p>综上所示，对于一个大小为$m \times n$的特征图，共有$mn$个单元，每个单元设置的先验框数目记为$k$，那么每个单元共需要$(C+4)k$个预测值，所有的单元共需要$(C+4)kmn$个预测值，由于SSD采用卷积做检测，所以就需要$(C+4)k$个卷积核完成这个特征图的检测过程。</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>SSD采用VGG16作为基础模型，然后在VGG16的基础上新增了卷积层来获得更多的特征图以用于检测。SSD的网络结构如图5所示。上面是SSD模型，下面是Yolo模型，可以明显看到SSD利用了多尺度的特征图做检测。模型的输入图片大小是$300\times300$（还可以是$500 \times 500$，其与前者网络结构没有差别，只是最后新增一个卷积层，本文不再讨论）。</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/v2-a43295a3e146008b2131b160eec09cd4_720w.jpg" alt="img"></p><p>采用VGG16做基础模型，首先VGG16是在ILSVRC CLS-LOC数据集预训练。然后借鉴了<a href="https://link.zhihu.com/?target=https%3A//export.arxiv.org/pdf/1606.00915" target="_blank" rel="noopener">DeepLab-LargeFOV</a>，分别将VGG16的全连接层fc6和fc7转换成$3 \times 3$卷积层conv6和$1\times1$的卷积层conv7，同时将池化层pool5由原来的stride=2的$2 \times 2$变成了stride=1的$3 \times 3$（猜想是不想reduce特征图大小），为了配合这种变化，采用了一种Atrous Algorithm，其实就是conv6采用扩展卷积或带孔卷积（<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1511.07122" target="_blank" rel="noopener">Dilation Conv</a>），其在不增加参数与模型复杂度的条件下指数级扩大卷积的视野，其使用扩张率(dilation rate)参数，来表示扩张的大小，如下图所示，(a)是普通的$3 \times 3$卷积，其视野为$3 \times 3$，（b）是扩张率为$2$，此时视野变成了$7 \times 7$，（c）扩张率为4，视野扩大为$15 \times 15$，但是视野的特征更稀疏了。Conv6采用$3 \times 3$大小但dilation rate=6的扩展卷积。</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/v2-e3201dedee06e7793affbed4504add17_720w.jpg" alt="img"></p><p>然后移除dropout层和fc8层，并新增一系列卷积层，在检测数据集上做finetuing。</p><p>其中VGG16中的Conv4_3层将作为用于检测的第一个特征图。conv4_3层特征图大小是$38 \times 38$，但是该层比较靠前，其norm较大，所以在其后面增加了一个L2 Normalization层（参见<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1506.04579" target="_blank" rel="noopener">ParseNet</a>），以保证和后面的检测层差异不是很大，这个和Batch Normalization层不太一样，其仅仅是对每个像素点在channle维度做归一化，而Batch Normalization层是在[batch_size, width, height]三个维度上做归一化。归一化后一般设置一个可训练的放缩变量gamma，使用TF可以这样简单实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># l2norm (not bacth norm, spatial normalization)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">l2norm</span><span class="params">(x, scale, trainable=True, scope=<span class="string">"L2Normalization"</span>)</span>:</span></span><br><span class="line">    n_channels = x.get_shape().as_list()[<span class="number">-1</span>]</span><br><span class="line">    l2_norm = tf.nn.l2_normalize(x, [<span class="number">3</span>], epsilon=<span class="number">1e-12</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope):</span><br><span class="line">        gamma = tf.get_variable(<span class="string">"gamma"</span>, shape=[n_channels, ], dtype=tf.float32,</span><br><span class="line">                                initializer=tf.constant_initializer(scale),</span><br><span class="line">                                trainable=trainable)</span><br><span class="line">        <span class="keyword">return</span> l2_norm * gamma</span><br></pre></td></tr></table></figure><p>从后面新增的卷积层中提取Conv7，Conv8_2，Conv9_2，Conv10_2，Conv11_2作为检测所用的特征图，加上Conv4_3层，共提取了6个特征图，其大小分别是$(38,38),(19,19),(10,10),(5,5),(3,3),(1,1)$，但是不同特征图设置的先验框数目不同（同一个特征图上每个单元设置的先验框是相同的，这里的数目指的是一个单元的先验框数目）。先验框的设置，包括尺度（或者说大小）和长宽比两个方面。对于先验框的尺度，其遵守一个线性递增规则：随着特征图大小降低，先验框尺度线性增加：</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/equation-1585832843676.svg" alt="[公式]"></p><p>其中$m$为特征图的个数，这里为5，因为第一层（Conv4_3层）是单独设置的，$S_k$表示先验框大小相对于图片的比例，而$S_{min}$和$S_{max}$表示比例的最小值与最大值，paper里面取0.2和0.9。对于第一个特征图，其先验框的尺度比例一般设置为$S_{min}/2=0.1$，那么尺度为$300 \times 0.1=30$。对于后面的特征图，先验框尺度按照上面公式线性增加，但是先将尺度比例先扩大100倍，此时增长步长为 <img src="/DeepLearningApplications/目标检测/SSD详解/equation-1585833183025.svg" alt="[公式]"> ，这样各个特征图的$S_k$为20,37,54,71,88，将这些比例除以100，然后再乘以图片大小，可以得到各个特征图的尺度为60,111,162,213,26，这种计算方式是参考SSD的Caffe源码。综上，可以得到各个特征图的先验框尺度30,60,111,162,213,264。对于长宽比，一般选取<img src="/DeepLearningApplications/目标检测/SSD详解/equation-1585833189538.svg" alt="[公式]">，给出特定的长宽比，按如下公式计算先验框的宽度与高度（后面的$S_k$均指的是先验框实际尺度，而不是尺度比例）：</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/equation-1585833225073.svg" alt="[公式]"></p><p>默认情况下，每个特征图会有一个$a_r=1$且尺寸为$S_k$的先验框，除此之外，还会设置一个尺度为$S’_k=\sqrt{S_kS_{k+1}}$且$a_r=1$的先验框，<strong>这样每个特征图都设置了两个长宽比为1但大小不同的正方形先验框。</strong>注意最后一个特征图需要参考一个虚拟$S_{m+1}=300\times150 /100=315$来计算$S’_m$。因此，每个特征图一共有6个先验框$\{1,2,3,\frac{1}{2},\frac{1}{2},1’\}$，但是在实现时，Conv4_3，Conv10_2和Conv11_2层仅使用4个先验框，它们不使用长宽比为$3，\frac{1}{3}$的先验框。每个单元的先验框的中心点分布在各个单元的中心，即<img src="/DeepLearningApplications/目标检测/SSD详解/equation-1585833458893.svg" alt="[公式]">，其中$|f_k|$表示特征图大小。</p><p>得到了特征图之后，需要对特征图进行卷积得到检测结果，下图给出了一个$5 \times 5$大小的特征图的检测过程。其中，Priorbox是得到先验框，前面已经介绍了生成规则。检测值包含两个部分：类别置信度和边界框位置，各采用一次$3 \times 3$卷积来完成。另$n_k$为该特征图所采用的先验框数目，那么类别置信度需要的卷积核数量为$n_k \times c$，而边界框位置需要的卷积核数量为$n_k \times 4$。由于每个先验框都会预测一个边界框，所以SSD300一共可以预测$38 \times 38 \times 4 +19 \times 19 \times 6 +10 \times 10 \times 6 +5 \times 5 \times 6 +3 \times 3 \times 4 + 1 \times 1 \times 4 = 8732$个边界框，这是一个相当庞大的数字，<strong>所以说SSD本质上是密集采样。</strong></p><p><img src="/DeepLearningApplications/目标检测/SSD详解/v2-2d20292e51ef0ce4008ef8a1cf860030_720w.jpg" alt="img"></p><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><h3 id="先验框匹配"><a href="#先验框匹配" class="headerlink" title="先验框匹配"></a>先验框匹配</h3><p>在训练过程中，首先要确定训练图片中的ground truth（真实目标）与哪个先验框来进行匹配，与之匹配的先验框所对应的边界框将负责预测它。在Yolo中，ground truth的中心落在哪个单元格，该单元格中与其IOU最大的边界框负责预测它。但是在SSD中却完全不一样，SSD的先验框与ground truth的匹配原则主要有两点。</p><ol><li>首先，对于图片中每个ground truth，找到与其IOU最大的先验框，该先验框与其匹配，这样，可以保证每个ground truth一定与某个先验框匹配。通常称与ground truth匹配的先验框为正样本（其实应该是先验框对应的预测box，不过由于是一一对应的就这样称呼了），反之，若一个先验框没有与任何ground truth进行匹配，那么该先验框只能与背景匹配，就是负样本。一个图片中ground truth是非常少的， 而先验框却很多，如果仅按第一个原则匹配，很多先验框会是负样本，正负样本极其不平衡，所以需要第二个原则。</li><li>第二个原则是：对于剩余的未匹配先验框，若某个ground truth的IOU大于某个阈值（一般是0.5），那么该先验框也与这个ground truth进行匹配。这意味着某个ground truth可能与多个先验框匹配，这是可以的。但是反过来却不可以，因为一个先验框只能匹配一个ground truth，如果多个ground truth与某个先验框IOU大于阈值，那么先验框只与IOU最大的那个ground truth进行匹配。</li></ol><p>第二个原则一定在第一个原则之后进行，仔细考虑一下这种情况，如果某个ground truth所对应最大IOU小于阈值，并且所匹配的先验框却与另外一个ground truth的IOU大于阈值，那么该先验框应该匹配谁，答案应该是前者，首先要确保某个ground truth一定有一个先验框与之匹配。但是，这种情况我觉得基本上是不存在的。由于先验框很多，某个ground truth的最大IOU肯定大于阈值，所以可能只实施第二个原则既可以了，这里的<a href="https://link.zhihu.com/?target=https%3A//github.com/xiaohu2015/SSD-Tensorflow/blob/master/nets/ssd_common.py" target="_blank" rel="noopener">TensorFlow版本</a>就是只实施了第二个原则，但是这里的<a href="https://link.zhihu.com/?target=https%3A//github.com/amdegroot/ssd.pytorch/blob/master/layers/box_utils.py" target="_blank" rel="noopener">Pytorch</a>两个原则都实施了。下图为一个匹配示意图，其中绿色的GT是ground truth，红色为先验框，FP表示负样本，TP表示正样本。</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/v2-174bec5acd695bacbdaa051b730f998a_720w.jpg" alt="img"></p><p>尽管一个ground truth可以与多个先验框匹配，但是ground truth相对先验框还是太少了，所以负样本相对正样本会很多。为了保证正负样本尽量平衡，<strong>SSD采用了hard negative mining</strong>，就是对负样本进行抽样，抽样时按照置信度误差（预测背景的置信度越小，误差越大）进行降序排列，选取误差的较大的top-k作为训练的负样本，以保证正负样本比例接近1:3。</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>训练样本确定了，然后就是损失函数了。损失函数定义为位置误差（locatization loss， loc）与置信度误差（confidence loss, conf）的加权和：</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/equation-1585876434317.svg" alt="[公式]"></p><p>其中$N$是先验框的正样本数量。这里$x_{ij}^p \in {1,0}$为一个指示参数，当$x_{ij}^p = 1$时表示第$i$个先验框与第$j$个ground truth匹配，并且ground truth的类别为$p$。$c$为类别置信度预测值。$l$为先验框的所对应边界框的位置预测值，而$g$是ground truth的位置参数。对于位置误差，其采用Smooth L1 loss，定义如下：</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/v2-a56019049a04217560ac498b626ad916_720w.jpg" alt="img"></p><p>由于$x_{ij}^p$的存在，所以位置误差仅针对正样本进行计算。值得注意的是，要先对ground truth的$g$进行解码得到$\hat{g}$，因为预测值$l$也是编码值，若设置variance_encoded_in_target=True，编码时要加上variance：</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/equation-1585876699702.svg" alt="[公式]"></p><p><img src="/DeepLearningApplications/目标检测/SSD详解/equation-1585876704028.svg" alt="[公式]"></p><p>对于置信度误差，其采用softmax loss:</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/v2-d28ded21949483b0fbb64b3612b0d543_720w.jpg" alt="img"></p><p>权重系数$\alpha$通过交叉验证设置为1。</p><h3 id="数据扩增"><a href="#数据扩增" class="headerlink" title="数据扩增"></a>数据扩增</h3><p>采用数据扩增（Data Augmentation）可以提升SSD的性能，主要采用的技术有水平翻转（horizontal flip），随机裁剪加颜色扭曲（random crop &amp; color distortion），随机采集块域（Randomly sample a patch）（获取小目标训练样本），如下图所示：</p><p><img src="/DeepLearningApplications/目标检测/SSD详解/v2-616b035d839ec419ad604409d4abf6b0_720w.jpg" alt="img"></p><h2 id="预测过程"><a href="#预测过程" class="headerlink" title="预测过程"></a>预测过程</h2><p>预测过程比较简单，对于每个预测框，首先根据类别置信度确定其类别（置信度最大者）与置信度值，并过滤掉属于背景的预测框。然后根据置信度阈值（如0.5）过滤掉阈值较低的预测框。对于留下的预测框进行解码，根据先验框得到其真实的位置参数（解码后一般还需要做clip，防止预测框位置超出图片）。解码之后，一般需要根据置信度进行降序排列，然后仅保留top-k（如400）个预测框。最后就是进行NMS算法，过滤掉那些重叠度较大的预测框。最后剩余的预测框就是检测结果了。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/33544892" target="_blank" rel="noopener">SSD原理与实现</a></p></div><div><div style="text-align:center;color:#ccc;font-size:14px">------ 本文结束------</div></div><div class="reward-container"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/uploads/wechat.png" alt="zdaiot 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/uploads/aipay.jpg" alt="zdaiot 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> zdaiot</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/" title="SSD详解">https://www.zdaiot.com/DeepLearningApplications/目标检测/SSD详解/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><p>欢迎关注我的其它发布渠道</p><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="/uploads/wechat-qcode.jpg"><span class="icon"><i class="fab fa-weixin"></i></span> <span class="label">WeChat</span></a></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/目标检测/" rel="tag"><i class="fa fa-tag"></i> 目标检测</a><a href="/tags/SSD/" rel="tag"><i class="fa fa-tag"></i> SSD</a></div><div class="post-nav"><div class="post-nav-item"><a href="/DeepLearningApplications/目标检测/实时目标检测：YOLO、YOLOv2以及YOLOv3/" rel="prev" title="实时目标检测：YOLO、YOLOv2以及YOLOv3"><i class="fa fa-chevron-left"></i> 实时目标检测：YOLO、YOLOv2以及YOLOv3</a></div><div class="post-nav-item"> <a href="/Python/基础语法/Python进程池：multiprocessing.pool/" rel="next" title="Python进程池：multiprocessing.pool">Python进程池：multiprocessing.pool<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="gitalk-container"></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#前言"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#设计理念"><span class="nav-number">2.</span> <span class="nav-text">设计理念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#采用多尺度特征图用于检测"><span class="nav-number">2.1.</span> <span class="nav-text">采用多尺度特征图用于检测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#采用卷积进行检测"><span class="nav-number">2.2.</span> <span class="nav-text">采用卷积进行检测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#设置先验框"><span class="nav-number">2.3.</span> <span class="nav-text">设置先验框</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#网络结构"><span class="nav-number">3.</span> <span class="nav-text">网络结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#训练过程"><span class="nav-number">4.</span> <span class="nav-text">训练过程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#先验框匹配"><span class="nav-number">4.1.</span> <span class="nav-text">先验框匹配</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#损失函数"><span class="nav-number">4.2.</span> <span class="nav-text">损失函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据扩增"><span class="nav-number">4.3.</span> <span class="nav-text">数据扩增</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#预测过程"><span class="nav-number">5.</span> <span class="nav-text">预测过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考"><span class="nav-number">6.</span> <span class="nav-text">参考</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="zdaiot" src="/uploads/avatar.png"><p class="site-author-name" itemprop="name">zdaiot</p><div class="site-description" itemprop="description">404NotFound</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">313</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">53</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">369</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zdaiot" title="GitHub → https://github.com/zdaiot" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:zdaiot@163.com" title="E-Mail → mailto:zdaiot@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/" title="知乎 → https://www.zhihu.com/people/" rel="noopener" target="_blank"><i class="fa fa-book fa-fw"></i> 知乎</a></span><span class="links-of-author-item"><a href="https://blog.csdn.net/zdaiot" title="CSDN → https://blog.csdn.net/zdaiot" rel="noopener" target="_blank"><i class="fa fa-copyright fa-fw"></i> CSDN</a></span></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="link fa-fw"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://kalacloud.com" title="https://kalacloud.com" rel="noopener" target="_blank">卡拉云低代码工具</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://beian.miit.gov.cn" rel="noopener" target="_blank">京ICP备2021031914号</a></div><div class="copyright"> &copy; <span itemprop="copyrightYear">2022</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">zdaiot</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-chart-area"></i></span> <span title="站点总字数">2.1m</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span title="站点阅读时长">31:16</span></div><div class="addthis_inline_share_toolbox"><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b5e7e498f94b7ad" async="async"></script></div> <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now=new Date;function createtime(){var n=new Date("08/01/2018 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="Run for "+dnum+" Days ",document.getElementById("times").innerHTML=hnum+" Hours "+mnum+" m "+snum+" s"}setInterval("createtime()",250)</script><div class="busuanzi-count"><script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script><script data-pjax>!function(){var o,n,e=document.getElementsByTagName("link");if(0<e.length)for(i=0;i<e.length;i++)"canonical"==e[i].rel.toLowerCase()&&e[i].href&&(o=e[i].href);n=o?o.split(":")[0]:window.location.protocol.split(":")[0],o||(o=window.location.href),function(){var e=o,i=document.referrer;if(!/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(e)){var t="https"===String(n).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";i?(t+="?r="+encodeURIComponent(document.referrer),e&&(t+="&l="+e)):e&&(t+="?l="+e),(new Image).src=t}}(window)}()</script><script src="/js/local-search.js"></script><div id="pjax"><script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '4800250e682fe873198b',
      clientSecret: '80f7f33f5f8ddfd3944f455cabadda4ff3299147',
      repo        : 'zdaiot.github.io',
      owner       : 'zdaiot',
      admin       : ['zdaiot'],
      id          : '0b338479ed2654f21eedacc21e5439b9',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/wanko.model.json"},display:{position:"left",width:150,height:300},mobile:{show:!0}})</script></body></html>