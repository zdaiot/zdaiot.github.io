<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 3.9.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"www.zdaiot.com",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="这篇论文相当经典，基本上后来的每篇文章都会将和这篇论文的结果作对比。但是这篇论文对我来说，有点生涩难懂，这是看的第二遍了。特来记录一下。 基本信息 年份：2016 期刊：NIPS 标签：Meta Learning、Attention、Memory 数据：Omniglot、Mini-ImageNet  创新点 模型方面，结合了注意力模块和记忆模块（输入为set），使得网络可以快速学习。其中注意力模块"><meta name="keywords" content="Few-Shot Learning,Attention,Memory,Metric learning"><meta property="og:type" content="article"><meta property="og:title" content="Matching Networks for One Shot Learning"><meta property="og:url" content="https://www.zdaiot.com/DeepLearningApplications/Few-shot Learning/Matching Networks for One-Shot Learning/index.html"><meta property="og:site_name" content="zdaiot"><meta property="og:description" content="这篇论文相当经典，基本上后来的每篇文章都会将和这篇论文的结果作对比。但是这篇论文对我来说，有点生涩难懂，这是看的第二遍了。特来记录一下。 基本信息 年份：2016 期刊：NIPS 标签：Meta Learning、Attention、Memory 数据：Omniglot、Mini-ImageNet  创新点 模型方面，结合了注意力模块和记忆模块（输入为set），使得网络可以快速学习。其中注意力模块"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://www.zdaiot.com/DeepLearningApplications/Few-shot%20Learning/Matching%20Networks%20for%20One-Shot%20Learning/1568965896252.png"><meta property="og:updated_time" content="2019-09-21T02:03:00.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Matching Networks for One Shot Learning"><meta name="twitter:description" content="这篇论文相当经典，基本上后来的每篇文章都会将和这篇论文的结果作对比。但是这篇论文对我来说，有点生涩难懂，这是看的第二遍了。特来记录一下。 基本信息 年份：2016 期刊：NIPS 标签：Meta Learning、Attention、Memory 数据：Omniglot、Mini-ImageNet  创新点 模型方面，结合了注意力模块和记忆模块（输入为set），使得网络可以快速学习。其中注意力模块"><meta name="twitter:image" content="https://www.zdaiot.com/DeepLearningApplications/Few-shot%20Learning/Matching%20Networks%20for%20One-Shot%20Learning/1568965896252.png"><link rel="canonical" href="https://www.zdaiot.com/DeepLearningApplications/Few-shot Learning/Matching Networks for One-Shot Learning/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>Matching Networks for One Shot Learning | zdaiot</title><script data-pjax>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?0b0b58037319da4959d5a3c014160ccd";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">zdaiot</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">404NotFound</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.zdaiot.com/DeepLearningApplications/Few-shot Learning/Matching Networks for One-Shot Learning/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/uploads/avatar.png"><meta itemprop="name" content="zdaiot"><meta itemprop="description" content="404NotFound"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="zdaiot"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> Matching Networks for One Shot Learning<a href="https://github.com/zdaiot/zdaiot.github.io/tree/hexo/source/_posts/DeepLearningApplications/Few-shot Learning/Matching Networks for One-Shot Learning.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pencil-alt"></i></a></h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-09-18 22:53:29" itemprop="dateCreated datePublished" datetime="2019-09-18T22:53:29+08:00">2019-09-18</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2019-09-21 10:03:00" itemprop="dateModified" datetime="2019-09-21T10:03:00+08:00">2019-09-21</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/DeepLearningApplications/" itemprop="url" rel="index"><span itemprop="name">DeepLearningApplications</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/DeepLearningApplications/Few-shot-Learning/" itemprop="url" rel="index"><span itemprop="name">Few-shot Learning</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>7.1k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>6 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>这篇论文相当经典，基本上后来的每篇文章都会将和这篇论文的结果作对比。但是这篇论文对我来说，有点生涩难懂，这是看的第二遍了。特来记录一下。</p><h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><ul><li>年份：2016</li><li>期刊：NIPS</li><li>标签：Meta Learning、Attention、Memory</li><li>数据：Omniglot、Mini-ImageNet</li></ul><h2 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h2><ul><li>模型方面，结合了注意力模块和记忆模块（输入为set），使得网络可以快速学习。其中注意力模块和度量学习和相似，所以也可以看成是度量学习（metric learning目前小样本学习的主流方法）和记忆模块（external memories以前小样本学习的主流方法）的结合</li><li>训练过程基于一个简单的机器学习原则：训练和测试是要在同样条件下进行的，<em>“one-shot learning is much easier if you train the network to do one-shot learning”</em>。提出在训练的时候不断地让网络只看每一类的少量样本，这将和测试的过程是一致的</li><li>模型学习了一个网络，它将带标签支撑集和一个无标签的查询集映射到它的标签上，从而避免了为了适应新的类类型而进行微调的需要</li><li>完成了一个端到端的完全可微分的近邻方法</li><li>提出了Mini-ImageNet基准数据集</li></ul><h2 id="创新点来源"><a href="#创新点来源" class="headerlink" title="创新点来源"></a>创新点来源</h2><p>One-shot Learning，每一类中只有一个已知类标的样本。<strong>数据增强和正则化技术</strong>可以缓解在少量数据集上的过拟合，但是不能解决这个问题。对于<strong>参数化的模型</strong>，需要经过训练，训练样本需要由模型慢慢的学习到参数中，所以会导致学习慢，需要很多次的权重迭代。相反，对于<strong>无参数化的模型</strong>，可以快速适应新样本，同时没有遭受灾难性的遗忘，但是这种方法的性能太依赖于参数的度量方式。本文主要是将<strong>参数化的模型和无数化的模型进行结合</strong>，即快速获取新示例（非参数化的模型），同时从常见示例中提供出色的概括（参数化模型）。也就是<strong>训练一个完全端到端的近邻分类器。</strong></p><blockquote><p>关于参数化模型和非参数化模型的对比，我觉得可以这样理解：给定一个训练集，在参数化的方法中，需要一步步的迭代学习其中的特征，学习很慢；而在非参数化的模型中，例如KNN，训练集都存储下来了，来一个测试样本需要跟训练集中所有样本比较，可以快速适应新样本，同时没有灾难性的遗忘。</p></blockquote><h2 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h2><h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="/DeepLearningApplications/Few-shot Learning/Matching Networks for One-Shot Learning/1568965896252.png" alt="1568965896252"></p><p>神经元注意力机制通常完全可微分，定义为访问存储有用信息的记忆力矩阵来解决手头的任务。external memories有很多种。在机器翻译，声音识别以及问答中这些结构模型为$P(B\mid A)$，其中$A$和(或)$B$可以为序列，代表external memories。而对我们来说external memories是集合，如上图所示，<strong>网络的输入是多个图片组成的set</strong>。</p><p>本文的贡献在于将One-Shot Learning问题映射到集合到集合的框架，在训练过程中，在不改变模型的情况下，可以产生查询集的类别。更精确地说，我们希望映射包含$k$个pair的支撑集$S$到分类器$C_s(\hat x)$。将查询样本$\hat x$输入到分类器中，产生$\hat y$的分布。我们定义映射$S \rightarrow C_s(\hat x)$为$P(\hat y \mid \hat x, S)$，其中$P$由一个神经网络<strong>参数化</strong>。更一般的，当给定查询样本$\hat x$和支撑集$S$的时候，预测输出为$argmax_yP(y|\hat x, S)$。</p><p>最重要的是下面这个公式的理解，给定包含$k$个pair的支撑集$S$，其每一个pair用$(x_i, y_i)$表示，给定查询样本$\hat x$，其属于各个类别的概率可以用下式计算：</p><script type="math/tex;mode=display">
\begin{eqnarray} P(\hat y\mid\hat x, S)=\sum_{i=1}^{k} a(\hat x,x_i)y_i \end{eqnarray}</script><p>其中，$f$和$g$可以是合适的神经网络，分别对$\hat x$和$x_i$进行嵌入；$c$表示余弦距离；$a$为<strong>注意力机制</strong>。从公式可以看出$\hat y$为支撑集类标$y_i$的线性组合。这有几种理解方法：</p><ul><li>当$a(\hat x,x_i)$为标量，表示查询样本$\hat x$和支撑样本$x_i$之间的相似度；而$y_i$为向量，表示支撑样本$x_i$对应的<strong>one-hot类标</strong>。将$a(\hat x,x_i)$和$y_i$相乘得到一个向量，只有在$x_i$所属的类别有值，且值等于查询样本$\hat x$和支撑样本$x_i$之间的相似度。将$k$个这样的向量按元素相加，得到一个新向量，该向量中的元素表示$\hat x$属于各个类别的概率，且<strong>相当于经过了softmax函数</strong>。这类似于kernel density estimator（KDE）算法。</li><li>将$\hat x$和$x_i$之间距离最远的$b$个$a(\hat x,x_i)$置为0或者根据合适的常量将其中的$b$个置为0，这就相当于$k-b$近邻。</li><li>将$\hat x$和$x_i$之间距离最近的$a(\hat x,x_i)$置为1，$y_i$为和$x_i$一一对应的<strong>memory</strong>，就像一个哈希表。在这种情况下，我们可以理解为<strong>一种特定的associative memory</strong>，给定一个输入，找到支撑集中的相应示例，检索其标签。然而和一般的attentional memory machanisms不同，公式$({1})$具有<strong>本质的无参数性（non-parametric）</strong>：随着支撑集的增加，所使用的memory也增加。</li></ul><p><strong>non-parametric：</strong>这里解释一下什么叫做non-parametric。<strong>首先</strong>，任何一个模型（Model）的建立都有其基础或假设（Assumptions）。而参数模型（parametric models）和非参数（Nonparametric models）亦不例外：二者最主要的<strong>区别</strong>是关于数据分布的假设——参数模型对数据分布（distribution，density）有假设，而非参数模型对数据分布假设自由（distribution－free），所以模型结构不是先验指定的，而是根据数据确定的。Nonparametric models也被称为distribution free.所以，回顾二者的名字“参数”，即指<strong>数据分布的参数。</strong></p><h3 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h3><p>注意力机制最简单的形式为余弦距离经过softmax函数，这和<strong>一般的注意力机制以及核函数</strong>有着紧密的联系。</p><script type="math/tex;mode=display">
\begin{eqnarray} a(\hat x,x_i)=\frac {e^{c\left( f(\hat x), g(x_i) \right)}}{\sum_{j=1}^k e^{c\left( f(\hat x), g(x_j) \right)}} \end{eqnarray}</script><script type="math/tex;mode=display">
\begin{eqnarray}  c\left( f(\hat x), g(x_i) \right) = \frac{<f(\hat x), g(x_i)>}{||f(\hat x)|| \ ||g(x_i)||} \end{eqnarray}</script><p>关于这两个方式和公式$({1})$联合在一起怎么解释，请看上面的理解方式一。</p><p>注意这虽然和度量学习也相关，但是由公式$({1})$定义的分类器是不同的，我们使用了整个支撑集$S$而不是成对的比较，这更适用于One-Shot Learning（TODO）。 对于给定的支撑集$S$和查询集$\hat x$，这是足够的将$\hat x$指派给$(x’,y’) \in S$，所以$y’=y$，和其他的支撑集不重合（TODO）。</p><blockquote><p>注意在本文中所有的带$’$的符号表示在测试集中的数据，以区别与训练过程中的数据。</p></blockquote><h3 id="Full-Context-Embeddings"><a href="#Full-Context-Embeddings" class="headerlink" title="Full Context Embeddings"></a>Full Context Embeddings</h3><p><strong>$x_i$的嵌入函数应该同时由$x_i$和支撑集$S$决定</strong>。support set是每次随机选取的，嵌入函数同时考虑support set和$x_i$可以消除随机选择造成的差异性（因为要比较$\hat x$和$x_i$的相似性，让$x_i$的嵌入和整个$S$有关可以减少随机挑选带来的误差）。这样嵌入函数就从$g(x_i)$变成了$g(x_i,S)$。类似机器翻译中word和context的关系，$S$可以看做是$x_i$的context。</p><p>除此之外，现在对$\hat x$的嵌入和对$x_i$的嵌入没有任何关联。但是support set是每次随机选取的，这样可能导致对于$\hat x$的预测出现偏差。为了消除这种随机选择造成的差异性，可以让对$x_i$的嵌入与$\hat x$有关。<strong>也就是说支撑集样本应该可以用来修改查询集的embedding模型$f$。</strong>嵌入函数就从$f(\hat x)$改为了$f(\hat x, S)$。</p><p>这两个问题可以分别通过下面两个方法解决，文中称这两种方法为FCE (fully-conditional embedding)。</p><p><strong>1）基于 attention-LSTM 来对查询样本 embedding $f$</strong> ，使得每个 Query 样本的 embedding 是支撑集 embedding 的函数。公式如下：</p><script type="math/tex;mode=display">
\begin{eqnarray}  f(\hat x,S)=\operatorname{attLSTM}(f'(\hat x),g(x),K) \end{eqnarray}</script><p>其中，$f’(x)$是特征（CNN嵌入层的输出，如VGG、Inception），作为LSTM的输入（在每一个time step为常量）。$K$为LSTM层的timesteps，等于support set的图片个数。$g(S)$表示support set中每一个样本$x_i$经过嵌入函数$g$。</p><p>经过$k$个steps后，状态如下：</p><script type="math/tex;mode=display">
\begin{eqnarray}  \hat{h}_{k}, c_{k} =\operatorname{LSTM}\left(f^{\prime}(\hat{x}),\left[h_{k-1}, r_{k-1}\right], c_{k-1}\right) \end{eqnarray}</script><script type="math/tex;mode=display">
\begin{eqnarray} h_{k} =\hat{h}_{k}+f^{\prime}(\hat{x}) \end{eqnarray}</script><script type="math/tex;mode=display">
\begin{eqnarray} r_{k-1} =\sum_{i=1}^{|S|} a\left(h_{k-1}, g\left(x_{i}\right)\right) g\left(x_{i}\right)\end{eqnarray}</script><script type="math/tex;mode=display">
\begin{eqnarray} a\left(h_{k-1}, g\left(x_{i}\right)\right) =\operatorname{softmax}\left(h_{k-1}^{T} g\left(x_{i}\right)\right) \end{eqnarray}</script><p>对于$\operatorname{LSTM}(x,h,c)$，$x$为输入，$h$为输出（cell after the output gate），$c$为cell。$a$就是所谓的 “content” based attention。公式$({8})$中的softmax对$g(x_i)$进行标准化。从$g(S)$出来的read-out $r_{k-1}$和$h_{k-1}$相连。我们做$K$步的“reads”，$\operatorname{attLSTM}(f’(\hat x),g(x),K)=h_K$，其中$h_K$正如公式$({6})$所描述的那样。</p><blockquote><p>在公式$({7})$中可能作者有个笔误：$r$的下标应该是$k$而不是$k-1$。</p></blockquote><p><strong>2）基于双向 LSTM 学习支撑集的 embedding $g$</strong>，使得每个支撑样本的 embedding 是其它训练样本的函数；更为精确地，让$g’(x)$为神经网络 （和上面的$f’$相似，例如一个VGG或者Inception模型）。然后我们定义$g\left(x_{i}, S\right)=\stackrel \rightarrow{h}_i+ \stackrel \leftarrow {h}_i + g^{\prime} \left(x_{i} \right)$</p><script type="math/tex;mode=display">
\begin{eqnarray} \vec{h}_{i}, \vec{c}_{i} &=\operatorname{LSTM}\left(g^{\prime}\left(x_{i}\right), \vec{h}_{i-1}, \vec{c}_{i-1}\right) \\ \stackrel \leftarrow {h}_{i},\stackrel \leftarrow {c}_i &=\operatorname{LSTM}\left(g^{\prime}\left(x_{i}\right), \stackrel \leftarrow {h}_{i+1}, \stackrel \leftarrow {c}_{i+1}\right) \end{eqnarray}</script><p>其中，对于$\operatorname{LSTM}(x,h,c)$，$x$为输入，$h$为输出（cell after the output gate），$c$为cell。注意$\stackrel \leftarrow {h}$ 从$i=|S|$开始。和公式$({6})$一样，我们在输入和输出添加一个skip connection。</p><p>注意，原文没有提及如何将无序的支撑集样本排序，但参考作者的另一篇文章文章：<a href="https://arxiv.org/abs/1511.06391" target="_blank" rel="noopener">Order Matters: Sequence to Sequence for Sets</a>。发现，这里将原本无序的支撑集样本集进行了排序。</p><p>有人可能会疑惑为什么要用LSTM，像LSTM、RNN这种模型都要记住一些东西，可是这些样本的类别又不同，所以是想要记住什么？网上有一个<a href="https://zhuanlan.zhihu.com/p/32101204" target="_blank" rel="noopener">大佬</a>的理解是将各个类别的样本作为序列输入到LSTM中，是为了模型纵观所有的样本去自动选择合适的特征去度量，例如如果我们的目标是识别人脸，那么就需要构建一个距离函数去强化合适的特征（如发色，脸型等）；而如果我们的目标是识别姿势，那么就需要构建一个捕获姿势相似度的距离函数，这里需要参考一下<a href="https://blog.csdn.net/nehemiah_li/article/details/44230053" target="_blank" rel="noopener">度量学习(Metric Learning)</a>。</p><h3 id="训练策略"><a href="#训练策略" class="headerlink" title="训练策略"></a>训练策略</h3><p>训练策略要保证训练和测试是要在同样条件下进行的。我们定义任务$T$为在可能的标签集$L$上的分布，考虑$T$为从所有的类中均匀采样到几个不同的类别（例如5），每个类别有几个样本（例如最多5个）。在这种情况下，从任务$T$中采样一个类标集合$L$，将有5到25个样本。</p><p>为了组成“episode”去计算梯度并更新我们的模型，我们首先从$T$中采样得到$L$（例如$L$可以为类别集合{cats，dogs}）。我们使用$L$取采样得到支撑集$S$和一个查询集 $B$（$S$和$B$都是cats和dogs的有类标样本）。Matching Nets的训练目标为：</p><script type="math/tex;mode=display">
\begin{eqnarray} \theta = \underset {\theta }{argmax} E_{L\sim T} \left[E_{S\sim L, B\sim L} \left[\sum_{(x,y)\in B} log P_\theta (y|x, S) \right] \right ]\end{eqnarray}</script><p>从公式看出，这是元学习的一种形式，因为模型要学习如何从给定的支撑集中最小化在查询集上的loss。最重要的是，我们的模型不需要在新的类别上进行fine tuning，得益于它的无参数特性（因为模型并没有假设数据的分布，只取决于当前task的数据分布）。</p><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul><li>该模型有一个<strong>缺点</strong>，当测试任务分布$T’$和训练所用的任务分布$T$相差很大的话，这个模型就不会work。</li><li>支撑集$S$增大时，计算梯度的代价也增大。</li><li>实现Full Context Embeddings的方式过于复杂。</li></ul><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><ul><li>在<code>Full Context Embeddings</code>小节中，能不能把一个task内的嵌入向量$g(x_i)$标准化，以此来实现$x_i$的嵌入函数应该同时由$x_i$和$S$决定。</li></ul><h2 id="疑惑"><a href="#疑惑" class="headerlink" title="疑惑"></a>疑惑</h2><ul><li>为什么嵌入函数$g$和$f$要使用不同的形式。为什么不能使用同一个嵌入函数。</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/hustqb/article/details/83861134" target="_blank" rel="noopener">Matching Networks for One Shot Learning论文分析</a><br><a href="https://www.jianshu.com/p/18406ab37bc7" target="_blank" rel="noopener">论文阅读（35）Matching Networks for One Shot Learning</a><br><a href="https://zhuanlan.zhihu.com/p/61215293" target="_blank" rel="noopener">小样本学习（Few-shot Learning）综述</a><br><a href="https://zhuanlan.zhihu.com/p/32101204" target="_blank" rel="noopener">论文笔记：Matching Networks for One Shot Learning</a><br><a href="https://github.com/karpathy/paper-notes/blob/master/matching_networks.md" target="_blank" rel="noopener">Matching Networks for One Shot Learning</a><br><a href="https://blog.csdn.net/bryant_meng/article/details/80662322" target="_blank" rel="noopener">【One Shot】《Matching Networks for One Shot Learning》</a><br><a href="https://zhuanlan.zhihu.com/p/54393739" target="_blank" rel="noopener">Matching Networks for One-Shot Learning</a><br><a href="https://lotabout.me/2018/kernel-density-estimation/" target="_blank" rel="noopener">核密度估计（kernel density estimation）</a><br><a href="https://en.wikipedia.org/wiki/Category:Nonparametric_statistics" target="_blank" rel="noopener">Category:Nonparametric statistics</a><br><a href="https://www.zhihu.com/question/22855599" target="_blank" rel="noopener">能不能用简明的语言解释什么是非参数（nonparametric）模型？</a></p></div><div><div style="text-align:center;color:#ccc;font-size:14px">------ 本文结束------</div></div><div class="reward-container"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/uploads/wechat.png" alt="zdaiot 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/uploads/aipay.jpg" alt="zdaiot 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> zdaiot</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.zdaiot.com/DeepLearningApplications/Few-shot Learning/Matching Networks for One-Shot Learning/" title="Matching Networks for One Shot Learning">https://www.zdaiot.com/DeepLearningApplications/Few-shot Learning/Matching Networks for One-Shot Learning/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><p>欢迎关注我的其它发布渠道</p><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="/uploads/wechat-qcode.jpg"><span class="icon"><i class="fab fa-weixin"></i></span> <span class="label">WeChat</span></a></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Few-Shot-Learning/" rel="tag"><i class="fa fa-tag"></i> Few-Shot Learning</a><a href="/tags/Attention/" rel="tag"><i class="fa fa-tag"></i> Attention</a><a href="/tags/Memory/" rel="tag"><i class="fa fa-tag"></i> Memory</a><a href="/tags/Metric-learning/" rel="tag"><i class="fa fa-tag"></i> Metric learning</a></div><div class="post-nav"><div class="post-nav-item"><a href="/DeepLearningApplications/Few-shot Learning/Meta Learning基础/" rel="prev" title="Meta Learning基础"><i class="fa fa-chevron-left"></i> Meta Learning基础</a></div><div class="post-nav-item"> <a href="/DeepLearningApplications/Few-shot Learning/Siamese Neural Networks for One-shot Image Recognition/" rel="next" title="Siamese Neural Networks for One-shot Image Recognition">Siamese Neural Networks for One-shot Image Recognition<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="gitalk-container"></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#基本信息"><span class="nav-number">1.</span> <span class="nav-text">基本信息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#创新点"><span class="nav-number">2.</span> <span class="nav-text">创新点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#创新点来源"><span class="nav-number">3.</span> <span class="nav-text">创新点来源</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#主要内容"><span class="nav-number">4.</span> <span class="nav-text">主要内容</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#模型结构"><span class="nav-number">4.1.</span> <span class="nav-text">模型结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#注意力机制"><span class="nav-number">4.2.</span> <span class="nav-text">注意力机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Full-Context-Embeddings"><span class="nav-number">4.3.</span> <span class="nav-text">Full Context Embeddings</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练策略"><span class="nav-number">4.4.</span> <span class="nav-text">训练策略</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#缺点"><span class="nav-number">5.</span> <span class="nav-text">缺点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#思考"><span class="nav-number">6.</span> <span class="nav-text">思考</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#疑惑"><span class="nav-number">7.</span> <span class="nav-text">疑惑</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考"><span class="nav-number">8.</span> <span class="nav-text">参考</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="zdaiot" src="/uploads/avatar.png"><p class="site-author-name" itemprop="name">zdaiot</p><div class="site-description" itemprop="description">404NotFound</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">318</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">54</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">374</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zdaiot" title="GitHub → https://github.com/zdaiot" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:zdaiot@163.com" title="E-Mail → mailto:zdaiot@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/" title="知乎 → https://www.zhihu.com/people/" rel="noopener" target="_blank"><i class="fa fa-book fa-fw"></i> 知乎</a></span><span class="links-of-author-item"><a href="https://blog.csdn.net/zdaiot" title="CSDN → https://blog.csdn.net/zdaiot" rel="noopener" target="_blank"><i class="fa fa-copyright fa-fw"></i> CSDN</a></span></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="link fa-fw"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://kalacloud.com" title="https://kalacloud.com" rel="noopener" target="_blank">卡拉云低代码工具</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://beian.miit.gov.cn" rel="noopener" target="_blank">京ICP备2021031914号</a></div><div class="copyright"> &copy; <span itemprop="copyrightYear">2023</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">zdaiot</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-chart-area"></i></span> <span title="站点总字数">2.4m</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span title="站点阅读时长">36:17</span></div><div class="addthis_inline_share_toolbox"><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b5e7e498f94b7ad" async="async"></script></div> <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now=new Date;function createtime(){var n=new Date("08/01/2018 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="Run for "+dnum+" Days ",document.getElementById("times").innerHTML=hnum+" Hours "+mnum+" m "+snum+" s"}setInterval("createtime()",250)</script><div class="busuanzi-count"><script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script><script data-pjax>!function(){var o,n,e=document.getElementsByTagName("link");if(0<e.length)for(i=0;i<e.length;i++)"canonical"==e[i].rel.toLowerCase()&&e[i].href&&(o=e[i].href);n=o?o.split(":")[0]:window.location.protocol.split(":")[0],o||(o=window.location.href),function(){var e=o,i=document.referrer;if(!/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(e)){var t="https"===String(n).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";i?(t+="?r="+encodeURIComponent(document.referrer),e&&(t+="&l="+e)):e&&(t+="?l="+e),(new Image).src=t}}(window)}()</script><script src="/js/local-search.js"></script><div id="pjax"><script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '4800250e682fe873198b',
      clientSecret: '80f7f33f5f8ddfd3944f455cabadda4ff3299147',
      repo        : 'zdaiot.github.io',
      owner       : 'zdaiot',
      admin       : ['zdaiot'],
      id          : '65b15255fc74653314217f258678dbc1',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/wanko.model.json"},display:{position:"left",width:150,height:300},mobile:{show:!0}})</script></body></html>